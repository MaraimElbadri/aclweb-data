{"sections":[{"title":"","paragraphs":["Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1250–1255, Denver, Colorado, May 31 – June 5, 2015. c⃝2015 Association for Computational Linguistics"]},{"title":"LR Parsing for LCFRS Laura Kallmeyer and Wolfgang Maier Institute for Language and Information University of Düsseldorf Düsseldorf, Germany {kallmeyer,maierwo}@phil.hhu.de Abstract","paragraphs":["LR parsing is a popular parsing strategy for variants of Context-Free Grammar (CFG). It has also been used for mildly context-sensitive formalisms, such as Tree-Adjoining Grammar. In this paper, we present the first LR-style parsing algorithm for Linear Context-Free Rewriting Systems (LCFRS), a mildly context-sensitive extension of CFG which has received considerable attention in the last years."]},{"title":"1 Introduction","paragraphs":["LR parsing is an incremental shift-reduce parsing strategy in which the transitions between parser states are guided by an automaton which is compiled offline. LR parsers were first introduced for deterministic context-free languages (Knuth, 1965) and later generalized to context-free languages (Tomita, 1984) and tree-adjoining languages (Nederhof, 1998; Prolo, 2003).","Linear Context-Free Rewriting System (LCFRS) (Vijay-Shanker et al., 1987) is an immediate extension of CFG in which each non-terminal can cover more than one continuous span of the input string. LCFRS and equivalent formalisms have been used for the modeling of discontinuous constituents (Maier and Lichte, 2011) and non-projective dependencies (Kuhlmann, 2013), as well as for data-driven parsing of such structures (Maier and Kallmeyer, 2010; Kallmeyer and Maier, 2013; van Cranenburgh, 2012; Angelov and Ljunglöf, 2014). They have also been used for modeling","non-concatenative morphology (Botha and Blunsom, 2013), for grammar engineering (Ranta, 2011), and for modeling alignments in machine translation (Søgaard, 2008; Kaeshammer, 2013). To our knowl-edge, so far, no LR strategy for LCFRS has been presented in the literature. In this paper, we present an LR-style parser for LCFRS. It is based on the incremental parsing strategy implemented by Thread Automata (Villemonte de la Clergerie, 2002).","The remainder of the article is structured as follows. In the following section, we introduce LCFRS and thread automata. Section 3 presents the algorithm along an example. In particular, section 3.2 gives the algorithms for automaton and parse table constructions, and section 3.3 presents the parsing algorithm. Section 4 concludes the article."]},{"title":"2 Preliminaries 2.1 LCFRS","paragraphs":["In this paper, we restrict ourselves to string rewriting LCFRS and omit the more general definition (Weir, 1988).","In LCFRS, a single non-terminal can span k ≥ 1 continuous blocks of a string. A CFG is simply a special case of an LCFRS in which k = 1. k is called the fan-out of the non-terminal. We notate LCFRS with the syntax of Simple Range Concatenation Grammars (SRCG) (Boullier, 1998), a for-malism equivalent to LCFRS.","An LCFRS1 (Vijay-Shanker et al., 1987; Seki et al., 1991) is a tuple G = (N, T, V, P, S) where N","1Note that for purposes of exposition, we limit ourselves to ε-free LCFRS.","1250","is a finite set of non-terminals with a functiondim: N → N determining the fan-out of each A ∈ N ; T and V are disjoint finite sets of terminals and variables; S ∈ N is the start symbol with dim(S) = 1.","P is a finite set of rewriting rules withrank m ≥ 0. All γ ∈ P have the form","A(α0, . . . , αdim(A)−1) → A1(X(1) 0 , . . . , X(1)","dim(A1)−1)","· · · Am(X(m) 0 , . . . , X(m)","dim(Am)−1)","where A, A1, . . . , Am ∈ N , X","(l)","j ∈ V for 1 ≤","l ≤ m, 0 ≤ j < dim(Ai) and αi ∈ (V ∪ T )+ for","0 ≤ i < dim(A). All αi and X","(l)","j are called arguments (or sometimes components); the elements in αi are called argument elements. Aγ is the set of all argument elements of γ. Variable occurrences in the arguments of the non-terminals of γ are ordered by a strict total order ≺. For all X1, X2 ∈ V occurring in arguments of a non-terminal of γ, it holds that X1 ≺ X2 iff either X1 precedes X2 in an argument of the non-terminal or the argument X1 occurs in precedes the argument X2 occurs in.","For all γ ∈ P , every variable X occurring in γ occurs exactly once in the left-hand side (LHS) and exactly once in the right-hand side (RHS). Further-more, if for two variables X1, X2 ∈ V , it holds that X1 ≺ X2 on the RHS, then also X1 ≺ X2 on the LHS. The rank of G is the maximal rank of any of its rules, its fan-out is the maximal fan-out of any of its non-terminals.","We use the following additional notation: For a rule γ ∈ P , lhs(γ) gives the LHS non-terminal; lhs(γ, i) gives the ith argument of the LHS and lhs(γ, i, j) its jth symbol; rhs(γ, k) gives the kth RHS non-terminal; and rhs(γ, k, l) gives the lth component of the kth RHS element (starting with in-dex 0 in all four cases). These function have value ⊥ whenever there is no such element. Furthermore, in the sense of dotted productions, we define for each γ ∈ P a set of symbols denoting computation points of γ, Cγ = {γi.j | 0 ≤ i < dimA, 0 ≤ j ≤ |αi|}, as well as the set C =","⋃","γ∈P Cγ.","A non-terminal A ∈ N can be instantiated w.r.t. an input string w1 · · · w|w| and a rule γ ∈ P with lhs(γ) = A. An instantiation maps all argument elements of γ to spans of w ((i−1, j)w denotes the span wi · · · wj, 1 ≤ i ≤ j ≤ n). All instantiations are given by a function σ : Aγ → N × N where","α : S(xy) → A(x, y) γ : A(a, b) → ε β : A(ax, ya) → A(x, y)","Figure 1: LCFRS for {anaban | n ≥ 0}","for all x, y ∈ Aγ with x ̸= y, σ(x) = (i, j)w and σ(y) = (k, l)w it holds that i, k ≥ 0; j, l ≤ |w|; if x (y) is a terminal, then j = i + 1 (l = k + 1), otherwise j > i (k > l). Iff x ≺ y in γ, then j ≤ k. A derivation rewrites strings of instantiated non-terminals, i.e., given an instantiated clause, the instantiated LHS non-terminal may be replaced with the sequence of instantiated RHS terminals. The language of the grammar is the set of strings which can be reduced to the empty word, starting with S instantiated to the input string.","See figure 1 for a sample LCFRS.","2.2 Thread Automata","Thread automata (TA) (Villemonte de la Clergerie, 2002) are a generic automaton model which can be parametrized to recognize different mildly context-sensitive languages. The TA for LCFRS (LCFRS-TA) implements a prefix-valid top-down incremental parsing strategy similar to the ones of Kallmeyer and Maier (2009) and Burden and Ljunglöf (2005).","An LCFRS-TA for some LCFRS G = (N, T, V, P, S) works as follows. The processing of a single rule is handled by a single thread which will traverse the LHS arguments of the rule. A thread is given by a pair p : X, where p ∈ {1, . . . , m}∗ with m the rank of G is the address, and X ∈ N ∪ {ret} ∪ C where ret /∈ N is the content of the thread. An automaton state is given by a tuple ⟨i, p, T ⟩ where T is a set of threads, the thread store, p is the address of the active thread, and i ≥ 0 indicates that i tokens have been recognized. We introduce a new start symbol S′ /∈ N that expands to S and use ⟨0, ε, {ε : S′}⟩ as start state.","The specific TA for a given LCFRS G = (N, T, V, P, S) can be defined as tuple ⟨N ′, T, S′, ret , δ, Θ⟩ with N ′ = N ∪ C ∪ {S′, ret}; δ is a function from C to {1, . . . , m} ∪ {⊥} such that δ(γk,i) = j if there is a l such that lhs(γ, k, i) = rhs(γ, j − 1, l), and δ(γk,i) = ⊥ if lhs(γ, k, i) ∈ T ∪ {⊥} (intuitively, a δ value j tells us that the next symbol to process is a variable that","1251","Call: S′ → [S′]S α","0,0 → [α0,0]A β0,1 → [β0,1]A Predict: S → α0,0 A → β0,0 A → γ0,0","Scan: β0,0","a → β0,1 β1,1","a → β1,2 γ0,0","a → γ0,1 γ1,0","b → γ1,1","Publish: α0,2 → ret β1,2 → ret γ1,1 → ret Suspend: [α0,1]ret → α0,2 [β1,0]ret → β1,1","[α0,0]β0,2 → α0,1[β0,2] [α0,0]γ0,1 → α0,1[γ0,1] [β0,1]β0,2 → β0,2[β0,2] [β0,1]γ0,1 → β0,2[γ0,1] Resume: α0,1[β0,2] → [α0,1]β1,0 α0,1[γ0,1] → [α0,1]γ1,0 β1,0[β0,2] → [β1,0]β1,0 β1,0[γ0,1] → [β1,0]γ1,0","Figure 2: TA transitions for the LCFRS from figure 1","is an argument of the jth RHS non-terminal); and Θ is a finite set of transitions. Every transition has the form α","a","→ β with a ∈ T ∪ {ε} and they roughly indicate that in the thread store, α can be replaced with β while scanning a. Square brackets in α and β indicate parts that do not belong to the active thread. This will be made more precise below. Θ contains the following transitions (see figure 2): • Call transitions start a new thread, either for","the start symbol or for a daughter non-terminal.","They move down in the parse tree.","S′ → [S′]S (initial call), γ","k,i → [γk,i]A if A = rhs(γ, j − 1) and lhs(γ, k, i) = rhs(γ, j − 1, 0) where j = δ(γk,i).","• Predict transitions predict a new rule for a non-terminal A: A → γ0,0 if A = lhs(γ).","• Scan reads a LHS terminal while scanning the next input symbol:","γk,i","lhs(γ,k,i)","→ γk,i+1 if lhs(γ, k, i) ∈ T .","• Publish marks the completion of a production, i.e., its full recognition: γk,j → ret if dim(lhs(γ)) = k + 1 and j = |lhs(γ, k)|.","• Suspend suspends a daughter thread and resumes the parent. i.e., moves up in the parse tree. There are two cases:","(i) The daughter is completely recognized: [γk,i]ret → γk,i+1 if lhs(γ, k, i) = rhs(γ, δ(γk,i)−1, dim(rhs(δ(γk,i)−1))−1).","(ii) The daughter is not yet completely recognized, we have only finished one of its components: [γk,i]βl,j → γk,i+1[βl,j] if dim(lhs(β)) > l + 1, |lhs(β, l)| = j, lhs(γ, k, i) = rhs(γ, δ(γk,i) − 1, l) and rhs(γ, δ(γk,i) − 1) = lhs(β).","• Resume resumes an already present daughter thread, i.e., moves down into some daughter that","has already been partly recognized.","γk,i[βl,j] → [γk,i]βl+1,0 if lhs(γ, k, i) =","rhs(γ, δ(γk,i) − 1, l + 1), rhs(γ, δ(γk,i) − 1) =","lhs(β) and βl,j+1 /∈ C.","This is not exactly the TA for LCFRS proposed in Villemonte de la Clergerie (2002) but rather the one from Kallmeyer (2010), which is close to the Earley parser from Burden and Ljunglöf (2005).","The set of configurations for a given inputw ∈ T ∗ is then defined by the deduction rules in figure 3 (the use of set union S1 ∪ S2 in these rules assumes that S1 ∩ S2 = ∅). The accepting state of the automaton for some input w is ⟨|w|, 1, {ε : S′, 1 : ret}⟩.","2.3 LR Parsing","In an LR parser, the parser actions are guided by an automaton, resp. a parse table which is compiled offline. Consider the context-free case. An LR parser for CFG is a guided shift-reduce parser, in which we first build the LR automaton. Its states are sets of dotted productions closed under prediction, and its transitions correspond to having recognized a part of the input, e.g., to moving the dot over a RHS element after having scanned a terminal or recognized a non-terminal. Given an automaton with n states, we build the parse table with n rows. Each row i, 0 ≤ i < n, describes the possible parser actions associated with the state qi, i.e., for each state and each possible shift or reduce operation, it tells us in which state to go after the operation."]},{"title":"3 LR for LCFRS 3.1 Intuition","paragraphs":["The states in the automaton are predict and resume closures of TA thread stores. In order to keep them finite, we allow the addresses to be regular expressions. A configuration of the parser consists of a","1252","Initial configuration:","⟨0, ε, {ε : S′}⟩ Initial call:","⟨0, ε, {ε : S′}⟩ ⟨0, 1, {ε : S′, 1 : S}⟩","Further calls:","⟨i, p, S ∪ p : γk,i⟩ ⟨i, pj, S ∪ p : γk,i ∪ pj : A⟩","γk,i → [γk,i]A ∈ Θ, A ∈ N, δ(γk,i) = j + 1 Predict:","⟨i, p, S ∪ p : A⟩ ⟨i, p, S ∪ p : γ0,0⟩","A ∈ N, A → γ1,0 ∈ Θ","Scan:","⟨j, p, S ∪ p : γk,i⟩ ⟨j + 1, p, S ∪ p : γk,i+1⟩","γk,i","wj+1 → γk,i+1 ∈ Θ Publish:","⟨i, p, S ∪ {p : γk,i}⟩ ⟨i, p, S ∪ {p : ret}⟩","γk,j → ret ∈ Θ","Suspend 1:","⟨i, pj, S ∪ {p : γk,i, pj : ret}⟩ ⟨i, p, S ∪ {p : γk,i+1}⟩","[γk,i]ret → γk,i+1 ∈ Θ","Suspend 2:","⟨i, pj, S ∪ {p : γk,i, pj : βl,m}⟩ ⟨i, p, S ∪ {p : γk,i+1, pj : βl,m}⟩","[γk,i]βl,m → γk,i+1[βl,m] ∈ Θ","Resume:","⟨i, p, S ∪ {p : γk,i, pδ(γk,i) : βl,j}⟩ ⟨i, pδ(γk,i), S ∪ {p : γk,i, pδ(γk,i) : βl+1,0}⟩","γk,i[βl,j] → [γk,i]βl+1,0 ∈ Θ","Figure 3: Deduction rules for TA configurations","stack, a set of completed components and the remaining input. The completed components are of the form p : γi where p is an address and γi the component of a rule. The stack has the form Γ1x1Γ2 . . . xn−1Γn where Γi is an address followed by a state and xi ∈ T ∪ {Ak | A ∈ N, 1 ≤ k ≤ dim(A)}.","Shift: Whenever we have p : q on top of the stack and an edge from q to q′ labeled with the next input symbol and an address p′, we add the input symbol followed by pp′ : q′ to the stack.","Suspend: Whenever the top of the stack is p1 : q such that there is a γi−1,k ∈ q with k = |lhs(γ, i − 1)| and i < dim(γ), we can suspend. If i = 1, we add p1 : γi to the set of completed components and we remove |lhs(γ, i)| terminals/component non-terminals and their preceding states from the stack. If i ≥ 1, we check whether there is a p2 : γi−1 in the set of completed components such that the intersection L(p1) ∩ L(p2) is not empty.2 We then remove p2 : γi−1 from the set of complete components and we add p : γi to it where p is a regular expression denoting L(p1) ∩ L(p2). Suppose the topmost state on the stack is now p′ : q′. We then have to follow the edge leading from q′ to some q′′ labeled A","i : p′′ where A = lhs(γ). This means that we push Ai followed by p′p′′ : q′′ on the stack.","2Note that the corresponding finite state automata can be deterministic; in this case the intersection is quadratic in the size of the two automata. In LCFRS without left recursion in any of the components, the intersection is trivial since the regular expressions denote only a single path each.","Reduce: Whenever there is a γi−1,k in our current state with k = |lhs(γ, i − 1)| and i = dim(γ), we can reduce, which is like suspend except that noth-ing is added to the set of completed components.","3.2 Automaton and parse table construction","The states of the LR-automaton are sets of pairs p : X where p is a regular expression over {1, . . . , m}, m the rank of G, and X ∈ C ∪ {S′}. They represent predict and resume closures.The predict/resume closure q of some set q is described by the deduction rules in figure 4. This closure is not always finite.","ε : S′","1 : α0,0","lhs(α) = S","p : γi,j pk : γ′","l,0","lhs(γ, i, j) = rhs(γ, k − 1, l), rhs(γ, k) = lhs(γ′)","Figure 4: Predict/resume closure","However, if it is not, we obtain a set of items that can be represented by a finite set of pairs r : γi,j plus eventually ε : S′ such that r is a regular expression denoting a set of possible addresses. As an example for such a case, see q3 in figure 5.","The reason why we can represent these closures by finite sets using regular expressions for paths is the following: There is a finite number of possible elements γi,j. For each of these, the set of possible addresses it might be combined with in a state that is the closure of {ε : X1, ε : X2, . . . , ε : Xn} is generated by the CFG ⟨C∪{S′}∪ {Snew}, {1, . . . , m}, P, Snew⟩ with Snew → Xi ∈ P for all 1 ≤ i ≤ n, X → Y k ∈ P for all in-","1253","stances p:X","pk:Y of deduction rules and γi,j → ε. This is a regular grammar, its string language can thus be characterized by a regular expression.","The construction of the set of states starts with q0 = {ε : S′}. For every state q, every non-terminal A and every 1 ≤ i ≤ dim(A), we define read (q, Ai, p) = {ε : γj,k+1 | p : γj,k ∈ q and there is some l such that rhs(γ, l) = A and lhs(γ, j, k) = rhs(γ, l, i−1)} and read (q, Ai, p) = read (q, Ai, p). Similarly, for every such q and every a ∈ T , we de- fine read (q, a, p) = {ε : γj,k+1 | p : γj,k ∈ q and lhs(γ, j, k) = a} and read (q, a, p) = read (q, a, p). The set of states of our automaton is then the closure of {q0} under the application of the read-functions. The edges in our automaton correspond to read-transitions, where each edge is labeled with the corresponding pair Ai, p or a, p respectively. The automaton we obtain for the grammar in figure 1 is shown in figure 5. The number of possible states","ε : S′, 1 : α0,0 11 : β0,0, 11 : γ0,0","q0","ε : β0,1, ε : γ0,1 1 : β0,0, 1 : γ0,0","q1","ε : β0,2","q2","ε : α0,1 1+ : β1,0, 1+ : γ1,0","q3","ε : β1,1","q4","ε : β1,2","q5","ε : γ1,1q6 ε : α0,2","q7","ε : S′• q8","a, 11","a, 1","A1, ε","A1, 1","A2, 1+","b, 1+ A2, ε a, ε","S1, ε","Figure 5: The automaton","is necessarily finite since each state is the closure of some set containing only items with address ε. There are only finitely many such sets.","In the parse table, our operations are s(p, q) for shifting some terminal a followed by the old address concatenated with p and state q and r(α, i) for reducing the ith component of rule α. The two reduce operations can be distinguished by the component indices. Furthermore, the goto-part of the table tells where to go when traversing a component edge and which address to add then. The parse table can be read off the automaton as follows: action(q, a) = s(p, q′) iff read (q, a, p) = q′; action(q, −) = r(γ, i) iff there is some p : γi,k ∈ q such that k = |lhs(γ, i)|. Concerning the goto part of the table, we have goto(q, Ai) = ⟨p, q′⟩ iff read (q, Ai, p) = q′. Figure 6 shows the parse table","a b A1 A2 S1 0 s(11, 1) ⟨1, 3⟩ ⟨ε, 8⟩ 1 s(1, 1) r(γ, 1) ⟨ε, 2⟩ 2 r(β, 1) 3 s(1+, 6) ⟨1+, 4⟩,","⟨ε, 7⟩","4 s(ε, 5) 5 r(β, 2) 6 r(γ, 2) 7 r(α, 1) 8 acc","Figure 6: The parse table","stack completed input operation ε:q0 [ ] aaba initial state ε:q0 a 11:q1 [ ] aba shift a,11 ε:q0 a 11:q1 a 111:q1 [ ] ba shift a,1 ε:q0 a 11:q1 A1 11:q2 [111:γ1] ba suspend γ0,1 ε:q0 A1 1:q3 [111:γ1,11:β1] ba suspend β0,2 ε:q0 A1 1:q3 b 11+:q6 [111:γ1,11:β1] a shift b,1+ ε:q0 A1 1:q3 A2 11+:q4 [11:β1] a reduce γ1,1 ε:q0 A1 1:q3 A2 11+:q4 a 11+:q5 [11:β1] ε shift a,ε ε:q0 A1 1:q3 A2 1:q4 [ ] ε reduce β1,2 ε:q0 S1 ε:q8 [ ] ε reduce α0,2","Figure 7: Sample run with w = aaba","for our example.","3.3 Parsing","We run the automaton with ⟨ε : q0, [ ], w⟩ and input w = aaba. The trace is shown in figure 7. We start in q0, and shift two as, which leads to q1. We have then fully recognized the first components ofγ and β: We suspend them and keep them in the set of completed components, which takes us to q3. Shifting the b takes us to q6, from where we can reduce, which finally takes us toq4. From there, we can shift the remaining a (to q5), with which we have fully recognized β. We can now reduce both β and with that, α, which takes us to the accepting state q8."]},{"title":"4 Conclusion","paragraphs":["We presented the first LR style algorithm for LCFRS parsing. It offers a convenient factorization of predict/resume operations. We are currently exploring the possibility to use it in data-driven parsing."]},{"title":"Acknowledgments","paragraphs":["The work presented in this paper was partly funded by the German Research Foundation (DFG). We wish to thank three anonymous reviewers for their valuable comments.","1254"]},{"title":"References","paragraphs":["Krasimir Angelov and Peter Ljunglöf. 2014. Fast statistical parsing with parallel multiple context-free grammars. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 368–376, Gothenburg, Sweden.","Jan A. Botha and Phil Blunsom. 2013. Adaptor grammars for learning non-concatenative morphology. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 345– 356, Seattle, WA.","Pierre Boullier. 1998. Proposal for a Natural Language Processing syntactic backbone. Research Report 3342, INRIA-Rocquencourt, Rocquencourt, France.","Håkan Burden and Peter Ljunglöf. 2005. Parsing linear context-free rewriting systems. In Proceedings of the Ninth International Workshop on Parsing Technology, pages 11–17, Vancouver, BC.","Miriam Kaeshammer. 2013. Synchronous linear context-free rewriting systems for machine translation. In Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 68–77, Atlanta, GA.","Laura Kallmeyer and Wolfgang Maier. 2009. An incremental Earley parser for simple range concatenation grammar. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 61–64, Paris, France.","Laura Kallmeyer and Wolfgang Maier. 2013. Data-driven parsing using probabilistic linear context-free rewriting systems. Computational Linguistics, 39(1):87–119.","Laura Kallmeyer. 2010. Parsing beyond Context-Free Grammar. Springer, Heidelberg.","Donald E. Knuth. 1965. On the translation of languages from left to right. Information and Control, 8(6):607– 639, July.","Marco Kuhlmann. 2013. Mildly non-projective dependency grammar. Computational Linguistics, 39(2):355–387.","Wolfgang Maier and Laura Kallmeyer. 2010. Discontinuity and non-projectivity: Using mildly context-sensitive formalisms for data-driven parsing. In Proceedings of the Tenth International Workshop on Tree Adjoining Grammar and Related Formalisms (TAG+10), pages 119–126, New Haven, CT.","Wolfgang Maier and Timm Lichte. 2011. Characterizing discontinuity in constituent treebanks. In Formal Grammar. 14th International Conference, FG 2009. Bordeaux, France, July 25-26, 2009. Revised Selected Papers, volume 5591 of Lecture Notes in Artificial In-telligence, pages 167–182, Berlin, Heidelberg, New York. Springer-Verlag.","Mark-Jan Nederhof. 1998. An alternative LR algorithm for TAGs. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, volume 1, pages 946–952, Montreal, QC.","Carlos A. Prolo. 2003. LR Parsing for Tree Adjoining Grammars and its Application to Corpus-based Natural Language Parsing. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA.","Aarne Ranta. 2011. Grammatical Framework: Programming with Multilingual Grammars. CSLI Publications, Stanford.","Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science, 88(2):191–229.","Anders Søgaard. 2008. Range concatenation grammars for translation. In The 22nd International Conference on Computational Linguistics (COLING), pages 103– 106, Manchester, England.","Masaru Tomita. 1984. LR parsers for natural languages. In Proceedings of COLING 1984: The 10th International Conference on Computational Linguistics, pages 354–357, Stanford University.","Andreas van Cranenburgh. 2012. Efficient parsing with linear context-free rewriting systems. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 460–470, Avignon, France.","K. Vijay-Shanker, David Weir, and Aravind K. Joshi. 1987. Characterising structural descriptions used by various formalisms. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, pages 104–111, Stanford, CA.","Éric Villemonte de la Clergerie. 2002. Parsing mildly context-sensitive languages with thread automata. In Proceedings of COLING 2002: The 19th International Conference on Computational Linguistics, Taipei, Taiwan.","David Weir. 1988. Characterizing Mildly Context-Sensitive Grammar Formalisms. Ph.D. thesis, University of Pennsylviania, Philadelphia, PA.","1255"]}]}
