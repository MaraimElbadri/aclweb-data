{"sections":[{"title":"The Multimedia Articulation of Answers in a Natural Language Database Query System","paragraphs":["Susan E. Brennan Stanford University","and Hewlett Packard Labs 1501 Page Mill Road Palo Alto, CA 94304"]},{"title":"Abstract","paragraphs":["This paper describes a domain independent strategy for the multimedia articulation of answers elicited by a natural language interface to database query applications. Multimedia answers include videodisc images and heuristically-produced complete sentences in text or text-to-speech form. Deictic reference and feedback about the discourse are enabled. The interface thus presents the application as cooperative and conversational."]},{"title":"1 Introduction","paragraphs":["It is useful to evaluate human-computer communication in light of Grice's cooperative principle and maxims [Gri75]. Recently there has been much interest in a \"cooperative response\" paradigm for interfaces to database query and expert systems [Ste87]. The most promising strategies in this area of investigation involve applying insights gained from psycholinguistics research in order to create better conversational human/computer interfaces. However, inventing adequate user modeling and inferencing systems for this purpose is no easy task, and much of the literature on the subject describes proposals for systems yet unimplemented or theoretical approaches which may depend heavily on a particular domain model. Our multimedia articulator consists of principled solutions which have been implemented in a domain independent manner and which produce answers that are reasonably relevant, informative, and conversational in style. Such a system makes it possible to begin to study users interacting with a question-answering application."]},{"title":"2 System overview","paragraphs":["The system described here functions as a conversational human/computer interface to database query systems. It consists of a natural language front end and a module which articulates multimedia answers. The system accepts well-formed strings as input; these sentences are interpreted by an HPSG-based parser [PS87] which produces a parse tree. After further processing by a semantics module, a pragmatics processor [BFP87] and a disambiguator, a logical formula in the language NFLT [CP85] is produced. This formula is transduced into a database query. Two database query formats are currently supported: a frame-based representation language, HPRL, and the standard relational database query language, SQL. Answers returned from the database are then packaged appropriately by the articulator for presentation to the user. The two database applications currently supported are a database of people and equipment (a subset of which we have proposed as a natural language evaluation test suite [FNSW87]), and a database of paintings by 19th century Dutch artist Vincent Van Gogh and his contemporaries. The latter database was based on the index to a commercially available videodisc [Nim82] and augmented from other sources. Both applications can be run on workstations configured with or without multimedia output devices."]},{"title":"3 Database answer format","paragraphs":["The driver of a database query application (i.e. the domain dependent part of the system) is responsible for returning answers in a list format which consists of a keyword specifying the type of the answer, followed by the answer itself. The answer types expected by the articulator are"]},{"title":"boolean, number, item, set, quantity,","paragraphs":["and"]},{"title":"table.","paragraphs":["In deciding how to package a response, the articulator uses the answer type along with additional information provided by the parser which identifies the illocutionary act of a query as imperative, declarative, yes/no question, or wh-question. An answer is presented textually as a single phrase, as a complete sentence which parallels the user's query, or as a table. In addition, depending on answer type and the system's hardware configuration, an answer may include videodisc images, text-to-speech, icons and maps. While a user can request answers in a particular medium via menus, a default strategy is in place which yields a fairly satisfying style of human/computer interaction."]},{"title":"4 Text answers","paragraphs":["4.1 Style Questions and answers are a common kind of adjacency pair in human language use. The preferred style of an answer is often elliptical and shows parallelism with the surface syntactic structure of the preceding question [CC77]. In addition, lexical choice in the answer is constrained by that in the question. An answer which is articulated using different lexical entries than its projecting question may lead the user to infer that the system is making a distinction when it is in fact only using a synonym. Although elliptical answers may be the norm in human/human conversation, the articulator described here defaults to \"verbose mode\"; it responds to most queries with complete sentence answers. The motivation for this approach arose when we noticed that shorter answers were unsatisfying in certain situations. When additional textual material intervenes on the user's screen after the input query is typed in and before the answer appears, and in other cases where the user is distracted or not watching the screen when the textual answer arrives, a short answer takes on something of the character of a nonsequitur. This problem manifested itself in an early version of our system that worked by having users send queries over the network via electronic mail to a single natural language server which in due time mailed its responses back to the user, and also in the current system, which returns most answers in a few seconds but can be operated in a mode which prints modular timing and status information during processing. Even more unsatisfying was the articulation of answers using text-to-speech hardware. Generated speech is often hard for users to understand [TRC84] and in our system, short answers delivered this way often failed even to attract a user's attention as information-bearing. To echo the query audibly seemed confusing; what was needed was the capability to frame the answer in a complete sentence based on the query. The final impetus for the verbose articulator was our desire to approximate some of the effects that real natural language generation capability might provide in a question-answering human/computer interface, before committing resources to a full-scale natural language generation effort. In verbose mode, a sententi~d answer consists simply of a string derived from the formatted database answer with constituents of the user's original query wrapped around it. Articulation achieves the dual purposes of satisfying the user's request for information while preserving a conversational style of interaction (figure 1). It is interesting to compare these answers with the kind of paraphrasing capacity that one finds in some other systems which are commercially available (figure 2). To paraphrase a user's query in a form that reflects the actual database access method (figure 1) can be extremely helpful in identifying misinterpretations of the query. However, that approach may interfere with 2 User: Who has a terminal? System: DAN FLICKINGER HAS A TERMINAL. Figure 1: Adjacency pair User: Who has a terminal?","System: Shall I do the following? Create a report showing the full name and the manager and the equipment from the forms on which the equipment includes \"TERMINAL\"?\" Figure 2: Dialogue from Q&A [Hen85] natural interaction by insisting that the user confirm his or her every conversational move. Furthermore, whether the system's interpretation of what the user meant by the query with respect to the database is a correct mapping or not, the user is forced to reformulate his or her question in a program-like or logical form. Such an interface imposes a significant cognitive load on the user. Presumably, a central motivation for providing a natural language interface to a database is to avoid forcing the user to use a for-eign language. This strategy pays homage to Grice's maxim of"]},{"title":"manner,","paragraphs":["\"avoid obscurity of expression\". On the other hand, the argument has been made that separate, non-equivalent representations providing different views of the world should be maintained by the system [Spa83]; each of these views should be available to the user at appropriate times. Thus logical paraphrases, desirable in establishing initial system credibility, should be available upon specific request by the user. 4.2 \"Namely\" answers Grice's maxim of"]},{"title":"quantity","paragraphs":["for cooperative communication is a reminder that it is frequently desirable to provide more information in an answer than was literally requested. For example, when a user asks \"Are there any secretaries?\" the best answer may be not \"Yes\", but \"Yes - namely, X, Y, and Z\" (where X,","Sentence: How many employees are there?","Answer list: (NUMBER 4 (NAMELY {abrams} {chiang} {devito} {browne}))","Articulated: THERE ARE 4 EMPLOYEES - NAMELY, IRA ABRAMS, LYN CHIANG, KAT DEVITO, AND DEREK BROWNE. Figure 3: \"Namely\" answer Y, and Z are the names of the secretaries). Several question-answering systems have addressed issues of this sort [WMJB83] [WJMM82]. While our system does not explicitly model the user's goals or know anything about indirect speech acts, it provides extended answers to some queries via a list containing the keyword"]},{"title":"namely,","paragraphs":["which appears as the last item in the answer list passed to the articulator (figure 3). Extended answer lists are constructed as follows. When an answer is of type"]},{"title":"number","paragraphs":["and its cardinality is below a certain threshold, or else when it is both of type"]},{"title":"boolean","paragraphs":["and affirmative, the articulator makes an additional query to the database which returns information for constructing the \"namely\" answer. This additional information is combined with the short answer to the user's original query, to create an extended answer. In this way we attempt to comply with Grice's maxims of manner and quantity: to \"be brief' and to \"make your contribution as informative as is required\". 4.3 Verbose mode Verbose mode works as follows. Initially, a short answer string is created from the formatted list that the database returns. First, the type keyword is stripped off the answer list. Depending on the type, the remaining short answer list is transformed into a string which is a textual phrase consisting of one of the following: a name or names (for type"]},{"title":"set","paragraphs":["or"]},{"title":"item","paragraphs":["the database is queried and returns appropriate nouns or proper names), a string containing an integer (for type"]},{"title":"number),","paragraphs":["a string containing a number followed by units of measure (for type"]},{"title":"quantity),","paragraphs":["or the strings \"yes\" or \"no\" (for type"]},{"title":"boolean). Set","paragraphs":["answers are expanded into coordinated noun phrases with appropriate punctuation. If the type is"]},{"title":"table,","paragraphs":["a table is produced. In constructing the short answers to wh-questions, some simple additional heuristics are used. First, if the short answer string was derived from a null set or null item, the answer is converted from the empty string to an appropriate string: \"nowhere\" if the wh-question word is \"where\", \"never\" for \"when\", \"no-body's\" for \"whose\", and either \"none\" or else \"no\" plus the string corresponding to the modified NP head for \"which\", \"what\" or \"how many\" phrases. Otherwise, when the answer is"]},{"title":"not","paragraphs":["an empty set and the wh-question word is \"whose\", \" 's\" is appended to the answer. When \"whose\" modifies the head of a noun phrase, the noun phrase is appended to the answer. Then, once the short answer has been produced, if the query is not an imperative (and the answer is not a table), the input query's parse tree representation is transformed into a template with which to frame the short answer. Four functions traverse the parse tree and return strings corresponding to constituents from the input query: these constituents are"]},{"title":"subject, auxiliary verb","paragraphs":["(if there is one),"]},{"title":"main verb phrase,","paragraphs":["and"]},{"title":"preposition","paragraphs":["(if the wh-question word is within a prepositional phrase or fills a trace in one). An"]},{"title":"end-of-sentence","paragraphs":["string is created which contains, simply, terminating punctuation, or else an expanded phrase consisting of \"namely,\" followed by a coordinated noun phrase with appropriate punctuation. This expanded phrase is constructed whenever a short to medium-length"]},{"title":"namely","paragraphs":["list is available at the end of an answer list, as shown in figure 3. Finally, the verbose answer string is constructed using one of two strategies: if the wh-question word is in subject position in the query, the constituents are positioned in the answer as follows, (the items in parentheses may or may not be present):"]},{"title":"answer (aux-verb) (main-verb-phrase) (preposition) end-of-sentence;","paragraphs":["if the wh-question word is in non-subject position, the positioning is:"]},{"title":"subject (aux-verb) mainverb-phrase (preposition) answer end-of-sentence.","paragraphs":["If the query is a declarative or a yes/no question, a"]},{"title":"boolean","paragraphs":["answer results. When a boolean answer is affirmative, the string \"yes,\" with the modified input string appended, is articulated. For negative boolean answers, if the input string contains an auxiliary verb, Sentence: Answer list: Articulated: Does Ira program? (BOOLEAN NIL) NO, IRA DOES NOT PROGRAM. Figure 4: Negation Sentence: Answer list: Articulated: Sentence: Answer list: Articulated: Are there any consultants? (BOOLEAN T (NAMELY {WASOW}"]},{"title":"{SAG})) YES, THERE ARE SOME CONSULTANTS - NAMELY, TOM WASOW AND IVAN SAG.","paragraphs":["Will any consultants work for Kat? (BOOLEAN NIL) NO, NO CONSULTANTS WILL WORK FOR KAT. Figure 5: Some/any the following sequence is articulated:"]},{"title":"\"No,\" subject auz-verb \"not\" main-verb-phrase end-of-sentence","paragraphs":["(figure 4). If there is no auxiliary verb in the negative answer, the canned phrase \"No, it is not true that,\" with the original input string appended, is articulated. In addition, a some/any transformation is applied to yes/no questions. \"Any of\" is replaced by \"none of\" or \"some of\", depending on whether the answer is affirmative or negative. If the input query contains an auxiliary verb and the word \"any\" without \"of', \"any\" is replaced by \"no\" or \"some\" (figure 5). If the constructed answer template contains successive double negatives (as might result from a query containing a negation), these are removed. Finally, contrast the situation where the answer list is (BOOLEAN NIL) with the one where the answer list is simply NIL (which means the database failed to return an answer). In this case, the system answers"]},{"title":"\"I","paragraphs":["don't know whether\" with the modified input query appended (figure 6). The style of the articulator's verbose responses, while somewhat quaint, appears cooperative because the answer is delivered using the same lexical and syn-Sentence: Answer list: Articulated: Do any vicepresidents work? NIL I DON'T KNOW WHETHER ANY VICE PRESIDENTS DO WORK. Figure 6: Successful failure Sentence: Answer list: Articulated: Which manager is Kat Devito? (ITEM) KAT DEVITO IS NO MANAGER. Figure 7: Pragmatic strangeness Sentence: Answer list: Articulated: Sentence: Ans.er list: Articulated: WHAT SELF-PORTRAITS DID VAN GOGH PAINT? (SET \"F0296 .... F0627 .... F0522\") VAN GOGH DID PAINT SELF-PORTRAIT, SELF-PORTRAIT, AND SELF-PORTRAIT WITH GRAY FELT HAT. SHOW ME STARRY NIGHT."]},{"title":"(ITEM \"F0612\") STARRY NIGHT.","paragraphs":["Figure 8: When words aren't enough tactic forms that the user chooses in the query. Of course, this technique of wrapping the query around the answer works only in very simple question-answering applications, where the system has little of its own to say. Failure in the form of ungrammatical answers to wh-questions sometimes occurs due to lack of agreement; rather than extend the verbose articulator any further, it seems a better strategy to simply detect those cases and suppress an ungrammatical verbose answer in favor of a short one. Pragmatic failures that are still syntactically well-formed may also occur, particularly in negative boolean answers and empty set answers; we have not arrived at a consistently successful strategy for detecting and treat-ing presuppositional failures (figure 7). Our implementation Mso does not take into account syntactic constraints on given/new information in framing the answer in the query. Despite these limitations, the appeal of verbose articulation argues for integrating a real generation capability with a natural language interface to database query."]},{"title":"5 Multimedia","paragraphs":["While the articulator always manages to produce some sort of textual answer, it is often desirable to respond with an answer in a different medium (figure 8). Visual images from a videodisc can be displayed whencver item or set answers are associated with videodisc frames in the database, in addition to whenever an imperative is used to explicitly request images. The articulator consults a module called circus which contains the drivers and methods pertaining to the videodisc player and the text-to-speech hardware. This module queries the database application to discover whether any entities in the answer list can be displayed as videodisc images. These images are represented and accessed by videodisc frame numbers which are stored in the database in SQL tables or in HPRL slots. When the system is configured with the text-to-speech generator and the items in a set answer are associated with videodisc images, the entire textual answer is displayed first. Then a synchronizing func-tion in circus articulates the items in the set by displaying the approprate image on the video monitor and speaking the corresponding items, one at a time. Thus the user hears the name of an item spoken immediately after it comes up on the video monitor; videodisc images are displayed for a few seconds each. We have not synchronized the textual answers with the videodisc answers, since these media are displayed on two separate screens at somewhat different rates and it would be difficult for a user to attend simultaneously to both. Laser videodiscs in CAV format (constant angular velocity) advertise fast, random access to still images, yet with most videodisc players there is some time cost to searching for frames on a disc and for changing search direction. We minimize this cost by reordering the items in the set according to their videodisc frame numbers, which correspond to their ordering on the disc. It seems appropriate to mention here that videodisc imagery, like sex and violence, can be either gratuitous or meaningful. In the course of our project, we have demonstrated both. In the context of our people and equipment database, the articulator is capable of displaying a picture of a featureless cubicle or a slide show of nervously posed employees in conjunction with a textual answer. On the other hand, the database of Van Gogh paintings has proven to be a very appealing application for visual articulation. With visually articulated answers, we were provided with an opportunity to begin to experiment with deictic reference. While personal pronouns are interpreted by the pragmatics processor using a discourse model which takes a centering approach [Gro77] [Sid79] [JW81] [GJW83] [BFP87], demonstrative pronouns are interpreted via a rudimentary environment model that knows which painting is currently displayed on the video screen. Note that the displayed image may not be the one currently under discussion in the the discourse, but may be left over from an earlier query if no intervening queries elicited videodisc answers. Since imagery can be such a salient part of the user's environment, it is necessary to support deictic references to the current image. At present in our system, \"this\" and \"that\" have the same interpretation, but we are exploring alternatives such as interpreting \"that\" as referring to the"]},{"title":"previously","paragraphs":["displayed image when it appears contrastively in the same context as \"this\". A more thorough treatment should of course integrate spatial, temporal and discourse perspective [Lin79]. We are attempting to model more of the visual environment, including graphic elements on the screen, and to integrate deictic information more fully into the discourse. By now it should be evident that one should not consider articulation of answers entirely independently from discourse. A natural language interface to a database query application can provide textual feedback about the discourse apart from the literal answer. Our articulator makes explicit the interpretation of the user's pronominal reference by substituting the phrase it cospecifies for the pronoun in the verbose answer (figure 9). Thus the user is likely to discover any misunderstanding instantly. On the other hand, since verbose answers rely on more or less blindly-applied heuristics to wrap text around the answer, the articulator is not a full part-ner in the discourse and is not capable of achieving Q: What did Gauguin paint? A: GAUGUIN PAINTED VINCENT PAINTING. Q: How many pictures of Van Gogh were not","painted by him? A: 8 PICTURES OF VAN GOGH WERE NOT PAINTED","BY GAUGUIN. Figure 9: References made explicit subtle but nevertheless critical discourse functions through syntactic choices. A true generation component would presumably exercise lexical and syntax choices, thus avoiding eccentric as well as ungrammatical exchanges."]},{"title":"6 Conclusion","paragraphs":["Obviously there is much ground to be covered in the areas of natural language communication and conversational human/computer interfaces. Yet interim applications can be built which are incrementally improved over previous ones. This approach is necessary in order to observe real users of these systems. The domain independent articulation strategy presented here enables two very different database query systems to present answers conversationally. Generality is achieved through the use of answer type keywords (provided by the application driver) and the illocutionary act of the query (provided by the parser). From this information, multimedia answers are assembled and templates in which to frame the textual answer are constructed from the input query. Although it lacks inferencing ability, the articulator described here provides several features desirable in a cooperative interface. These features include answers presented in a style that parallels the user's question, extended answers, the ability to refer deictically to an image, and explicit feedback regarding co-specifiers of personal pronouns. Finally, multimedia articulation provides serendipitous opportunities for dispersing ambiguity, due to multiple representation of the answer. Take the following query to our Van Gogh database: \"Show me the pictures of Van Gogh that he didn't paint.\" The textual answer came back: \"The pictures of Van Gogh that Van Gogh didn't paint are Vincent Painting and Self-Portrait.\" As we puzzled over \"Self-Portrait\" (how could a self portrait be of Van Gogh, but not painted by him?) the videodisc answer was displayed on the adjacent screen: first, a portrait of Van Gogh that had been painted by his friend Gauguin, and - surprisingly - a self portrait of Van Gogh that was not"]},{"title":"painted,","paragraphs":["but"]},{"title":"drawn. 7 Acknowledgements","paragraphs":["The work reported herein was jointly supported by the National Science Foundation and Hewlett Packard Labs. It was done in collaboration with HPLab's Natural Language group. I would especially like to thank Lew Creary, Dan Flickinger, Lyn Friedman and Herb Clark."]},{"title":"References","paragraphs":["[BFP87] [CC77]"]},{"title":"[cP851","paragraphs":["[FNSW87]"]},{"title":"[cJwsz]","paragraphs":["S.E. Brennan, M.W. Friedman, and C.J. Pollard. A centering approach to pronouns. In"]},{"title":"Proc., 25st Annual Meeting of the ACL, Association of Computational Linguistics,","paragraphs":["pages 155-162, Stanford, CA, 1987. H.H. Clark and E.V. Clark."]},{"title":"Psychology and Language.","paragraphs":["Harcourt Brace Jovanovich, Publishers, 1977. L. Creary and C.J. Pollard. A computational semantics for natural language. In"]},{"title":"Proc., 23st Annual Meeting of the ACL, Association of Computational Linguistics,","paragraphs":["pages 172-179, Chicago, IL, 1985. D.P. Flickinger, J. Nerbonne, I. Sag, and T. Wasow. Toward evaluation of NLP systems (in conjunction with panel). In"]},{"title":"25st Annual Meeting of the ACL, Association of Computational Linguistics,","paragraphs":["Stanford, CA, 1987. B.J. Grosz, A.K. Joshi, and S. Weinstein. Providing a unified account of definite [Gri75] [Gro77]"]},{"title":"[cs85]","paragraphs":["[Hen85]"]},{"title":"[Jw81]","paragraphs":["[Kap82] [KJM86] [Lin79] [LS85] noun phrases in discourse. In"]},{"title":"Proc., 21st Annual Meeting of the ACL, Association of Computational Linguistics,","paragraphs":["pages 44-50, Cambridge, MA, 1983. H.P. Grice. Logic and conversation (from the William James lectures, Harvard University, 1967). In P. Cole and J. Morgan, editors,"]},{"title":"Syntax and Semantics 3: Speech Acts,","paragraphs":["pages 41-58, Academic Press, Inc., 1975. Barbara.J. Grosz."]},{"title":"The representation and use of focus in dialogue understand-ing.","paragraphs":["Technical Report 151, SRI International, 333 Ravenswood Ave, Menlo Park, Ca. 94025, 1977. B.J. Grosz and C.L. Sidner."]},{"title":"The structure of discourse structure.","paragraphs":["Technical Report CSLI-85-39, Center for the Study of Language and Information, Stanford, CA, 1985. G. Hendrix. Q&A. Software, Symantec, 1985. A.K. Joshi and S. Weinstein. Control of inference: role of some aspects of discourse structure - centering. In"]},{"title":"Proe., International Joint Conference on Artificial Intelligence,","paragraphs":["pages 385-387, Van-couver, B.C., 1981. S.J. Kaplan. Cooperative responses from a portable natural language query system."]},{"title":"Artificial Intelligence,","paragraphs":["2(19), 1982. J. Kalita, M. Jobes, and G. McCalla. Summarizing natural language database responses."]},{"title":"Computational Linguistics,","paragraphs":["12(2):107-124, 1986. C. Linde. Focus of attention and the choice of pronouns in discourse. In T. Givon, editor,"]},{"title":"Syntax and Semantics,","paragraphs":["pages 337-354, Academic Press, Inc., 1979. W.G. Lehnert and S.P. Schwartz. Data base querying by computer. In A.C. Graesser and J.B. Black, editors,"]},{"title":"The Psychology of Questions,","paragraphs":["pages 359-374, Lawrence Erlbaum Associates, Publishers, 1985."]},{"title":"[Nim82] [Po185] [PS87] [ReiSS] [Sid79] [Sid81] [Spa83] [Ste87] [TRC84] [WJMM82] [WMJB83] L. Nimoy. Vincent Van Gogh: a portrait in two parts. Videodisc, Philips International/North American Philips Corpora-tion, 1982. M. Pollack. Information sought and information provided. In","paragraphs":["CHI '85,"]},{"title":"pages 155-160, San Francisco, CA, 1985. C. Pollard and I.A. Sag.","paragraphs":["Information-Based Syntax and Semantics. Vol. i: Fundamentals."]},{"title":"(in press). Lecture notes series no. 13, Center for the Study of Language and Information, Stanford, CA, 1987. R. Reichman.","paragraphs":["Getting Computers to Talk Like You and Me."]},{"title":"MIT Press, Cambridge, MA, 1985. Candace L. Sidner.","paragraphs":["Toward a computational theory of definite anaphora comprehension in English."]},{"title":"Technical Report AI-TR-537, MIT, 1979. C.L. Sidner. Focusing for interpretation of pronouns.","paragraphs":["American Journal of Computational Linguistics,"]},{"title":"7(4):217-231, 1981. K. Sparck-Jones. Shifting meaning representations. In","paragraphs":["Proc., International Joint Conference on Artificial Intelligence,"]},{"title":"pages 621-623, 1983. P. Stenton.","paragraphs":["Designing a co-operative interface to an expert system."]},{"title":"Technical Report HPL-BRC-TM-87-023, HPLabs Technical Memo, 1987. J.C. Thomas, M.B. Rosson, and M. Chodorow. Human factors and synthetic speech. In","paragraphs":["Proc., INTERA CT '84,"]},{"title":"pages 37-42, 1984. B. Webber, A. Joshi, E. Mays, and K. McKeown. Extended natural language data base interactions.","paragraphs":["International Journal of Computers and Mathematics: Special issue on computational linguistics,"]},{"title":"1982. W. Walster, H. Marburger, A. Jameson, and S. Busemann. Over-answering yes-no questions: extended responses in a NL interface to a vision system. In","paragraphs":["Proc., International Joint Conference on Artificial Intelligence,"]},{"title":"pages 643-646, 1983.","paragraphs":[]}],"references":[{"authors":[],"source":"[BFP87] [CC77]"}],"cites":[{"style":0,"text":"CA, 1987","origin":{"pointer":"/sections/39/paragraphs/0","offset":25,"length":8},"authors":[{"last":"CA"}],"year":"1987","references":[]},{"style":0,"text":"Publishers, 1977","origin":{"pointer":"/sections/40/paragraphs/0","offset":27,"length":16},"authors":[{"last":"Publishers"}],"year":"1977","references":[]},{"style":0,"text":"IL, 1985","origin":{"pointer":"/sections/41/paragraphs/0","offset":24,"length":8},"authors":[{"last":"IL"}],"year":"1985","references":[]},{"style":0,"text":"CA, 1987","origin":{"pointer":"/sections/42/paragraphs/0","offset":10,"length":8},"authors":[{"last":"CA"}],"year":"1987","references":[]},{"style":0,"text":"MA, 1983","origin":{"pointer":"/sections/45/paragraphs/0","offset":24,"length":8},"authors":[{"last":"MA"}],"year":"1983","references":[]},{"style":0,"text":"University, 1967","origin":{"pointer":"/sections/45/paragraphs/0","offset":111,"length":16},"authors":[{"last":"University"}],"year":"1967","references":[]},{"style":0,"text":"Inc., 1975","origin":{"pointer":"/sections/46/paragraphs/0","offset":29,"length":10},"authors":[{"last":"Inc."}],"year":"1975","references":[]},{"style":0,"text":"CA, 1985","origin":{"pointer":"/sections/48/paragraphs/0","offset":89,"length":8},"authors":[{"last":"CA"}],"year":"1985","references":[]},{"style":0,"text":"Symantec, 1985","origin":{"pointer":"/sections/48/paragraphs/0","offset":126,"length":14},"authors":[{"last":"Symantec"}],"year":"1985","references":[]},{"style":0,"text":"B.C., 1981","origin":{"pointer":"/sections/49/paragraphs/0","offset":27,"length":10},"authors":[{"first":"B.","last":"C."}],"year":"1981","references":[]},{"style":0,"text":"Inc., 1979","origin":{"pointer":"/sections/52/paragraphs/0","offset":31,"length":10},"authors":[{"last":"Inc."}],"year":"1979","references":[]},{"style":0,"text":"Publishers, 1985","origin":{"pointer":"/sections/53/paragraphs/0","offset":44,"length":16},"authors":[{"last":"Publishers"}],"year":"1985","references":[]}]}
