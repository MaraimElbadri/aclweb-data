{"sections":[{"title":"MHATLex : Lexical Resources for Modelling the French Pronunciation Guy PÃ©rennou, Martine de CalmÃs̈","paragraphs":["Institut de Recherche en Informatique, UniversitÃ© Paul Sabatier 118,route de Narbonne, 31062 Toulouse Cedex France","(perennou, decalmes)@irit.fr","Abstract The aim of this paper is to introduce the lexical resources and environment, called MHATLex, and intended for speech and text processing. A particular attention is paid to a pronunciation modelling which can be used in automatic speech processing as well as in phonological/phonetic description of languages. In our paper we will introduce a pronunciation model, the MHAT model (Markovian Harmonic Adaptation and Transduction), which copes with free and context-dependent variants. At the same time, we will present the MHATLex resources. They include 500,000 inflected forms and tools allowing the generation of various lexicons through phonological tables. Finally, some illustrations of the use of MHATLex in ASR will be shown."]},{"title":"1 Introduction","paragraphs":["Lexical resources including a pronunciation component play an important role in automatic speech processing as well as in the phonetic description of languages.","In matters of automatic speech recognition a crucial problem is the extremely high variability of the pronunciation. One part of this variability can be taken into account through a careful training of the acoustic-phonetic units from a large amount of data. Another part of variability must be modelled in the lexicon as pronunciation variants.","During the last decade various experiments have proved that introducing pronunciation variants in automatic speech recognition improve the error rate, for example (Aubert & Dugast, 1995), (Gauvain & coll., 1993). Our experiments have focused on the context-dependant pronunciation variants and proved the error rate can be reduced by their introduction (PÃ©rennou & Pousse, 1998), (Pousse et PÃ©rennou, 1999).","This was our motivation for developing lexical resources for spoken and written French. BDLex is our first generation of lexical material (PÃ©rennou & de CalmÃs̈, 1987), (de CalmÃs̈ & PÃ©rennou, 1998). In BDLex each lexical entry includes orthographic form, various morpho-syntactic information and a phonological representation.","Pronunciation variants are generated thanks to a set of phonological rules, which take into account free- and context-dependant variations, and, in addition, special variation in borrowed foreign words.","It is a fact that the BDLex user may have to develop some tool for generating pronunciation-variants. In spite of the simplicity of the phonological component this may be a drawback.","This is one of the reasons why we have developed a second-generation lexical material, called MHATLex. Another reason has been the need for an appropriate lexicon for ASR in a language such as French where context-dependent pronunciations play a significant role. This aspect of pronunciation is also important for a text to speech synthesis of good quality.","In our paper we have a double purpose. For one thing, it aims to introduce the MHAT model of pronunciation including free and context-dependent variability (PÃ©rennou, 1995, 1996), (PÃ©rennou & Pousse, 1998). The role and the structure of the lexicon will be defined within this framework.","At the same time, within the above context, we will present the MHATLex materials which include 500 000 inflected forms at the phonological level. Particular attention will be paid to the concept of flexibility, that is the various lexicons which can be derived from the basic materials and their use in ASR and the adaptation of phonological and the phonetic components according to the precision needed by specific application."]},{"title":"2 The phonological MHAT model 2.1 General framework","paragraphs":["Four levels of representation play an important role for modelling the pronunciation: - the syntactic level (S), where the representations","consist of strings of references to inflected words and","syntactic boundariesÂ–Â–NB: for the sake of legibility,","at S level we refer to a word through its spelling, for","example the French word mardi (Angl.: Tuesday),","rather than its abstract address in the lexicon. - the phonological word level (W), where the","representations consist of strings of phonological","units and phonological boundaries, - the phonetic level (P), where the representations","consist of strings of phonetic units - the acoustic level (A), where the representation","consist of stings of acoustical vectors.","The abstract morpho-phonological level(s) can be ignored as long as only the post-lexical phonological transformations are involved. This is generally the case for pronunciation dictionaries used in automatic speech processing or in various phonetic domains.","In the MHAT model a sentence is also represented at these levels. Moreover each level N has its alphabets of N-units and its structural constraints, which must be satisfied by any well-formed representation.","So, at each level N, a sentence has two representations: the input representation (called also N-representation) Y=y1Â...ym and the output representation (called also N'-representation) Y'=y'1Â...y'n. Y' results from the adaptation of YÂ–Â–the harmonic adaptation component C(N,N')Â–. Consequently Y' is a well-formed representation of the level N, but this is not generally the case for Y(except if Y=Y').","The distinction between input- and output-representation structures each level N as a twofold representation domain including two (sub-)levels N and N'","The input representation Y results from an output M'- representation X'=x'1Â...x'm by a transduction. In the MHAT model, such a transduction is a one-step non-contextual transformation, that is a transformation based on rules of the form x'ĵykÂ...yk+l. These rules are stored in a dictionary Dic(M',N).","So, at the level S', the units are inflected words, represented in Dic(S',W) as a string of W-units, that is phonological units. For example the entry (mardi ; maRdi) means that mardi (Tuesday) is represented by /maRdi/Â–Â– one word reference represented by a string of 5 phonological units (the slash being the classical meta-symbol used as phonological delimiter at level W)Â–Â–. Fig.1 - Structure of MHAT model."]},{"title":"2.2 The syntactic level","paragraphs":["An S-representation consists of a word string and a","syntactic structure (which is not considered here). C(S,S')","inserts phonological boundaries according to the syntactic","context; for example (1a) is represented by (1b) at the S'","level:","je voudrais me rendre Ã Paris (1a)","(I would like to go to Paris)","Â§ je # voudrais #(#) aller) ## Ã # Paris Â§ (1b)","Principles for the boundary adaptation are given in SPE (Chomsky & Halle, 1968) and, for French, in (Selkirk, 1974), (Dell, 1985). We introduce a version more adapted for our purpose Â–Â–for a more complete discussion see (PÃ©rennou, 1995, 1996, 1998).","2.2.1 Boundary insertion The major post-lexical phonological rules of French","can be formalised using the following boundaries:","1. # between two words having a strong cohesion, as between a proclitic and a verb, a determiner and a noun, etc;","2. #(#) between two words, if a liaison is optional whenever it is phonetically possible, for example between a finite verb and its complement;","3. ## between two words where the syntactic structure prohibits a liaison, for example between two proposition phrases;","4. Â§ at the beginning and at the end of a phonological group (phrase). 2.2.2 Allomorphic adaptations depending on the","phonological context","Certain words have spelling and phonological (allomorphic) variantsÂ–Â–refered here as SPV-wordsÂ–Â–, depending on their phonological context in the sentence.","This is the case for several French determiners, including adjectives like beau/bel (beautifull). These words have two allomorphs, one before a non-consonant (that is the right context is: __#[-cons]), the second one in other contexts. For example the demonstrative adjective ce/cet has two contextual entries:","(cet ; sEt) / __#[-cons]","(ce ;s@) / ELSE where the slash stands in this case for \"in the context\". NB - In this paper, all the phonetic transcriptions use the SAMPA code completed by special conventions of MHATLex. Ex.","cet horaire (this timetable) VS. ce train (this train)","Words as ce/cet, which have two possible forms in texts, have two context-dependent entries in Dic(S',W).","One or more entry per word ? The question becomes more perplexing for words as le and les (the singular resp. plural) also sensitive to right contexts __# [-cons]. The former le/l' can be assimilated to a SPV-word and has two lexical entries","(l' ; l) / __#[-cons]","(le ; l@) / ELSE Ex.: l'horaire /l # ORER@/ (the timetable) VS. le train /l@ # tRe~/ (the train)","The second has only one spelling form, but two phonological variants (lE/lEz) (such words are refered here as PV-words):","(les ; lEz) / __#[-cons]","(les ; lE) / ELSE Ex.: les horaires /lEz # ORER@/ VS. les trains /lE # tRe~/","From a phonological point of view, these words have two phonological variants and are sensitive to the same context. However the word les has a single entry in Dic(S',W). This is motivated by the fact that only one form appears in texts.","Of course, it would be possible to consider a dictionary where such words have two entries, for example les1 /lEz/ and les2 /lE/ .","This question will come up in connection with the definition of the phonotypical dictionary Dic(S',W') introduced below.","Note that the English articles a/an and the present similar alternations, and can be compared respectively to le/l' and les Â–Â–see also, for example, the Italian articles un/uno, il/lo/l' where the contexts involved are slightly different."]},{"title":"2.3 The phonological word level","paragraphs":["The W-representations consist of phonological word representations separated by boundaries. This is illustrated in (2): Voici les horaires (here are the timetables) /Â§ vwasi #(#) lE<+z\"#> # ORER@ Â§/ (2)","(MHATLex conventions used here are explained in Â§2.4). The contextual adaptation component C(W,W') applies"]},{"title":"W","paragraphs":["W' W S' P yiÂ... Dic(W',P) x'iÂ... Dic(S',W) y'jÂ... ukÂ... C(W,W') the juncture (Sandhi) phonological rules. Given the phonological context, it transforms each W-representation into a W'-representation, also called phonotypical representation.","We recall below some rules that play an important role in ASR for French (a more introduction can be found in (PÃ©rennou, 1995, 1996, 1998). ASR literature mentions often the liaison as THE important phonological alternation of French. As a matter of fact it is ONE among others. 2.3.1 Liaison of latent consonants","A latent consonant (notation C\") is an ending consonant, which may be pronounced in a liaison context, more precisely:","C / __ # [-cons] C\" → (C) / __ #(#) [-cons] (Liaison)","() /else where (C) stands for an optional consonant and () for the empty string.","So a latent consonant C\" is (almost) always pronounced before the boundary # followed by a non-consonant (that is a vowel or a glide). Ex.:","deux heures (two o'clock)","/d2z\"#9R@z\"/→ [d2z 9R] (3) A latent consonant C\" may be pronounced before the","boundary #(#) followed by a vowel or a glide. Ex.: voudrais avoir (would have): /vudREz\"#(#)avwaR/ → [vudREz avwaR] (4)","[vudRE avwaR] Otherwise the latent consonant is deleted. Remark. The phonological unit h of French is not pronounced (It is why we prefer the notation /*/) but it prohibits the liaison. Consequently it has the feature [+cons]. In spelling h and /*/ are not in a one to one relationship (compare (3) and (5) for example). Ex.:","deux hÃ©ros (two heros):","/d2z\"#*eRoz\"/ → [d2 eRo] (5) 2.3.2 Schwa elision (deletion) at the word ending","At the phonological level the representations may contain the schwa symbol @. This abstract unit can generally be elided; if not, it is pronounced [6] the central and neutral vowel of French (close to the IPA schwa). A simplified version of the @-elision rule at word ending position is as follow:","() / __ $ [-cons] @ → (6) / Â–Â– {## ; Â§ ; $ [+cons] } (@fin-Elis)","6 / ! [-cons] __ # *","where $ stands for # or #(#) and \"!\" for any boundary.","The first rule means that the ending schwa is almost","never pronounced before $ followed by a vowel or a glide.","Ex.:","prendre Ã Pierre(to take from Peter):","/pRÃ£dR@ #(#)a#pjER@/ → [pRÃ£dR a pjER] (6)","The second one is a synthetic and simplified rule for the optional elision of an ending schwa Â–Â–a careful formulation must, for example, introduce a specific rule for monosyllabic words like the article le. Ex.:","horaire du bus (bus timetable) /ORER@#(#)dy#bys/ → [ORER6 dy bys] (7) [ORER dy bys] The schwa elision probability depends on various","factors. The third rule applies for the monosyllabic words","/C@/ before the /*/ unit.Ex.: le huit (the eight) /l@ # *Hit/ → [l6 Hit] (8)","2.3.3 Liquid elision A liquid (/l/ or /R/) in ending position is always elided L → () / C __ $ (LiqElis) This situation occurs generally after a @-elision. Ex.: votre billet (your ticket) /vOtR@ # tikE/ ̂[vOtR6 tikE] (9a)","[vOt tikE] (9b)","Two optional pronunciations are possible: (9a) if schwa is pronounced, (9b) if schwa is elided; in this case /R/ is also elided.","2.3.4 Nasal assimilation of stop consonants","These rules apply optionally and participate to the","contextual adaptation. The regressive (resp. progressive)","nasal assimilation (PNA) (rep. RNA) applies optionally","after the elision of an ending schwa and possibly of a","liquid.","PNA needs a nasal vowel in the left context. Ex.:","prendre son temps (take his time)","/pRÃ£dR@ #(#)sÃμn\"#tÃ£/ ̂[pRÃ£dR6 sÃμ tÃ£] (10)","[pRÃ£n sÃμ tÃ£] RNA needs a nasal consonant in the right context. Ex.: regarde-moi (look at me) /R@gaRd@#mwa/ ̂[R(6)gaRd6 mwa] (11)","[R(6)gaRn mwa]","A more complete presentation can be found in (PÃ©rennou, 1997). Other ending juncture rules. Voice assimilation of glides and consonants, reduction of geminated units Â... may be considered for an exhaustive specification of C(W,W').","2.3.5 Schwa elision in a word initial-syllable In words like record /R@kOR/ (record), after a closed","syllable (refered as +CS) the schwa is always pronounced","as in (12a). In other cases it may be elided as in (12b).Ex.: Quel record ? / Un record. /kEl R@kOR/ ̂[kEl R6kOR] (12a) /9~n\" R@kOR/ ̂[9~ R(6)kOR] (12b)","As an approximation, the phonological rule underlying","such examples can be schematised as follow:","@ ̂6 / +CS $ [+cons] __ (@init-Elis)","(6) / else","For the French language, this is the only initial juncture rule to be considered in ASR systems. In this matter, certain languages may exhibit more important initial phonological alternations, for example Celtic and Italic languages."]},{"title":"2.4 Contextual phonological group and multi-pronunciation group 2.4.1 Contextual phonological group","paragraphs":["In a W-representation a sub-string x1x2Â...of phonemes, object of interdependent phonological adaptations, are called contextual phonological group (CPG) and are represented by <x1x2Â...> or, if necessary, <Lx1x2Â...R> where L (resp. R)","is a diacritic related to the left (resp. right) word context; for example: cadre (frame) represented by /ka<dR@>/, prendre (to take) represented by /pRÃ£<~dR@>/ where L=~ involve a possible progressive nasal assimilation. So <dR@> and <~dR@> have not the same pronunciations in all contexts (see Table 1 and 2).","A CPG may also consist of a single unit; for example: pendant (during) represented by /pÃ£dÃ£<t\">/ where R=\" denotes a latent (liaison) consonant, les (the) represented by /lE<+z\"#>/ where L=+ denotes an ending boundary and R=\"# denotes a latent consonant in a proclitic (in this case the liaison is always required except before a consonant). 2.4.2 Multi-pronunciation group","In a W'-representation a sub-string x1x2Â...of phonemes having interdependent and multiple pronunciations are called multi-pronunciation group (MPG) and are represented as (x1x2Â...) or, if necessary, (Lx1x2Â...R). For example:","(~dR@) → dR6 ; n","A probability law can be associated to such a MPG-rule; which can then be learned from corpora and adapted for each particular application. A MPG-rule can also be simply used as a set of possible pronunciations of a phonological unit in a given context.","2.4.3 The C(W,W') adaptation From this definition, C(W,W') can be considered as a","one-step phonological transformation. For example","<n\"#>, <dR@>, <~dR@> are subject to the following","context-dependent and one-step transformations: <n\"#> → n /__#[-cons] () / else","dR /__$[-cons] <dR@> → (dR@Â§) / __Â§ (dR@) / else","dR /__$[-cons] <~dR@> → (~dR@Â§)/ __Â§","(~dR@) / else","Tables 1 and 2 (line 1,2,3) show examples of one-step C(W,W') adaptations"]},{"title":"2.5 The phonetic level","paragraphs":["The pronunciation variants are generated at level P using Dic(W',P). These pronunciations are subject to coarticulation effects and can be adapted through the C(P,P') component. In ASR systems it is frequently based on contextual allophones. This last component, which is not included in the lexical resources, is not discussed here. 2.5.1 Transduction through Dic(W',P)","The transduction of W'-representation into P-representation is based on such MPG rules stored in","Dic(W',P). Each rule lists the possible pronunciations of a","MPG and is context-free (in W'-representations the","context has already be compiled using C(W,W')). Ex.:","(dR@Â§) ̂dR6; d","(dR@Â§) ̂dR6; dR","(~dR@Â§) ̂dR6; dR; n","(~dR@) ̂dR6; n Tables 1 and 2 (line 4) give examples of such","transductions. prendre #(#) (to take) un # (a)","cadre Â§","(frame)","WpRÃ£<~dR@> 9~ <n\"#> k a <dR@>","W' p R Ã£dR 9~ k a (dR@)","PpRÃ£dR 9~ k a dR6","dR","Table 1","In the example of Table 1 the liaison is prohibited for","the article un. Only the last word cadre has pronunciation","variants (two variants: [kadR6] and [kadR]). prendre #(#) (to take) son # (his)","avis Â§","(opinion)","WpRÃ£<~dR@> s Ãμ <n\"#> a v i","W' p R Ã£(~dR@) s Ãμ navi","PpRÃ£dR6","n s Ãμ navi","Table2","In the example of Table 2 the liaison is require for un. Only the first word prendre has pronunciation variants (here there are two variants: [pRÃ£dR6] and [pRÃ£n], but, of course, more sophisticated list of pronunciations may be considered)."]},{"title":"3 MHAT lexicons 3.1 Lexicons within MHAT model","paragraphs":["We call lexicon every list of word entries represented by given attribute(s), for example spelling, phonological representation Â...","Fig. 2 - Derived lexicons. Several kind of lexicon may be defined within MHAT","model as shown in figure 2.","Dic(W',P) MPGs","C(W,W') CPGs Lex≡Dic (S',W)","Lex (S',W,W') Lex","(S',W',P) Lex","(S',W,P) 3.1.1 The basic lexicon Lex(S',W)","The basic lexicon of MHAT model is Dic(S',W) Â–Â–that is Lex(S',W)≡Dic(S',W)Â–Â– introduced below (Figure 1, Â§2.1) where each lexical entry is a pair (spelling, W-representation), for example :","(les ; lE<+z\"#>) (l' ; l) (mardi ; maRdi) 3.1.2 The phonotypical lexicon Lex(S',W')","This lexicon specifies the word phonological representations in each pertinent context, that is the word phonotypical representations. It is derived from Dic(S',W) through the C(W,W') adaptation, that is by applying CPG-rules stored in Dic(W,W').","It consists of 4-uples (spell.;Idx;L-ctxt;W'-rep.;R-ctxt), where L- (resp. R-) ctxt specifies the left- (resp. right-) context to be satisfied; Idx is the number of the phonotypical variant. For example :","(les;1; ;lEz; -C) (record;1; +CS ; r6kOR ;)","(mardi,1; ; maRdi ;) (record;2; -CS ; r(6)kOR ; )","In these examples -C (resp. +CS, -CS) stands for non-consonant (resp. closed syllable, non-closed syllable) in the R- or L-ctxt attributes.","An empty value means: no condition on the context. So the representation /maRdi/ is well formed at the level W' for any context; the W'-representation /lEz/ needs only that R-ctxt is -C and this results from the CPG-rule related to <+z\"#>.","In the above examples each W'-lexical entry, except the last one, has a single pronunciation, which is the replica of the W'-representation. So the first one has always the pronunciation [lEz] (so long as the R-context is a non-consonant).","In the last example, two pronunciations, [RkOR] and [R6kOR], can be derived (if L-context is not a closed syllable) by applying the MPG-rule : (6) ̂() ; 6.","The index Idx is useful for transcribing usual texts into phonotypical texts where each word spelling is completed by its pertinent Idx, that is the Idx for which L- and R-ctx fit with the environment of the word in the text. So the example given in table 2 will be transcribed: (Il1 va1) prendre3 son2 bus1.((He is going) to take his bus). Property. A one to one relationship exists between a text and its phonotypical transcription. As a matter of fact when a word occurs in a text its legal Idx results without ambiguity from its context. Remark. If we consider that already a few words are spelled with respect to their phonological contexts in usual text (word as le/l' as pointed out in Â§2.2.2), we might consider that usual texts are partly phonotypical; the use of Idx leads to a systematic phonotypical transcription. 3.1.3 Derived phonetic lexicons","Two lexicons play an important role in ASR.","Lex(S',W',P) is obtained by applying MPG-rules of Dic(W',P) on phonotypical representations. So each entry of Lex(S',W') generates as many entries in Lex(S',W',P) as pronunciation variants of the phonotypical word (given the context). Lex(S,W,P) is obtained in a similar way except for the context: each entry of Lex(S',W) generates as many entries in Lex(S',W,P) as pronunciation variants of the word.","Table 3 shows the lexical entries of the word prendre (to take) in the four lexicons introduced above (the L-context, which is empty in this example, is omitted ).","Lex Spell. W-rep. R-ctxt P-rep.","S'W prendre pRÃ£<~dR@>","prendre pRÃ£<~dR@> pRÃ£dR","-id- -id- pRÃ£dR@ S'WP -id- -id- pRÃ£n","Lex Spell. idx W'-rep. R-ctxt P-rep. prendre 1 pRÃ£dR __-C -id- 2 pRÃ£(~dR@Â§)__Â§ SW' -id- 3 pRÃ£(~dR@) ELSE prendre 1 pRÃ£dR __-C pRÃ£dR -id- 2 pRÃ£(~dR@Â§)__Â§ pRÃ£dR -id- 2 -id- -id- pRÃ£dR6 -id- 2 -id- -id- pRÃ£n -id- 3 pRÃ£(~dR@) ELSE pRÃ£dR6 S'W' P -id- 3 -id- -id- pRÃ£n Table 3 - 3.1.4 Forward and backward constraints induced","by a word","Each word occurring in a sentence induces phonological constraints on the subsequent (resp. antecedent) word, that is forward (resp. backward) phonological constraints FC (resp. BC). These constraints are those involved in CPG-rule as illustrated by the examples introduced above.","Table 4 gives a more exhaustive list of possible BC (FC takes only the values +CS or -CS). Depending on the desired precision in the phonological and/or phonetic modelling, different lists of possible values for BC can be adopted. The second column shows two simplified versions included in MHATLex resources.","All the lexicons within MHAT may be augmented by the attributes FC and BC. We adopt this option in MHATLex because this makes it easier to generate ASR lexical networks.","BC BC simple explicit backw. constraint Examples * * __* hi-fi /*ifi/ (hi-fi) +N +N __[+cons +nas] moi /mwa/ (me) B __[+cons -son +voi] vol /vol/ (fly) Q __[+cons -son -voi] chat /Sa/ (cat) L __[+cons +son -nas] lait /lE/ (milk) *U -N +C","__*[-cons -syll] yogi /*jogi/ (yogi) -C -C __[-cons] ami /ami/ (friend) Table 4."]},{"title":"4 MHAT model and ASR 4.1 The representations involved","paragraphs":["The following chains can be consider when speech production is modelled as multilevel Markov source emission (HMM approach):","X=x1Â...xiÂ...xL a word string, where xi refers to a words at the S' level or at the W level (this is equivalent because a S'-representation have one and only W-representation).","X'= x'1Â...x'iÂ...x'L be a phonotypical-word string, where x'i refers to a words at the W' level which is a phonotypical variant of xi (identified, for example, by a pair (x'i,Idx) as shown in Â§3.1.2)","V= v1Â...viÂ...vL, a phonetic representation at P level, where vi refers to a pronunciation variant of xi. The symbol vi represents (is the name of) a string of phonetic units but is considered as one symbol.","A=a1Â...ak Â...aT the acoustical representation of the input signal, where each is an acoustic vector."]},{"title":"4.2 Pronunciation variants and decision making 4.2.1 (W,P) models","paragraphs":["To take into account pronunciation variants the recognition can be based on (X*,V*)= argmaxX,V {P(A/V).P(V/X).P(X)} (13)","The decision is then in favour of the best pair (X*,V*) given A.","In (13), P(A/V) is the contribution of the acoustic modelling through Dic(P,A) Â–Â–not discussed hereÂ–Â–; P(X) is the contribution of the language model (LM); P(V/X) is the contribution of the pronunciation model. It can be evaluated as follows: P(V/X)="]},{"title":"∏","paragraphs":["i p(v i /x i) (14) where p(v i /x i) is the probability of the variant vi given the word xi.","The estimation of such probability is not easy. Large transcribed corpora are needed. In (Mailland and coll, 1995) an experiment of automatic training Â–Â– P(V/X) can be replaced by ε(V/X)="]},{"title":"∏","paragraphs":["i ε(vi/xi) (15) where ε(vi/xi) is a binary function taking the value 1 if vi is accepted as a pronunciation for x i, the value 0 else. Then ε(V/X)=1 if V is accepted as a pronunciation for X, ε(V/X)=0 else.","Depending on the recogniser, several definitions of ε are possible : ε(vi/xi)=1 iff vi is a possible (resp. the most probable, one of the k-most probableÂ...) pronunciation of xi.","(W,P)-Models defined above do not control the validity of pronunciation variants with respect to their contexts in sentences. 4.2.2 (W',P)-models","To take into account these contexts we can replace (13) (14) (15) by (16) (17) (18) (X*,V*)= argmaxX,V {P(A/V).P(V/X').P(X')} (16) P(V/X')="]},{"title":"∏","paragraphs":["i p(v i /x' i) (17) ε(V/X)="]},{"title":"∏","paragraphs":["i ε(vi/x'i) (18)","In these models variants and LM are related to phonotypical variants.","The contribution of LM, that is P(X) in standard approaches, is now P(X'). As pointed out in Â§3.1.2 there is a one to one relationship between X and X' so long as X' is legal, that is if the phonotypical variants x'i are selected in accordance to their phonological contexts in X'.","Let δ(x'i,x'i+1) be the binary function taking the value 0 when no contextual constraints are violated in the bigram and 1 otherwise (that is the bigram is legal). δ can be extended to control the legality of X' by δ(X') ="]},{"title":"∏","paragraphs":["i δ(x'i,x'i+1) (19)","It follows that we can obtain the bigram-based LM contribution in (W',P) model by using (20) or (21): P(X') ="]},{"title":"∏","paragraphs":["i P(x'i+1/x'i) (20) P(X')= δ(X').P(X)="]},{"title":"∏","paragraphs":["i δ(x'i,x'i+1).P(xi+1/xi) (21)","This last formula allows a second computation method of the phonotypical LM contribution. It uses the same bigrams as in the standard case (where P(X)="]},{"title":"∏","paragraphs":["i P(xi+1/xi)). What is specific here is the control of the legality of X' by the function δ. In this case training material can be the same for the two recognition models."]},{"title":"4.3 Lexical resources needed for (W,P) and (W',P) recognisers","paragraphs":["Knowledge involved in the above formulas Â–Â–(13) to (21)Â–Â– can be found in the lexicons introduced in Â§3.1. 4.3.1 Pronunciation variants","Possible pronunciations of a word (resp. a phonotypical word) are given by Lex(S',W,P) (resp. Lex(S',W',P)). This allows an initial implementation of the function ε. Moreover they provide the phonetic transcription of the pronunciation variants. 4.3.2 Language models","The (W,P) model needs only a list of words. When this list is obtained from corpora, a mere lexicon Lex(S') Â– Â–list of word spellingsÂ–Â– may be useful.","Lex(S',W') is necessary to implement and/or to train a (W',P)-based system.","For example the estimation of the phonotypical-bigram probabilities (or more generally k-gram probabilities) need phonotypical texts transcribed using Lex(S',W').","It allows also the evaluation of the δ bigrams thanks to the L-ctx, R-ctx, FC and BC attributes."]},{"title":"5 MHATLex resources","paragraphs":["These resources implement the basic lexicon Lex(S',W) Â–Â–including backward- and forward-constraintsÂ–Â– and the morpho-syntactic attributes inherited from BDLex. We call MHATLex-W the basic lexicon obtained in this way.","After the first experiments of the MHATLex material, new ideas related to flexible adaptation of these resources were brought out."]},{"title":"5.1 Flexible generation of specific lexicons 5.1.1 Projection of the lexicon","paragraphs":["Depending on the particular application, various forms","of lexicon may be useful. Basically the environment of MHATLex allows the","projection of MATLexW","- at level W', thanks to a GPC table, that is by performing C(W,W'); MHATLexW' is the resulting phonotypical lexicon which includes L- and R-ctxt attributes;","- at level P thanks to a MPG table, that is Dic(W',P); the resulting lexicon is called MHATLexP All these projections may be restricted to a sub-","vocabulary and to a subset of attributes. 5.1.2 Adaptation of the phonological model","Generally an application does not need the whole phonological component. So, since pronunciation variants are obtained through CPG- and MPG-tables, the user can implement its own pronunciation model by simple modification of these tables and he can also specify its own list of backward- and forward-constraints.","A particular simplified context-free pronunciation model, MHATLex-standard, is included in MHATLex resources. 5.1.3 Adaptation of the phonetic level","MHATLex allows the adaptation of the phonetic level according to the ASR acoustic-phonetic dictionary.","New phonetic alphabets lead only to the modification of the GPM-table."]},{"title":"5.2 MHATLex figures 5.2.1 Figures for the basic materials","paragraphs":["Table 5 gives figures related to the amount of data in MHATLexW and in the CPG- and MPG-tables for a given pronunciation model included in the resources. For this model simplifications have been introduced. In particular the list of backward-constrain values is restricted to four values *, +N, -N and -C (as shown in table 4, column 2). Type of W entries Entry number","GPC number","GPM","number","Canonical 49 962 252 75","Inflected 437 998 478 84 Table 5 5.2.2 Figures for the derived lexicons","Table 6 gives the corresponding figures at level W'. As all the CPG has been rewritten they disappear at this level, but new MPG's are introduced. Type of W' entries Entry number","GPM","number","Canonical 81 456 148","Inflected 854 452 220","Table 6 The projection of the basic lexicon at levels W' and P extends the number of entries by an ANV factor (average number of variants).","Level Entry nb ANV W 437 998 1.00 W' 854 452 1.95 P 1 708 913 3.90","Table 7","Table 7 gives these figures for the above model of pronunciation.","It can be observed that even a simplified model increases the size of a phonetic lexicon by a factor of about 4. All these phonetic variants are not always necessary.","This has been demonstrated by several ASR experiments Â–Â– see for example (Strik & Cucchiarini, 1998) various approaches are discussedÂ–Â–. But, in (PÃ©rennou & Pousse, 1998; Pousse & PÃ©rennou, 1999) the evaluations comparing (W,P) and (W',P) approaches, where MHATlex resources are used, has shown a clear advantage of the (W',P) model.","A distinction must be done between recognition and training. Indeed, in a first stage, particularly when automatic phonetic alignments are involved, a careful preparation of training data may require a lexicon with a wide coverage of the pronunciation variants. In a second stage, the pronunciation model can be reduced in the recogniser by taking into account the statistics extracted from the specific training data (see Â§4.2)."]},{"title":"6 Conclusion","paragraphs":["The MHATlex resources can be used to generate specific lexicons for applications in various domains going from corpus lemmatisation to ASR. Basically the environment of MHATLex allows the generation of various types of lexicons according to particular pronunciation models.","More information on linguistic resources BDLex and MHATLex can be found in the web site http://www.irit.fr/ACTIVITES/EQ_IHMPT /ress_ling/.","Future developments involve ASR domain, annotation of text and speech corpora and extension of the model to other languages."]},{"title":"7 References","paragraphs":["Aubert, X. Dugast, Ch. (1995). Improved Acoustic-Modelling in Dictation System by Handling Liaisons and Multiple Pronunciations. Proc. Eurospeech'95 (pp. 767-70). Madrid, Spain.","Chomsky, N. Halle, M. (1968). The Sound and Pattern of English. Harper & Row Pub.","De CalmÃs̈, M. PÃ©rennou, G. (1998). BDLEX : a Lexicon for Spoken and Written French. In A.Rubio, N. Gallardo, R. Castro, A. Tejada, (Eds), 1st International Conference on Langage Resources & Evaluation (pp. 1129-36), Grenade. ELRA, Paris. Dell, F. (1985). Les rÃg̈les et les sons. Herman.","Gauvain J.L. Lamel, L.F. Adda, G. Adda-Decker, M. (1993). Speaker-Independent Continuous Speech Dictation. Proc. EuroSpeech93","Mailland, A. de CalmÃs̈, M. , PÃ©rennou, G. (1995). Learning of a Phonological Component from BREF Corpus. Proc. ICPhS 95 (pp.13-9), Stockholm","PÃ©rennou, G. (1995). Phonological Component of an Automatic Speech Recognition, The Case of Liaison Processing. In C. Sorin, J. Mariani, H. Meloni, J. Schoentgen (Eds.), Levels in Speech Communication, Relations and Communications (pp.211-24). Elsevier.","PÃ©rennou, G. (1996). Les rÃg̈les et les niveaux en phonologie: du gÃ©nÃ©rativisme aux modÃl̈es markoviens. In H. MÃ©loni (Ed.), Fondements et perspectives en traitement automatique de la parole (pp.185-204). AUPELF-UREF, HACHETTE or ELLIPSES.","PÃ©rennou, G. de CalmÃs̈, M. (1987). BDLEX Lexical Data and Knowledge Base of Spoken and Written French. European Conference on Speech Technology (pp. 393-6), Edinburgh, Scotland.","PÃ©rennou, G. Pousse L. (1998). Phonological Component in Automatic Speech Recognition . In H. Strik, J.M. Kessens, M. Webster (Eds.), Proceedings of ESCA Tutorial and Research Workshop on Modelling Pronunciation Variation for Automatic Speech Recognition (pp. 91-6), Rolduc, Kerkrade, Netherlands. A2RT, Dept. of Language & Speech, University of Nimegen.","Pousse, L. PÃ©rennou, G. (1999). Language Model Level vs. Lexical Level for Modelling Pronunciation Variation in a French CSR. In G. Olaszy, G. NÃ©meth, K. Erdohegyi (Eds.) EUROSPEECH'99 (pp. 1771-4, vol 4, 5), Budapest, Hungary.","Selkirk, E. (1974). French Liaison and X\"-notation. Linguistic Inquiry 5, pp. 573-90.","Strike, H; Cucchiarini, C. (1998). Modeling Pronunciation Variation for ASR: Overview and Comparison of Methods. In H. Strik, J.M. Kessens, M. Webster (Eds.), Proceedings of ESCA Tutorial and Research Workshop on Modelling Pronunciation Variation for Automatic Speech Recognition (pp. 137-44), Rolduc, Kerkrade, Netherlands. A2RT, Dept. of Language & Speech, University of Nimegen."]}]}
