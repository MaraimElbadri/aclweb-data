{"sections":[{"title":"","paragraphs":["Proceedings of the 43rd Annual Meeting of the ACL, pages 115–124, Ann Arbor, June 2005. c⃝2005 Association for Computational Linguistics"]},{"title":"Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales Bo Pang   and Lillian Lee    (1) Department of Computer Science, Cornell University (2) Language Technologies Institute, Carnegie Mellon University (3) Computer Science Department, Carnegie Mellon University Abstract","paragraphs":["We address the rating-inference problem, wherein rather than simply decide whether a review is thumbs up or thumbs down, as in previous sentiment analysis work, one must determine an author’s evaluation with respect to a multi-point scale (e.g., one to ve stars). This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example, three stars is intuitively closer to four stars than to one star. We rst evaluate human performance at the task. Then, we apply a meta-algorithm, based on a metric labeling formulation of the problem, that alters a given","-ary classier’s output in an explicit attempt to ensure that similar items receive similar labels. We show that the meta-algorithm can provide signicant improvements over both multi-class and regression versions of SVMs when we employ a novel similarity measure appropriate to the problem."]},{"title":"1 Introduction","paragraphs":["There has recently been a dramatic surge of interest in sentiment analysis, as more and more people become aware of the scientic challenges posed and the scope of new applications enabled by the processing of subjective language. (The papers collected by Qu, Shanahan, and Wiebe (2004) form a representative sample of research in the area.) Most prior work on the specic problem of categorizing expressly opinionated text has focused on the binary distinction of positive vs. negative (Turney, 2002; Pang, Lee, and Vaithyanathan, 2002; Dave, Lawrence, and Pennock, 2003; Yu and Hatzivassiloglou, 2003). But it is often helpful to have more information than this binary distinction provides, especially if one is ranking items by recommendation or comparing several reviewers’ opinions: example applications include collaborative ltering and deciding which conference submissions to accept.","Therefore, in this paper we consider generalizing to ner-grained scales: rather than just determine whether a review is thumbs up or not, we attempt to infer the author’s implied numerical rating, such as three stars or four stars. Note that this differs from identifying opinion strength (Wilson, Wiebe, and Hwa, 2004): rants and raves have the same strength but represent opposite evaluations, and referee forms often allow one to indicate that one is very condent (high strength) that a conference submission is mediocre (middling rating). Also, our task differs from ranking not only because one can be given a single item to classify (as opposed to a set of items to be ordered relative to one another), but because there are settings in which classication is harder than ranking, and vice versa. One can apply standard","-ary classiers or regression to this rating-inference problem; independent work by Koppel and Schler (2005) considers such 115 methods. But an alternative approach that explicitly incorporates information about item similarities together with label similarity information (for instance, one star is closer to two stars than to four stars) is to think of the task as one of metric labeling (Kleinberg and Tardos, 2002), where label relations are encoded via a distance metric. This observation yields a meta-algorithm, applicable to both semi-supervised (via graph-theoretic techniques) and supervised settings, that alters a given  -ary classier’s output so that similar items tend to be assigned similar labels.","In what follows, we rst demonstrate that humans can discern relatively small differences in (hidden) evaluation scores, indicating that rating inference is indeed a meaningful task. We then present three types of algorithms one-vs-all, regression, and metric labeling that can be distinguished by how explicitly they attempt to leverage similarity between items and between labels. Next, we consider what item similarity measure to apply, propos-ing one based on the positive-sentence percentage. Incorporating this new measure within the metric-labeling framework is shown to often provide signicant improvements over the other algorithms.","We hope that some of the insights derived here might apply to other scales for text classifcation that have been considered, such as clause-level opinion strength (Wilson, Wiebe, and Hwa, 2004); affect types like disgust (Subasic and Huettner, 2001; Liu, Lieberman, and Selker, 2003); reading level (Collins-Thompson and Callan, 2004); and urgency or criticality (Horvitz, Jacobs, and Hovel, 1999)."]},{"title":"2 Problem validation and formulation","paragraphs":["We rst ran a small pilot study on human subjects in order to establish a rough idea of what a reasonable classication granularity is: if even people cannot accurately infer labels with respect to a ve-star scheme with half stars, say, then we cannot expect a learning algorithm to do so. Indeed, some potential obstacles to accurate rating inference include lack of calibration (e.g., what an understated author in-tends as high praise may seem lukewarm), author inconsistency at assigning ne-grained ratings, and Rating diff. Pooled Subject 1 Subject 2 ","or more 100% 100% (35) 100% (15) 2 (e.g., 1 star) 83% 77% (30) 100% (11) 1 (e.g.,   star) 69% 65% (57) 90% (10)","0 55% 47% (15) 80% ( 5) Table 1: Human accuracy at determining relative positivity. Rating differences are given in notches. Parentheses enclose the number of pairs attempted. ratings not entirely supported by the text1",".","For data, we rst collected Internet movie reviews in English from four authors, removing explicit rating indicators from each document’s text automatically. Now, while the obvious experiment would be to ask subjects to guess the rating that a review represents, doing so would force us to specify a xed rating-scale granularity in advance. Instead, we examined people’s ability to discern relative differences, because by varying the rating differences represented by the test instances, we can evaluate multiple granularities in a single experiment. Specically, at intervals over a number of weeks, we authors (a non-native and a native speaker of English) examined pairs of reviews, attemping to determine whether the rst review in each pair was (1) more positive than, (2) less positive than, or (3) as positive as the second. The texts in any particular review pair were taken from the same author to factor out the effects of cross-author divergence.","As Table 1 shows, both subjects performed perfectly when the rating separation was at least 3 notches in the original scale (we dene a notch as a half star in a four- or ve-star scheme and 10 points in a 100-point scheme). Interestingly, although human performance drops as rating difference decreases, even at a one-notch separation, both subjects handily outperformed the random-choice baseline of 33%. However, there was large variation in accuracy between subjects.2","1","For example, the critic Dennis Schwartz writes that sometimes the review itself [indicates] the letter grade should have been higher or lower, as the review might fail to take into consideration my overall impression of the lm which I hope to capture in the grade (http://www.sover.net/ozus/cinema.htm).","2","One contributing factor may be that the subjects viewed disjoint document sets, since we wanted to maximize experimental coverage of the types of document pairs within each difference class. We thus cannot report inter-annotator agreement, 116","Because of this variation, we dened two different classication regimes. From the evidence above, a three-class task (categories 0, 1, and 2 essentially negative, middling, and positive, respectively) seems like one that most people would do quite well at (but we should not assume 100% human accuracy: according to our one-notch results, people may misclassify borderline cases like 2.5 stars). Our study also suggests that people could do at least fairly well at distinguishing full stars in a zero- to four-star scheme. However, when we began to construct ve-category datasets for each of our four authors (see below), we found that in each case, either the most negative or the most positive class (but not both) contained only about 5% of the documents. To make the classes more balanced, we folded these minority classes into the adjacent class, thus arriving at a four-class problem (categories 0-3, increasing in positivity). Note that the four-class problem seems to offer more possibilities for leveraging class relationship information than the three-class setting, since it involves more class pairs. Also, even the two-category version of the rating-inference problem for movie reviews has proven quite challenging for many automated classication techniques (Pang, Lee, and Vaithyanathan, 2002; Turney, 2002).","We applied the above two labeling schemes to a scale dataset3","containing four corpora of movie reviews. All reviews were automatically preprocessed to remove both explicit rating indicators and objective sentences; the motivation for the latter step is that it has previously aided positive vs. negative classication (Pang and Lee, 2004). All of the 1770, 902, 1307, or 1027 documents in a given corpus were written by the same author. This decision facilitates interpretation of the results, since it factors out the effects of different choices of methods for calibrating authors’ scales.4","We point out that but since our goal is to recover a reviewer’s true recommendation, reader-author agreement is more relevant.","While another factor might be degree of English uency, in an informal experiment (six subjects viewing the same three pairs), native English speakers made the only two errors.","3","Available at http://www.cs.cornell.edu/People/pabo/movie-review-data as scale dataset v1.0.","4","From the Rotten Tomatoes website’s FAQ: star systems are not consistent between critics. For critics like Roger Ebert and James Berardinelli, 2.5 stars or lower out of 4 stars is always negative. For other critics, 2.5 stars can either be positive it is possible to gather author-specic information in some practical applications: for instance, systems that use selected authors (e.g., the Rotten Tomatoes movie-review website where, we note, not all authors provide explicit ratings) could require that someone submit rating-labeled samples of newlyadmitted authors’ work. Moreover, our results at least partially generalize to mixed-author situations (see Section 5.2)."]},{"title":"3 Algorithms","paragraphs":["Recall that the problem we are considering is multi-category classication in which the labels can be naturally mapped to a metric space (e.g., points on a line); for simplicity, we assume the distance metric","","throughout. In this section, we present three approaches to this problem in order of increasingly explicit use of pairwise similarity information between items and between labels. In order to make comparisons between these methods meaningful, we base all three of them on Support Vector Machines (SVMs) as implemented in Joachims’ (1999)","package. 3.1 One-vs-all The standard SVM formulation applies only to binary classication. One-vs-all (OVA) (Rifkin and Klautau, 2004) is a common extension to the","-ary case. Training consists of building, for each label  , an SVM binary classier distinguishing label  from not- ",". We consider the nal output to be a label preference function  , dened as the signed distance of (test) item  to the  side of the  vs. not- ","decision plane.","Clearly, OVA makes no explicit use of pairwise label or item relationships. However, it can perform well if each class exhibits sufciently distinct language; see Section 4 for more discussion. 3.2 Regression Alternatively, we can take a regression perspective by assuming that the labels come from a discretiza-tion of a continuous function","mapping from the or negative. Even though Eric Lurio uses a 5 star system, his grading is very relaxed. So, 2 stars can be positive. Thus, calibration may sometimes require strong familiarity with the authors involved, as anyone who has ever needed to reconcile conicting referee reports probably knows. 117 feature space to a metric space.5","If we choose from a family of sufciently gradual functions, then similar items necessarily receive similar labels. In particular, we consider linear,","-insensitive SVM regression (Vapnik, 1995; Smola and Sch¤olkopf, 1998); the idea is to nd the hyperplane that best ts the training data, but where training points whose labels are within distance","of the hyperplane incur no loss. Then, for (test) instance  , the label preference function  is the negative of the distance between  and the value predicted for  by the tted hyperplane function.","Wilson, Wiebe, and Hwa (2004) used SVM regression to classify clause-level strength of opinion, reporting that it provided lower accuracy than other methods. However, independently of our work, Koppel and Schler (2005) found that applying linear regression to classify documents (in a different corpus than ours) with respect to a three-point rating scale provided greater accuracy than OVA SVMs and other algorithms. 3.3 Metric labeling Regression implicitly encodes the similar items, similar labels heuristic, in that one can restrict consideration to gradual functions. But we can also think of our task as a metric labeling problem (Kleinberg and Tardos, 2002), a special case of the maximum a posteriori estimation problem for Markov random elds, to explicitly encode our desideratum. Suppose we have an initial label preference function ",", perhaps computed via one of the two methods described above. Also, let  be a distance metric on labels, and let  de-","note the nearest neighbors of item ","according to some item-similarity function",". Then, it is quite natural to pose our problem as nding a mapping of instances  to labels ","(respecting the original labels of the training instances) that minimizes   test    ","  ","  ","     "," ","where is monotonically increasing (we chose   unless otherwise specied) and ","is a","trade-off and/or scaling parameter. (The inner sum-","mation is familiar from work in locally-weighted 5 We discuss the ordinal regression variant in Section 6. learning6","(Atkeson, Moore, and Schaal, 1997).) In a sense, we are using explicit item and label similarity information to increasingly penalize the initial classier as it assigns more divergent labels to similar items.","In this paper, we only report supervised-learning experiments in which the nearest neighbors for any given test item were drawn from the training set alone. In such a setting, the labeling decisions for different test items are independent, so that solving the requisite optimization problem is simple. Aside: transduction The above formulation also allows for transductive semi-supervised learning as well, in that we could allow nearest neighbors to come from both the training and test sets. We intend to address this case in future work, since there are important settings in which one has a small number of labeled reviews and a large number of unlabeled reviews, in which case considering similarities between unlabeled texts could prove quite helpful. In full generality, the corresponding multi-label optimization problem is intractable, but for many families of","functions (e.g., convex) there exist practical exact or approximation algorithms based on techniques for nding minimum s-t cuts in graphs (Ishikawa and Geiger, 1998; Boykov, Veksler, and Zabih, 1999; Ishikawa, 2003). Interestingly, previous sentiment analysis research found that a minimum-cut formulation for the binary subjective/objective distinction yielded good results (Pang and Lee, 2004). Of course, there are many other related semi-supervised learning algorithms that we would like to try as well; see Zhu (2005) for a survey."]},{"title":"4 Class struggle: nding a label-correlated item-similarity function","paragraphs":["We need to specify an item similarity function to use the metric-labeling formulation described in Section 3.3. We could, as is commonly done, employ a term-overlap-based measure such as the cosine between term-frequency-based document vectors (henceforth TO(cos)). However, Table 2 6 If we ignore the","term, different choices of","cor-","respond to different versions of nearest-neighbor learning, e.g.,","majority-vote, weighted average of labels, or weighted median","of labels. 118","Label difference:","1 2 3","Three-class data 37% 33%","Four-class data 34% 31% 30% Table 2: Average over authors and class pairs of between-class vocabulary overlap as the class labels of the pair grow farther apart. shows that in aggregate, the vocabularies of distant classes overlap to a degree surprisingly similar to that of the vocabularies of nearby classes. Thus, item similarity as measured by TO(cos) may not correlate well with similarity of the item’s true labels.","We can potentially develop a more useful similarity metric by asking ourselves what, intuitively, accounts for the label relationships that we seek to exploit. A simple hypothesis is that ratings can be determined by the positive-sentence percentage (PSP) of a text, i.e., the number of positive sentences divided by the number of subjective sentences. (Term-based versions of this premise have motivated much sentiment-analysis work for over a decade (Das and Chen, 2001; Tong, 2001; Turney, 2002).) But counterexamples are easy to construct: reviews can contain off-topic opinions, or recount many positive as-pects before describing a fatal aw.","We therefore tested the hypothesis as follows. To avoid the need to hand-label sentences as positive or negative, we rst created a sentence polarity dataset7","consisting of 10,662 movie-review snippets (a striking extract usually one sentence long) downloaded from www.rottentomatoes.com; each snippet was labeled with its source review’s label (positive or negative) as provided by Rotten Tomatoes. Then, we trained a Naive Bayes classier on this data set and applied it to our scale dataset to identify the positive sentences (recall that objective sentences were already removed).","Figure 1 shows that all four authors tend to exhibit a higher PSP when they write a more positive review, and we expect that most typical reviewers would follow suit. Hence, PSP appears to be a promising basis for computing document similarity for our rating-inference task. In particular, 7 Available at http://www.cs.cornell.edu/People/pabo/movie-","review-data as sentence polarity dataset v1.0. we dened      to be the two-dimensional vector     ","   ",", and then set the item-similarity function required by the metric-labeling optimization function (Section 3.3) to          "," ","8 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0 2 4 6 8 10 mean and standard deviation of PSP rating (in notches) Positive-sentence percentage (PSP) statistics Author a Author b Author c Author d Figure 1: Average and standard deviation of PSP for reviews expressing different ratings.","But before proceeding, we note that it is possible that similarity information might yield no extra benet at all. For instance, we don’t need it if we can reliably identify each class just from some set of distinguishing terms. If we dene such terms as frequent ones (","",") that appear in a single class 50% or more of the time, then we do nd many instances; some examples for one author are: meaningless, disgusting (class 0); pleasant, uneven (class 1); and oscar, gem (class 2) for the three-class case, and, in the four-class case, at, tedious (class 1) versus straightforward, likeable (class 2). Some unexpected distinguishing terms for this author are lion for class 2 (three-class case), and for class 2 in the four-class case, jennifer, for a wide variety of Jennifers."]},{"title":"5 Evaluation","paragraphs":["This section compares the accuracies of the approaches outlined in Section 3 on the four corpora comprising our scale dataset. (Results using","","error were qualitatively similar.) Throughout, when","8","While admittedly we initially chose this function because it was convenient to work with cosines, post hoc analysis revealed that the corresponding metric space stretched certain distances in a useful way. 119 we refer to something as signicant, we mean statistically so with respect to the paired","-test, ","",". The results that follow are based on","","’s","default parameter settings for SVM regression and","OVA. Preliminary analysis of the effect of varying","the regression parameter","in the four-class case re-","vealed that the default value was often optimal. The notation A ","B denotes metric labeling","where method A provides the initial label preference","function","and B serves as similarity measure. To","train, we rst select the meta-parameters","and  by running 9-fold cross-validation within the training set. Fixing","and ","to those values yielding the best performance, we then re-train A (but with SVM parameters xed, as described above) on the whole training set. At test time, the nearest neighbors of each item are also taken from the full training set. 5.1 Main comparison Figure 2 summarizes our average 10-fold cross-validation accuracy results. We rst observe from the plots that all the algorithms described in Section 3 always denitively outperform the simple baseline of predicting the majority class, although the improvements are smaller in the four-class case. In-cidentally, the data was distributed in such a way that the absolute performance of the baseline itself does not change much between the three- and four-class case (which implies that the three-class datasets were relatively more balanced); and Author c’s datasets seem noticeably easier than the others.","We now examine the effect of implicitly using label and item similarity. In the four-class case, regression performed better than OVA (signicantly so for two authors, as shown in the righthand table); but for the three-category task, OVA signicantly outperforms regression for all four authors. One might initially interprete this ip as showing that in the four-class scenario, item and label similarities provide a richer source of information relative to class-specic characteristics, especially since for the non-majority classes there is less data available; whereas in the three-class setting the categories are better modeled as quite distinct entities.","However, the three-class results for metric labeling on top of OVA and regression (shown in Figure 2 by black versions of the corresponding icons) show that employing explicit similarities always improves results, often to a signicant degree, and yields the best overall accuracies. Thus, we can in fact effectively exploit similarities in the three-class case. Additionally, in both the three- and four- class scenarios, metric labeling often brings the performance of the weaker base method up to that of the stronger one (as indicated by the disappearance of upward triangles in corresponding table rows), and never hurts performance signicantly.","In the four-class case, metric labeling and regression seem roughly equivalent. One possible interpretation is that the relevant structure of the problem is already captured by linear regression (and perhaps a different kernel for regression would have improved its three-class performance). However, according to additional experiments we ran in the four-class situation, the test-set-optimal parameter settings for metric labeling would have produced signicant improvements, indicating there may be greater potential for our framework. At any rate, we view the fact that metric labeling performed quite well for both rating scales as a denitely positive result. 5.2 Further discussion Q: Metric labeling looks like it’s just combining SVMs with nearest neighbors, and classier combination often improves performance. Couldn’t we get the same kind of results by combining SVMs with any other reasonable method? A: No. For example, if we take the strongest base SVM method for initial label preferences, but replace PSP with the term-overlap-based cosine (TO(cos)), performance often drops signicantly. This result, which is in accordance with Section 4’s data, suggests that choosing an item similarity function that correlates well with label similarity is important. (ova ","PSP ova  TO(cos) [3c]; reg ","PSP reg ","TO(cos) [4c]) Q: Could you explain that notation, please? A: Triangles point toward the signicantly better algorithm for some dataset. For instance, M","N [3c] means, In the 3-class task, method M is signicantly better than N for two author datasets and signicantly worse for one dataset (so the algorithms were statistically indistinguishable on the remaining dataset). When the algorithms being compared are statistically indistinguishable on 120 Average accuracies, three-class data Average accuracies, four-class data 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 Author a Author b Author c Author d majority ova ova+PSP reg reg+PSP 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 Author a Author b Author c Author d majority ova ova+PSP reg reg+PSP Average ten-fold cross-validation accuracies. Open icons: SVMs in either one-versus-all (square) or regression (circle) mode; dark versions: metric labeling using the corresponding SVM together with the positive-sentence percentage (PSP). The  -axes of the two plots are aligned. Signicant differences, three-class data Signicant differences, four-class data ova ova+PSP reg reg+PSP a b c d a b c d a b c d a b c d","ova .",".",". .","ova+PSP",".","",".","reg","",".",".","reg+PSP .",". . . .",". ova ova+PSP reg reg+PSP a b c d a b c d a b c d a b c d","ova .","",". .",". .","ova+PSP .","",". . .",". . .","reg",". . . . . . . . .","reg+PSP",". .  . . . . . . . Triangles point towards signicantly better algorithms for the results plotted above. Specically, if the difference between a row and a column algorithm for a given author dataset (a, b, c, or d) is signicant, a triangle points to the better one; otherwise, a dot (.) is shown. Dark icons highlight the effect of adding PSP information via metric labeling. Figure 2: Results for main experimental comparisons. all four datasets (the no triangles case), we indicate this with an equals sign (=). Q: Thanks. Doesn’t Figure 1 show that the positive-sentence percentage would be a good classier even in isolation, so metric labeling isn’t necessary? A: No. Predicting class labels directly from the PSP value via trained thresholds isn’t as effective (ova ","PSP threshold PSP [3c]; reg  PSP","threshold PSP [4c]). Alternatively, we could use only the PSP com-","ponent of metric labeling by setting the label preference function to the constant function 0, but even with test-set-optimal parameter settings, doing so underperforms the trained metric labeling algorithm with access to an initial SVM classier (ova ","PSP 0","    [3c]; reg ","PSP 0","    [4c]). Q: What about using PSP as one of the features for input to a standard classier? A: Our focus is on investigating the utility of similarity information. In our particular rating-inference setting, it so happens that the basis for our pairwise similarity measure can be incorporated as an 121 item-specic feature, but we view this as a tangential issue. That being said, preliminary experiments show that metric labeling can be better, barely (for test-set-optimal parameter settings for both algorithms: signicantly better results for one author, four-class case; statistically indistinguishable otherwise), although one needs to determine an appropriate weight for the PSP feature to get good performance. Q: You dened the metric transformation function","as the identity function ",", imposing greater loss as the distance between labels assigned to two similar items increases. Can you do just as well if you penalize all non-equal label assignments by the same amount, or does the distance between labels really matter? A: You’re asking for a comparison to the Potts model, which sets","to the function","","   if"," ","",",","otherwise. In the one set-","ting in which there is a signicant difference","between the two, the Potts model does worse","(ova ","PSP ova ","PSP [3c]). Also, employing the Potts model generally leads to fewer signicant improvements over a chosen base method (compare Figure 2’s tables with: reg ","PSP reg [3c]; ova ","PSP ova [3c]; ova  PSP  ova [4c]; but note that reg ","PSP","reg [4c]). We note that optimizing the Potts model in the multi-label case is NPhard, whereas the optimal metric labeling with the identity metric-transformation function can be efciently obtained (see Section 3.3). Q: Your datasets had many labeled reviews and only one author each. Is your work relevant to settings with many authors but very little data for each? A: As discussed in Section 2, it can be quite difcult to properly calibrate different authors’ scales, since the same number of stars even within what is ostensibly the same rating system can mean different things for different authors. But since you ask: we temporarily turned a blind eye to this serious is-sue, creating a collection of 5394 reviews by 496 authors with at most 80 reviews per author, where we pretended that our rating conversions mapped correctly into a universal rating scheme. Preliminary results on this dataset were actually comparable to the results reported above, although since we are not condent in the class labels themselves, more work is needed to derive a clear analysis of this setting. (Abusing notation, since we’re already play-ing fast and loose: [3c]: baseline 52.4%, reg 61.4%, reg ","PSP 61.5%, ova (65.4%) ova  PSP (66.3%);","[4c]: baseline 38.8%, reg (51.9%)","reg  PSP","(52.7%), ova (53.8%) ova ","PSP (54.6%))","In future work, it would be interesting to determine author-independent characteristics that can be used on (or suitably adapted to) data for specic authors. Q: How about trying A: Y es, there are many alternatives. A few that we tested are described in the Appendix, and we propose some others in the next section. We should mention that we have not yet experimented with all-vs.-all (AVA), another standard binary-to-multi-category classier conversion method, because we wished to focus on the effect of omitting pairwise information. In independent work on 3-category rating inference for a different corpus, Koppel and Schler (2005) found that regression outperformed AVA, and Rifkin and Klautau (2004) argue that in principle OVA should do just as well as AVA. But we plan to try it out."]},{"title":"6 Related work and future directions","paragraphs":["In this paper, we addressed the rating-inference problem, showing the utility of employing label similarity and (appropriate choice of) item similarity either implicitly, through regression, or explicitly and often more effectively, through metric labeling.","In the future, we would like to apply our methods to other scale-based classication problems, and explore alternative methods. Clearly, varying the kernel in SVM regression might yield better results. Another choice is ordinal regression (McCullagh, 1980; Herbrich, Graepel, and Obermayer, 2000), which only considers the ordering on labels, rather than any explicit distances between them; this approach could work well if a good metric on labels is lacking. Also, one could use mixture models (e.g., combine positive and negative language models) to capture class relationships (McCallum, 1999; Schapire and Singer, 2000; Takamura, Matsumoto, and Yamada, 2004).","We are also interested in framing multi-class but non-scale-based categorization problems as metric 122 labeling tasks. For example, positive vs. negative vs. neutral sentiment distinctions are sometimes considered in which neutral means either objective (Engstr¤om, 2004) or a conation of objective with a rating of mediocre (Das and Chen, 2001). (Koppel and Schler (2005) in independent work also discuss various types of neutrality.) In either case, we could apply a metric in which positive and negative are closer to objective (or objective+mediocre) than to each other. As another example, hierarchical label relationships can be easily encoded in a label metric.","Finally, as mentioned in Section 3.3, we would like to address the transductive setting, in which one has a small amount of labeled data and uses relationships between unlabeled items, since it is particularly well-suited to the metric-labeling approach and may be quite important in practice. Acknowledgments We thank Paul Bennett, Dave Blei, Claire Cardie, Shimon Edelman, Thorsten Joachims, Jon Kleinberg, Oren Kurland, John Lafferty, Guy Lebanon, Pradeep Ravikumar, Jerry Zhu, and the anonymous reviewers for many very useful comments and discussion. We learned of Moshe Koppel and Jonathan Schler’s work while preparing the cameraready version of this paper; we thank them for so quickly an-swering our request for a pre-print. Our descriptions of their work are based on that pre-print; we apologize in advance for any inaccuracies in our descriptions that result from changes between their pre-print and their nal version. We also thank CMU for its hospitality during the year. This paper is based upon work supported in part by the National Science Founda-tion (NSF) under grant no. IIS-0329064 and CCR-0122581; SRI International under subcontract no. 03-000211 on their project funded by the Department of the Interior’s National Business Center; and by an Alfred P. Sloan Research Fellowship. Any opinions, ndings, and conclusions or recommendations expressed are those of the authors and do not necessarily reect the views or ofcial policies, either expressed or implied, of any sponsoring institutions, the U.S. government, or any other entity."]},{"title":"References","paragraphs":["Atkeson, Christopher G., Andrew W. Moore, and Stefan Schaal. 1997. Locally weighted learning. Articial Intelligence Review, 11(1):1173.","Boykov, Yuri, Olga Veksler, and Ramin Zabih. 1999. Fast approximate energy minimization via graph cuts. In Proceedings of the International Conference on Computer Vision (ICCV), pages 377384. Journal version in IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 23(11):12221239, 2001.","Collins-Thompson, Kevyn and Jamie Callan. 2004. A language modeling approach to predicting reading difculty. In HLT-NAACL: Proceedings of the Main Conference, pages 193 200.","Das, Sanjiv and Mike Chen. 2001. Yahoo! for Amazon: Extracting market sentiment from stock message boards. In Proceedings of the Asia Pacic Finance Association Annual Conference (APFA).","Dave, Kushal, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: Opinion extraction and semantic classication of product reviews. In Proceedings of WWW, pages 519528.","Engstr¤om, Charlotta. 2004. Topic dependence in sentiment classication. Master’s thesis, University of Cambridge.","Herbrich, Ralf, Thore Graepel, and Klaus Obermayer. 2000. Large margin rank boundaries for ordinal regression. In Alexander J. Smola, Peter L. Bartlett, Bernhard Sch¤olkopf, and Dale Schuurmans, editors, Advances in Large Margin Classiers, Neural Information Processing Systems. MIT Press, pages 115132.","Horvitz, Eric, Andy Jacobs, and David Hovel. 1999. Attentionsensitive alerting. In Proceedings of the Conference on Uncertainty and Articial Intelligence, pages 305313.","Ishikawa, Hiroshi. 2003. Exact optimization for Markov random elds with convex priors. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(10).","Ishikawa, Hiroshi and Davi Geiger. 1998. Occlusions, discontinuities, and epipolar lines in stereo. In Proceedings of the 5th European Conference on Computer Vision (ECCV), volume I, pages 232248, London, UK. Springer-Verlag.","Joachims, Thorsten. 1999. Making large-scale SVM learning practical. In Bernhard Sch¤olkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press, pages 4456.","Kleinberg, Jon and ·Eva Tardos. 2002. Approximation algorithms for classication problems with pairwise relationships: Metric labeling and Markov random elds. Journal of the ACM, 49(5):616639.","Koppel, Moshe and Jonathan Schler. 2005. The importance of neutral examples for learning sentiment. In Workshop on the Analysis of Informal and Formal Information Exchange during Negotiations (FINEXIN).","Liu, Hugo, Henry Lieberman, and Ted Selker. 2003. A model of textual affect sensing using real-world knowledge. In Proceedings of Intelligent User Interfaces (IUI), pages 125132.","McCallum, Andrew. 1999. Multi-label text classication with a mixture model trained by EM. In AAAI Workshop on Text Learning.","McCullagh, Peter. 1980. Regression models for ordinal data. Journal of the Royal Statistical Society, 42(2):10942. 123","Pang, Bo and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the ACL, pages 271278.","Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classication using machine learning techniques. In Proceedings of EMNLP, pages 7986.","Qu, Yan, James Shanahan, and Janyce Wiebe, editors. 2004. Proceedings of the AAAI Spring Symposium on Explor-ing Attitude and Affect in Text: Theories and Applications. AAAI Press. AAAI technical report SS-04-07.","Rifkin, Ryan M. and Aldebaro Klautau. 2004. In defense of one-vs-all classication. Journal of Machine Learning Research, 5:101141.","Schapire, Robert E. and Yoram Singer. 2000. BoosTexter: A boosting-based system for text categorization. Machine Learning, 39(2/3):135168.","Smola, Alex J. and Bernhard Sch¤olkopf. 1998. A tutorial on support vector regression. Technical Report Neuro-COLT NC-TR-98-030, Royal Holloway College, University of London.","Subasic, Pero and Alison Huettner. 2001. Affect analysis of text using fuzzy semantic typing. IEEE Transactions on Fuzzy Systems, 9(4):483496.","Takamura, Hiroya, Yuji Matsumoto, and Hiroyasu Yamada. 2004. Modeling category structures with a kernel function. In Proceedings of CoNLL, pages 5764.","Tong, Richard M. 2001. An operational system for detecting and tracking opinions in on-line discussion. SIGIR Workshop on Operational Text Classication.","Turney, Peter. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classication of reviews. In Proceedings of the ACL, pages 417424.","Vapnik, Vladimir. 1995. The Nature of Statistical Learning Theory. Springer.","Wilson, Theresa, Janyce Wiebe, and Rebecca Hwa. 2004. Just how mad are you? Finding strong and weak opinion clauses. In Proceedings of AAAI, pages 761769.","Yu, Hong and Vasileios Hatzivassiloglou. 2003. Towards an-swering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of EMNLP.","Zhu, Xiaojin (Jerry). 2005. Semi-Supervised Learning with Graphs. Ph.D. thesis, Carnegie Mellon University."]},{"title":"A Appendix: other variations attempted A.1 Discretizing binary classication","paragraphs":["In our setting, we can also incorporate class relations by directly altering the output of a binary classier, as follows. We rst train a standard SVM, treating ratings greater than 0.5 as positive labels and others as negative labels. If we then consider the resulting classier to output a positivity-preference function  ",", we can then learn a series of thresholds to","convert this value into the desired label set, under","the assumption that the bigger"," ","is, the more positive the review.9","This algorithm always outperforms the majority-class baseline, but not to the degree that the best of SVM OVA and SVM regression does. Koppel and Schler (2005) independently found in a three-class study that thresholding a positive/negative classier trained only on clearly positive or clearly negative examples did not yield large improvements. A.2 Discretizing regression In our experiments with SVM regression, we discretized regression output via a set of xed decision thresholds         ","to map it into our set of class labels. Alternatively, we can learn the thresholds instead. Neither option clearly outperforms the other in the four-class case. In the three-class setting, the learned version provides noticeably better performance in two of the four datasets. But these results taken together still mean that in many cases, the difference is negligible, and if we had started down this path, we would have needed to consider similar tweaks for one-vs-all SVM as well. We therefore stuck with the simpler version in order to maintain focus on the central issues at hand.","9","This is not necessarily true: if the classier’s goal is to optimize binary classication error, its major concern is to increase condence in the positive/negative distinction, which may not correspond to higher condence in separating ve stars from four stars. 124"]}],"references":[{"authors":[{"last":"Atkeson"},{"first":"Christopher","last":"G."},{"first":"Andrew","middle":"W.","last":"Moore"},{"first":"Stefan","last":"Schaal"}],"year":"1997","title":"Locally weighted learning","source":"Atkeson, Christopher G., Andrew W. Moore, and Stefan Schaal. 1997. Locally weighted learning. Articial Intelligence Review, 11(1):1173."},{"authors":[{"last":"Boykov"},{"last":"Yuri"},{"first":"Olga","last":"Veksler"},{"first":"Ramin","last":"Zabih"}],"year":"1999","title":"Fast approximate energy minimization via graph cuts","source":"Boykov, Yuri, Olga Veksler, and Ramin Zabih. 1999. Fast approximate energy minimization via graph cuts. In Proceedings of the International Conference on Computer Vision (ICCV), pages 377384. Journal version in IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 23(11):12221239, 2001."},{"authors":[{"last":"Collins-Thompson"},{"last":"Kevyn"},{"first":"Jamie","last":"Callan"}],"year":"2004","title":"A language modeling approach to predicting reading difculty","source":"Collins-Thompson, Kevyn and Jamie Callan. 2004. A language modeling approach to predicting reading difculty. In HLT-NAACL: Proceedings of the Main Conference, pages 193 200."},{"authors":[{"last":"Das"},{"last":"Sanjiv"},{"first":"Mike","last":"Chen"}],"year":"2001","title":"Yahoo! for Amazon: Extracting market sentiment from stock message boards","source":"Das, Sanjiv and Mike Chen. 2001. Yahoo! for Amazon: Extracting market sentiment from stock message boards. In Proceedings of the Asia Pacic Finance Association Annual Conference (APFA)."},{"authors":[{"last":"Dave"},{"last":"Kushal"},{"first":"Steve","last":"Lawrence"},{"first":"David","middle":"M.","last":"Pennock"}],"year":"2003","title":"Mining the peanut gallery: Opinion extraction and semantic classication of product reviews","source":"Dave, Kushal, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: Opinion extraction and semantic classication of product reviews. In Proceedings of WWW, pages 519528."},{"authors":[{"last":"Engstr¤om"},{"last":"Charlotta"}],"year":"2004","title":"Topic dependence in sentiment classication","source":"Engstr¤om, Charlotta. 2004. Topic dependence in sentiment classication. Master’s thesis, University of Cambridge."},{"authors":[{"last":"Herbrich"},{"last":"Ralf"},{"first":"Thore","last":"Graepel"},{"first":"Klaus","last":"Obermayer"}],"year":"2000","title":"Large margin rank boundaries for ordinal regression","source":"Herbrich, Ralf, Thore Graepel, and Klaus Obermayer. 2000. Large margin rank boundaries for ordinal regression. In Alexander J. Smola, Peter L. Bartlett, Bernhard Sch¤olkopf, and Dale Schuurmans, editors, Advances in Large Margin Classiers, Neural Information Processing Systems. MIT Press, pages 115132."},{"authors":[{"last":"Horvitz"},{"last":"Eric"},{"first":"Andy","last":"Jacobs"},{"first":"David","last":"Hovel"}],"year":"1999","title":"Attentionsensitive alerting","source":"Horvitz, Eric, Andy Jacobs, and David Hovel. 1999. Attentionsensitive alerting. In Proceedings of the Conference on Uncertainty and Articial Intelligence, pages 305313."},{"authors":[{"last":"Ishikawa"},{"last":"Hiroshi"}],"year":"2003","title":"Exact optimization for Markov random elds with convex priors","source":"Ishikawa, Hiroshi. 2003. Exact optimization for Markov random elds with convex priors. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(10)."},{"authors":[{"last":"Ishikawa"},{"last":"Hiroshi"},{"first":"Davi","last":"Geiger"}],"year":"1998","title":"Occlusions, discontinuities, and epipolar lines in stereo","source":"Ishikawa, Hiroshi and Davi Geiger. 1998. Occlusions, discontinuities, and epipolar lines in stereo. In Proceedings of the 5th European Conference on Computer Vision (ECCV), volume I, pages 232248, London, UK. Springer-Verlag."},{"authors":[{"last":"Joachims"},{"last":"Thorsten"}],"year":"1999","title":"Making large-scale SVM learning practical","source":"Joachims, Thorsten. 1999. Making large-scale SVM learning practical. In Bernhard Sch¤olkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press, pages 4456."},{"authors":[{"last":"Kleinberg"},{"last":"Jon"},{"first":"·Eva","last":"Tardos"}],"year":"2002","title":"Approximation algorithms for classication problems with pairwise relationships: Metric labeling and Markov random elds","source":"Kleinberg, Jon and ·Eva Tardos. 2002. Approximation algorithms for classication problems with pairwise relationships: Metric labeling and Markov random elds. Journal of the ACM, 49(5):616639."},{"authors":[{"last":"Koppel"},{"last":"Moshe"},{"first":"Jonathan","last":"Schler"}],"year":"2005","title":"The importance of neutral examples for learning sentiment","source":"Koppel, Moshe and Jonathan Schler. 2005. The importance of neutral examples for learning sentiment. In Workshop on the Analysis of Informal and Formal Information Exchange during Negotiations (FINEXIN)."},{"authors":[{"last":"Liu"},{"last":"Hugo"},{"first":"Henry","last":"Lieberman"},{"first":"Ted","last":"Selker"}],"year":"2003","title":"A model of textual affect sensing using real-world knowledge","source":"Liu, Hugo, Henry Lieberman, and Ted Selker. 2003. A model of textual affect sensing using real-world knowledge. In Proceedings of Intelligent User Interfaces (IUI), pages 125132."},{"authors":[{"last":"McCallum"},{"last":"Andrew"}],"year":"1999","title":"Multi-label text classication with a mixture model trained by EM","source":"McCallum, Andrew. 1999. Multi-label text classication with a mixture model trained by EM. In AAAI Workshop on Text Learning."},{"authors":[{"last":"McCullagh"},{"last":"Peter"}],"year":"1980","title":"Regression models for ordinal data","source":"McCullagh, Peter. 1980. Regression models for ordinal data. Journal of the Royal Statistical Society, 42(2):10942. 123"},{"authors":[{"last":"Pang"},{"last":"Bo"},{"first":"Lillian","last":"Lee"}],"year":"2004","title":"A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","source":"Pang, Bo and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the ACL, pages 271278."},{"authors":[{"last":"Pang"},{"last":"Bo"},{"first":"Lillian","last":"Lee"},{"first":"Shivakumar","last":"Vaithyanathan"}],"year":"2002","title":"Thumbs up? Sentiment classication using machine learning techniques","source":"Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classication using machine learning techniques. In Proceedings of EMNLP, pages 7986."},{"authors":[{"last":"Qu"},{"last":"Yan"},{"first":"James","last":"Shanahan"},{"first":"Janyce","last":"Wiebe"},{"last":"editors"}],"year":"2004","title":"Proceedings of the AAAI Spring Symposium on Explor-ing Attitude and Affect in Text: Theories and Applications","source":"Qu, Yan, James Shanahan, and Janyce Wiebe, editors. 2004. Proceedings of the AAAI Spring Symposium on Explor-ing Attitude and Affect in Text: Theories and Applications. AAAI Press. AAAI technical report SS-04-07."},{"authors":[{"last":"Rifkin"},{"first":"Ryan","last":"M."},{"first":"Aldebaro","last":"Klautau"}],"year":"2004","title":"In defense of one-vs-all classication","source":"Rifkin, Ryan M. and Aldebaro Klautau. 2004. In defense of one-vs-all classication. Journal of Machine Learning Research, 5:101141."},{"authors":[{"last":"Schapire"},{"first":"Robert","last":"E."},{"first":"Yoram","last":"Singer"}],"year":"2000","title":"BoosTexter: A boosting-based system for text categorization","source":"Schapire, Robert E. and Yoram Singer. 2000. BoosTexter: A boosting-based system for text categorization. Machine Learning, 39(2/3):135168."},{"authors":[{"last":"Smola"},{"first":"Alex","last":"J."},{"first":"Bernhard","last":"Sch¤olkopf"}],"year":"1998","title":"A tutorial on support vector regression","source":"Smola, Alex J. and Bernhard Sch¤olkopf. 1998. A tutorial on support vector regression. Technical Report Neuro-COLT NC-TR-98-030, Royal Holloway College, University of London."},{"authors":[{"last":"Subasic"},{"last":"Pero"},{"first":"Alison","last":"Huettner"}],"year":"2001","title":"Affect analysis of text using fuzzy semantic typing","source":"Subasic, Pero and Alison Huettner. 2001. Affect analysis of text using fuzzy semantic typing. IEEE Transactions on Fuzzy Systems, 9(4):483496."},{"authors":[{"last":"Takamura"},{"last":"Hiroya"},{"first":"Yuji","last":"Matsumoto"},{"first":"Hiroyasu","last":"Yamada"}],"year":"2004","title":"Modeling category structures with a kernel function","source":"Takamura, Hiroya, Yuji Matsumoto, and Hiroyasu Yamada. 2004. Modeling category structures with a kernel function. In Proceedings of CoNLL, pages 5764."},{"authors":[{"last":"Tong"},{"first":"Richard","last":"M"}],"year":"2001","title":"An operational system for detecting and tracking opinions in on-line discussion","source":"Tong, Richard M. 2001. An operational system for detecting and tracking opinions in on-line discussion. SIGIR Workshop on Operational Text Classication."},{"authors":[{"last":"Turney"},{"last":"Peter"}],"year":"2002","title":"Thumbs up or thumbs down? Semantic orientation applied to unsupervised classication of reviews","source":"Turney, Peter. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classication of reviews. In Proceedings of the ACL, pages 417424."},{"authors":[{"last":"Vapnik"},{"last":"Vladimir"}],"year":"1995","title":"The Nature of Statistical Learning Theory","source":"Vapnik, Vladimir. 1995. The Nature of Statistical Learning Theory. Springer."},{"authors":[{"last":"Wilson"},{"last":"Theresa"},{"first":"Janyce","last":"Wiebe"},{"first":"Rebecca","last":"Hwa"}],"year":"2004","title":"Just how mad are you? Finding strong and weak opinion clauses","source":"Wilson, Theresa, Janyce Wiebe, and Rebecca Hwa. 2004. Just how mad are you? Finding strong and weak opinion clauses. In Proceedings of AAAI, pages 761769."},{"authors":[{"last":"Yu"},{"last":"Hong"},{"first":"Vasileios","last":"Hatzivassiloglou"}],"year":"2003","title":"Towards an-swering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences","source":"Yu, Hong and Vasileios Hatzivassiloglou. 2003. Towards an-swering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of EMNLP."},{"authors":[{"last":"Zhu"},{"first":"Xiaojin","last":"(Jerry)"}],"year":"2005","title":"Semi-Supervised Learning with Graphs","source":"Zhu, Xiaojin (Jerry). 2005. Semi-Supervised Learning with Graphs. Ph.D. thesis, Carnegie Mellon University."}],"cites":[{"style":0,"text":"Shanahan, and Wiebe (2004)","origin":{"pointer":"/sections/2/paragraphs/0","offset":259,"length":26},"authors":[{"last":"Shanahan"},{"last":"Wiebe"}],"year":"2004","references":[]},{"style":0,"text":"Turney, 2002","origin":{"pointer":"/sections/2/paragraphs/0","offset":486,"length":12},"authors":[{"last":"Turney"}],"year":"2002","references":[]},{"style":0,"text":"Lee, and Vaithyanathan, 2002","origin":{"pointer":"/sections/2/paragraphs/0","offset":506,"length":28},"authors":[{"last":"Lee"},{"last":"Vaithyanathan"}],"year":"2002","references":[]},{"style":0,"text":"Lawrence, and Pennock, 2003","origin":{"pointer":"/sections/2/paragraphs/0","offset":542,"length":27},"authors":[{"last":"Lawrence"},{"last":"Pennock"}],"year":"2003","references":[]},{"style":0,"text":"Yu and Hatzivassiloglou, 2003","origin":{"pointer":"/sections/2/paragraphs/0","offset":571,"length":29},"authors":[{"last":"Yu"},{"last":"Hatzivassiloglou"}],"year":"2003","references":[]},{"style":0,"text":"Wiebe, and Hwa, 2004","origin":{"pointer":"/sections/2/paragraphs/1","offset":298,"length":20},"authors":[{"last":"Wiebe"},{"last":"Hwa"}],"year":"2004","references":[]},{"style":0,"text":"Koppel and Schler (2005)","origin":{"pointer":"/sections/2/paragraphs/2","offset":83,"length":24},"authors":[{"last":"Koppel"},{"last":"Schler"}],"year":"2005","references":[]},{"style":0,"text":"Kleinberg and Tardos, 2002","origin":{"pointer":"/sections/2/paragraphs/2","offset":390,"length":26},"authors":[{"last":"Kleinberg"},{"last":"Tardos"}],"year":"2002","references":[]},{"style":0,"text":"Wiebe, and Hwa, 2004","origin":{"pointer":"/sections/2/paragraphs/4","offset":172,"length":20},"authors":[{"last":"Wiebe"},{"last":"Hwa"}],"year":"2004","references":[]},{"style":0,"text":"Subasic and Huettner, 2001","origin":{"pointer":"/sections/2/paragraphs/4","offset":222,"length":26},"authors":[{"last":"Subasic"},{"last":"Huettner"}],"year":"2001","references":[]},{"style":0,"text":"Lieberman, and Selker, 2003","origin":{"pointer":"/sections/2/paragraphs/4","offset":255,"length":27},"authors":[{"last":"Lieberman"},{"last":"Selker"}],"year":"2003","references":[]},{"style":0,"text":"Collins-Thompson and Callan, 2004","origin":{"pointer":"/sections/2/paragraphs/4","offset":300,"length":33},"authors":[{"last":"Collins-Thompson"},{"last":"Callan"}],"year":"2004","references":[]},{"style":0,"text":"Jacobs, and Hovel, 1999","origin":{"pointer":"/sections/2/paragraphs/4","offset":373,"length":23},"authors":[{"last":"Jacobs"},{"last":"Hovel"}],"year":"1999","references":[]},{"style":0,"text":"Lee, and Vaithyanathan, 2002","origin":{"pointer":"/sections/3/paragraphs/10","offset":1277,"length":28},"authors":[{"last":"Lee"},{"last":"Vaithyanathan"}],"year":"2002","references":[]},{"style":0,"text":"Turney, 2002","origin":{"pointer":"/sections/3/paragraphs/10","offset":1307,"length":12},"authors":[{"last":"Turney"}],"year":"2002","references":[]},{"style":0,"text":"Pang and Lee, 2004","origin":{"pointer":"/sections/3/paragraphs/12","offset":256,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2004","references":[]},{"style":0,"text":"Joachims’ (1999)","origin":{"pointer":"/sections/4/paragraphs/2","offset":321,"length":16},"authors":[{"last":"Joachims’"}],"year":"1999","references":[]},{"style":0,"text":"Rifkin and Klautau, 2004","origin":{"pointer":"/sections/4/paragraphs/3","offset":108,"length":24},"authors":[{"last":"Rifkin"},{"last":"Klautau"}],"year":"2004","references":[]},{"style":0,"text":"Vapnik, 1995","origin":{"pointer":"/sections/4/paragraphs/10","offset":29,"length":12},"authors":[{"last":"Vapnik"}],"year":"1995","references":[]},{"style":0,"text":"Smola and Sch¤olkopf, 1998","origin":{"pointer":"/sections/4/paragraphs/10","offset":43,"length":26},"authors":[{"last":"Smola"},{"last":"Sch¤olkopf"}],"year":"1998","references":[]},{"style":0,"text":"Wiebe, and Hwa (2004)","origin":{"pointer":"/sections/4/paragraphs/12","offset":8,"length":21},"authors":[{"last":"Wiebe"},{"last":"Hwa"}],"year":"2004","references":[]},{"style":0,"text":"Koppel and Schler (2005)","origin":{"pointer":"/sections/4/paragraphs/12","offset":194,"length":24},"authors":[{"last":"Koppel"},{"last":"Schler"}],"year":"2005","references":[]},{"style":0,"text":"Kleinberg and Tardos, 2002","origin":{"pointer":"/sections/4/paragraphs/12","offset":638,"length":26},"authors":[{"last":"Kleinberg"},{"last":"Tardos"}],"year":"2002","references":[]},{"style":0,"text":"Moore, and Schaal, 1997","origin":{"pointer":"/sections/4/paragraphs/26","offset":10,"length":23},"authors":[{"last":"Moore"},{"last":"Schaal"}],"year":"1997","references":[]},{"style":0,"text":"Ishikawa and Geiger, 1998","origin":{"pointer":"/sections/4/paragraphs/28","offset":139,"length":25},"authors":[{"last":"Ishikawa"},{"last":"Geiger"}],"year":"1998","references":[]},{"style":0,"text":"Veksler, and Zabih, 1999","origin":{"pointer":"/sections/4/paragraphs/28","offset":174,"length":24},"authors":[{"last":"Veksler"},{"last":"Zabih"}],"year":"1999","references":[]},{"style":0,"text":"Ishikawa, 2003","origin":{"pointer":"/sections/4/paragraphs/28","offset":200,"length":14},"authors":[{"last":"Ishikawa"}],"year":"2003","references":[]},{"style":0,"text":"Pang and Lee, 2004","origin":{"pointer":"/sections/4/paragraphs/28","offset":376,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2004","references":[]},{"style":0,"text":"Zhu (2005)","origin":{"pointer":"/sections/4/paragraphs/28","offset":512,"length":10},"authors":[{"last":"Zhu"}],"year":"2005","references":[]},{"style":0,"text":"Das and Chen, 2001","origin":{"pointer":"/sections/5/paragraphs/10","offset":453,"length":18},"authors":[{"last":"Das"},{"last":"Chen"}],"year":"2001","references":[]},{"style":0,"text":"Tong, 2001","origin":{"pointer":"/sections/5/paragraphs/10","offset":473,"length":10},"authors":[{"last":"Tong"}],"year":"2001","references":[]},{"style":0,"text":"Turney, 2002","origin":{"pointer":"/sections/5/paragraphs/10","offset":485,"length":12},"authors":[{"last":"Turney"}],"year":"2002","references":[]},{"style":0,"text":"Koppel and Schler (2005)","origin":{"pointer":"/sections/6/paragraphs/86","offset":612,"length":24},"authors":[{"last":"Koppel"},{"last":"Schler"}],"year":"2005","references":[]},{"style":0,"text":"Rifkin and Klautau (2004)","origin":{"pointer":"/sections/6/paragraphs/86","offset":681,"length":25},"authors":[{"last":"Rifkin"},{"last":"Klautau"}],"year":"2004","references":[]},{"style":0,"text":"McCullagh, 1980","origin":{"pointer":"/sections/7/paragraphs/1","offset":239,"length":15},"authors":[{"last":"McCullagh"}],"year":"1980","references":[]},{"style":0,"text":"Graepel, and Obermayer, 2000","origin":{"pointer":"/sections/7/paragraphs/1","offset":266,"length":28},"authors":[{"last":"Graepel"},{"last":"Obermayer"}],"year":"2000","references":[]},{"style":0,"text":"McCallum, 1999","origin":{"pointer":"/sections/7/paragraphs/1","offset":581,"length":14},"authors":[{"last":"McCallum"}],"year":"1999","references":[]},{"style":0,"text":"Schapire and Singer, 2000","origin":{"pointer":"/sections/7/paragraphs/1","offset":597,"length":25},"authors":[{"last":"Schapire"},{"last":"Singer"}],"year":"2000","references":[]},{"style":0,"text":"Matsumoto, and Yamada, 2004","origin":{"pointer":"/sections/7/paragraphs/1","offset":634,"length":27},"authors":[{"last":"Matsumoto"},{"last":"Yamada"}],"year":"2004","references":[]},{"style":0,"text":"Engstr¤om, 2004","origin":{"pointer":"/sections/7/paragraphs/2","offset":256,"length":15},"authors":[{"last":"Engstr¤om"}],"year":"2004","references":[]},{"style":0,"text":"Das and Chen, 2001","origin":{"pointer":"/sections/7/paragraphs/2","offset":327,"length":18},"authors":[{"last":"Das"},{"last":"Chen"}],"year":"2001","references":[]},{"style":0,"text":"Koppel and Schler (2005)","origin":{"pointer":"/sections/7/paragraphs/2","offset":349,"length":24},"authors":[{"last":"Koppel"},{"last":"Schler"}],"year":"2005","references":[]},{"style":0,"text":"Koppel and Schler (2005)","origin":{"pointer":"/sections/8/paragraphs/6","offset":135,"length":24},"authors":[{"last":"Koppel"},{"last":"Schler"}],"year":"2005","references":[]}]}
