{"sections":[{"title":"","paragraphs":["Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 997–1005, Jeju, Republic of Korea, 8-14 July 2012. c⃝2012 Association for Computational Linguistics"]},{"title":"Polarity Consistency Checking for Sentiment Dictionaries Eduard Dragut Cyber Center Purdue University","paragraphs":["edragut@purdue.edu"]},{"title":"Hong Wang Clement Yu Prasad Sistla Computer Science Dept. University of Illinois at Chicago","paragraphs":["{hwang207,cyu,sistla}@uic.edu"]},{"title":"Weiyi Meng Computer Science Dept. Binghamton University","paragraphs":["meng@cs.binghamton.edu"]},{"title":"Abstract","paragraphs":["Polarity classification of words is important for applications such as Opinion Mining and Sentiment Analysis. A number of sentiment word/sense dictionaries have been manually or (semi)automatically constructed. The dictionaries have substantial inaccuracies. Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection. We introduce the concept of polarity consistency of words/senses in sentiment dictionaries in this paper. We show that the consistency problem is NP-complete. We reduce the polarity consistency problem to the satisfiability problem and utilize a fast SAT solver to detect inconsistencies in a sentiment dictionary. We perform experiments on four sentiment dictionaries and WordNet."]},{"title":"1 Introduction","paragraphs":["The opinions expressed in various Web and media outlets (e.g., blogs, newspapers) are an important yardstick for the success of a product or a govern-ment policy. For instance, a product with consistently good reviews is likely to sell well. The general approach is to summarize the semantic polarity (i.e., positive or negative) of sentences/documents by analysis of the orientations of the individual words (Pang and Lee, 2004; Danescu-N.-M. et al., 2009; Kim and Hovy, 2004; Takamura et al., 2005). Sentiment dictionaries are utilized to facilitate the summarization. There are numerous works that, given a sentiment lexicon, analyze the structure of a sentence/document to infer its orientation, the holder of an opinion, the sentiment of the opinion, etc. (Breck et al., 2007; Ding and Liu, 2010; Kim and Hovy, 2004). Several domain independent sentiment dictionaries have been manually or (semi)-automatically created, e.g., General Inquirer (GI) (Stone et al., 1996), Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), SentiWordNet (Baccianella et al., 2010) and Q-WordNet (Agerri and Garc ı́a-Serrano, 2010). Q-WordNet and SentiWordNet are lexical resources which classify the synsets(senses) in WordNet according to their polarities. We call them sentiment sense dictionaries (SSD). OF, GI and AL are called sentiment word dictionaries (SWD). They consist of words manually annotated with their corresponding polarities. The sentiment dictionaries have the following problems: • They exhibit substantial (intra-dictionary) inac-","curacies. For example, the synset","{Indo-European, Indo-Aryan, Aryan} (of or re-","lating to the former Indo-European people),","has a negative polarity in Q-WordNet, while","most people would agree that this synset has a","neutral polarity instead. • They have (inter-dictionary) inconsistencies.","For example, the adjective cheap is positive in","AL and negative in OF. • These dictionaries do not address the concept of","polarity (in)consistency of words/synsets.","We concentrate on the concept of (in)consistency in this paper. We define consistency among the polarities of words/synsets in a dictionary and give methods to check it. A couple of examples help illustrate the problem we attempt to address. 997","The first example is the verbs confute and disprove, which have positive and negative polarities, respectively, in OF. According to WordNet, both words have a unique sense, which they share: disprove, confute (prove to be false) ”The physicist disproved his colleagues’ theories” Assuming that WordNet has complete information about the two words, it is rather strange that the words have distinct polarities. By manually checking two other authoritative English dictionaries, Oxford1","and Cambridge2",", we note that the information about confute and disprove in WordNet is the same as that in these dictionaries. So, the problem seems to originate in OF.","The second example is the verbs tantalize and taunt, which have positive and negative polarities, respectively, in OF. They also have a unique sense in WordNet, which they share. Again, there is a contradiction. In this case Oxford dictionary mentions a sense of tantalize that is missing from WordNet: “excite the senses or desires of (someone)”. This sense conveys a positive polarity. Hence, tantalize conveys a positive sentiment when used with this sense.","In summary, these dictionaries have conflicting information. Manual checking of sentiment dictionaries for inconsistency is a difficult endeavor. We deem words such as confute and disprove inconsistent. We aim to unearth these inconsistencies in sentiment dictionaries. The presence of inconsistencies found via polarity analysis is not exclusively attributed to one party, i.e., either the sentiment dictionary or WordNet. Instead, as emphasized by the above examples, some of them lie in the sentiment dictionaries, while others lie in WordNet. Therefore, a by-product of our polarity consistency analysis is that it can also locate some of the likely places where WordNet needs linguists’ attention.","We show that the problem of checking whether the polarities of a set of words is consistent is NP-complete. Fortunately, the consistency problem can be reduced to the satisfiability problem (SAT). A fast SAT solver is utilized to detect inconsistencies and it is known such solvers can in practice determine consistency or detect inconsistencies. Experimental results show that substantial inconsistencies 1 http://oxforddictionaries.com/ 2 http://dictionary.cambridge.org/ are discovered among words with polarities within and across sentiment dictionaries. This suggests that some remedial work needs to be performed on these sentiment dictionaries as well as on WordNet. The contributions of this paper are: • address the consistency of polarities of","words/senses. The problem has not been","addressed before; • show that the consistency problem is NP-","complete; • reduce the polarity consistency problem to the","satisfiability problem and utilize a fast SAT","solver to detect inconsistencies; • give experimental results to demonstrate that our","technique identifies considerable inconsistencies","in various sentiment lexicons as well as discrep-","ancies between these lexicons and WordNet."]},{"title":"2 Problem Definition","paragraphs":["The polarities of the words in a sentiment dictionary may not necessarily be consistent (or correct). In this paper, we focus on the detection of polarity assignment inconsistencies for the words and synsets within and across dictionaries (e.g., OF vs. GI). We attempt to pinpoint the words with polarity inconsistencies and classify them (Section 3). 2.1 WordNet We give a formal characterization of WordNet. This consists of words, synsets and frequency counts. A word-synset network N is quadruple (W, S, E, f ) where W is a finite set of words, S is a finite set of synsets, E is a set of undirected edges between elements in W and S, i.e., E ⊆ W × S and f is a function assigning a positive integer to each element in E. For an edge (w, s), f (w, s) is called the frequency of use of w in the sense given by s. For any word w and synset s, we say that s is a synset of w if (w, s) ∈ E. Also, for any word w, we let f req(w) denote the sum of all f (w, s) such that (w, s) ∈ E. If a synset has a 0 frequency of use we replace it with 0.1, which is a standard smoothing technique (Han, 2005). For instance, the word cheap has four senses. The frequencies of occurrence of the word in the four senses are f1 = 9, f2 = 1, f3 = 1 and f4 = 0, respectively. By smoothing, f4 = 0.1. Hence, f req(cheap) = f1 + f2 + f3 + f4 = 11.1. The relative frequency of the synset in the first sense of cheap, which denotes the probability that the word is used in the first sense, is f1","freq(cheap) = 9","11.1 = 0.81. 998 2.2 Consistent Polarity Assignment We assume that each synset has a unique polarity. We define the polarity of a word to be a discrete probability distribution: P+, P−, P0 with P+ +P− + P0 = 1, where they represent the “likelihoods” that the word is positive, negative or neutral, respectively. We call this distribution a polarity distribution. For instance, the word cheap has the polarity distribution P+ = 0.81, P− = 0.19 and P0 = 0. The polarity distribution of a word is estimated using the polarities of its underlying synsets. For instance cheap has four senses, with the first sense being positive and the last three senses being negative. The probability that the word expresses a negative sentiment is P− = f2+f3+f4","freq(cheap) = 0.19, while the probability that the word expresses a positive sentiment is P+ = f1","freq(cheap) = 0.81. P0 = 1 − P+ − P− = 0.","Our view of characterizing the polarity of a word using a polarity distribution is shared with other previous works (Kim and Hovy, 2006; Andreevskaia and Bergler, 2006). Nonetheless, we depart from these works in the following key aspect. We say that a word has a (mostly) positive (negative) polarity if the majority sense of the word is positive (negative). That is, a word has a mostly positive polarity if P+ > P− + P0 and it has a mostly negative polarity if P− > P+ + P0. Or, equivalently, if P + > 1","2 or P− > 1","2 , respectively. For example, on majority, cheap conveys positive polarity since P+ = .081 > 1","2 , i.e., the majority sense of the word cheap has positive connotation.","Based on this study, we contend that GI, OF and AL tacitly assume this property. For example, the verb steal is assigned only negative polarity in GI. This word has two other less frequently occurring senses, which have positive polarities. The polarity of steal according to these two senses is not mentioned in GI. This is the case for the overwhelm-ing majority of the entries in the three dictionaries: only 112 out of a total of 14,105 entries in the three dictionaries regard words with multiple polarities. For example, the verb arrest is mentioned with both negative and positive polarities in GI. We regard an entry in an SWD as the majority sense of the word has the specified polarity, although the word may carry other polarities. For instance, the adjective cheap has positive polarity in GI. The only as-sumption we make about the word is that it has a polarity distribution such that P+ > P− + P0. This in-terpretation is consistent with the senses of the word. In this work we show that this property allows the polarities of words in input sentiment dictionaries to be checked. We formally state this property. Definition 1. Let w be a word and Sw its set of synsets. Each synset in Sw has an associated polarity and a relative frequency with respect to w. w has polarity p, p ∈ {positive, negative} if there is a subset of synsets S′","⊆ S","w such that each synset","s ∈ S′","has polarity p and ∑","s∈S′","f(w,s)","freq(w) > 0.5. S′","is called a polarity dominant subset. If there is no","such subset then w has a neutral polarity.","S′","⊆ S","w is a minimally dominant subset of synsets (MDSs) if the sum of the relative frequencies of the synsets in S′","is larger than 0.5 and the removal of any synset s from S′","will make the sum of the relative frequencies of the synsets in S′","− {s} smaller than or equal to 0.5.","The definition does not preclude a word from having a polarity with a majority sense and a different polarity with a minority sense. For example, the definition does not prevent a word from having both positive and negative senses, but it prevents a word from concomitantly having a majority sense of being positive and a majority sense of being negative.","Despite using a “hard-coded” constant in the definition, our approach is generic and does not dependent on the constant 0.5. This constant is just a lower bound for deciding whether a word has a majority sense with a certain polarity. It also is intuitively appealing. The constant can be replaced with an arbitrary threshold τ between 0.5 and 1.","We need a formal description of polarity assignments to the words and synsets in WordNet. We assign polarities from the set P = {positive, negative, neutral} to elements in W ∪ S. Formally, a polarity assignment γ for a network N is a function from W ∪ S to the set P. Let γ be a polarity assignment for N . We say that γ is consistent if it satisfies the following condition for each w ∈ W:","For p ∈ {positive, negative}, γ(w) = p iff the sum of all f (w, s) such that (w, s) ∈ E and γ(s) = p, is greater than","f req(w) 2 . Note that, for any w ∈ W, γ(w) = neutral iff the above inequality is not satisfied for both values of p in {positive, negative}.","We contend that our approach is applicable to do-999 Table 1: Disagreement between dictionaries. Pairs of Word Polarity Disagreement Dictionaries Inconsistency Overlap OF & GI 90 2,924 OF & AL 73 1,150 GI & AL 18 712 main dependent sentiment dictionaries, too. We can employ WordNet Domains (Bentivogli et al., 2004). WordNet Domains augments WordNet with domain labels. Hence, we can project the words/synsets in WordNet according to a domain label and then apply our methodology to the projection."]},{"title":"3 Inconsistency Classification","paragraphs":["Polarity inconsistencies are of two types: input and complex. We discuss them in this section. 3.1 Input Dictionaries Polarity Inconsistency Input polarity inconsistencies are of two types: intra-dictionary and inter-dictionary inconsistencies. The latter are obtained by comparing (1) two SWDs, (2) an SWD with an SSD and (3) two SSDs. 3.1.1 Intra-dictionary inconsistency","An SWD may have triplets of the form (w, pos, p) and (w, pos, p′","), where p ̸= p′",". For instance, the verb brag has both positive and negative polarities in OF. For these cases, we look up WordNet and apply Definition 1 to determine the polarity of word w with part of speech pos. The verb brag has negative polarity according to Definition 1. Such cases simply say that the team who constructs the dictionary believes the word has multiple polarities as they do not adopt our dominant sense principle. There are 58 occurrences of this type of inconsistency in GI, OF and AL. Q-WordNet, a sentiment sense dictionary, does not have intra-inconsistencies as it does do not have a synset with multiple polarities. 3.1.2 Inter-dictionary inconsistency","A word belongs to this category if it appears with different polarities in different SWDs. For instance, the adjective joyless has positive polarity in OF and negative polarity in GI. Table 1 depicts the overlapping relationships between the three SWDs: e.g., OF has 2,933 words in common with GI. The three dictionaries largely agree on the polarities of the words they pairwise share. For instance, out of 2,924 words shared by OF and GI, 2,834 have the same polarities. However, there are also a significant number of words which have different polarities across dictionaries. Case in point, OF and GI disagree on the polarities of 90 words. Among the three dictionaries there are 181 polarity inconsistent words. These words are manually corrected using Definition 1 be-fore the polarity consistency checking is applied to the union of the three dictionaries. This union is called disagreement-free union. 3.2 Complex Polarity Inconsistency This kind of inconsistency is more subtle and cannot be detected by direct comparison of words/synsets. They consist of sets of words and/or synsets whose polarities cannot concomitantly be satisfied. Recall the example of the verbs confute and disprove in OF given in Section 1. Recall our argument that by assuming that WordNet is correct, it is not possible for the two words to have different polarities: the sole synset, which they share, would have two different polarities, which is a contradiction.","The occurrence of an inconsistency points out the presence of incorrect input data: • the information given in WordNet is incorrect, or • the information in the given sentiment dictionary","is incorrect, or both.","Regarding WordNet, the errors may be due to (1) a word has senses that are missing from WordNet or (2) the frequency count of a synset is inaccurate. A comprehensive analysis of every synset/word with inconsistency is a tantalizing endeavor requiring not only a careful study of multiple sources (e.g., dictionaries such as Oxford and Cambridge) but also linguistic expertise. It is beyond the scope of this paper to enlist all potentially inconsistent words/synsets and the possible remedies. Instead, we limit our-selves to drawing attention to the occurrence of these issues through examples, welcoming experts in the area to join the corrective efforts. We give more examples of inconsistencies in order to illustrate additional discrepancies between input dictionaries. 3.2.1 WordNet vs. Sentiment Dictionaries","The adjective bully is an example of a discrepancy between WordNet and a sentiment dictionary. The word has negative polarity in OF and has a single sense in WordNet. The sense is shared with the word nifty, which has positive polarity in OF. By applying Definition 1 to nifty we obtain that the sense is positive, which in turn, by Definition 1, implies that bully is positive. This contradicts the 1000 input polarity of bully. According to the Webster dictionary, the word has a sense (i.e., resembling or characteristic of a bully) which has a negative polarity, but it is not present in WordNet. The example shows the presence of a discrepancy between WordNet and OF, namely, OF seems to assign polarity to a word according to a sense that is not in WordNet. 3.2.2 Across Sentiment Dictionaries","We provide examples of inconsistencies across sentiment dictionaries here. Our first example is obtained by comparing SWDs. The adjective comic has negative polarity in AL and the adjective laughable has positive polarity in OF. Through deduction (i.e., by successive applications of Definition 1), the word risible, which is not present in either of the dictionaries, is assigned negative polarity because of comic and is assigned positive polarity because of laughable.","The second example illustrates that an SWD and an SSD may have contradicting information. The verb intoxicate has three synsets in WordNet, each with the same frequency. Hence, their relative frequencies with respect to intoxicate are 1 3 . On one hand, intoxicate has a negative polarity in GI. This means that P− > 1","2 . On the other hand, two of its three synsets have positive polarity in Q-WordNet. So, P+ = 2","3 > 1","2 , which means that P− < 1","2 . This is a contradiction. This example can also be used to illustrate the presence of a discrepancy between WordNet and sentiment dictionaries. Note that all the frequencies of use of the senses of intoxicate in WordNet are 0. The problem is that when all the senses of a word have a 0 frequency of use, wrong polarity inference may be produced. 3.3 Consistent Polarity Assignment Given the discussion above, it clearly is important to find all occurrences of inconsistent words. This in turn boils down to finding those words with the property that there does not exist any polarity assignment to the synsets, which is consistent with their polarities. It turns out that the complexity of the problem of assigning polarities to the synsets such that the assignment is consistent with the polarities of the input words, called Consistent Polarity Assignment problem, is a “hard” problem, as described below. The problem is stated as follows:","Consider two sets of nodes of type synsets and type words, in which each synset of a word has a relative frequency with respect to the word. Each synset can be assigned a positive, negative or neutral polarity. A word has polarity p if it satisfies the hypothesis of Definition 1. The question to be an-swered is: Given an assignment of polarities to the words, does there exist an assignment of polarities to the synsets that agrees with that of the words?","In other words, given the polarities of a subset of words (e.g., that given by one of the three SWDs) the problem of finding the polarities of the synsets that agree with this assignment is a “hard” problem. Theorem 1. The Consistent Polarity Assignment problem is NP-complete."]},{"title":"4 Polarity Consistency Checking","paragraphs":["To “exhaustively” solve the problem of finding the polarity inconsistencies in an SWD, we propose a solution that reduces an instance of the problem to an instance of CNF-SAT. We can then employ a fast SAT solver (e.g., (Xu et al., 2008; Babic et al., 2006)) to solve our problem. CNF-SAT is a decision problem of determining if there is an assignment of True and False to the variables of a Boolean formula Φ in conjunctive normal form (CNF) such that Φ evaluates to True. A formula is in CNF if it is a conjunction of one or more clauses, each of which is a disjunction of literals. CNF-SAT is a classic NP-complete problem, but, modern SAT solvers are capable of solving many practical instances of the problem. Since, in general, there is no easy way to tell the difficulty of a problem without trying it, SAT solvers include time-outs, so they will terminate even if they cannot find a solution.","We developed a method of converting an instance of the polarity consistency checking problem into an instance of CNF-SAT, which we will describe next. 4.1 Conversion to CNF-SAT The input consists of an SWD D and the word-synset network N . We partition N into connected components. For each synset s we define three Boolean variables s−, s+ and s0, corresponding to the negative, positive and neutral polarities, respectively. In this section we use −, +, 0 to denote negative, positive and neutral polarities, respectively.","Let Φ be the Boolean formula for a connected component M of the word-synset network N . We introduce its clauses. First, for each synset s we need a clause C(s) that expresses that the synset can have 1001 only one of the three polarities: C(s) = (s+ ∧¬s− ∧ ¬s0) ∨ (s− ∧ ¬s+ ∧ ¬s0) ∨ (s0 ∧ ¬s− ∧ ¬s+).","Since a word has a neutral polarity if it has neither positive nor negative polarities, we have that s0 = ¬s+ ∧ ¬s−. Replacing this expression in the equation above and applying standard Boolean logic formulas, we can reduce it to C(s) = ¬s+ ∨ ¬s− (1)","For each word w with polarity p ∈ {−, +, 0} in D we need a clause C(w, p) that states that w has polarity p. So, the Boolean formula for a connected component M of the word-synset network N is: Φ = ∧ s∈M C(s) ∧ ∧ (w,p)∈D C(w, p). (2)","From Definition 1, w is neutral if it is neither positive nor negative. Hence, C(w, 0) = ¬C(w, −) ∧ ¬C(w, +). So, we need to define only the clauses C(w, −) and C(w, +), which correspond to w having polarity negative and positive, respectively. So, herein p ∈ {−, +}, unless otherwise specified.","Our method is based on the following statement in Definition 1: w has polarity p if there exists a polarity dominant subset among its synsets. Thus, C(w, p) is defined by enumerating all the MDSs of w. If at least one of them is a polarity dominant subset then C(w, p) evaluates to True. Exhaustive Enumeration of MDSs Method (EEM) We now elaborate the construction of C(w, p). We enumerate all the MDSs of w and for each of them we introduce a clause. The clauses are then concatenated by OR in the Boolean formula. Let C(w, p, T ) denote the clause for an MDS T of w, when w has polarity p ∈ {−, +}. Hence, C(w, p) = ∨ T ∈MDS(w) C(w, p, T ), (3) where M DS(w) is the set of all MDSs of w. For each MDS T of w, the clause C(w, p, T ) is the AND of the variables corresponding to polarity p of the synsets in T . That is, C(w, p, T ) = ∧ s∈T sp, p ∈ {−, +}. (4)","The formula Φ is not in CNF after this construction and it needs to be converted. The conversion to CNF is a standard procedure and we omit it in this paper. Φ in CNF is input to a SAT solver.","Example 1. Consider a connected component","consisting of the words w = cheap, v =","inexpensive and u = sleazy. cheap has","a positive polarity, whereas inexpensive and","sleazy have negative polarities. The synsets","of these words are: {s1",", s2",", s3",", s4","}, {s1","} and","{s3",", s4",", s5 }, respectively (refer to WordNet). The","relative frequencies of s3",", s4","and s5","w.r.t. sleazy","are all equal to 1/3. We have 15 binary variables,","3 per synset, si","−, si","+, si","0, 1 ≤ i ≤ 5. The only","MDS of cheap is {s1","}, which coincides with that","of inexpensive. Those of sleazy are {s3",", s4","},","{s3",", s5","} and {s4",", s5","}. For each si","we need a clause","C(si","). Hence, C(w, +) = s1","+, C(v, −) = s1","− and","C(u, −) = (s3","− ∧ s4","−) ∨ (s3 − ∧ s5","−) ∨ (s4","− ∧ s5","−). Thus, Φ = ∧ i","C(si",") ∧ [s1","+ ∧ s1","− ∧ ((s3","− ∧ s4","−) ∨","(s3","− ∧ s5","−) ∨ (s4","− ∧ s5","−))]. Φ is not in CNF and","needs to be converted. For Φ to be True, the clauses","C(w, +) = s1","+ and C(v, −) = s1","− must be True.","But, this makes C(s1",") False. Hence, Φ is not satisfi-","able. The clauses C(w, +) = s1","+ and C(v, −) = s1","−","are unsatisfiable and thus the polarities of cheap","and inexpensive are inconsistent. 4.2 Implementation Issues The above reduction is exponential in the number of clauses (see, Equation 3) in the worst case. A polynomial reduction is possible, but it is significantly more complicated to implement. We choose to present the exponential reduction in this paper because it can handle over 97% of the words in WordNet and it is better suited to explain one of the main contributions of paper: the translation from the polarity consistency problem to SAT.","WordNet possesses nice properties, which allows the exponential reduction to run efficiently in practice. First, 97.2% of its (word, part-of-speech) pairs have 4 or fewer synsets. Thus, these words add very few clauses to a CNF formula (Equation 3). Second, WordNet can be partitioned into 33,015 non-trivial connected components, each of which corresponds to a Boolean formula and they all are independently handled. A non-trivial connected component has at least two words. Finally, in practice, not all connected components need to be considered for an input sentiment dictionary D, but only those having at least two words in D. In our experiments the largest number of components that need to be processed is 1002","Table 2: Distribution of words and synsets POS Words Synsets OF GI AL QWN Noun117,798 82,115 1,907 1,444 2 7,403 Verb 11,529 13,767 1,501 1,041 0 4006 Adj. 21,479 18,156 2,608 1,188 1,440 4050 Adv. 4,481 3,621 775 51 317 40 Total155,287 117,659 6,791 3,961 1,759 15,499 1,581, for the disagreement-free union dictionary."]},{"title":"5 Detecting Inconsistencies","paragraphs":["In this section we describe how we detect the words with polarity inconsistencies using the output of a SAT solver. For an unsatisfiable formula, a modern SAT solver returns a minimal unsatisfiable core (MUC) from the original formula. An unsatisfiable core is minimal if it becomes satisfiable whenever any one of its clauses is removed. There are no known practical algorithms for computing the minimum core (Dershowitz et al., 2006). In our problem a MUC corresponds to a set of polarity inconsistent words. The argument is as follows. Consider W the set of words in a connected component and Φ the CNF formula generated with the above method. During the transformation we keep track of the clauses introduced in Φ by each word. Suppose Φ is inconsistent. Then, the SAT solver returns a MUC. Each clause in a MUC is mapped back to its corresponding word(s). We obtain the corresponding subset of words W ′",", W ′","⊆ W . Suppose that Φ′ is the Boolean CNF formula for the words in W ′",". The set of clauses in Φ′","is a subset of those in Φ. Also, the clauses in the MUC appear in Φ′",". Thus, Φ′ is unsatisfiable and the words in W ′","are inconsistent.","To find all inconsistent words we ought to generate all MUCs. Unfortunately, this is a “hard” problem (Dershowitz et al., 2006) and no open source SAT solver possesses this functionality. We however observe that the two SAT solvers we use for our experiments (SAT4j and PicoSAT (Biere, 2008)) return different MUCs for the same formula and we use them to find as many inconsistencies as possible."]},{"title":"6 Experiments","paragraphs":["The goal of the experimental study is to show that our techniques can identify considerable inconsistencies in various sentiment dictionaries.","Table 3: Intra- and inter-dictionaries inconsistency POS OF QW GI QW AL QW UF QW Noun 23 119 4 61 0 42 90 140 Verb 66 113 2 67 0 0 63 137 Adj. 90 170 8 48 0 0 27 177 Adv. 61 1 0 0 2 0 69 1 Total 240 403 14 176 2 42 249 455 Data sets In our experiments, we use WordNet 3.0, GI, OF, AL and Q-WordNet. Their statistics are given in Table 2. The table shows the distribution of the words and synsets per part of speech. Columns 2 and 3 pertain to WordNet. There are 3,961 entries in GI, 1,759 entries in AL and 6,791 entries in OF which appear in WordNet. Q-WordNet has 15,499 entries, i.e., synsets with polarities. Inconsistency Detection We applied our method to (1) each of AL, GI and OF; (2) the disagreement-free union (UF); (3) each of AL, GI and OF together with Q-WordNet and (4) UF and Q-WordNet. Table 3 summarizes the outcome of the experimental study. EEM finds 240, 14 and 2 polarity inconsistent words in OF, GI and AL, respectively. The ratio between the number of inconsistent words and the number of input words is the highest for OF and the lowest for AL. The union dictionary has 7,794 words and 249 out of them are found to be polarity inconsistent words. Recall that we manually corrected the polarities of 181 words, to the best of our understanding. So, in effect the three dictionaries have 249 + 181 = 430 polarity inconsistent words. As discussed in the previous section, these may not be all the polarity inconsistencies in UF. In general, to find all inconsistencies we need to generate all MUCs. Generating all MUCs is an “overkill” and the SAT solvers we use do not implement such a functionality. In addition, the intention of SAT solver designers is to use MUCs in a interactive manner. That is, the errors pointed out by a MUC are corrected and then the new improved formula is re-evaluated by the SAT solver. If an error is still present a new MUC is reported, and the process repeats until the formula has no errors. Or, in our problem, until a dictionary is consistent.","We also paired Q-WordNet with each of the SWDs. Table 3 presents the results. Observe that polarities assigned to the words in AL and GI largely agree with the polarities assigned to the synsets in 1003 Q-WordNet. This is expected for AL because it has only two nouns and no verb, while Q-WordNet has only 40 adverbs. Consequently, these two dictionaries have limited “overlay”. The union dictionary and Q-WordNet have substantial inconsistencies: the polarity of 455 words in the union dictionary disagrees with the polarities assigned to their underlying synsets in Q-WordNet. Sentence Level Evaluation We took 10 pairs of inconsistent words per part of speech; in total, we collected a set IW of 80 inconsistent words. Let ⟨w, pos, p⟩ ∈ IW , p is the polarity of w. We collected 5 sentences for ⟨w, pos⟩ from the set of snippets returned by Google for query w. We parsed the snippets and identified the first 5 occurrences of w with the part of speech pos. Then two graduate students with English background analyzed the polarities of ⟨w, pos⟩ in the 5 sentences. We counted the number of times ⟨w, pos⟩ appears with polarity p and polarities different from p. We defined an agreement scale: total agreement (5/5), most agreement (4/5), majority agreement (3/5), majority disagreement (2/5), most disagreement (1/5), total disagreement (0/5). We computed the percentage of words per agreement category. We repeated the experiment for 40 randomly drawn words (10 per part of speech) from the set of consistent words. In total 600 sentences were manually analyzed. Figure 1 shows the distribution of the (in)consistent words. For example, the annotators totally agree with the polarities of 55% of the consistent words, whereas they only totally agree with 16% of the polarities of the inconsistent words. The graph suggests that the annotators disagree to some extent (total disagreement + most disagreement + major disagreement) with 40% of the polarities of the inconsistent words, whereas they disagree to some extent with only 5% of the consistent words. We also manually investigated the senses of these words in WordNet. We noted that 36 of the 80 inconsistent words (45%) have missing senses according to one of these English dictionaries: Oxford and Cambridge. Computational Issues We used a 4-core CPU computer with 12GB of memory. EEM requires 10GB of memory and cannot handle words with more than 200,000 MDSs: for UF we left the SAT solver running for a week without ever terminating. In contrast, it takes about 4 hours if we limit the set Figure 1: Human classification of (in)consistent words. of words to those that have up to 200,000 MDSs. EEM could not handle words such as make, give and break. Recall however that we did not generate all MUCs. We do not know how long would that might have taken. (The polynomial method handles all the words in WordNet and it takes 5GB of memory and about 2 hours to finish.)"]},{"title":"7 Related Work","paragraphs":["Several researchers have studied the problem of finding opinion words (Liu, 2010). There are two lines of work on sentiment polarity lexicon induction: corpora-based (Hatzivassiloglou and McKeown, 1997; Kanayama and Nasukawa, 2006; Qiu et al., 2009; Wiebe, 2000) and dictionary-based (Andreevskaia and Bergler, 2006; Agerri and Garcı́a-Serrano, 2010; Dragut et al., 2010; Esuli and Sebastiani, 2005; Baccianella et al., 2010; Hu and Liu, 2004; Kamps et al., 2004; Kim and Hovy, 2006; Rao and Ravichandran, 2009; Takamura et al., 2005). Our work falls into the latter. Most of these works use the lexical relations defined in WordNet (e.g., synonym, antonym) to derive sentiment lexicons. To our knowledge, none of the earlier works studied the problem of polarity consistency checking for a sentiment dictionary. Our techniques can pinpoint the inconsistencies within individual dictionaries and across dictionaries."]},{"title":"8 Conclusion","paragraphs":["We studied the problem of checking polarity consistency for sentiment word dictionaries. We proved that this problem is NP-complete. We showed that in practice polarity inconsistencies of words both within a dictionary and across dictionaries can be obtained using an SAT solver. The inconsistencies are pinpointed and this allows the dictionaries to be improved. We reported experiments on four sentiment dictionaries and their union dictionary. 1004"]},{"title":"Acknowledgments","paragraphs":["This work is supported in part by the following NSF grants: IIS-0842546 and IIS-0842608."]},{"title":"References","paragraphs":["Rodrigo Agerri and Ana Garcı́a-Serrano. 2010. Q-wordnet: Extracting polarity from wordnet senses. In LREC.","A. Andreevskaia and S. Bergler. 2006. Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses. In EACL.","Domagoj Babic, Jesse Bingham, and Alan J. Hu. 2006. B-cubing: New possibilities for efficient sat-solving. TC, 55(11).","Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In LREC, Valletta, Malta, May.","Luisa Bentivogli, Pamela Forner, Bernardo Magnini, and Emanuele Pianta. 2004. Revising the wordnet do-mains hierarchy: semantics, coverage and balancing. MLR.","Armin Biere. 2008. PicoSAT essentials. JSAT, 4(2-4):75–97.","Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In IJCAI.","Cristian Danescu-N.-M., Gueorgi Kossinets, Jon Kleinberg, and Lillian Lee. 2009. How opinions are received by online communities: a case study on amazon.com helpfulness votes. In WWW, pages 141–150.","Nachum Dershowitz, Ziyad Hanna, and Er Nadel. 2006. A scalable algorithm for minimal unsatisfiable core extraction. In In Proc. SAT06. Springer.","Xiaowen Ding and Bing Liu. 2010. Resolving object and attribute coreference in opinion mining. In COLING.","Eduard C. Dragut, Clement T. Yu, A. Prasad Sistla, and Weiyi Meng. 2010. Construction of a sentimental word dictionary. In CIKM, pages 1761–1764.","Andrea Esuli and Fabrizio Sebastiani. 2005. Determining the semantic orientation of terms through gloss classification. In CIKM, pages 617–624.","Jiawei Han. 2005. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers Inc.","Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In ACL, pages 174–181, Stroudsburg, PA, USA. Association for Computational Linguistics.","Minqing Hu and Bing Liu. 2004. Mining and summariz-ing customer reviews. In ACM SIGKDD, pages 168– 177, New York, NY, USA. ACM.","J. Kamps, M. Marx, R. Mokken, and M. de Rijke. 2004. Using wordnet to measure semantic orientation of adjectives. In LREC.","Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domain-oriented sentiment analysis. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 355–363, Stroudsburg, PA, USA. Association for Computational Linguistics.","M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In COLING.","Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. In HLT-NAACL.","Bing Liu. 2010. Sentiment analysis and subjectivity. In Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing, Second Edition. CRC Press, Taylor and Francis Group, Boca Raton, FL. ISBN 978-1420085921.","B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACL.","Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In IJCAI, pages 1199–1204.","Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In EACL.","P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. 1996. The general inquirer: A computer approach to content analysis. In MIT Press.","M. Taboada and J. Grieve. 2004. Analyzing appraisal automatically. In AAAI Spring Symposium.","Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In ACL, pages 133–140.","Janyce Wiebe. 2000. Learning subjective adjectives from corpora. In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence, pages 735–740. AAAI Press.","T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recogniz-ing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP.","Lin Xu, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 2008. Satzilla: portfolio-based algorithm selection for sat. J. Artif. Int. Res., 32:565–606, June. 1005"]}],"references":[{"authors":[{"first":"Rodrigo","last":"Agerri"},{"first":"Ana","last":"Garcı́a-Serrano"}],"year":"2010","title":"Q-wordnet: Extracting polarity from wordnet senses","source":"Rodrigo Agerri and Ana Garcı́a-Serrano. 2010. Q-wordnet: Extracting polarity from wordnet senses. In LREC."},{"authors":[{"first":"A.","last":"Andreevskaia"},{"first":"S.","last":"Bergler"}],"year":"2006","title":"Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses","source":"A. Andreevskaia and S. Bergler. 2006. Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses. In EACL."},{"authors":[{"first":"Domagoj","last":"Babic"},{"first":"Jesse","last":"Bingham"},{"first":"Alan","middle":"J.","last":"Hu"}],"year":"2006","title":"B-cubing: New possibilities for efficient sat-solving","source":"Domagoj Babic, Jesse Bingham, and Alan J. Hu. 2006. B-cubing: New possibilities for efficient sat-solving. TC, 55(11)."},{"authors":[{"first":"Stefano","last":"Baccianella"},{"first":"Andrea","last":"Esuli"},{"first":"Fabrizio","last":"Sebastiani"}],"year":"2010","title":"SentiWordNet 3","source":"Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In LREC, Valletta, Malta, May."},{"authors":[{"first":"Luisa","last":"Bentivogli"},{"first":"Pamela","last":"Forner"},{"first":"Bernardo","last":"Magnini"},{"first":"Emanuele","last":"Pianta"}],"year":"2004","title":"Revising the wordnet do-mains hierarchy: semantics, coverage and balancing","source":"Luisa Bentivogli, Pamela Forner, Bernardo Magnini, and Emanuele Pianta. 2004. Revising the wordnet do-mains hierarchy: semantics, coverage and balancing. MLR."},{"authors":[{"first":"Armin","last":"Biere"}],"year":"2008","title":"PicoSAT essentials","source":"Armin Biere. 2008. PicoSAT essentials. JSAT, 4(2-4):75–97."},{"authors":[{"first":"Eric","last":"Breck"},{"first":"Yejin","last":"Choi"},{"first":"Claire","last":"Cardie"}],"year":"2007","title":"Identifying expressions of opinion in context","source":"Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In IJCAI."},{"authors":[{"first":"Cristian","last":"Danescu-N.-M."},{"first":"Gueorgi","last":"Kossinets"},{"first":"Jon","last":"Kleinberg"},{"first":"Lillian","last":"Lee"}],"year":"2009","title":"How opinions are received by online communities: a case study on amazon","source":"Cristian Danescu-N.-M., Gueorgi Kossinets, Jon Kleinberg, and Lillian Lee. 2009. How opinions are received by online communities: a case study on amazon.com helpfulness votes. In WWW, pages 141–150."},{"authors":[{"first":"Nachum","last":"Dershowitz"},{"first":"Ziyad","last":"Hanna"},{"first":"Er","last":"Nadel"}],"year":"2006","title":"A scalable algorithm for minimal unsatisfiable core extraction","source":"Nachum Dershowitz, Ziyad Hanna, and Er Nadel. 2006. A scalable algorithm for minimal unsatisfiable core extraction. In In Proc. SAT06. Springer."},{"authors":[{"first":"Xiaowen","last":"Ding"},{"first":"Bing","last":"Liu"}],"year":"2010","title":"Resolving object and attribute coreference in opinion mining","source":"Xiaowen Ding and Bing Liu. 2010. Resolving object and attribute coreference in opinion mining. In COLING."},{"authors":[{"first":"Eduard","middle":"C.","last":"Dragut"},{"first":"Clement","middle":"T.","last":"Yu"},{"first":"A.","middle":"Prasad","last":"Sistla"},{"first":"Weiyi","last":"Meng"}],"year":"2010","title":"Construction of a sentimental word dictionary","source":"Eduard C. Dragut, Clement T. Yu, A. Prasad Sistla, and Weiyi Meng. 2010. Construction of a sentimental word dictionary. In CIKM, pages 1761–1764."},{"authors":[{"first":"Andrea","last":"Esuli"},{"first":"Fabrizio","last":"Sebastiani"}],"year":"2005","title":"Determining the semantic orientation of terms through gloss classification","source":"Andrea Esuli and Fabrizio Sebastiani. 2005. Determining the semantic orientation of terms through gloss classification. In CIKM, pages 617–624."},{"authors":[{"first":"Jiawei","last":"Han"}],"year":"2005","title":"Data Mining: Concepts and Techniques","source":"Jiawei Han. 2005. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers Inc."},{"authors":[{"first":"Vasileios","last":"Hatzivassiloglou"},{"first":"Kathleen","middle":"R.","last":"McKeown"}],"year":"1997","title":"Predicting the semantic orientation of adjectives","source":"Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In ACL, pages 174–181, Stroudsburg, PA, USA. Association for Computational Linguistics."},{"authors":[{"first":"Minqing","last":"Hu"},{"first":"Bing","last":"Liu"}],"year":"2004","title":"Mining and summariz-ing customer reviews","source":"Minqing Hu and Bing Liu. 2004. Mining and summariz-ing customer reviews. In ACM SIGKDD, pages 168– 177, New York, NY, USA. ACM."},{"authors":[{"first":"J.","last":"Kamps"},{"first":"M.","last":"Marx"},{"first":"R.","last":"Mokken"},{"first":"M.","last":"de Rijke"}],"year":"2004","title":"Using wordnet to measure semantic orientation of adjectives","source":"J. Kamps, M. Marx, R. Mokken, and M. de Rijke. 2004. Using wordnet to measure semantic orientation of adjectives. In LREC."},{"authors":[{"first":"Hiroshi","last":"Kanayama"},{"first":"Tetsuya","last":"Nasukawa"}],"year":"2006","title":"Fully automatic lexicon expansion for domain-oriented sentiment analysis","source":"Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domain-oriented sentiment analysis. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 355–363, Stroudsburg, PA, USA. Association for Computational Linguistics."},{"authors":[{"first":"M.","last":"Kim"},{"first":"E.","last":"Hovy"}],"year":"2004","title":"Determining the sentiment of opinions","source":"M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In COLING."},{"authors":[{"first":"Soo-Min","last":"Kim"},{"first":"Eduard","last":"Hovy"}],"year":"2006","title":"Identifying and analyzing judgment opinions","source":"Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. In HLT-NAACL."},{"authors":[{"first":"Bing","last":"Liu"}],"year":"2010","title":"Sentiment analysis and subjectivity","source":"Bing Liu. 2010. Sentiment analysis and subjectivity. In Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing, Second Edition. CRC Press, Taylor and Francis Group, Boca Raton, FL. ISBN 978-1420085921."},{"authors":[{"first":"B.","last":"Pang"},{"first":"L.","last":"Lee"}],"year":"2004","title":"A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","source":"B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACL."},{"authors":[{"first":"Guang","last":"Qiu"},{"first":"Bing","last":"Liu"},{"first":"Jiajun","last":"Bu"},{"first":"Chun","last":"Chen"}],"year":"2009","title":"Expanding domain sentiment lexicon through double propagation","source":"Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In IJCAI, pages 1199–1204."},{"authors":[{"first":"Delip","last":"Rao"},{"first":"Deepak","last":"Ravichandran"}],"year":"2009","title":"Semisupervised polarity lexicon induction","source":"Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In EACL."},{"authors":[{"first":"P.","last":"Stone"},{"first":"D.","last":"Dunphy"},{"first":"M.","last":"Smith"},{"first":"J.","last":"Ogilvie"}],"year":"1996","title":"The general inquirer: A computer approach to content analysis","source":"P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. 1996. The general inquirer: A computer approach to content analysis. In MIT Press."},{"authors":[{"first":"M.","last":"Taboada"},{"first":"J.","last":"Grieve"}],"year":"2004","title":"Analyzing appraisal automatically","source":"M. Taboada and J. Grieve. 2004. Analyzing appraisal automatically. In AAAI Spring Symposium."},{"authors":[{"first":"Hiroya","last":"Takamura"},{"first":"Takashi","last":"Inui"},{"first":"Manabu","last":"Okumura"}],"year":"2005","title":"Extracting semantic orientations of words using spin model","source":"Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In ACL, pages 133–140."},{"authors":[{"first":"Janyce","last":"Wiebe"}],"year":"2000","title":"Learning subjective adjectives from corpora","source":"Janyce Wiebe. 2000. Learning subjective adjectives from corpora. In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence, pages 735–740. AAAI Press."},{"authors":[{"first":"T.","last":"Wilson"},{"first":"J.","last":"Wiebe"},{"first":"P.","last":"Hoffmann"}],"year":"2005","title":"Recogniz-ing contextual polarity in phrase-level sentiment analysis","source":"T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recogniz-ing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP."},{"authors":[{"first":"Lin","last":"Xu"},{"first":"Frank","last":"Hutter"},{"first":"Holger","middle":"H.","last":"Hoos"},{"first":"Kevin","last":"Leyton-Brown"}],"year":"2008","title":"Satzilla: portfolio-based algorithm selection for sat","source":"Lin Xu, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. 2008. Satzilla: portfolio-based algorithm selection for sat. J. Artif. Int. Res., 32:565–606, June. 1005"}],"cites":[{"style":0,"text":"Pang and Lee, 2004","origin":{"pointer":"/sections/5/paragraphs/0","offset":410,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2004","references":["/references/20"]},{"style":0,"text":"Danescu-N.-M. et al., 2009","origin":{"pointer":"/sections/5/paragraphs/0","offset":430,"length":26},"authors":[{"last":"Danescu-N.-M."},{"last":"al."}],"year":"2009","references":["/references/7"]},{"style":0,"text":"Kim and Hovy, 2004","origin":{"pointer":"/sections/5/paragraphs/0","offset":458,"length":18},"authors":[{"last":"Kim"},{"last":"Hovy"}],"year":"2004","references":["/references/17"]},{"style":0,"text":"Takamura et al., 2005","origin":{"pointer":"/sections/5/paragraphs/0","offset":478,"length":21},"authors":[{"last":"Takamura"},{"last":"al."}],"year":"2005","references":["/references/25"]},{"style":0,"text":"Breck et al., 2007","origin":{"pointer":"/sections/5/paragraphs/0","offset":762,"length":18},"authors":[{"last":"Breck"},{"last":"al."}],"year":"2007","references":["/references/6"]},{"style":0,"text":"Ding and Liu, 2010","origin":{"pointer":"/sections/5/paragraphs/0","offset":782,"length":18},"authors":[{"last":"Ding"},{"last":"Liu"}],"year":"2010","references":["/references/9"]},{"style":0,"text":"Kim and Hovy, 2004","origin":{"pointer":"/sections/5/paragraphs/0","offset":802,"length":18},"authors":[{"last":"Kim"},{"last":"Hovy"}],"year":"2004","references":["/references/17"]},{"style":0,"text":"Stone et al., 1996","origin":{"pointer":"/sections/5/paragraphs/0","offset":954,"length":18},"authors":[{"last":"Stone"},{"last":"al."}],"year":"1996","references":["/references/23"]},{"style":0,"text":"Wilson et al., 2005","origin":{"pointer":"/sections/5/paragraphs/0","offset":996,"length":19},"authors":[{"last":"Wilson"},{"last":"al."}],"year":"2005","references":["/references/27"]},{"style":0,"text":"Taboada and Grieve, 2004","origin":{"pointer":"/sections/5/paragraphs/0","offset":1042,"length":24},"authors":[{"last":"Taboada"},{"last":"Grieve"}],"year":"2004","references":["/references/24"]},{"style":0,"text":"Baccianella et al., 2010","origin":{"pointer":"/sections/5/paragraphs/0","offset":1083,"length":24},"authors":[{"last":"Baccianella"},{"last":"al."}],"year":"2010","references":["/references/3"]},{"style":0,"text":"Serrano, 2010","origin":{"pointer":"/sections/5/paragraphs/0","offset":1144,"length":13},"authors":[{"last":"Serrano"}],"year":"2010","references":[]},{"style":0,"text":"Han, 2005","origin":{"pointer":"/sections/6/paragraphs/0","offset":1084,"length":9},"authors":[{"last":"Han"}],"year":"2005","references":["/references/12"]},{"style":0,"text":"Kim and Hovy, 2006","origin":{"pointer":"/sections/6/paragraphs/5","offset":117,"length":18},"authors":[{"last":"Kim"},{"last":"Hovy"}],"year":"2006","references":["/references/18"]},{"style":0,"text":"Andreevskaia and Bergler, 2006","origin":{"pointer":"/sections/6/paragraphs/5","offset":137,"length":30},"authors":[{"last":"Andreevskaia"},{"last":"Bergler"}],"year":"2006","references":["/references/1"]},{"style":0,"text":"Bentivogli et al., 2004","origin":{"pointer":"/sections/6/paragraphs/30","offset":292,"length":23},"authors":[{"last":"Bentivogli"},{"last":"al."}],"year":"2004","references":["/references/4"]},{"style":0,"text":"Xu et al., 2008","origin":{"pointer":"/sections/8/paragraphs/0","offset":221,"length":15},"authors":[{"last":"Xu"},{"last":"al."}],"year":"2008","references":["/references/28"]},{"style":0,"text":"Babic et al., 2006","origin":{"pointer":"/sections/8/paragraphs/0","offset":238,"length":18},"authors":[{"last":"Babic"},{"last":"al."}],"year":"2006","references":["/references/2"]},{"style":0,"text":"Dershowitz et al., 2006","origin":{"pointer":"/sections/9/paragraphs/0","offset":411,"length":23},"authors":[{"last":"Dershowitz"},{"last":"al."}],"year":"2006","references":["/references/8"]},{"style":0,"text":"Dershowitz et al., 2006","origin":{"pointer":"/sections/9/paragraphs/7","offset":103,"length":23},"authors":[{"last":"Dershowitz"},{"last":"al."}],"year":"2006","references":["/references/8"]},{"style":0,"text":"Biere, 2008","origin":{"pointer":"/sections/9/paragraphs/7","offset":279,"length":11},"authors":[{"last":"Biere"}],"year":"2008","references":["/references/5"]},{"style":0,"text":"Liu, 2010","origin":{"pointer":"/sections/11/paragraphs/0","offset":71,"length":9},"authors":[{"last":"Liu"}],"year":"2010","references":["/references/19"]},{"style":0,"text":"Hatzivassiloglou and McKeown, 1997","origin":{"pointer":"/sections/11/paragraphs/0","offset":167,"length":34},"authors":[{"last":"Hatzivassiloglou"},{"last":"McKeown"}],"year":"1997","references":["/references/13"]},{"style":0,"text":"Kanayama and Nasukawa, 2006","origin":{"pointer":"/sections/11/paragraphs/0","offset":203,"length":27},"authors":[{"last":"Kanayama"},{"last":"Nasukawa"}],"year":"2006","references":["/references/16"]},{"style":0,"text":"Qiu et al., 2009","origin":{"pointer":"/sections/11/paragraphs/0","offset":232,"length":16},"authors":[{"last":"Qiu"},{"last":"al."}],"year":"2009","references":["/references/21"]},{"style":0,"text":"Wiebe, 2000","origin":{"pointer":"/sections/11/paragraphs/0","offset":250,"length":11},"authors":[{"last":"Wiebe"}],"year":"2000","references":["/references/26"]},{"style":0,"text":"Andreevskaia and Bergler, 2006","origin":{"pointer":"/sections/11/paragraphs/0","offset":285,"length":30},"authors":[{"last":"Andreevskaia"},{"last":"Bergler"}],"year":"2006","references":["/references/1"]},{"style":0,"text":"Agerri and Garcı́a-Serrano, 2010","origin":{"pointer":"/sections/11/paragraphs/0","offset":317,"length":32},"authors":[{"last":"Agerri"},{"last":"Garcı́a-Serrano"}],"year":"2010","references":["/references/0"]},{"style":0,"text":"Dragut et al., 2010","origin":{"pointer":"/sections/11/paragraphs/0","offset":351,"length":19},"authors":[{"last":"Dragut"},{"last":"al."}],"year":"2010","references":["/references/10"]},{"style":0,"text":"Esuli and Sebastiani, 2005","origin":{"pointer":"/sections/11/paragraphs/0","offset":372,"length":26},"authors":[{"last":"Esuli"},{"last":"Sebastiani"}],"year":"2005","references":["/references/11"]},{"style":0,"text":"Baccianella et al., 2010","origin":{"pointer":"/sections/11/paragraphs/0","offset":400,"length":24},"authors":[{"last":"Baccianella"},{"last":"al."}],"year":"2010","references":["/references/3"]},{"style":0,"text":"Hu and Liu, 2004","origin":{"pointer":"/sections/11/paragraphs/0","offset":426,"length":16},"authors":[{"last":"Hu"},{"last":"Liu"}],"year":"2004","references":["/references/14"]},{"style":0,"text":"Kamps et al., 2004","origin":{"pointer":"/sections/11/paragraphs/0","offset":444,"length":18},"authors":[{"last":"Kamps"},{"last":"al."}],"year":"2004","references":["/references/15"]},{"style":0,"text":"Kim and Hovy, 2006","origin":{"pointer":"/sections/11/paragraphs/0","offset":464,"length":18},"authors":[{"last":"Kim"},{"last":"Hovy"}],"year":"2006","references":["/references/18"]},{"style":0,"text":"Rao and Ravichandran, 2009","origin":{"pointer":"/sections/11/paragraphs/0","offset":484,"length":26},"authors":[{"last":"Rao"},{"last":"Ravichandran"}],"year":"2009","references":["/references/22"]},{"style":0,"text":"Takamura et al., 2005","origin":{"pointer":"/sections/11/paragraphs/0","offset":512,"length":21},"authors":[{"last":"Takamura"},{"last":"al."}],"year":"2005","references":["/references/25"]}]}
