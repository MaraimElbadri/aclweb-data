{"sections":[{"title":"","paragraphs":["Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 881–891, Baltimore, Maryland, USA, June 23-25 2014. c⃝2014 Association for Computational Linguistics"]},{"title":"Response-based Learning for Grounded Machine Translation Stefan Riezler and Patrick Simianer and Carolin Haas Department of Computational Linguistics Heidelberg University, 69120 Heidelberg, Germany {riezler,simianer,haas1}@cl.uni-heidelberg.de Abstract","paragraphs":["We propose a novel learning approach for statistical machine translation (SMT) that allows to extract supervision signals for structured learning from an extrinsic response to a translation input. We show how to generate responses by grounding SMT in the task of executing a semantic parse of a translated query against a database. Experiments on the GEOQUERY database show an improvement of about 6 points in F1-score for response-based learning over learning from references only on returning the correct answer from a semantic parse of a translated query. In general, our approach alleviates the dependency on human reference translations and solves the reachability problem in structured learning for SMT."]},{"title":"1 Introduction","paragraphs":["In this paper, we propose a novel approach for learning and evaluation in statistical machine translation (SMT) that borrows ideas from response-based learning for grounded semantic parsing. In this framework, the meaning of a sentence is defined in the context of an extrinsic task. Successful communication of meaning is measured by a successful interaction in this task, and feedback from this interaction is used for learning.","We suggest that in a similar way the preservation of meaning in machine translation should be defined in the context of an interaction in an extrinsic task. For example, in the context of a game, a description of a game rule is translated successfully if correct game moves can be performed based only on the translation. In the context of a question-answering scenario, a question is translated successfully if the correct answer is returned based only on the translation of the query.","We propose a framework of response-based learning that allows to extract supervision signals for structured learning from the response of an extrinsic task to a translation input. Here, learning proceeds by “trying out” translation hypotheses, receiving a response from interacting in the task, and converting this response into a supervision signal for updating model parameters. In case of positive feedback, the predicted translation can be treated as reference translation for a structured learning update. In case of negative feedback, a structural update can be performed against translations that have been approved previously by positive task feedback. This framework has several advantages:","• The supervision signal in response-based learning has a different quality than supervision by human-generated reference translations. While a human reference translation is generated independently of the SMT task, conversion of predicted translations into references is always done with respect to a specific task. In this sense we speak of grounding meaning transfer in an extrinsic task.","• Response-based learning can repeatedly try out system predictions by interacting in the extrinsic task. Instead of and in addition to learning from human reference translations, response-based learning allows to convert multiple system translations into references. This alleviates the supervision problem in cases where parallel data are scarce.","• Task-specific response acts upon system translations. This avoids the problem of unreachability of independently generated reference translations by the SMT system.","The proposed approach of response-based learning opens the doors for various extrinsic tasks 881 in which SMT systems can be trained and evaluated. In this paper, we present a proof-of-concept experiment that uses feedback from a simulated world environment. Building on prior work in grounded semantic parsing, we generate translations of queries, and receive feedback by executing semantic parses of translated queries against the database. Successful response is defined as receiving the same answer from the semantic parses for the translation and the original query. Our experimental results show an improvement of about 6 points in F1-score for response-based learning over standard structured learning from reference translations. We show in an error analysis that this improvement can be attributed to using structural and lexical variants of reference translations as positive examples in response-based learning. Furthermore, translations produced by response-based learning are found to be grammatical. This is due to the possibility to boost similarity to human reference translations by the additional use of a cost function in our approach."]},{"title":"2 Related Work","paragraphs":["The key idea of grounded language learning is to study natural language in the context of a non-linguistic environment, in which meaning is grounded in perception and/or action. This presents an analogy to human learning, where a learner tests her understanding in an actionable setting. Such a setting can be a simulated world environment in which the linguistic representation can be directly executed by a computer system. For example, in semantic parsing, the learning goal is to produce and successfully execute a meaning representation. Executable system ac-tions include access to databases such as the GEOQUERY database on U.S. geography (Wong and Mooney (2006), inter alia), the ATIS travel planning database (Zettlemoyer and Collins (2009), inter alia), robotic control in simulated navigation tasks (Chen and Mooney (2011), inter alia), databases of simulated card games (Goldwasser and Roth (2013), inter alia), or the user-generated contents of FREEBASE (Cai and Yates (2013), inter alia). Since there are many possible correct parses, matching against a single gold standard falls short of grounding in a non-linguistic environment. Rather, the semantic context for interpretation, as well as the success criterion in evaluation is defined by successful execution of an action in the extrinsic environment, e.g., by receiving the correct answer from the database or by successful navigation to the destination. Recent attempts to learn semantic parsing from question-answer pairs without recurring to annotated logical forms have been presented by Kwiatowski et al. (2013), Berant et al. (2013), or Goldwasser and Roth (2013). The algorithms presented in these works are variants of structured prediction that take executability of semantic parses into account. Our work builds upon these ideas, however, to our knowledge the presented work is the first to embed translations into grounded scenarios in order to use feedback from interactions in these scenarios for structured learning in SMT.","A recent important research direction in SMT has focused on employing automated translation as an aid to human translators. Computer as-sisted translation (CAT) subsumes several modes of interaction, ranging from binary feedback on the quality of the system prediction (Saluja et al., 2012), to human post-editing operations on a system prediction resulting in a reference translation (Cesa-Bianchi et al., 2008), to human acceptance or overriding of sentence completion predictions (Langlais et al., 2000; Barrachina et al., 2008; Koehn and Haddow, 2009). In all interaction scenarios, it is important that the system learns dynamically from its errors in order to of-fer the user the experience of a system that adapts to the provided feedback. Since retraining the SMT model after each interaction is too costly, online adaptation after each interaction has be-come the learning protocol of choice for CAT. Online learning has been applied in generative SMT, e.g., using incremental versions of the EM algorithm (Ortiz-Martı́nez et al., 2010; Hardt and Elm-ing, 2010), or in discriminative SMT, e.g., using perceptron-type algorithms (Cesa-Bianchi et al., 2008; Martı́nez-Gómez et al., 2012; Wäschle et al., 2013; Denkowski et al., 2014). In a similar way to deploying human feedback, extrinsic loss functions have been used to provide learning signals for SMT. For example, Nikoulina et al. (2012) propose a setup where an SMT system feeds into cross-language information retrieval, and receives feedback from the performance of translated queries with respect to cross-language retrieval performance. This feedback is used to train a reranker on an n-best list of translations order with respect to retrieval performance. In con-882 Figure 1: Response-based learning cycle for grounding SMT in virtual trivia gameplay. trast to our work, all mentioned approaches to in-teractive or adaptive learning in SMT rely on human post-edits or human reference translations. Our work differs from these approaches in that exactly this dependency is alleviated by learning from responses in an extrinsic task.","Interactive scenarios have been used for evaluation purposes of translation systems for nearly 50 years, especially using human reading comprehension testing (Pfafflin, 1965; Fuji, 1999; Jones et al., 2005), and more recently, using face-to-face conversation mediated via machine translation (Sakamoto et al., 2013). However, despite of-fering direct and reliable prediction of translation quality, the cost and lack of reusability has confined task-based evaluations involving humans to testing scenarios, but prevented a use for interac-tive training of SMT systems as in our work.","Lastly, our work is related to cross-lingual natural language processing such as cross-lingual question answering or cross-lingual information retrieval as conducted at recent evaluation campaigns of the CLEF initiative.1","While these approaches focus on improvements of the respective natural language processing task, our goal is to improve SMT by gathering feedback from the task. 1 http://www.clef-initiative.eu"]},{"title":"3 Grounding SMT in Semantic Parsing","paragraphs":["In this paper, we present a proof-of-concept of our ideas of embedding SMT into simulated world environments as used in semantic parsing. We use the well-known GEOQUERY database on U.S. geography for this purpose. Embedding SMT in a semantic parsing scenario means to define translation quality by the ability of a semantic parser to construct a meaning representation from the translated query, which returns the correct answer when executed against the database. If viewed as simulated gameplay, a valid game move in this scenario returns the correct answer to a translated query.","The diagram in Figure 1 gives a sketch of response-based learning from semantic parsing in the geographical domain. Given a manual German translation of the English query as source sentence, the SMT system produces an English target translation. This sentence is fed into a semantic parser that produces an executable parse representation ph. Feedback is generated by executing the parse against the database of geographical facts. Positive feedback means that the correct answer is received, i.e., exec(pg)","?","= exec(ph) indicates that the same answer is received from the gold standard parse pg and the parse for the hypothesis translation ph; negative feedback results in case a different or no answer is received.","The key advantage of response-based learning 883 is the possibility to receive positive feedback even from predictions that differ from gold standard reference translations, but yet receive the correct answer when parsed and matched against the database. Such structural and lexical variation broadens the learning capabilities in contrast to learning from fixed labeled data. For example, assume the following English query in the geographical domain, and assume positive feedback from executing the corresponding semantic parse against the geographical database: Name prominent elevations in the USA The manual translation of the English original reads Nenne prominente Erhebungen in den USA An automatic translation2","of the German string produces the result Give prominent surveys in the US This translation will trigger negative task-based feedback: A comparison with the original allows the error to be traced back to the ambiguity of the German word Erhebung. Choosing a general domain translation instead of a translation appropriate for the geographical domain hinders the construction of a semantic parse that returns the correct answer from the database. An alternative translation might look as follows: Give prominent heights in the US Despite a large difference to the original English string, key terms such as elevations and heights, or USA and US, can be mapped into the same predicate in the semantic parse, thus allow-ing to receive positive feedback from parse execution against the geographical database."]},{"title":"4 Response-based Online Learning","paragraphs":["Recent approaches to machine learning for SMT formalize the task of discriminating good from bad translations as a structured prediction problem. Assume a joint feature representation φ(x, y) of input sentences x and output translations y ∈ Y (x), and a linear scoring function s(x, y; w) for predicting a translation ŷ (where ⟨·, ·⟩ denotes the standard vector dot product) s.t.","ŷ = arg max y∈Y (x)","s(x, y; w) = arg max y∈Y (x) ⟨w, φ(x, y)⟩ . 2 http://translate.google.com The structured perceptron algorithm (Collins, 2002) learns an optimal weight vector w by updating w on input x(i)","by the following rule, in case the predicted translation ŷ is different from and scored higher than the reference translation y(i)",":","w = w + φ(x(i)",", y(i)",") − φ(x(i)",", ŷ). This stochastic structural update aims to demote weights of features corresponding to incorrect decisions, and to promote weights of features for correct decisions.","An application of structured prediction to SMT involves more than a straightforward replacement of labeled output structures by reference translations. Firstly, update rules that require to compute a feature representation for the reference translation are suboptimal in SMT, because of-ten human-generated reference translations cannot be generated by the SMT system. Such “unreachable” gold-standard translations need to be replaced by “surrogate” gold-standard translations that are close to the human-generated translations and still lie within the reach of the SMT system. Computation of distance to the reference translation usually involves cost functions based on sentence-level BLEU (Nakov et al. (2012), inter alia) and incorporates the current model score, leading to various ramp loss objectives described in Gimpel and Smith (2012).","An alternative approach to alleviate the dependency on labeled training data is response-based learning. Clarke et al. (2010) or Goldwasser and Roth (2013) describe a response-driven learning framework for the area of semantic parsing: Here a meaning representation is “tried out” by iteratively generating system outputs, receiving feedback from world interaction, and updating the model parameters. Applied to SMT, this means that we predict translations and use positive response from acting in the world to create “surrogate” gold-standard translations. This decreases the dependency on a few (mostly only one) reference translations and guides the learner to promote translations that perform well with respect to the extrinsic task.","In the following, we will present a framework that combines standard structured learning from given reference translations with response-based learning from task-approved references. We need to ensure that gold-standard translations lead to positive task-based feedback, that means they can 884 be parsed and executed successfully against the database. In addition, we can use translation-specific cost functions based on sentence-level BLEU in order to boost similarity of translations to human reference translations.","We denote feedback by a binary execution function e(y) ∈ {1, 0} that tests whether executing the semantic parse for the prediction against the database receives the same answer as the parse for the gold standard reference. Our cost function c(y(i)",", y) = (1−BLEU(y(i)",", y)) is based on a version of sentence-level BLEU Nakov et al. (2012). Definey+","as a surrogate gold-standard translation that receives positive feedback, has a high model score, and a low cost of predicting y instead of y(i)",":","y+ = arg max y∈Y (x(i)","):e(y)=1","(","s(x(i)",", y; w) − c(y(i)",", y)) . The opposite of y+","is the translation y−","that leads to negative feedback, has a high model score, and a high cost. It is defined as follows:","y− = arg max y∈Y (x(i)","):e(y)=0","(","s(x(i)",", y; w) + c(y(i)",", y)) . Update rules can be derived by minimization of the following ramp loss objective: min w","( − max y∈Y (x(i)","):e(y)=1","(","s(x(i)",", y; w) − c(y(i)",", y))","+ max y∈Y (x(i)","):e(y)=0","(","s(x(i)",", y; w) + c(y(i)",", y) )) . Minimization of this objective using stochastic (sub)gradient descent (McAllester and Keshet, 2011) yields the following update rule:","w = w + φ(x(i)",", y+ ) − φ(x(i)",", y−","). The intuition behind this update rule is to discriminate the translation y+","that leads to positive feedback and best approximates (or is identical to) the reference within the means of the model from a translation y−","which is favored by the model but does not execute and has high cost. This is done by putting all the weight on the former.","Algorithm 1 presents pseudo-code for our response-driven learning scenario. Upon predicting translation ŷ, in case of positive feedback from the task, we treat the prediction as surrogate reference by setting y+","← ŷ, and by adding it to the set of reference translations for future use. Then","we need to compute y−",", and update by the differ-","ence in feature representations of y+","and y−",", at","a learning rate η. If the feedback is negative, we","want to move the weights away from the predic-","tion, thus we treat it as y−",". To perform an update,","we need to compute y+",". If either y+","or y−","cannot","be computed, the example is skipped.","Algorithm 1 Response-based Online Learning","repeat","for i = 1, . . . , n do","Receive input string x(i)","Predict translation ŷ","Receive task feedback e(ŷ) ∈ {1, 0}","if e(ŷ) = 1 then y+","← ŷ Store ŷ as reference y(i)","for x(i) Compute y−","else y−","← ŷ Receive reference y(i) Compute y+","end if","w ← w + η(φ(x(i)",", y+",") − φ(x(i)",", y−","))","end for","until Convergence","The sketched algorithm allows several varia-tions. In the form depicted above, it allows to use human reference translations in addition to task-approved surrogate references. The cost function can be implemented by different versions of sentence-wise BLEU, or it can be omitted completely so that learning relies on task-based feedback alone, similar to algorithms recently suggested for semantic parsing (Goldwasser and Roth, 2013; Kwiatowski et al., 2013; Berant et al., 2013). Lastly, regularization can be introduced by using update rules corresponding to primal form optimization variants of support vector machines (Collobert and Bengio, 2004; Chapelle, 2007; Shalev-Shwartz et al., 2007)."]},{"title":"5 Experiments 5.1 Experimental Setup","paragraphs":["In our experiments, we use the GEOQUERY database on U.S. geography as provided by Jones 885 method precision recall F1 BLEU 1 CDEC 63.67 58.21 60.82 46.53 2 EXEC 70.36 63.57 66.791","48.001 3 RAMPION 75.58 69.64 72.4912","56.6412 4 REBOL 81.15 75.36 78.15123","55.6612 Table 1: Experimental results using extended parser for returning answers from GEOQUERY (precision, recall, F1) and n-gram match to original English query (BLEU) on 280 re-translated test examples. Best results for each column are highlighted in bold face. Superscripts 1234","denote a significant improvement over the respective method. method precision recall F1 BLEU 1 CDEC 65.59 57.86 61.48 46.53 2 EXEC 66.54 61.79 64.07 46.00 3 RAMPION 67.68 63.57 65.56 55.6712 4 REBOL 70.68 67.14 68.8612","55.6712 Table 2: Experimental results using the original parser for returning answers from GEOQUERY (precision, recall, F1) and n-gram match to original English query (BLEU) on 280 re-translated test examples. et al. (2012).3","The dataset includes 880 English questions and their logical forms. The English strings were manually translated into German by the authors of Jones et al. (2012)), and corrected for typos by the authors of this paper. We follow the provided split into 600 training examples and 280 test examples.","For response-based learning, we retrained the semantic parser of Andreas et al. (2013)4","on the full 880 GEOQUERY examples in order to reach full parse coverage. This parser is itself based on SMT, trained on parallel data consisting of English queries and linearized logical forms, and on a language model trained on linearized logical forms. We used the hierarchical phrase-based variant of the parser. Note that we do not use GEOQUERY test data in SMT training. Parser training includes GEOQUERY test data in order to be less dependent on parse and execution failures in the evaluation: If a translation system, response-based or reference-based, translates the German input into the gold standard English query it should be rewarded by positive task feedback. To doublecheck whether including the 280 test examples in parser training gives an unfair advantage to response-based learning, we also present experimental results using the original parser of Andreas","3","http://homepages.inf.ed.ac.uk/ s1051107/geoquery-2012-08-27.zip","4","https://github.com/jacobandreas/ smt-semparse et al. (2013) that is trained only on the 600 GEOQUERY training examples.","The bilingual SMT system used in our experiments is the state-of-the-art SCFG decoder CDEC (Dyer et al., 2010)5",". We built grammars using its implementation of the suffix array extrac-tion method described in Lopez (2007). For language modeling, we built a modified Kneser-Ney smoothed 5-gram language model using the English side of the training data. We trained the SMT system on the English-German parallel web data provided in the COMMON CRAWL6","(Smith et al., 2013) dataset. 5.2 Compared Systems Method 1 is the baseline system, consisting of the CDEC SMT system trained on the COMMON CRAWL data as described above. This system does not use any GEOQUERY data for training. Methods 2-4 use the 600 training examples from GEOQUERY for discriminative training only.","Variants of the response-based learning algorithm described above are implemented as a standalone tool that operates on CDEC n-best lists of 10,000 translations of the GEOQUERY training data. All variants use sparse features of CDEC as described in Simianer et al. (2012) that extract rule 5 https://github.com/redpony/cdec 6 http://www.statmt.org/wmt13/","training-parallel-commoncrawl.tgz 886 prediction: how many inhabitants has new york reference: how many people live in new york prediction: how big is the population of texas reference: how many people live in texas prediction: which are the cities of the state with the highest elevation reference: what are the cities of the state with the highest point prediction: how big is the population of states , through which the mississippi runs reference: what are the populations of the states through which the mississippi river runs prediction: what state borders california reference: what is the adjacent state of california prediction: what are the capitals of the states which have cities with the name durham reference: what is the capital of states that have cities named durham prediction: what rivers go through states with the least cities reference: which rivers run through states with fewest cities Table 3: Predicted translations by response-based learning (REBOL) leading to positive feedback versus gold standard references. shapes, rule identifiers, and bigrams in rule source and target directly from grammar rules. Method 4, named REBOL, implements REsponse-Based Online Learning by instantiating y+","and y−","to the form described in Section 4: In addition to the model score s, it uses a cost function c based on sentence-level BLEU (Nakov et al., 2012) and tests translation hypotheses for task-based feedback using a binary execution function e. This algorithm can convert predicted translations into references by task-feedback, and additionally use the given original English queries as references. Method 2, named EXEC, relies on task-execution by function e and searches for executable or non-executable translations with highest score s to distinguish positive from negative training examples. It does not use a cost function and thus cannot make use of the original English queries.","We compare response-based learning with a standard structured prediction setup that omits the use of the execution function e in the definition of y+","and y−",". This algorithm can be seen as a stochastic (sub)gradient descent variant of RAMPION (Gimpel and Smith, 2012). It does not make use of the semantic parser, but defines positive and negative examples based on score s and cost c with respect to human reference translations.","We report BLEU (Papineni et al., 2001) of translation system output measured against the original English queries. Furthermore, we report precision, recall, and F1-score for executing semantic parses built from translation system out-puts against the GEOQUERY database. Precision is defined as the percentage of correctly answered examples out of those for which a parse could be produced; recall is defined as the percentage of to-tal examples answered correctly; F1-score is the harmonic mean of both. Statistical significance is measured using Approximate Randomization (Noreen, 1989) where result differences with a pvalue smaller than 0.05 are considered statistically significant.","Methods 2-4 perform structured learning for SMT on the 600 GEOQUERY training examples and re-translate the 280 unseen GEOQUERY test data, following the data split of Jones et al. (2012). Training for RAMPION, REBOL and EXEC was repeated for 10 epochs. The learning rate η is set to a constant that is adjusted by cross-validation on the 600 training examples. 5.3 Empirical Results We present an experimental comparison of the four different systems according to BLEU and 887 reference RAMPION REBOL how many colorado rivers are there how many rivers with the name colorado gives it how many rivers named colorado are there what are the populations of states which border texas how big are the populations of the states , which in texas borders how big are the populations of the states which on texas border what is the biggest capital city in the us","what is the largest city in the usa what is the largest capital in the usa what state borders new york what states limits of new york what states border new york which states border the state with the smallest area what states boundaries of the state with the smallest surface area what states border the state with the smallest surface area Table 4: Predicted translations by response-based learning (REBOL) leading to positive feedback versus translations by supervised structured learning (RAMPION) leading to negative feedback. F1, using an extended semantic parser (trained on 880 GEOQUERY examples) and the original parser (trained on 600 GEOQUERY training examples). The extended parser reaches and F1-score of 99.64% on the 280 GEOQUERY test examples; the original parser yields an F1-score of 82.76%.","Table 1 reports results for the extended semantic parser. A system ranking according to F1-score shows about 6 points difference between the respective methods, ranking REBOL over RAMPION, EXEC and CDEC. The exploitation of task-feedback allows both EXEC and REBOL to improve task-performance over the baseline. REBOL’s combination of task feedback with a cost function achieves the best results since positively executable hypotheses and reference translations can both be exploited to guide the learning process. Since all English reference queries lead to positively executable parses in the setup that uses the extended semantic parser, RAMPION implicitly also has access to task feedback. This allows RAMPION to improve F1 over the baseline. All result differences are statistically significant.","In terms of BLEU score measured against the original English GEOQUERY queries, the best nominal result is obtained by RAMPION which uses them as reference translations. REBOL performs worse since BLEU performance is optimized only implicitly in cases where original English queries function as positive examples. However, the result differences between these two systems do not score as statistically significant. Despite not optimizing for BLEU performance against references, the fact that positively executable translations include the references allows even EXEC to improve BLEU over CDEC which does not use GEOQUERY data at all in training. This result difference is statistically significant.","Table 2 compares the same systems using the original parser trained on 600 training examples. The system ranking according to F1-score shows the same ordering that is obtained when using an extended semantic parser. However, the respective methods are separated only by 3 or less points in F1 score such that only the result difference of REBOL over the baseline CDEC and over EXEC is statistically significant. We conjecture that this is due to a higher number of empty parses on the test set which makes this comparison unstable.","In terms of BLEU measured against the original queries, the result differences between REBOL and RAMPION are not statistically significant, and neither are the result differences between EXEC and CDEC. The result differences between systems of the former group and the systems of latter group are statistically significant. 5.4 Error Analysis For a better understanding of the differences between the results produced by supervised and response-based learning, we conducted an er-888 reference RAMPION REBOL how many states have a higher point than the highest point of the state with the largest capital city in the us how many states have a higher nearby point as the highest point of the state with the largest capital in the usa how many states have a high point than the highest point of the state with the largest capital in the usa how tall is mount mckinley how high is mount mckinley what is mount mckinley what is the longest river that flows through a state that borders indiana how is the longest river , which runs through a state , borders the of indiana what is the longest river which runs through a state of indiana borders what states does the mississippi river run through through which states runs the mississippi through which states is the mississippi which is the highest peak not in alaska how is the highest peaks of not in alaska is what is the highest peak in alaska is Table 5: Predicted translations where supervised structured learning (RAMPION) leads to positive feedback versus translations by response-based learning (REBOL) leading to negative feedback. ror analysis on the test examples. Table 3 shows examples where the translation predicted by response-based learning (REBOL) differs from the gold standard reference translation, but yet leads to positive feedback via a parse that returns the correct answer from the database. The examples show structural and lexical variation that leads to differences on the string level at equivalent positive feedback from the extrinsic task. This can explain the success of response-based learning: Lexical and structural variants of reference translations can be used to boost model parameters to-wards translations with positive feedback, while the same translations might be considered as negative examples in standard structured learning.","Table 4 shows examples where translations from REBOL and RAMPION differ from the gold standard reference, and predictions by REBOL lead to positive feedback, while predictions by RAMPION lead to negative feedback. Table 5 shows examples where translations from RAMPION outperform translations from REBOL in terms of task feedback. We see that predictions from both systems are in general grammatical. This can be attributed to the use of sentence-level BLEU as cost function in RAMPION and REBOL. Translation errors of RAMPION can be traced back to mistranslations of key terms (city versus capital, limits or boundaries versus border). Translation errors of REBOL more frequently show missing translations of terms."]},{"title":"6 Conclusion","paragraphs":["We presented a proposal for a new learning and evaluation framework for SMT. The central idea is to ground meaning transfer in successful interaction in an extrinsic task, and use task-based feedback for structured learning. We presented a proof-of-concept experiment that defines the extrinsic task as executing semantic parses of translated queries against the GEOQUERY database. Our experiments show an improvement of about 6 points in F1-score for response-based learning over structured learning from reference translations. Our error analysis shows that response-based learning generates grammatical translations which is due to the additional use of a cost function that boosts similarity of translations to human reference translations.","In future work, we would like to extend our work on embedding SMT in virtual gameplay to larger and more diverse datasets, and involve human feedback in the response-based learning loop."]},{"title":"References","paragraphs":["Jacob Andreas, Andreas Vlachos, and Stephen Clark. 2013. Semantic parsing as machine translation. In 889 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria.","Sergio Barrachina, Oliver Bender, Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio Lagarda, Hermann Ney, Jesús Tomás, Enrique Vidal, and Juan-Miguel Vilar. 2008. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28.","Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP’13), Seattle, WA.","Qingqing Cai and Alexander Yates. 2013. Large-scale semantic parsing via schema matching and lexicon extenstion. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria.","Nicolò Cesa-Bianchi, Gabriele Reverberi, and San-dor Szedmak. 2008. Online learning algorithms for computer-assisted translation. Technical report, SMART (www.smart-project.eu).","Olivier Chapelle. 2007. Training a support vector machine in the primal. Neural Computation, 19(5):1155–1178.","David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI’11), pages 859–866, San Francisco, CA.","James Clarke, Dan Goldwasser, Wing-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the 14th Conference on Natural Language Learning (CoNLL’10), pages 18–27, Uppsala, Sweden.","Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of the conference on Empirical Methods in Natural Language Processing (EMNLP’02), Philadelphia, PA.","Ronan Collobert and Samy Bengio. 2004. Links between perceptrons, MLPs, and SVMs. In Proceedings of the 21st International Conference on Machine Learning (ICML’04), Banff, Canada.","Michael Denkowski, Chris Dyer, and Alon Lavie. 2014. Learning from post-editing: Online model adaptation for statistical machine translation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL’14), Gothenburg, Sweden.","Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of the ACL 2010 System Demonstra-tions, Uppsala, Sweden.","Masaru Fuji. 1999. Evaluation experiment for reading comprehension of machine translation outputs. In Proceedings of the Machine Translation Summit VII, Singapore.","Kevin Gimpel and Noah A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2012), Montreal, Canada.","Dan Goldwasser and Dan Roth. 2013. Learning from natural instructions. Machine Learning, 94(2):205– 232.","Daniel Hardt and Jakob Elming. 2010. Incremental re-training for post-editing SMT. In Proceedings of the 9th Conference of the Association for Machine Tranlation in the Americas (AMTA’10), Denver, CO.","Douglas Jones, Wade Shen, Neil Granoien, Martha Herzog, and Clifford Weinstein. 2005. Measuring translation quality by testing english speakers with a new defense language proficiency test for arabic. In Proceedings of 2005 International Conference on Intelligence Analysis, McLean, VA.","Bevan K. Jones, Mark Johnson, and Sharon Goldwater. 2012. Semantic parsing with bayesion tree transducers. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL’12), Jeju Island, Korea.","Philipp Koehn and Barry Haddow. 2009. Interactive assistance to human translators using statistical machine translation methods. In Proceedings of MT Summit XII, Ottawa, Ontario, Canada.","Tom Kwiatowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP’13), Seattle, WA.","Philippe Langlais, George Foster, and Guy Lapalme. 2000. Transtype: a computer-aided translation typ-ing system. In Proceedings of the ANLP-NAACL 2000 Workshop on Embedded Machine Translation Systems, Seattle, WA.","Adam Lopez. 2007. Hierarchical phrase-based translation with suffix arrays. InProceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), Prague, Czech Republic.","Pascual Martı́nez-Gómez, Germán Sanchis-Trilles, and Francisco Casacuberta. 2012. Online adaptation 890 strategies for statistical machine translation in post-editing scenarios. Pattern Recognition, 45(9):3193– 3202.","David McAllester and Joseph Keshet. 2011. Generalization bounds and consistency for latent structural probit and ramp loss. In Proceedings of the 25th Annual Conference on Neural Information Processing Sytems (NIPS 2011), Granada, Spain.","Preslav Nakov, Francisco Guzmán, and Stephan Vogel. 2012. Optimizing for sentence-level bleu+1 yields short translations. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012), Bombay, India.","Vassilina Nikoulina, Bogomil Kovachev, Nikolaos Lagos, and Christof Monz. 2012. Adaptation of statistical machine translation model for cross-lingual information retrieval in a service context. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL’12), Avignon, France.","Eric W. Noreen. 1989. Computer Intensive Methods for Testing Hypotheses. An Introduction. Wiley, New York.","Daniel Ortiz-Martı́nez, Ismal Garcı́a-Varea, and Francisco Casacuberta. 2010. Online learning for in-teractive statistical machine translation. In Proceedings of the Human Language Technologies conference and the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10), Los Angeles, CA.","Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report IBM Research Division Technical Report, RC22176 (W0190-022), Yorktown Heights, N.Y.","Sheila M. Pfafflin. 1965. Evaluation of machine translations by reading comprehension tests and subjec-tive judgements. Mechanical Translation and Computational Linguistics, 8(2):2–8.","Akiko Sakamoto, Nayuko Watanabe, Satoshi Kamatani, and Kazuo Sumita. 2013. Development of a simultaneous interpretation system for face-to-face services and its evaluation experiment in real situation. In Proceedings of the Machine Translation Summit XIV, Nice, France.","Avneesh Saluja, Ian Lane, and Ying Zhang. 2012. Machine translation with binary feedback: A largemargin approach. In Proceedings of the 10th Biennial Conference of the Association for Machine Translation in the Americas (AMTA’12), San Diego, CA.","Shai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. 2007. Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. In Proceedings of the 24th International Conference on Machine Learning (ICML’07), Corvallis, OR.","Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012. Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012), Jeju, Korea.","Jason R. Smith, Herve Saint-Amand, Magdalena Plamada, Philipp Koehn, Chris Callison-Burch, and Adam Lopez. 2013. Dirt cheap web-scale parallel text from the common crawl. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria.","Katharina Wäschle, Patrick Simianer, Nicola Bertoldi, Stefan Riezler, and Marcello Federico. 2013. Generative and discriminative methods for online adaptation in SMT. In Proceedings of the Machine Translation Summit XIV, Nice, France.","Yuk Wah Wong and Raymond J. Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL’06), New York City, NY.","Luke S. Zettlemoyer and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP’09), Singapore. 891"]}],"references":[{"authors":[{"first":"Jacob","last":"Andreas"},{"first":"Andreas","last":"Vlachos"},{"first":"Stephen","last":"Clark"}],"year":"2013","title":"Semantic parsing as machine translation","source":"Jacob Andreas, Andreas Vlachos, and Stephen Clark. 2013. Semantic parsing as machine translation. In 889 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria."},{"authors":[{"first":"Sergio","last":"Barrachina"},{"first":"Oliver","last":"Bender"},{"first":"Francisco","last":"Casacuberta"},{"first":"Jorge","last":"Civera"},{"first":"Elsa","last":"Cubel"},{"first":"Shahram","last":"Khadivi"},{"first":"Antonio","last":"Lagarda"},{"first":"Hermann","last":"Ney"},{"first":"Jesús","last":"Tomás"},{"first":"Enrique","last":"Vidal"},{"first":"Juan-Miguel","last":"Vilar"}],"year":"2008","title":"Statistical approaches to computer-assisted translation","source":"Sergio Barrachina, Oliver Bender, Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio Lagarda, Hermann Ney, Jesús Tomás, Enrique Vidal, and Juan-Miguel Vilar. 2008. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28."},{"authors":[{"first":"Jonathan","last":"Berant"},{"first":"Andrew","last":"Chou"},{"first":"Roy","last":"Frostig"},{"first":"Percy","last":"Liang"}],"year":"2013","title":"Semantic parsing on freebase from question-answer pairs","source":"Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP’13), Seattle, WA."},{"authors":[{"first":"Qingqing","last":"Cai"},{"first":"Alexander","last":"Yates"}],"year":"2013","title":"Large-scale semantic parsing via schema matching and lexicon extenstion","source":"Qingqing Cai and Alexander Yates. 2013. Large-scale semantic parsing via schema matching and lexicon extenstion. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria."},{"authors":[{"first":"Nicolò","last":"Cesa-Bianchi"},{"first":"Gabriele","last":"Reverberi"},{"first":"San-dor","last":"Szedmak"}],"year":"2008","title":"Online learning algorithms for computer-assisted translation","source":"Nicolò Cesa-Bianchi, Gabriele Reverberi, and San-dor Szedmak. 2008. Online learning algorithms for computer-assisted translation. Technical report, SMART (www.smart-project.eu)."},{"authors":[{"first":"Olivier","last":"Chapelle"}],"year":"2007","title":"Training a support vector machine in the primal","source":"Olivier Chapelle. 2007. Training a support vector machine in the primal. Neural Computation, 19(5):1155–1178."},{"authors":[{"first":"David","middle":"L.","last":"Chen"},{"first":"Raymond","middle":"J.","last":"Mooney"}],"year":"2011","title":"Learning to interpret natural language navigation instructions from observations","source":"David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI’11), pages 859–866, San Francisco, CA."},{"authors":[{"first":"James","last":"Clarke"},{"first":"Dan","last":"Goldwasser"},{"first":"Wing-Wei","last":"Chang"},{"first":"Dan","last":"Roth"}],"year":"2010","title":"Driving semantic parsing from the world’s response","source":"James Clarke, Dan Goldwasser, Wing-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the 14th Conference on Natural Language Learning (CoNLL’10), pages 18–27, Uppsala, Sweden."},{"authors":[{"first":"Michael","last":"Collins"}],"year":"2002","title":"Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms","source":"Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of the conference on Empirical Methods in Natural Language Processing (EMNLP’02), Philadelphia, PA."},{"authors":[{"first":"Ronan","last":"Collobert"},{"first":"Samy","last":"Bengio"}],"year":"2004","title":"Links between perceptrons, MLPs, and SVMs","source":"Ronan Collobert and Samy Bengio. 2004. Links between perceptrons, MLPs, and SVMs. In Proceedings of the 21st International Conference on Machine Learning (ICML’04), Banff, Canada."},{"authors":[{"first":"Michael","last":"Denkowski"},{"first":"Chris","last":"Dyer"},{"first":"Alon","last":"Lavie"}],"year":"2014","title":"Learning from post-editing: Online model adaptation for statistical machine translation","source":"Michael Denkowski, Chris Dyer, and Alon Lavie. 2014. Learning from post-editing: Online model adaptation for statistical machine translation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL’14), Gothenburg, Sweden."},{"authors":[{"first":"Chris","last":"Dyer"},{"first":"Adam","last":"Lopez"},{"first":"Juri","last":"Ganitkevitch"},{"first":"Jonathan","last":"Weese"},{"first":"Ferhan","last":"Ture"},{"first":"Phil","last":"Blunsom"},{"first":"Hendra","last":"Setiawan"},{"first":"Vladimir","last":"Eidelman"},{"first":"Philip","last":"Resnik"}],"year":"2010","title":"cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models","source":"Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of the ACL 2010 System Demonstra-tions, Uppsala, Sweden."},{"authors":[{"first":"Masaru","last":"Fuji"}],"year":"1999","title":"Evaluation experiment for reading comprehension of machine translation outputs","source":"Masaru Fuji. 1999. Evaluation experiment for reading comprehension of machine translation outputs. In Proceedings of the Machine Translation Summit VII, Singapore."},{"authors":[{"first":"Kevin","last":"Gimpel"},{"first":"Noah","middle":"A.","last":"Smith"}],"year":"2012","title":"Structured ramp loss minimization for machine translation","source":"Kevin Gimpel and Noah A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2012), Montreal, Canada."},{"authors":[{"first":"Dan","last":"Goldwasser"},{"first":"Dan","last":"Roth"}],"year":"2013","title":"Learning from natural instructions","source":"Dan Goldwasser and Dan Roth. 2013. Learning from natural instructions. Machine Learning, 94(2):205– 232."},{"authors":[{"first":"Daniel","last":"Hardt"},{"first":"Jakob","last":"Elming"}],"year":"2010","title":"Incremental re-training for post-editing SMT","source":"Daniel Hardt and Jakob Elming. 2010. Incremental re-training for post-editing SMT. In Proceedings of the 9th Conference of the Association for Machine Tranlation in the Americas (AMTA’10), Denver, CO."},{"authors":[{"first":"Douglas","last":"Jones"},{"first":"Wade","last":"Shen"},{"first":"Neil","last":"Granoien"},{"first":"Martha","last":"Herzog"},{"first":"Clifford","last":"Weinstein"}],"year":"2005","title":"Measuring translation quality by testing english speakers with a new defense language proficiency test for arabic","source":"Douglas Jones, Wade Shen, Neil Granoien, Martha Herzog, and Clifford Weinstein. 2005. Measuring translation quality by testing english speakers with a new defense language proficiency test for arabic. In Proceedings of 2005 International Conference on Intelligence Analysis, McLean, VA."},{"authors":[{"first":"Bevan","middle":"K.","last":"Jones"},{"first":"Mark","last":"Johnson"},{"first":"Sharon","last":"Goldwater"}],"year":"2012","title":"Semantic parsing with bayesion tree transducers","source":"Bevan K. Jones, Mark Johnson, and Sharon Goldwater. 2012. Semantic parsing with bayesion tree transducers. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL’12), Jeju Island, Korea."},{"authors":[{"first":"Philipp","last":"Koehn"},{"first":"Barry","last":"Haddow"}],"year":"2009","title":"Interactive assistance to human translators using statistical machine translation methods","source":"Philipp Koehn and Barry Haddow. 2009. Interactive assistance to human translators using statistical machine translation methods. In Proceedings of MT Summit XII, Ottawa, Ontario, Canada."},{"authors":[{"first":"Tom","last":"Kwiatowski"},{"first":"Eunsol","last":"Choi"},{"first":"Yoav","last":"Artzi"},{"first":"Luke","last":"Zettlemoyer"}],"year":"2013","title":"Scaling semantic parsers with on-the-fly ontology matching","source":"Tom Kwiatowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP’13), Seattle, WA."},{"authors":[{"first":"Philippe","last":"Langlais"},{"first":"George","last":"Foster"},{"first":"Guy","last":"Lapalme"}],"year":"2000","title":"Transtype: a computer-aided translation typ-ing system","source":"Philippe Langlais, George Foster, and Guy Lapalme. 2000. Transtype: a computer-aided translation typ-ing system. In Proceedings of the ANLP-NAACL 2000 Workshop on Embedded Machine Translation Systems, Seattle, WA."},{"authors":[{"first":"Adam","last":"Lopez"}],"year":"2007","title":"Hierarchical phrase-based translation with suffix arrays","source":"Adam Lopez. 2007. Hierarchical phrase-based translation with suffix arrays. InProceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), Prague, Czech Republic."},{"authors":[{"first":"Pascual","last":"Martı́nez-Gómez"},{"first":"Germán","last":"Sanchis-Trilles"},{"first":"Francisco","last":"Casacuberta"}],"year":"2012","title":"Online adaptation 890 strategies for statistical machine translation in post-editing scenarios","source":"Pascual Martı́nez-Gómez, Germán Sanchis-Trilles, and Francisco Casacuberta. 2012. Online adaptation 890 strategies for statistical machine translation in post-editing scenarios. Pattern Recognition, 45(9):3193– 3202."},{"authors":[{"first":"David","last":"McAllester"},{"first":"Joseph","last":"Keshet"}],"year":"2011","title":"Generalization bounds and consistency for latent structural probit and ramp loss","source":"David McAllester and Joseph Keshet. 2011. Generalization bounds and consistency for latent structural probit and ramp loss. In Proceedings of the 25th Annual Conference on Neural Information Processing Sytems (NIPS 2011), Granada, Spain."},{"authors":[{"first":"Preslav","last":"Nakov"},{"first":"Francisco","last":"Guzmán"},{"first":"Stephan","last":"Vogel"}],"year":"2012","title":"Optimizing for sentence-level bleu+1 yields short translations","source":"Preslav Nakov, Francisco Guzmán, and Stephan Vogel. 2012. Optimizing for sentence-level bleu+1 yields short translations. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012), Bombay, India."},{"authors":[{"first":"Vassilina","last":"Nikoulina"},{"first":"Bogomil","last":"Kovachev"},{"first":"Nikolaos","last":"Lagos"},{"first":"Christof","last":"Monz"}],"year":"2012","title":"Adaptation of statistical machine translation model for cross-lingual information retrieval in a service context","source":"Vassilina Nikoulina, Bogomil Kovachev, Nikolaos Lagos, and Christof Monz. 2012. Adaptation of statistical machine translation model for cross-lingual information retrieval in a service context. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL’12), Avignon, France."},{"authors":[{"first":"Eric","middle":"W.","last":"Noreen"}],"year":"1989","title":"Computer Intensive Methods for Testing Hypotheses","source":"Eric W. Noreen. 1989. Computer Intensive Methods for Testing Hypotheses. An Introduction. Wiley, New York."},{"authors":[{"first":"Daniel","last":"Ortiz-Martı́nez"},{"first":"Ismal","last":"Garcı́a-Varea"},{"first":"Francisco","last":"Casacuberta"}],"year":"2010","title":"Online learning for in-teractive statistical machine translation","source":"Daniel Ortiz-Martı́nez, Ismal Garcı́a-Varea, and Francisco Casacuberta. 2010. Online learning for in-teractive statistical machine translation. In Proceedings of the Human Language Technologies conference and the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10), Los Angeles, CA."},{"authors":[{"first":"Kishore","last":"Papineni"},{"first":"Salim","last":"Roukos"},{"first":"Todd","last":"Ward"},{"first":"Wei-Jing","last":"Zhu"}],"year":"2001","title":"Bleu: a method for automatic evaluation of machine translation","source":"Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report IBM Research Division Technical Report, RC22176 (W0190-022), Yorktown Heights, N.Y."},{"authors":[{"first":"Sheila","middle":"M.","last":"Pfafflin"}],"year":"1965","title":"Evaluation of machine translations by reading comprehension tests and subjec-tive judgements","source":"Sheila M. Pfafflin. 1965. Evaluation of machine translations by reading comprehension tests and subjec-tive judgements. Mechanical Translation and Computational Linguistics, 8(2):2–8."},{"authors":[{"first":"Akiko","last":"Sakamoto"},{"first":"Nayuko","last":"Watanabe"},{"first":"Satoshi","last":"Kamatani"},{"first":"Kazuo","last":"Sumita"}],"year":"2013","title":"Development of a simultaneous interpretation system for face-to-face services and its evaluation experiment in real situation","source":"Akiko Sakamoto, Nayuko Watanabe, Satoshi Kamatani, and Kazuo Sumita. 2013. Development of a simultaneous interpretation system for face-to-face services and its evaluation experiment in real situation. In Proceedings of the Machine Translation Summit XIV, Nice, France."},{"authors":[{"first":"Avneesh","last":"Saluja"},{"first":"Ian","last":"Lane"},{"first":"Ying","last":"Zhang"}],"year":"2012","title":"Machine translation with binary feedback: A largemargin approach","source":"Avneesh Saluja, Ian Lane, and Ying Zhang. 2012. Machine translation with binary feedback: A largemargin approach. In Proceedings of the 10th Biennial Conference of the Association for Machine Translation in the Americas (AMTA’12), San Diego, CA."},{"authors":[{"first":"Shai","last":"Shalev-Shwartz"},{"first":"Yoram","last":"Singer"},{"first":"Nathan","last":"Srebro"}],"year":"2007","title":"Pegasos: Primal Estimated sub-GrAdient SOlver for SVM","source":"Shai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. 2007. Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. In Proceedings of the 24th International Conference on Machine Learning (ICML’07), Corvallis, OR."},{"authors":[{"first":"Patrick","last":"Simianer"},{"first":"Stefan","last":"Riezler"},{"first":"Chris","last":"Dyer"}],"year":"2012","title":"Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT","source":"Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012. Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012), Jeju, Korea."},{"authors":[{"first":"Jason","middle":"R.","last":"Smith"},{"first":"Herve","last":"Saint-Amand"},{"first":"Magdalena","last":"Plamada"},{"first":"Philipp","last":"Koehn"},{"first":"Chris","last":"Callison-Burch"},{"first":"Adam","last":"Lopez"}],"year":"2013","title":"Dirt cheap web-scale parallel text from the common crawl","source":"Jason R. Smith, Herve Saint-Amand, Magdalena Plamada, Philipp Koehn, Chris Callison-Burch, and Adam Lopez. 2013. Dirt cheap web-scale parallel text from the common crawl. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL’13), Sofia, Bulgaria."},{"authors":[{"first":"Katharina","last":"Wäschle"},{"first":"Patrick","last":"Simianer"},{"first":"Nicola","last":"Bertoldi"},{"first":"Stefan","last":"Riezler"},{"first":"Marcello","last":"Federico"}],"year":"2013","title":"Generative and discriminative methods for online adaptation in SMT","source":"Katharina Wäschle, Patrick Simianer, Nicola Bertoldi, Stefan Riezler, and Marcello Federico. 2013. Generative and discriminative methods for online adaptation in SMT. In Proceedings of the Machine Translation Summit XIV, Nice, France."},{"authors":[{"first":"Yuk","middle":"Wah","last":"Wong"},{"first":"Raymond","middle":"J.","last":"Mooney"}],"year":"2006","title":"Learning for semantic parsing with statistical machine translation","source":"Yuk Wah Wong and Raymond J. Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL’06), New York City, NY."},{"authors":[{"first":"Luke","middle":"S.","last":"Zettlemoyer"},{"first":"Michael","last":"Collins"}],"year":"2009","title":"Learning context-dependent mappings from sentences to logical form","source":"Luke S. Zettlemoyer and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP’09), Singapore. 891"}],"cites":[{"style":0,"text":"Wong and Mooney (2006)","origin":{"pointer":"/sections/3/paragraphs/0","offset":647,"length":22},"authors":[{"last":"Wong"},{"last":"Mooney"}],"year":"2006","references":["/references/36"]},{"style":0,"text":"Zettlemoyer and Collins (2009)","origin":{"pointer":"/sections/3/paragraphs/0","offset":719,"length":30},"authors":[{"last":"Zettlemoyer"},{"last":"Collins"}],"year":"2009","references":["/references/37"]},{"style":0,"text":"Chen and Mooney (2011)","origin":{"pointer":"/sections/3/paragraphs/0","offset":811,"length":22},"authors":[{"last":"Chen"},{"last":"Mooney"}],"year":"2011","references":["/references/6"]},{"style":0,"text":"Goldwasser and Roth (2013)","origin":{"pointer":"/sections/3/paragraphs/0","offset":883,"length":26},"authors":[{"last":"Goldwasser"},{"last":"Roth"}],"year":"2013","references":["/references/14"]},{"style":0,"text":"Cai and Yates (2013)","origin":{"pointer":"/sections/3/paragraphs/0","offset":968,"length":20},"authors":[{"last":"Cai"},{"last":"Yates"}],"year":"2013","references":["/references/3"]},{"style":0,"text":"Kwiatowski et al. (2013)","origin":{"pointer":"/sections/3/paragraphs/0","offset":1562,"length":24},"authors":[{"last":"Kwiatowski"},{"last":"al."}],"year":"2013","references":["/references/19"]},{"style":0,"text":"Berant et al. (2013)","origin":{"pointer":"/sections/3/paragraphs/0","offset":1588,"length":20},"authors":[{"last":"Berant"},{"last":"al."}],"year":"2013","references":["/references/2"]},{"style":0,"text":"Goldwasser and Roth (2013)","origin":{"pointer":"/sections/3/paragraphs/0","offset":1613,"length":26},"authors":[{"last":"Goldwasser"},{"last":"Roth"}],"year":"2013","references":["/references/14"]},{"style":0,"text":"Saluja et al., 2012","origin":{"pointer":"/sections/3/paragraphs/1","offset":270,"length":19},"authors":[{"last":"Saluja"},{"last":"al."}],"year":"2012","references":["/references/31"]},{"style":0,"text":"Cesa-Bianchi et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":386,"length":25},"authors":[{"last":"Cesa-Bianchi"},{"last":"al."}],"year":"2008","references":["/references/4"]},{"style":0,"text":"Langlais et al., 2000","origin":{"pointer":"/sections/3/paragraphs/1","offset":484,"length":21},"authors":[{"last":"Langlais"},{"last":"al."}],"year":"2000","references":["/references/20"]},{"style":0,"text":"Barrachina et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":507,"length":23},"authors":[{"last":"Barrachina"},{"last":"al."}],"year":"2008","references":["/references/1"]},{"style":0,"text":"Koehn and Haddow, 2009","origin":{"pointer":"/sections/3/paragraphs/1","offset":532,"length":22},"authors":[{"last":"Koehn"},{"last":"Haddow"}],"year":"2009","references":["/references/18"]},{"style":0,"text":"Ortiz-Martı́nez et al., 2010","origin":{"pointer":"/sections/3/paragraphs/1","offset":1016,"length":28},"authors":[{"last":"Ortiz-Martı́nez"},{"last":"al."}],"year":"2010","references":["/references/27"]},{"style":0,"text":"Hardt and Elm-ing, 2010","origin":{"pointer":"/sections/3/paragraphs/1","offset":1046,"length":23},"authors":[{"last":"Hardt"},{"last":"Elm-ing"}],"year":"2010","references":[]},{"style":0,"text":"Cesa-Bianchi et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":1138,"length":25},"authors":[{"last":"Cesa-Bianchi"},{"last":"al."}],"year":"2008","references":["/references/4"]},{"style":0,"text":"Martı́nez-Gómez et al., 2012","origin":{"pointer":"/sections/3/paragraphs/1","offset":1165,"length":28},"authors":[{"last":"Martı́nez-Gómez"},{"last":"al."}],"year":"2012","references":["/references/22"]},{"style":0,"text":"Wäschle et al., 2013","origin":{"pointer":"/sections/3/paragraphs/1","offset":1195,"length":20},"authors":[{"last":"Wäschle"},{"last":"al."}],"year":"2013","references":["/references/35"]},{"style":0,"text":"Denkowski et al., 2014","origin":{"pointer":"/sections/3/paragraphs/1","offset":1217,"length":22},"authors":[{"last":"Denkowski"},{"last":"al."}],"year":"2014","references":["/references/10"]},{"style":0,"text":"Nikoulina et al. (2012)","origin":{"pointer":"/sections/3/paragraphs/1","offset":1378,"length":23},"authors":[{"last":"Nikoulina"},{"last":"al."}],"year":"2012","references":["/references/25"]},{"style":0,"text":"Pfafflin, 1965","origin":{"pointer":"/sections/3/paragraphs/2","offset":159,"length":14},"authors":[{"last":"Pfafflin"}],"year":"1965","references":["/references/29"]},{"style":0,"text":"Fuji, 1999","origin":{"pointer":"/sections/3/paragraphs/2","offset":175,"length":10},"authors":[{"last":"Fuji"}],"year":"1999","references":["/references/12"]},{"style":0,"text":"Jones et al., 2005","origin":{"pointer":"/sections/3/paragraphs/2","offset":187,"length":18},"authors":[{"last":"Jones"},{"last":"al."}],"year":"2005","references":["/references/16"]},{"style":0,"text":"Sakamoto et al., 2013","origin":{"pointer":"/sections/3/paragraphs/2","offset":293,"length":21},"authors":[{"last":"Sakamoto"},{"last":"al."}],"year":"2013","references":["/references/30"]},{"style":0,"text":"Collins, 2002","origin":{"pointer":"/sections/5/paragraphs/2","offset":111,"length":13},"authors":[{"last":"Collins"}],"year":"2002","references":["/references/8"]},{"style":0,"text":"Nakov et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/9","offset":693,"length":19},"authors":[{"last":"Nakov"},{"last":"al."}],"year":"2012","references":["/references/24"]},{"style":0,"text":"Gimpel and Smith (2012)","origin":{"pointer":"/sections/5/paragraphs/9","offset":821,"length":23},"authors":[{"last":"Gimpel"},{"last":"Smith"}],"year":"2012","references":["/references/13"]},{"style":0,"text":"Clarke et al. (2010)","origin":{"pointer":"/sections/5/paragraphs/10","offset":105,"length":20},"authors":[{"last":"Clarke"},{"last":"al."}],"year":"2010","references":["/references/7"]},{"style":0,"text":"Goldwasser and Roth (2013)","origin":{"pointer":"/sections/5/paragraphs/10","offset":129,"length":26},"authors":[{"last":"Goldwasser"},{"last":"Roth"}],"year":"2013","references":["/references/14"]},{"style":0,"text":"Nakov et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/14","offset":51,"length":19},"authors":[{"last":"Nakov"},{"last":"al."}],"year":"2012","references":["/references/24"]},{"style":0,"text":"McAllester and Keshet, 2011","origin":{"pointer":"/sections/5/paragraphs/42","offset":81,"length":27},"authors":[{"last":"McAllester"},{"last":"Keshet"}],"year":"2011","references":["/references/23"]},{"style":0,"text":"Goldwasser and Roth, 2013","origin":{"pointer":"/sections/5/paragraphs/84","offset":407,"length":25},"authors":[{"last":"Goldwasser"},{"last":"Roth"}],"year":"2013","references":["/references/14"]},{"style":0,"text":"Kwiatowski et al., 2013","origin":{"pointer":"/sections/5/paragraphs/84","offset":434,"length":23},"authors":[{"last":"Kwiatowski"},{"last":"al."}],"year":"2013","references":["/references/19"]},{"style":0,"text":"Berant et al., 2013","origin":{"pointer":"/sections/5/paragraphs/84","offset":459,"length":19},"authors":[{"last":"Berant"},{"last":"al."}],"year":"2013","references":["/references/2"]},{"style":0,"text":"Collobert and Bengio, 2004","origin":{"pointer":"/sections/5/paragraphs/84","offset":623,"length":26},"authors":[{"last":"Collobert"},{"last":"Bengio"}],"year":"2004","references":["/references/9"]},{"style":0,"text":"Chapelle, 2007","origin":{"pointer":"/sections/5/paragraphs/84","offset":651,"length":14},"authors":[{"last":"Chapelle"}],"year":"2007","references":["/references/5"]},{"style":0,"text":"Shalev-Shwartz et al., 2007","origin":{"pointer":"/sections/5/paragraphs/84","offset":667,"length":27},"authors":[{"last":"Shalev-Shwartz"},{"last":"al."}],"year":"2007","references":["/references/32"]},{"style":0,"text":"Jones et al. (2012)","origin":{"pointer":"/sections/6/paragraphs/6","offset":143,"length":19},"authors":[{"last":"Jones"},{"last":"al."}],"year":"2012","references":["/references/17"]},{"style":0,"text":"Andreas et al. (2013)","origin":{"pointer":"/sections/6/paragraphs/7","offset":65,"length":21},"authors":[{"last":"Andreas"},{"last":"al."}],"year":"2013","references":["/references/0"]},{"style":0,"text":"Dyer et al., 2010","origin":{"pointer":"/sections/6/paragraphs/13","offset":92,"length":17},"authors":[{"last":"Dyer"},{"last":"al."}],"year":"2010","references":["/references/11"]},{"style":0,"text":"Lopez (2007)","origin":{"pointer":"/sections/6/paragraphs/14","offset":97,"length":12},"authors":[{"last":"Lopez"}],"year":"2007","references":["/references/21"]},{"style":0,"text":"Smith et al., 2013","origin":{"pointer":"/sections/6/paragraphs/15","offset":1,"length":18},"authors":[{"last":"Smith"},{"last":"al."}],"year":"2013","references":["/references/34"]},{"style":0,"text":"Simianer et al. (2012)","origin":{"pointer":"/sections/6/paragraphs/16","offset":249,"length":22},"authors":[{"last":"Simianer"},{"last":"al."}],"year":"2012","references":["/references/33"]},{"style":0,"text":"Nakov et al., 2012","origin":{"pointer":"/sections/6/paragraphs/19","offset":126,"length":18},"authors":[{"last":"Nakov"},{"last":"al."}],"year":"2012","references":["/references/24"]},{"style":0,"text":"Gimpel and Smith, 2012","origin":{"pointer":"/sections/6/paragraphs/22","offset":87,"length":22},"authors":[{"last":"Gimpel"},{"last":"Smith"}],"year":"2012","references":["/references/13"]},{"style":0,"text":"Papineni et al., 2001","origin":{"pointer":"/sections/6/paragraphs/23","offset":16,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"2001","references":["/references/28"]},{"style":0,"text":"Noreen, 1989","origin":{"pointer":"/sections/6/paragraphs/23","offset":574,"length":12},"authors":[{"last":"Noreen"}],"year":"1989","references":["/references/26"]},{"style":0,"text":"Jones et al. (2012)","origin":{"pointer":"/sections/6/paragraphs/24","offset":166,"length":19},"authors":[{"last":"Jones"},{"last":"al."}],"year":"2012","references":["/references/17"]}]}
