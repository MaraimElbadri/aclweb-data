{"sections":[{"title":"","paragraphs":["Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1113–1122, Baltimore, Maryland, USA, June 23-25 2014. c⃝2014 Association for Computational Linguistics"]},{"title":"Political Ideology Detection Using Recursive Neural Networks Mohit Iyyer","paragraphs":["1"]},{"title":", Peter Enns","paragraphs":["2"]},{"title":", Jordan Boyd-Graber","paragraphs":["3,4"]},{"title":", Philip Resnik","paragraphs":["2,4 1"]},{"title":"Computer Science,","paragraphs":["2"]},{"title":"Linguistics,","paragraphs":["3"]},{"title":"iSchool, and","paragraphs":["4 UMIACS"]},{"title":"University of Maryland {miyyer,peter,jbg}@umiacs.umd.edu, resnik@umd.edu Abstract","paragraphs":["An individual’s words often reveal their political ideology. Existing automated techniques to identify ideology from text focus on bags of words or wordlists, ignoring syntax. Taking inspiration from recent work in sentiment analysis that successfully models the compositional aspect of language, we apply a recursive neural network (RNN) framework to the task of identifying the political position evinced by a sentence. To show the importance of modeling subsentential elements, we crowdsource political annotations at a phrase and sentence level. Our model outperforms existing models on our newly annotated dataset and an existing dataset."]},{"title":"1 Introduction","paragraphs":["Many of the issues discussed by politicians and the media are so nuanced that even word choice entails choosing an ideological position. For example, what liberals call the “estate tax” conservatives call the “death tax”; there are no ideologically neutral alternatives (Lakoff, 2002). While objectivity remains an important principle of journalistic professionalism, scholars and watchdog groups claim that the media are biased (Groseclose and Milyo, 2005; Gentzkow and Shapiro, 2010; Niven, 2003), backing up their assertions by publishing examples of obviously biased articles on their websites. Whether or not it reflects an underlying lack of objectivity, quantitative changes in the popular framing of an issue over time—favoring one ideologically-based position over another—can have a substantial effect on the evolution of policy (Dardis et al., 2008).","Manually identifying ideological bias in political text, especially in the age of big data, is an impractical and expensive process. Moreover, bias They","dubbed it the","death tax“ ” and created a big lie about","its adverse effects on small businesses Figure 1: An example of compositionality in ideological bias detection (red → conservative, blue → liberal, gray → neutral) in which modifier phrases and punctuation cause polarity switches at higher levels of the parse tree. may be localized to a small portion of a document, undetectable by coarse-grained methods. In this paper, we examine the problem of detecting ideological bias on the sentence level. We say a sentence contains ideological bias if its author’s political position (here liberal or conservative, in the sense of U.S. politics) is evident from the text.","Ideological bias is difficult to detect, even for humans—the task relies not only on political knowledge but also on the annotator’s ability to pick up on subtle elements of language use. For example, the sentence in Figure 1 includes phrases typically associated with conservatives, such as “small businesses” and “death tax”. When we take more of the structure into account, however, we find that scare quotes and a negative propositional attitude (a lie about X) yield an evident liberal bias.","Existing approaches toward bias detection have not gone far beyond “bag of words” classifiers, thus ignoring richer linguistic context of this kind and often operating at the level of whole documents. In contrast, recent work in sentiment analysis has used deep learning to discover compositional effects (Socher et al., 2011b; Socher et al., 2013b).","Building from those insights, we introduce a recursive neural network (RNN) to detect ideological bias on the sentence level. This model requires 1113 wb = changewa = climate wd = so-called pc = climate change pe = so-called climate change xd= xc= xe= xa= xb= WL WR WRWL Figure 2: An example RNN for the phrase “so-called climate change”. Two d-dimensional word vectors (here, d = 6) are composed to generate a phrase vector of the same dimensionality, which can then be recursively used to generate vectors at higher-level nodes. richer data than currently available, so we develop a new political ideology dataset annotated at the phrase level. With this new dataset we show that RNNs not only label sentences well but also improve further when given additional phrase-level annotations. RNNs are quantitatively more effective than existing methods that use syntactic and semantic features separately, and we also illustrate how our model correctly identifies ideological bias in complex syntactic constructions."]},{"title":"2 Recursive Neural Networks","paragraphs":["Recursive neural networks (RNNs) are machine learning models that capture syntactic and semantic composition. They have achieved state-of-the-art performance on a variety of sentence-level NLP tasks, including sentiment analysis, paraphrase detection, and parsing (Socher et al., 2011a; Hermann and Blunsom, 2013). RNN models represent a shift from previous research on ideological bias detection in that they do not rely on hand-made lexicons, dictionaries, or rule sets. In this section, we describe a supervised RNN model for bias detection and highlight differences from previous work in training procedure and initialization. 2.1 Model Description By taking into account the hierarchical nature of language, RNNs can model semantic composition, which is the principle that a phrase’s meaning is a combination of the meaning of the words within that phrase and the syntax that combines those words. While semantic composition does not apply universally (e.g., sarcasm and idioms), most language follows this principle. Since most ideological bias becomes identifiable only at higher levels of sentence trees (as verified by our annotation, Figure 4), models relying primarily on word-level distributional statistics are not desirable for our problem.","The basic idea behind the standard RNN model is that each word w in a sentence is associated with a vector representation xw ∈ Rd",". Based on a parse tree, these words form phrases p (Figure 2). Each of these phrases also has an associated vector xp ∈ Rd","of the same dimension as the word vectors. These phrase vectors should represent the meaning of the phrases composed of individual words. As phrases themselves merge into complete sentences, the underlying vector representation is trained to retain the sentence’s whole meaning.","The challenge is to describe how vectors combine to form complete representations. If two words wa and wb merge to form phrase p, we posit that the phrase-level vector is xp = f (WL · xa + WR · xb + b1), (1) where WL and WR are d × d left and right composition matrices shared across all nodes in the tree, b1 is a bias term, and f is a nonlinear activa-tion function such as tanh. The word-level vectors xa and xb come from a d × V dimensional word embedding matrix We, where V is the size of the vocabulary.","We are interested in learning representations that can distinguish political polarities given labeled data. If an element of this vector space, xd, represents a sentence with liberal bias, its vector should be distinct from the vector xr of a conservative-leaning sentence.","Supervised RNNs achieve this distinction by applying a regression that takes the node’s vector xp as input and produces a prediction ŷp. This is a softmax layer ŷd = softmax(Wcat · xp + b2), (2) where the softmax function is softmax(q) = exp q","∑k j=1 exp qj (3) and Wcat is a k × d matrix for a dataset with k-dimensional labels.","We want the predictions of the softmax layer to match our annotated data; the discrepancy between categorical predictions and annotations is measured 1114 through the cross-entropy loss. We optimize the model parameters to minimize the cross-entropy loss over all sentences in the corpus. The cross-entropy loss of a single sentence is the sum over the true labels yi in the sentence, l(ŷs) = k ∑ p=1 yp ∗ log(ŷp). (4)","This induces a supervised objective function over all sentences: a regularized sum over all node losses normalized by the number of nodes N in the training set, C = 1 N N ∑ i l(predi) + λ 2 ∥θ∥2 . (5)","We use L-BFGS with parameter averag-ing (Hashimoto et al., 2013) to optimize the model parameters θ = (WL, WR, Wcat, We, b1, b2). The gradient of the objective, shown in Eq. (6), is computed using backpropagation through structure (Goller and Kuchler, 1996), ∂C ∂θ = 1 N N ∑ i","∂l(ŷi) ∂θ + λθ. (6) 2.2 Initialization When initializing our model, we have two choices: we can initialize all of our parameters randomly or provide the model some prior knowledge. As we see in Section 4, these choices have a significant effect on final performance. Random The most straightforward choice is to initialize the word embedding matrix We and composition matrices WL and WR randomly such that without any training, representations for words and phrases are arbitrarily projected into the vector space. word2vec The other alternative is to initialize the word embedding matrix We with values that reflect the meanings of the associated word types. This improves the performance of RNN models over random initializations (Collobert and Weston, 2008; Socher et al., 2011a). We initialize our model with 300-dimensional word2vec toolkit vectors generated by a continuous skip-gram model trained on around 100 billion words from the Google News corpus (Mikolov et al., 2013).","The word2vec embeddings have linear relationships (e.g., the closest vectors to the average of “green” and “energy” include phrases such as “renewable energy”, “eco-friendly”, and “efficient lightbulbs”). To preserve these relationships as phrases are formed in our sentences, we initialize our left and right composition matrices such that parent vector p is computed by taking the average of children a and b (WL = WR = 0.5Id×d). This initialization of the composition matrices has previously been effective for parsing (Socher et al., 2013a)."]},{"title":"3 Datasets","paragraphs":["We performed initial experiments on a dataset of Congressional debates that has annotations on the author level for partisanship, not ideology. While the two terms are highly correlated (e.g., a member of the Republican party likely agrees with conservative stances on most issues), they are not identical. For example, a moderate Republican might agree with the liberal position on increased gun control but take conservative positions on other issues. To avoid conflating partisanship and ideology we create a new dataset annotated for ideological bias on the sentence and phrase level. In this section we describe our initial dataset (Convote) and explain the procedure we followed for creating our new dataset (IBC).1 3.1 Convote The Convote dataset (Thomas et al., 2006) consists of US Congressional floor debate transcripts from 2005 in which all speakers have been labeled with their political party (Democrat, Republican, or independent). We propagate party labels down from the speaker to all of their individual sentences and map from party label to ideology label (Democrat → liberal, Republican → conservative). This is an expedient choice; in future work we plan to make use of work in political science characteriz-ing candidates’ ideological positions empirically based on their behavior (Carroll et al., 2009).","While the Convote dataset has seen widespread use for document-level political classification, we are unaware of similar efforts at the sentence level. 3.1.1 Biased Sentence Selection The strong correlation between US political parties and political ideologies (Democrats with liberal, Republicans with conservative) lends confidence that this dataset contains a rich mix of ideological 1 Available at http://cs.umd.edu/m̃iyyer/ibc 1115 statements. However, the raw Convote dataset contains a low percentage of sentences with explicit ideological bias.2","We therefore use the features in Yano et al. (2010), which correlate with political bias, to select sentences to annotate that have a higher likelihood of containing bias. Their features come from the Linguistic Inquiry and Word Count lexicon (LIWC) (Pennebaker et al., 2001), as well as from lists of “sticky bigrams” (Brown et al., 1992) strongly associated with one party or another (e.g., “illegal aliens” implies conservative, “universal healthcare” implies liberal).","We first extract the subset of sentences that contains any words in the LIWC categories of Negative Emotion, Positive Emotion, Causation, Anger, and Kill verbs.3","After computing a list of the top 100 sticky bigrams for each category, ranked by loglikelihood ratio, and selecting another subset from the original data that included only sentences containing at least one sticky bigram, we take the union of the two subsets. Finally, we balance the resulting dataset so that it contains an equal number of sentences from Democrats and Republicans, leaving us with a total of 7,816 sentences. 3.2 Ideological Books In addition to Convote, we use the Ideological Books Corpus (IBC) developed by Gross et al. (2013). This is a collection of books and magazine articles written between 2008 and 2012 by authors with well-known political leanings. Each document in the IBC has been manually labeled with coarse-grained ideologies (right, left, and center) as well as fine-grained ideologies (e.g., religious-right, libertarian-right) by political science experts.","There are over a million sentences in the IBC, most of which have no noticeable political bias. Therefore we use the filtering procedure outlined in Section 3.1.1 to obtain a subset of 55,932 sentences. Compared to our final Convote dataset, an even larger percentage of the IBC sentences exhibit no noticeable political bias.4","Because our goal is to distinguish between liberal and conservative","2","Many sentences in Convote are variations on “I think this is a good/bad bill”, and there is also substantial parliamentary boilerplate language.","3","While Kill verbs are not a category in LIWC, Yano et al. (2010) adopted it from Greene and Resnik (2009) and showed it to be a useful predictor of political bias. It includes words such as “slaughter” and “starve”.","4","This difference can be mainly attributed to a historical topics in the IBC (e.g., the Crusades, American Civil War). In Convote, every sentence is part of a debate about 2005 political policy. bias, instead of the more general task of classify-ing sentences as “neutral” or “biased”, we filter the dataset further using DUALIST (Settles, 2011), an active learning tool, to reduce the proportion of neutral sentences in our dataset. To train the DUALIST classifier, we manually assigned class labels of “neutral” or “biased” to 200 sentences, and selected typical partisan unigrams to represent the “biased” class. DUALIST labels 11,555 sentences as politically biased, 5,434 of which come from conservative authors and 6,121 of which come from liberal authors. 3.2.1 Annotating the IBC For purposes of annotation, we define the task of political ideology detection as identifying, if possible, the political position of a given sentence’s author, where position is either liberal or conservative.5","We used the Crowdflower crowdsourcing platform (crowdflower.com), which has previously been used for subsentential sentiment annotation (Sayeed et al., 2012), to obtain human annotations of the filteredIBC dataset for political bias on both the sentence and phrase level. While members of the Crowdflower workforce are certainly not experts in political science, our simple task and the ubiquity of political bias allows us to acquire useful annotations. Crowdflower Task First, we parse the filtered IBC sentences using the Stanford constituency parser (Socher et al., 2013a). Because of the expense of labeling every node in a sentence, we only label one path in each sentence. The process for selecting paths is as follows: first, if any paths contain one of the top-ten partisan unigrams,6","we select the longest such path; otherwise, we select the path with the most open class constituencies (NP, VP, ADJP). The root node of a sentence is always included in a path.","Our task is shown in Figure 3. Open class constituencies are revealed to the worker incrementally, starting with the NP, VP, or ADJP furthest from the root and progressing up the tree. We choose this design to prevent workers from changing their lower-level phrase annotations after reading the full sentence.","5","This is a simplification, as the ideological hierarchy in IBC makes clear.","6","The words that the multinomial naı̈ve Bayes classifier in DUALIST marked as highest probability given a polarity: market, abortion, economy, rich, liberal, tea, economic, taxes, gun, abortion 1116 Filtering the Workforce To ensure our annotators have a basic understanding of US politics, we restrict workers to US IP addresses and require workers manually annotate one node from 60 different “gold ” paths annotated by the authors. We select these nodes such that the associated phrase is either obviously biased or obviously neutral. Workers must correctly annotate at least six of eight gold paths before they are granted access to the full task. In addition, workers must maintain 75% accuracy on gold paths that randomly appear alongside normal paths. Gold paths dramatically improve the quality of our workforce: 60% of contributors passed the initial quiz (the 40% that failed were barred from working on the task), while only 10% of workers who passed the quiz were kicked out for mislabeling subsequent gold paths.","Annotation Results Workers receive the following instructions: Each task on this page contains a set of phrases from a single sentence. For each phrase, decide whether or not the author favors a political position to the left (Liberal) or right (Conservative) of center.","• If the phrase is indicative of a position to the left of center, please choose Liberal.","• If the phrase is indicative of a position to the right of center, please choose Conservative.","• If you feel like the phrase indicates some position to the left or right of the political center, but you’re not sure which direction, please mark Not neutral, but I’m unsure of which direction.","• If the phrase is not indicative of a position to the left or right of center, please mark Neutral.","We had workers annotate 7,000 randomly selected paths from the filteredIBC dataset, with half of the paths coming from conservative authors and the other half from liberal authors, as annotated by Gross et al. (2013). Three workers annotated each path in the dataset, and we paid $0.03 per sentence. Since identifying political bias is a relatively difficult and subjective task, we include all sentences where at least two workers agree on a label for the root node in our final dataset, except when that label is “Not neutral, but I’m unsure of Figure 3: Example political ideology annotation task showing incremental reveal of progressively longer phrases. which direction”. We only keep phrase-level annotations where at least two workers agree on the label: 70.4% of all annotated nodes fit this defini-tion of agreement. All unannotated nodes receive the label of their closest annotated ancestor. Since the root of each sentence is always annotated, this strategy ensures that every node in the tree has a label. Our final balanced IBC dataset consists of 3,412 sentences (4,062 before balancing and removing neutral sentences) with a total of 13,640 annotated nodes. Of these sentences, 543 switch polarity (liberal → conservative or vice versa) on an annotated path.","While we initially wanted to incorporate neutral labels into our model, we observed that lower-level phrases are almost always neutral while full sentences are much more likely to be biased (Figure 4). Due to this discrepancy, the objective function in Eq. (5) was minimized by making neutral predictions for almost every node in the dataset."]},{"title":"4 Experiments","paragraphs":["In this section we describe our experimental framework. We discuss strong baselines that use lexical and syntactic information (including framing-specific features from previous work) as well as multiple RNN configurations. Each of these models have the same task: to predict sentence-level ideology labels for sentences in a test set. To account for label imbalance, we subsample the data so that there are an equal number of labels and report accuracy over this balanced dataset. 1117","0 1 2 3 4 5 6 7 8 9 10 Node Depth 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Label Probability","Label Probability vs. Node Depth Conservative Liberal Neutral / No Agreement Figure 4: Proportion of liberal, conservative, and neutral annotations with respect to node depth (distance from root). As we get farther from the root of the tree, nodes are more likely to be neutral. 4.1 Baselines","• The RANDOM baseline chooses a label at random from {liberal, conservative}.","• LR1, our most basic logistic regression baseline, uses only bag of words (BoW) features.","• LR2 uses only BoW features. However, LR2 also includes phrase-level annotations as separate training instances.7","• LR3 uses BoW features as well as syntactic pseudo-word features from Greene & Resnik (2009). These features from dependency relations specify properties of verbs (e.g., transitivity or nominalization).8","• LR-(W2V) is a logistic regression model trained on the average of the pretrained word embeddings for each sentence (Section 2.2).","The LR-(W2V) baseline allows us to compare against a strong lexical representation that encodes syntactic and semantic information without the RNN tree structure. (LR1, LR2) offer a comparison to simple bag of words models, while the LR3 baseline contrasts traditional syntactic features with those learned by RNN models. 4.2 RNN Models For RNN models, we generate a feature vector for every node in the tree. Equation 1 allows us to 7 The Convote dataset was not annotated on the phrase","level, so we only provide a result for the IBC dataset. 8 We do not include phrase-level annotations in the LR3","feature set because the pseudo-word features can only be","computed from full sentence parses. Model Convote IBC RANDOM 50% 50% LR1 64.7% 62.1% LR2 – 61.9% LR3 66.9% 62.6% LR-(W2V) 66.6% 63.7% RNN1 69.4% 66.2% RNN1-(W2V) 70.2% 67.1% RNN2-(W2V) – 69.3% Table 1: Sentence-level bias detection accuracy. The RNN framework, adding phrase-level data, and initializing with word2vec all improve performance over logistic regression baselines. The LR2 and RNN2-(W2V) models were not trained on Convote since it lacks phrase annotations. percolate the representations to the root of the tree. We generate the final instance representation by concatenating the root vector and the average of all other vectors (Socher et al., 2011b). We train an L2-regularized logistic regression model over these concatenated vectors to obtain final accuracy numbers on the sentence level.","To analyze the effects of initialization and phrase-level annotations, we report results for three different RNN settings. All three models were implemented as described in Section 2 with the nonlinearity f set to the normalized tanh function, f (v) = tanh(v) ∥tanh(v)∥ . (7) We perform 10-fold cross-validation on the training data to find the bestRNN hyperparameters.9","We report results for RNN models with the following configurations:","• RNN1 initializes all parameters randomly and uses only sentence-level labels for training.","• RNN1-(W2V) uses the word2vec initialization described in Section 2.2 but is also trained on only sentence-level labels.","• RNN2-(W2V) is initialized using word2vec embeddings and also includes annotated phrase labels in its training. For this model, we also introduce a hyperparameter β that weights the error at annotated nodes (1 − β) higher than the error at unannotated nodes (β); since we have more confidence in the annotated labels, we want them to contribute more towards the objective function.","9 [λWe =1e-6, λW =1e-4, λW","cat =1e-3, β = 0.3] 1118","For all RNN models, we set the word vector dimension d to 300 to facilitate direct comparison against the LR-(W2V) baseline.10"]},{"title":"5 Where Compositionality Helps Detect Ideological Bias","paragraphs":["In this section, we examine the RNN models to see why they improve over our baselines. We also give examples of sentences that are correctly classified by our best RNN model but incorrectly classified by all of the baselines. Finally, we investigate sentence constructions that our model cannot handle and offer possible explanations for these errors. Experimental Results Table 1 shows the RNN models outperforming the bag-of-words baselines as well as the word2vec baseline on both datasets. The increased accuracy suggests that the trained RNNs are capable of detecting bias polarity switches at higher levels in parse trees. While phrase-level annotations do not improve baseline performance, the RNN model significantly benefits from these annotations because the phrases are themselves derived from nodes in the network structure. In particular, the phrase annotations allow our best model to detect bias accurately in complex sentences that the baseline models cannot handle.","Initializing the RNN We matrix with word2vec embeddings improves accuracy over randomly initialization by 1%. This is similar to improvements from pretrained vectors from neural language models (Socher et al., 2011b).","We obtain better results on Convote than on IBC with both bag-of-words and RNN models. This result was unexpected since the Convote labels are noisier than the annotated IBC labels; however, there are three possible explanations for the discrepancy. First, Convote has twice as many sentences as IBC, and the extra training data might help the model more than IBC’s better-quality labels. Second, since the sentences in Convote were originally spoken, they are almost half as short (21.3 words per sentence) as those in the IBC (42.2 words per sentence). Finally, some information is lost at every propagation step, so RNNs are able to model the shorter sentences in Convote more effectively than the longer IBC sentences. Qualitative Analysis As in previous work (Socher et al., 2011b), we visualize the learned","10","Using smaller vector sizes (d ∈ {50, 100}, as in previous work) does not significantly change accuracy. vector space by listing the most probable n-grams for each political affiliation in Table 2. As expected, conservatives emphasize values such as freedom and religion while disparaging excess government spending and their liberal opposition. Meanwhile, liberals inveigh against the gap between the rich and the poor while expressing concern for minority groups and the working class.","Our best model is able to accurately model the compositional effects of bias in sentences with complex syntactic structures. The first three sentences in Figure 5 were correctly classified by our best model (RNN2-(W2V)) and incorrectly classified by all of the baselines. Figures 5A and C show traditional conservative phrases, “free market ideology” and “huge amounts of taxpayer money”, that switch polarities higher up in the tree when combined with phrases such as “made worse by” and “saved by”. Figure 5B shows an example of a bias polarity switch in the opposite direction: the sentence negatively portrays supporters of nationalized health care, which our model picks up on.","Our model often makes errors when polarity switches occur at nodes that are high up in the tree. In Figure 5D, “be used as an instrument to achieve charitable or social ends” reflects a liberal ideology, which the model predicts correctly. However, our model is unable to detect the polarity switch when this phrase is negated with “should not”. Since many different issues are discussed in the IBC, it is likely that our dataset has too few examples of some of these issues for the model to adequately learn the appropriate ideological positions, and more training data would resolve many of these errors."]},{"title":"6 Related Work","paragraphs":["A growing NLP subfield detects private states such as opinions, sentiment, and beliefs (Wilson et al., 2005; Pang and Lee, 2008) from text. In general, work in this category tends to combine traditional surface lexical modeling (e.g., bag-of-words) with hand-designed syntactic features or lexicons. Here we review the most salient literature related to the present paper. 6.1 Automatic Ideology Detection Most previous work on ideology detection ignores the syntactic structure of the language in use in favor of familiar bag-of-words representations for 1119 be used as an instrument to achieve charitable or social ends should notthe law"]},{"title":"X X X","paragraphs":["nationalized health careAn entertainer once said a sucker is born every minute , and surely this is the case with those who support made worse by the implementing Thus , the harsh conditions for farmers caused by a number of factors , , have created a continuing stream of people leaving the countryside and going to live in cities that do not have jobs for them . of free-market ideology huge amounts of taxpayer money","saved byBut taxpayers do know already that TARP was designed in a way that allowed to continue to show the same arrogant traits that should have destroyed their companies . the same corporations who were A B C D Figure 5: Predictions by RNN2-(W2V) on four sentences from the IBC. Node color is the true label (red for conservative, blue for liberal), and an “X” next to a node means the model’s prediction was wrong. In A and C, the model accurately detects conservative-to-liberal polarity switches, while in B it correctly predicts the liberal-to-conservative switch. In D, negation confuses our model. the sake of simplicity. For example, Gentzkow and Shapiro (2010) derive a “slant index” to rate the ideological leaning of newspapers. A newspa-per’s slant index is governed by the frequency of use of partisan collocations of 2-3 tokens. Similarly, authors have relied on simple models of language when leveraging inferred ideological positions. E.g., Gerrish and Blei (2011) predict the voting patterns of Congress members based on bag-of-words representations of bills and inferred political leanings of those members.","Recently, Sim et al. (2013) have proposed a model to infer mixtures of ideological positions in documents, applied to understanding the evolution of ideological rhetoric used by political can-didates during the campaign cycle. They use an HMM-based model, defining the states as a set of fine-grained political ideologies, and rely on a closed set of lexical bigram features associated with each ideology, inferred from a manually labeled ideological books corpus. Although it takes elements of discourse structure into account (capturing the“burstiness” of ideological terminology usage), their model explicitly ignores intrasentential contextual influences of the kind seen in Figure 1. Other approaches on the document level use topic models to analyze bias in news articles, blogs, and political speeches (Ahmed and Xing, 2010; Lin et al., 2008; Nguyen et al., 2013). 6.2 Subjectivity Detection Detecting subjective language, which conveys opinion or speculation, is a related NLP problem. While sentences lacking subjective language may contain ideological bias (e.g., the topic of the sentence), highly-opinionated sentences likely have obvious ideological leanings. In addition, sentiment and subjectivity analysis offers methodolog-ical approaches that can be applied to automatic bias detection.","Wiebe et al. (2004) show that low-frequency words and some collocations are a good indicators of subjectivity. More recently, Recasens et al. (2013) detect biased words in sentences using indicator features for bias cues such as hedges and fac-tive verbs in addition to standard bag-of-words and part-of-speech features. They show that this type of linguistic information dramatically improves performance over several standard baselines.","Greene and Resnik (2009) also emphasize the connection between syntactic and semantic relationships in their work on “implicit sentiment”, 1120 n Most conservative n-grams Most liberal n-grams 1 Salt, Mexico, housework, speculated, consensus, lawyer,","pharmaceuticals, ruthless, deadly, Clinton, redistribution rich, antipsychotic, malaria, biodiversity, richest, gene, pesticides, desertification, Net, wealthiest, labor, fertilizer, nuclear, HIV","3 prize individual liberty, original liberal idiots, stock market crash, God gives freedom, federal government interference, federal oppression nullification, respect individual liberty, Tea Party patriots, radical Sunni Islamists, Obama stimulus programs rich and poor,“corporate greed”, super rich pay, carrying the rich, corporate interest groups, young women workers, the very rich, for the rich, by the rich, soaking the rich, getting rich often, great and rich, the working poor, corporate income tax, the poor migrants","5 spending on popular government programs, bailouts and unfunded government promises, North America from external threats, government regulations place on businesses, strong Church of Christ convictions, radical Islamism and other threats the rich are really rich, effective forms of worker participation, the pensions of the poor, tax cuts for the rich, the ecological services of biodiversity, poor children and pregnant women, vacation time for overtime pay","7 government intervention helped make the Depression Great, by God in His image and likeness, producing wealth instead of stunting capital creation, the traditional American values of limited government, trillions of dollars to overseas oil producers, its troubled assets to federal sugar daddies, Obama and his party as racialist fanatics African Americans and other disproportionately poor groups; the growing gap between rich and poor; the Bush tax cuts for the rich; public outrage at corporate and societal greed; sexually transmitted diseases , most notably AIDS; organize unions or fight for better conditions, the biggest hope for health care reform Table 2: Highest probability n-grams for conservative and liberal ideologies, as predicted by the RNN2- (W2V) model. which refers to sentiment carried by sentence structure and not word choice. They use syntactic dependency relation features combined with lexical information to achieve then state-of-the-art performance on standard sentiment analysis datasets. However, these syntactic features are only computed for a thresholded list of domain-specific verbs. This work extends their insight of modeling sentiment as an interaction between syntax and semantics to ideological bias. Future Work There are a few obvious directions in which this work can be expanded. First, we can consider more nuanced political ideologies beyond liberal and conservative. We show that it is possible to detect ideological bias given this binary problem; however, a finer-grained study that also includes neutral annotations may reveal more subtle distinctions between ideologies. While acquir-ing data with obscure political biases from the IBC or Convote is unfeasible, we can apply a similar analysis to social media (e.g., Twitter or Facebook updates) to discover how many different ideologies propagate in these networks.","Another direction is to implement more sophisticated RNN models (along with more training data) for bias detection. We attempted to apply syntactically-untied RNNs (Socher et al., 2013a) to our data with the idea that associating separate matrices for phrasal categories would improve representations at high-level nodes. While there were too many parameters for this model to work well here, other variations might prove successful, especially with more data. Finally, combining sentence-level and document-level models might improve bias detection at both levels."]},{"title":"7 Conclusion","paragraphs":["In this paper we apply recursive neural networks to political ideology detection, a problem where previous work relies heavily on bag-of-words models and hand-designed lexica. We show that our approach detects bias more accurately than existing methods on two different datasets. In addition, we describe an approach to crowdsourcing ideological bias annotations. We use this approach to create a new dataset from the IBC, which is labeled at both the sentence and phrase level."]},{"title":"Acknowledgments","paragraphs":["We thank the anonymous reviewers, Hal Daumé, Yuening Hu, Yasuhiro Takayama, and Jyothi Vinjumur for their insightful comments. We also want to thank Justin Gross for providing the IBC and Asad Sayeed for help with the Crowdflower task design, as well as Richard Socher and Karl Moritz Hermann for assisting us with our model implementations. This work was supported by NSF Grant CCF-1018625. Boyd-Graber is also supported by NSF Grant IIS-1320538. Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and do not necessarily reflect the view of the sponsor. 1121"]},{"title":"References","paragraphs":["Amr Ahmed and Eric P Xing. 2010. Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective. In EMNLP.","Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai. 1992. Class-based n-gram models of natural language. Comp. Ling., 18(4):467–479.","Royce Carroll, Jeffrey B Lewis, James Lo, Keith T Poole, and Howard Rosenthal. 2009. Measuring bias and uncertainty in dw-nominate ideal point estimates via the parametric bootstrap. Political Analysis, 17(3):261–275.","Ronan Collobert and Jason Weston. 2008. A unified architec-ture for natural language processing: Deep neural networks with multitask learning. In ICML.","Frank E Dardis, Frank R Baumgartner, Amber E Boydstun, Suzanna De Boef, and Fuyuan Shen. 2008. Media framing of capital punishment and its impact on individuals’ cogni-tive responses. Mass Communication & Society, 11(2):115– 140.","Matthew Gentzkow and Jesse M Shapiro. 2010. What drives media slant? evidence from us daily newspapers. Econometrica, 78(1):35–71.","Sean Gerrish and David M Blei. 2011. Predicting legislative roll calls from text. In ICML.","Christoph Goller and Andreas Kuchler. 1996. Learning task-dependent distributed representations by backpropagation through structure. In Neural Networks, 1996., IEEE International Conference on, volume 1.","Stephan Greene and Philip Resnik. 2009. More than words: Syntactic packaging and implicit sentiment. In NAACL.","Tim Groseclose and Jeffrey Milyo. 2005. A measure of media bias. The Quarterly Journal of Economics, 120(4):1191– 1237.","Justin Gross, Brice Acree, Yanchuan Sim, and Noah A Smith. 2013. Testing the etch-a-sketch hypothesis: A computational analysis of mitt romney’s ideological makeover during the 2012 primary vs. general elections. In APSA 2013 Annual Meeting Paper.","Kazuma Hashimoto, Makoto Miwa, Yoshimasa Tsuruoka, and Takashi Chikayama. 2013. Simple customization of recursive neural networks for semantic relation classification. In EMNLP.","Karl Moritz Hermann and Phil Blunsom. 2013. The Role of Syntax in Vector Space Models of Compositional Semantics. In ACL.","George Lakoff. 2002. Moral Politics: How Liberals and Conservatives Think, Second Edition. University of Chicago Press.","Wei-Hao Lin, Eric Xing, and Alexander Hauptmann. 2008. A joint topic and perspective model for ideological discourse. In Machine Learning and Knowledge Discovery in Databases, pages 17–32. Springer.","Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.","Viet-An Nguyen, Jordan Boyd-Graber, and Philip Resnik. 2013. Lexical and hierarchical topic regression. In NIPS, pages 1106–1114.","David Niven. 2003. Objective evidence on media bias: News-paper coverage of congressional party switchers. Journalism & Mass Communication Quarterly, 80(2):311–326.","Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2).","James W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic inquiry and word count [computer software]. Mahwah, NJ: Erlbaum Publishers.","Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic models for analyzing and detecting biased language.","Asad B Sayeed, Jordan Boyd-Graber, Bryan Rusk, and Amy Weinberg. 2012. Grammatical structures for word-level sentiment detection. In NAACL.","Burr Settles. 2011. Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances. In EMNLP.","Yanchuan Sim, Brice Acree, Justin H Gross, and Noah A Smith. 2013. Measuring ideological proportions in political speeches. In EMNLP.","Richard Socher, Eric H. Huang, Jeffrey Pennington, Andrew Y. Ng, and Christopher D. Manning. 2011a. Dynamic Pool-ing and Unfolding Recursive Autoencoders for Paraphrase Detection. In NIPS.","Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning. 2011b. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions. In EMNLP.","Richard Socher, John Bauer, Christopher D. Manning, and Andrew Y. Ng. 2013a. Parsing With Compositional Vector Grammars. In ACL.","Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013b. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP.","Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from Congressional floor-debate transcripts. In EMNLP.","Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Comp. Ling., 30(3):277–308.","Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In EMNLP.","Tae Yano, Philip Resnik, and Noah A Smith. 2010. Shedding (a thousand points of) light on biased language. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 152–158. 1122"]}],"references":[{"authors":[{"first":"Amr","last":"Ahmed"},{"first":"Eric","middle":"P","last":"Xing"}],"year":"2010","title":"Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective","source":"Amr Ahmed and Eric P Xing. 2010. Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective. In EMNLP."},{"authors":[{"first":"Peter","middle":"F","last":"Brown"},{"first":"Peter V","last":"Desouza"},{"first":"Robert","middle":"L","last":"Mercer"},{"first":"Vincent","middle":"J Della","last":"Pietra"},{"first":"Jenifer","middle":"C","last":"Lai"}],"year":"1992","title":"Class-based n-gram models of natural language","source":"Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai. 1992. Class-based n-gram models of natural language. Comp. Ling., 18(4):467–479."},{"authors":[{"first":"Royce","last":"Carroll"},{"first":"Jeffrey","middle":"B","last":"Lewis"},{"first":"James","last":"Lo"},{"first":"Keith","middle":"T","last":"Poole"},{"first":"Howard","last":"Rosenthal"}],"year":"2009","title":"Measuring bias and uncertainty in dw-nominate ideal point estimates via the parametric bootstrap","source":"Royce Carroll, Jeffrey B Lewis, James Lo, Keith T Poole, and Howard Rosenthal. 2009. Measuring bias and uncertainty in dw-nominate ideal point estimates via the parametric bootstrap. Political Analysis, 17(3):261–275."},{"authors":[{"first":"Ronan","last":"Collobert"},{"first":"Jason","last":"Weston"}],"year":"2008","title":"A unified architec-ture for natural language processing: Deep neural networks with multitask learning","source":"Ronan Collobert and Jason Weston. 2008. A unified architec-ture for natural language processing: Deep neural networks with multitask learning. In ICML."},{"authors":[{"first":"Frank","middle":"E","last":"Dardis"},{"first":"Frank","middle":"R","last":"Baumgartner"},{"first":"Amber","middle":"E","last":"Boydstun"},{"first":"Suzanna","last":"De Boef"},{"first":"Fuyuan","last":"Shen"}],"year":"2008","title":"Media framing of capital punishment and its impact on individuals’ cogni-tive responses","source":"Frank E Dardis, Frank R Baumgartner, Amber E Boydstun, Suzanna De Boef, and Fuyuan Shen. 2008. Media framing of capital punishment and its impact on individuals’ cogni-tive responses. Mass Communication & Society, 11(2):115– 140."},{"authors":[{"first":"Matthew","last":"Gentzkow"},{"first":"Jesse","middle":"M","last":"Shapiro"}],"year":"2010","title":"What drives media slant? evidence from us daily newspapers","source":"Matthew Gentzkow and Jesse M Shapiro. 2010. What drives media slant? evidence from us daily newspapers. Econometrica, 78(1):35–71."},{"authors":[{"first":"Sean","last":"Gerrish"},{"first":"David","middle":"M","last":"Blei"}],"year":"2011","title":"Predicting legislative roll calls from text","source":"Sean Gerrish and David M Blei. 2011. Predicting legislative roll calls from text. In ICML."},{"authors":[{"first":"Christoph","last":"Goller"},{"first":"Andreas","last":"Kuchler"}],"year":"1996","title":"Learning task-dependent distributed representations by backpropagation through structure","source":"Christoph Goller and Andreas Kuchler. 1996. Learning task-dependent distributed representations by backpropagation through structure. In Neural Networks, 1996., IEEE International Conference on, volume 1."},{"authors":[{"first":"Stephan","last":"Greene"},{"first":"Philip","last":"Resnik"}],"year":"2009","title":"More than words: Syntactic packaging and implicit sentiment","source":"Stephan Greene and Philip Resnik. 2009. More than words: Syntactic packaging and implicit sentiment. In NAACL."},{"authors":[{"first":"Tim","last":"Groseclose"},{"first":"Jeffrey","last":"Milyo"}],"year":"2005","title":"A measure of media bias","source":"Tim Groseclose and Jeffrey Milyo. 2005. A measure of media bias. The Quarterly Journal of Economics, 120(4):1191– 1237."},{"authors":[{"first":"Justin","last":"Gross"},{"first":"Brice","last":"Acree"},{"first":"Yanchuan","last":"Sim"},{"first":"Noah","middle":"A","last":"Smith"}],"year":"2013","title":"Testing the etch-a-sketch hypothesis: A computational analysis of mitt romney’s ideological makeover during the 2012 primary vs","source":"Justin Gross, Brice Acree, Yanchuan Sim, and Noah A Smith. 2013. Testing the etch-a-sketch hypothesis: A computational analysis of mitt romney’s ideological makeover during the 2012 primary vs. general elections. In APSA 2013 Annual Meeting Paper."},{"authors":[{"first":"Kazuma","last":"Hashimoto"},{"first":"Makoto","last":"Miwa"},{"first":"Yoshimasa","last":"Tsuruoka"},{"first":"Takashi","last":"Chikayama"}],"year":"2013","title":"Simple customization of recursive neural networks for semantic relation classification","source":"Kazuma Hashimoto, Makoto Miwa, Yoshimasa Tsuruoka, and Takashi Chikayama. 2013. Simple customization of recursive neural networks for semantic relation classification. In EMNLP."},{"authors":[{"first":"Karl","middle":"Moritz","last":"Hermann"},{"first":"Phil","last":"Blunsom"}],"year":"2013","title":"The Role of Syntax in Vector Space Models of Compositional Semantics","source":"Karl Moritz Hermann and Phil Blunsom. 2013. The Role of Syntax in Vector Space Models of Compositional Semantics. In ACL."},{"authors":[{"first":"George","last":"Lakoff"}],"year":"2002","title":"Moral Politics: How Liberals and Conservatives Think, Second Edition","source":"George Lakoff. 2002. Moral Politics: How Liberals and Conservatives Think, Second Edition. University of Chicago Press."},{"authors":[{"first":"Wei-Hao","last":"Lin"},{"first":"Eric","last":"Xing"},{"first":"Alexander","last":"Hauptmann"}],"year":"2008","title":"A joint topic and perspective model for ideological discourse","source":"Wei-Hao Lin, Eric Xing, and Alexander Hauptmann. 2008. A joint topic and perspective model for ideological discourse. In Machine Learning and Knowledge Discovery in Databases, pages 17–32. Springer."},{"authors":[{"first":"Tomas","last":"Mikolov"},{"first":"Kai","last":"Chen"},{"first":"Greg","last":"Corrado"},{"first":"Jeffrey","last":"Dean"}],"year":"2013","title":"Efficient estimation of word representations in vector space","source":"Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781."},{"authors":[{"first":"Viet-An","last":"Nguyen"},{"first":"Jordan","last":"Boyd-Graber"},{"first":"Philip","last":"Resnik"}],"year":"2013","title":"Lexical and hierarchical topic regression","source":"Viet-An Nguyen, Jordan Boyd-Graber, and Philip Resnik. 2013. Lexical and hierarchical topic regression. In NIPS, pages 1106–1114."},{"authors":[{"first":"David","last":"Niven"}],"year":"2003","title":"Objective evidence on media bias: News-paper coverage of congressional party switchers","source":"David Niven. 2003. Objective evidence on media bias: News-paper coverage of congressional party switchers. Journalism & Mass Communication Quarterly, 80(2):311–326."},{"authors":[{"first":"Bo","last":"Pang"},{"first":"Lillian","last":"Lee"}],"year":"2008","title":"Opinion mining and sentiment analysis","source":"Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2)."},{"authors":[{"first":"James","middle":"W.","last":"Pennebaker"},{"first":"Martha","middle":"E.","last":"Francis"},{"first":"Roger","middle":"J.","last":"Booth"}],"year":"2001","title":"Linguistic inquiry and word count [computer software]","source":"James W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic inquiry and word count [computer software]. Mahwah, NJ: Erlbaum Publishers."},{"authors":[{"first":"Marta","last":"Recasens"},{"first":"Cristian","last":"Danescu-Niculescu-Mizil"},{"first":"Dan","last":"Jurafsky"}],"year":"2013","title":"Linguistic models for analyzing and detecting biased language","source":"Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic models for analyzing and detecting biased language."},{"authors":[{"first":"Asad","middle":"B","last":"Sayeed"},{"first":"Jordan","last":"Boyd-Graber"},{"first":"Bryan","last":"Rusk"},{"first":"Amy","last":"Weinberg"}],"year":"2012","title":"Grammatical structures for word-level sentiment detection","source":"Asad B Sayeed, Jordan Boyd-Graber, Bryan Rusk, and Amy Weinberg. 2012. Grammatical structures for word-level sentiment detection. In NAACL."},{"authors":[{"first":"Burr","last":"Settles"}],"year":"2011","title":"Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances","source":"Burr Settles. 2011. Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances. In EMNLP."},{"authors":[{"first":"Yanchuan","last":"Sim"},{"first":"Brice","last":"Acree"},{"first":"Justin","middle":"H","last":"Gross"},{"first":"Noah","middle":"A","last":"Smith"}],"year":"2013","title":"Measuring ideological proportions in political speeches","source":"Yanchuan Sim, Brice Acree, Justin H Gross, and Noah A Smith. 2013. Measuring ideological proportions in political speeches. In EMNLP."},{"authors":[{"first":"Richard","last":"Socher"},{"first":"Eric","middle":"H.","last":"Huang"},{"first":"Jeffrey","last":"Pennington"},{"first":"Andrew","middle":"Y.","last":"Ng"},{"first":"Christopher","middle":"D.","last":"Manning"}],"year":"2011a","title":"Dynamic Pool-ing and Unfolding Recursive Autoencoders for Paraphrase Detection","source":"Richard Socher, Eric H. Huang, Jeffrey Pennington, Andrew Y. Ng, and Christopher D. Manning. 2011a. Dynamic Pool-ing and Unfolding Recursive Autoencoders for Paraphrase Detection. In NIPS."},{"authors":[{"first":"Richard","last":"Socher"},{"first":"Jeffrey","last":"Pennington"},{"first":"Eric","middle":"H.","last":"Huang"},{"first":"Andrew","middle":"Y.","last":"Ng"},{"first":"Christopher","middle":"D.","last":"Manning"}],"year":"2011b","title":"Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions","source":"Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning. 2011b. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions. In EMNLP."},{"authors":[{"first":"Richard","last":"Socher"},{"first":"John","last":"Bauer"},{"first":"Christopher","middle":"D.","last":"Manning"},{"first":"Andrew","middle":"Y.","last":"Ng"}],"year":"2013a","title":"Parsing With Compositional Vector Grammars","source":"Richard Socher, John Bauer, Christopher D. Manning, and Andrew Y. Ng. 2013a. Parsing With Compositional Vector Grammars. In ACL."},{"authors":[{"first":"Richard","last":"Socher"},{"first":"Alex","last":"Perelygin"},{"first":"Jean","middle":"Y","last":"Wu"},{"first":"Jason","last":"Chuang"},{"first":"Christopher","middle":"D","last":"Manning"},{"first":"Andrew","middle":"Y","last":"Ng"},{"first":"Christopher","last":"Potts"}],"year":"2013b","title":"Recursive deep models for semantic compositionality over a sentiment treebank","source":"Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013b. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP."},{"authors":[{"first":"Matt","last":"Thomas"},{"first":"Bo","last":"Pang"},{"first":"Lillian","last":"Lee"}],"year":"2006","title":"Get out the vote: Determining support or opposition from Congressional floor-debate transcripts","source":"Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from Congressional floor-debate transcripts. In EMNLP."},{"authors":[{"first":"Janyce","last":"Wiebe"},{"first":"Theresa","last":"Wilson"},{"first":"Rebecca","last":"Bruce"},{"first":"Matthew","last":"Bell"},{"first":"Melanie","last":"Martin"}],"year":"2004","title":"Learning subjective language","source":"Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Comp. Ling., 30(3):277–308."},{"authors":[{"first":"Theresa","last":"Wilson"},{"first":"Janyce","last":"Wiebe"},{"first":"Paul","last":"Hoffmann"}],"year":"2005","title":"Recognizing contextual polarity in phrase-level sentiment analysis","source":"Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In EMNLP."},{"authors":[{"first":"Tae","last":"Yano"},{"first":"Philip","last":"Resnik"},{"first":"Noah","middle":"A","last":"Smith"}],"year":"2010","title":"Shedding (a thousand points of) light on biased language","source":"Tae Yano, Philip Resnik, and Noah A Smith. 2010. Shedding (a thousand points of) light on biased language. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 152–158. 1122"}],"cites":[{"style":0,"text":"Lakoff, 2002","origin":{"pointer":"/sections/9/paragraphs/0","offset":271,"length":12},"authors":[{"last":"Lakoff"}],"year":"2002","references":["/references/13"]},{"style":0,"text":"Groseclose and Milyo, 2005","origin":{"pointer":"/sections/9/paragraphs/0","offset":430,"length":26},"authors":[{"last":"Groseclose"},{"last":"Milyo"}],"year":"2005","references":["/references/9"]},{"style":0,"text":"Gentzkow and Shapiro, 2010","origin":{"pointer":"/sections/9/paragraphs/0","offset":458,"length":26},"authors":[{"last":"Gentzkow"},{"last":"Shapiro"}],"year":"2010","references":["/references/5"]},{"style":0,"text":"Niven, 2003","origin":{"pointer":"/sections/9/paragraphs/0","offset":486,"length":11},"authors":[{"last":"Niven"}],"year":"2003","references":["/references/17"]},{"style":0,"text":"Dardis et al., 2008","origin":{"pointer":"/sections/9/paragraphs/0","offset":840,"length":19},"authors":[{"last":"Dardis"},{"last":"al."}],"year":"2008","references":["/references/4"]},{"style":0,"text":"Socher et al., 2011b","origin":{"pointer":"/sections/9/paragraphs/6","offset":306,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011b","references":["/references/25"]},{"style":0,"text":"Socher et al., 2013b","origin":{"pointer":"/sections/9/paragraphs/6","offset":328,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2013b","references":["/references/27"]},{"style":0,"text":"Socher et al., 2011a","origin":{"pointer":"/sections/10/paragraphs/0","offset":265,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011a","references":["/references/24"]},{"style":0,"text":"Hermann and Blunsom, 2013","origin":{"pointer":"/sections/10/paragraphs/0","offset":287,"length":25},"authors":[{"last":"Hermann"},{"last":"Blunsom"}],"year":"2013","references":["/references/12"]},{"style":0,"text":"Hashimoto et al., 2013","origin":{"pointer":"/sections/10/paragraphs/10","offset":41,"length":22},"authors":[{"last":"Hashimoto"},{"last":"al."}],"year":"2013","references":["/references/11"]},{"style":0,"text":"Goller and Kuchler, 1996","origin":{"pointer":"/sections/10/paragraphs/10","offset":232,"length":24},"authors":[{"last":"Goller"},{"last":"Kuchler"}],"year":"1996","references":["/references/7"]},{"style":0,"text":"Collobert and Weston, 2008","origin":{"pointer":"/sections/10/paragraphs/11","offset":733,"length":26},"authors":[{"last":"Collobert"},{"last":"Weston"}],"year":"2008","references":["/references/3"]},{"style":0,"text":"Socher et al., 2011a","origin":{"pointer":"/sections/10/paragraphs/11","offset":761,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011a","references":["/references/24"]},{"style":0,"text":"Mikolov et al., 2013","origin":{"pointer":"/sections/10/paragraphs/11","offset":961,"length":20},"authors":[{"last":"Mikolov"},{"last":"al."}],"year":"2013","references":["/references/15"]},{"style":0,"text":"Socher et al., 2013a","origin":{"pointer":"/sections/10/paragraphs/12","offset":523,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2013a","references":["/references/26"]},{"style":0,"text":"Thomas et al., 2006","origin":{"pointer":"/sections/11/paragraphs/0","offset":755,"length":19},"authors":[{"last":"Thomas"},{"last":"al."}],"year":"2006","references":["/references/28"]},{"style":0,"text":"Carroll et al., 2009","origin":{"pointer":"/sections/11/paragraphs/0","offset":1304,"length":20},"authors":[{"last":"Carroll"},{"last":"al."}],"year":"2009","references":["/references/2"]},{"style":0,"text":"Yano et al. (2010)","origin":{"pointer":"/sections/11/paragraphs/2","offset":33,"length":18},"authors":[{"last":"Yano"},{"last":"al."}],"year":"2010","references":["/references/31"]},{"style":0,"text":"Pennebaker et al., 2001","origin":{"pointer":"/sections/11/paragraphs/2","offset":251,"length":23},"authors":[{"last":"Pennebaker"},{"last":"al."}],"year":"2001","references":["/references/19"]},{"style":0,"text":"Brown et al., 1992","origin":{"pointer":"/sections/11/paragraphs/2","offset":320,"length":18},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1992","references":["/references/1"]},{"style":0,"text":"Gross et al. (2013)","origin":{"pointer":"/sections/11/paragraphs/4","offset":529,"length":19},"authors":[{"last":"Gross"},{"last":"al."}],"year":"2013","references":["/references/10"]},{"style":0,"text":"Yano et al. (2010)","origin":{"pointer":"/sections/11/paragraphs/10","offset":45,"length":18},"authors":[{"last":"Yano"},{"last":"al."}],"year":"2010","references":["/references/31"]},{"style":0,"text":"Greene and Resnik (2009)","origin":{"pointer":"/sections/11/paragraphs/10","offset":80,"length":24},"authors":[{"last":"Greene"},{"last":"Resnik"}],"year":"2009","references":["/references/8"]},{"style":0,"text":"Settles, 2011","origin":{"pointer":"/sections/11/paragraphs/12","offset":329,"length":13},"authors":[{"last":"Settles"}],"year":"2011","references":["/references/22"]},{"style":0,"text":"Sayeed et al., 2012","origin":{"pointer":"/sections/11/paragraphs/13","offset":137,"length":19},"authors":[{"last":"Sayeed"},{"last":"al."}],"year":"2012","references":["/references/21"]},{"style":0,"text":"Socher et al., 2013a","origin":{"pointer":"/sections/11/paragraphs/13","offset":555,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2013a","references":["/references/26"]},{"style":0,"text":"Gross et al. (2013)","origin":{"pointer":"/sections/11/paragraphs/25","offset":197,"length":19},"authors":[{"last":"Gross"},{"last":"al."}],"year":"2013","references":["/references/10"]},{"style":0,"text":"Greene & Resnik (2009)","origin":{"pointer":"/sections/12/paragraphs/6","offset":71,"length":22},"authors":[{"last":"Greene"},{"last":"Resnik"}],"year":"2009","references":["/references/8"]},{"style":0,"text":"Socher et al., 2011b","origin":{"pointer":"/sections/12/paragraphs/11","offset":643,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011b","references":["/references/25"]},{"style":0,"text":"Socher et al., 2011b","origin":{"pointer":"/sections/13/paragraphs/1","offset":195,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011b","references":["/references/25"]},{"style":0,"text":"Socher et al., 2011b","origin":{"pointer":"/sections/13/paragraphs/2","offset":765,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2011b","references":["/references/25"]},{"style":0,"text":"Wilson et al., 2005","origin":{"pointer":"/sections/14/paragraphs/0","offset":88,"length":19},"authors":[{"last":"Wilson"},{"last":"al."}],"year":"2005","references":["/references/30"]},{"style":0,"text":"Pang and Lee, 2008","origin":{"pointer":"/sections/14/paragraphs/0","offset":109,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2008","references":["/references/18"]},{"style":0,"text":"Gentzkow and Shapiro (2010)","origin":{"pointer":"/sections/15/paragraphs/1","offset":642,"length":27},"authors":[{"last":"Gentzkow"},{"last":"Shapiro"}],"year":"2010","references":["/references/5"]},{"style":0,"text":"Gerrish and Blei (2011)","origin":{"pointer":"/sections/15/paragraphs/1","offset":957,"length":23},"authors":[{"last":"Gerrish"},{"last":"Blei"}],"year":"2011","references":["/references/6"]},{"style":0,"text":"Sim et al. (2013)","origin":{"pointer":"/sections/15/paragraphs/2","offset":10,"length":17},"authors":[{"last":"Sim"},{"last":"al."}],"year":"2013","references":["/references/23"]},{"style":0,"text":"Ahmed and Xing, 2010","origin":{"pointer":"/sections/15/paragraphs/2","offset":810,"length":20},"authors":[{"last":"Ahmed"},{"last":"Xing"}],"year":"2010","references":["/references/0"]},{"style":0,"text":"Lin et al., 2008","origin":{"pointer":"/sections/15/paragraphs/2","offset":832,"length":16},"authors":[{"last":"Lin"},{"last":"al."}],"year":"2008","references":["/references/14"]},{"style":0,"text":"Nguyen et al., 2013","origin":{"pointer":"/sections/15/paragraphs/2","offset":850,"length":19},"authors":[{"last":"Nguyen"},{"last":"al."}],"year":"2013","references":["/references/16"]},{"style":0,"text":"Wiebe et al. (2004)","origin":{"pointer":"/sections/15/paragraphs/3","offset":0,"length":19},"authors":[{"last":"Wiebe"},{"last":"al."}],"year":"2004","references":["/references/29"]},{"style":0,"text":"Recasens et al. (2013)","origin":{"pointer":"/sections/15/paragraphs/3","offset":126,"length":22},"authors":[{"last":"Recasens"},{"last":"al."}],"year":"2013","references":["/references/20"]},{"style":0,"text":"Greene and Resnik (2009)","origin":{"pointer":"/sections/15/paragraphs/4","offset":0,"length":24},"authors":[{"last":"Greene"},{"last":"Resnik"}],"year":"2009","references":["/references/8"]},{"style":0,"text":"Socher et al., 2013a","origin":{"pointer":"/sections/15/paragraphs/9","offset":165,"length":20},"authors":[{"last":"Socher"},{"last":"al."}],"year":"2013a","references":["/references/26"]}]}
