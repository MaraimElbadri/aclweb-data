{"sections":[{"title":"","paragraphs":["Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 65–68, Sydney, July 2006. c⃝2006 Association for Computational Linguistics"]},{"title":"An Implemented Description of Japanese: The Lexeed Dictionary and the Hinoki Treebank Sanae Fujita, Takaaki Tanaka, Francis Bond, Hiromi Nakaiwa NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation {sanae, takaaki, bond, nakaiwa}@cslab.kecl.ntt.co.jp Abstract","paragraphs":["In this paper we describe the current state of a new Japanese lexical resource: the Hinoki treebank. The treebank is built from dictionary denition sentences, and uses an HPSG based Japanese grammar to encode both syntactic and semantic information. It is combined with an ontology based on the denition sentences to give a detailed sense level description of the most familiar 28,000 words of Japanese."]},{"title":"1 Introduction","paragraphs":["In this paper we describe the current state of a new lexical resource: the Hinoki treebank. The ultimate goal of our research is natural language understanding we aim to create a system that can parse text into some useful semantic representation. This is an ambitious goal, and this presentation does not present a complete solution, but rather a road-map to the solution, with some progress along the way.","The rst phase of the project, which we present here, is to construct a syntactically and semantically annotated corpus based on the machine readable dictionary Lexeed (Kasahara et al., 2004). This is a hand built self-contained lexicon: it consists of headwords and their denitions for the most familiar 28,000 words of Japanese. Each denition and example sentence has been parsed, and the most appropriate analysis selected. Each content word in the sentences has been marked with the appropriate Lexeed sense. The syntactic model is embodied in a grammar, while the semantic model is linked by an ontology. This makes it possible to test the use of similarity and/or semantic class based back-offs for parsing and generation with both symbolic grammars and statistical models.","In order to make the system self sustaining we base the rst growth of our treebank on the dictionary denition sentences themselves. We then train a statistical model on the treebank and parse the entire lexicon. From this we induce a thesaurus. We are currently tagging other genres with the same information. We will then use this information and the thesaurus to build a parsing model that combines syntactic and semantic information. We will also produce a richer ontology for example extracting selectional preferences. In the last phase, we will look at ways of extending our lexicon and ontology to less familiar words."]},{"title":"2 The Lexeed Semantic Database of Japanese","paragraphs":["The Lexeed Semantic Database of Japanese consists of all Japanese words with a familiarity greater than or equal to ve on a seven point scale (Kasahara et al., 2004). This gives 28,000 words in all, with 46,000 different senses. Denition sentences for these sentences were rewritten to use only the 28,000 familiar words (and some function words). The dening vocabulary is actually 16,900 different words (60% of all possible words). A simplied example entry for the last two senses of the word %I%i%$%P!< doraibfla driver is given in Figure 1, with English glosses added, but omitting the example sentences. Lexeed itself consists of just the denitions, familiarity and part of speech, all the underlined features are those added by the Hinoki project."]},{"title":"3 The Hinoki Treebank","paragraphs":["The structure of our treebank is inspired by the Redwoods treebank of English (Oepen et al., 2002) in which utterances are parsed and the annotator selects the best parse from the full analyses derived by the grammar. We had four main reasons for selecting this approach. The rst was that we wanted to develop a precise broad-coverage 65                                 INDEX %I%i%$%P!< doraibfla POS noun Lexical-Type noun-lex FAMILIARITY 6.5 [17] ( 5) Frequency 37 Entropy 0.79","SENSE 1 . . . SENSE 2 P(S2) = 0.84        DEFINITION <+F0<V1/$r/1?E>1/$9$k/?M1/!#","Someone who drives a car. HYPERNYM ?M1 hito person SEM. CLASS h292:chauffeur/driveri ( h5:personi) WORDNET driver1        SENSE 3 P(S2) = 0.05           DEFINITION %4%k%U1/$G/ !\"/1s5wN%1/MQ/$N/%/%i%V3/!#0lHV/%&%C%I/!#","In golf, a long-distance club. A number one wood. HYPERNYM %/%i%V3 kurabu club SEM. CLASS h921:leisure equipmenti ( 921) WORDNET driver5 DOMAIN %4%k%U1 gorufu golf                                           Figure 1: Entry for the Word doraib fla driver (with English glosses) grammar in tandem with the treebank, as part of our research into natural language understanding. Treebanking the output of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually benecial feedback loop.","The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel (2000)) based on a monostratal theory of grammar (Head Driven Phrase Structure Grammar) we could simultaneously annotate syntactic and semantic structure without overburden-ing the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of information can be extracted at various levels of granularity: A simplied example of the labeled tree, minimal recursion semantics representation (MRS) and semantic dependency views for the denition of %I%i%$%P!<2 doraib fla driver is given in Figure 2.","The third reason was that use of the grammar as a base enforces consistency all sentences annotated are guaranteed to have well-formed parses. The last reason was the availability of a reason-ably robust existing HPSG of Japanese (JACY), and a wide range of open source tools for developing the grammars. We made extensive use of tools from the the Deep Linguistic Processing with HPSG Initiative (DELPH-IN: http:// www.delph-in.net/) These existing resources enabled us to rapidly develop and test our approach. 3.1 Syntactic Annotation The construction of the treebank is a two stage process. First, the corpus is parsed (in our case using JACY), and then the annotator selects the correct analysis (or occasionally rejects all analyses). Selection is done through a choice of discriminants. The system selects features that distinguish between different parses, and the annotator selects or rejects the features until only one parse is left. The number of decisions for each sentence is proportional to log2 in the length of the sentence (Tanaka et al., 2005). Because the disambiguat-ing choices made by the annotators are saved, it is possible to semi-automatically update the treebank when the grammar changes. Re-annotation is only necessary in cases where the parse has become more ambiguous or, more rarely, existing rules or lexical items have changed so much that the system cannot reconstruct the parse.","The Lexeed denition sentences were already POS tagged. We experimented with using the POS tags to mark trees as good or bad (Tanaka et al., 2005). This enabled us to reduce the number of annotator decisions by 20%.","One concern with Redwoods style treebanking is that it is only possible to annotate those trees that the grammar can parse. Sentences for which no analysis had been implemented in the grammar or which fail to parse due to processing constraints are left unannotated. This makes grammar cov-66 UTTERANCE NP VP N PP V N CASE-P V V <+F0<V $r 1?E> $9$k ?M jidflosha o unten suru hito car ACC drive do person","Parse Tree","hh0, x1fh0 :proposition m(h1) h1 :hito n(x1) person h2 :ude f q(x1, h1, h6) h3 : jidosha n(x2) car h4 :ude f q(x2, h3, h7) h5 :unten s(e1, x1, x2)gidrive","MRS fx1 : e1 :unten s(ARG1 x1 : hito n, ARG2 x2 : jidosha n) r1 : proposition m(MARG e1 : unten s)g","Semantic Dependency Figure 2: Parse Tree, Simplied MRS and Dependency Views for %I%i%$%P!<2 doraib fla driver erage a signicant issue. We extended JACY by adding the dening vocabulary, and added some new rules and lexical-types (more detail is given in Bond et al. (2004)). None of the rules are specic to the dictionary domain. The grammatical coverage over all sentences is now 86%. Around 12% of the parsed sentences were rejected by the treebankers due to an incomplete semantic representation. The total size of the treebank is currently 53,600 denition sentences and 36,000 example sentences: 89,600 sentences in total. 3.2 Sense Annotation All open class words were annotated with their sense by ve annotators. Inter-annotator agreement ranges from 0.79 to 0.83. For example, the word %/%i%V kurabu club is tagged as sense 3 in the denition sentence for driver3, with the mean-ing golf-club. For each sense, we calculate the entropy and per sense probabilities over four corpora: the Lexeed denition and example sentences and Newspaper text from the Kyoto University and Senseval 2 corpora (Tanaka et al., 2006)."]},{"title":"4 Applications 4.1 Stochastic Parse Ranking","paragraphs":["Using the treebanked data, we built a stochastic parse ranking model. The ranker uses a maximum entropy learner to train a PCFG over the parse derivation trees, with the current node, two grandparents and several other conditioning features. A preliminary experiment showed the correct parse is ranked rst 69% of the time (10-fold cross validation on 13,000 sentences; evaluated per sentence). We are now experimenting with extensions based on constituent weight, hypernym, semantic class and selectional preferences. 4.2 Ontology Acquisition To extract hypernyms, we parse the rst denition sentence for each sense (Nichols et al., 2005). The parser uses the stochastic parse ranking model learned from the Hinoki treebank, and returns the semantic representation (MRS) of the rst ranked parse. In cases where JACY fails to return a parse, we use a dependency parser instead. The highest scoping real predicate is generally the hypernym. For example, for doraib fla2 the hypernym is ?M hito person and for doraib fla3 the hypernym is %/%i %V kurabu club (see Figure 1). We also extract other relationships, such as synonym and domain. Because the words are sense tags, we can specialize the relations to relations between senses, rather than just words: hhypernym: doraibfla3, kurabu3i.","Once we have synonym/hypernym relations, we can link the lexicon to other lexical resources. For example, for the manually constructed Japanese ontology Goi-Taikei (Ikehara et al., 1997) we link to its semantic classes by the following heuristic: look up the semantic classes C for both the head-word (wi) and hypernym(s) (wg). If at least one of the index word’s classes is subsumed by at least one of the genus’ classes, then we consider the relationship conrmed. To link cross-linguistically, we look up the headwords and hypernym(s) in a translation lexicon and compare the set of translations ci C(T (wi)) with WordNet (Fellbaum, 1998)). Although looking up the translation adds noise, the additional lter of the relationship triple effectively lters it out again.","Adding the ontology to the dictionary interface makes a far more exible resource. For example, by clicking on the hhypernym: doraibfla3, goru f u1i link, it is possible to see a list of all the senses re-67 lated to golf, a link that is inaccessible in the paper dictionary. 4.3 Semi-Automatic Grammar","Documentation A detailed grammar is a fundamental component for precise natural language processing. It provides not only detailed syntactic and morphological information on linguistic expressions but also precise and usually language-independent semantic structures of them. To simplify grammar development, we take a snapshot of the grammar used to treebank in each development cycle. From this we extract information about lexical items and their types from both the grammar and treebank and convert it into an electronically accesible structured database (the lexical-type database: Hashimoto et al., 2005). This allows grammar developers and treebankers to see comprehensive up-to-date information about lexical types, including documentation, syntactic properties (super types, valence, category and so on), usage examples from the treebank and links to other dictionaries."]},{"title":"5 Further Work","paragraphs":["We are currently concentrating on three tasks. The rst is improving the coverage of the grammar, so that we can parse more sentences to a correct parse. The second is improving the knowledge acquisition, in particular learning other information from the parsed dening sentences such as lexical-types, semantic association scores, meronyms, and antonyms. The third task is adding the knowledge of hypernyms into the stochastic model.","The Hinoki project is being extended in several ways. For Japanese, we are treebanking other genres, starting with Newspaper text, and increasing the vocabulary, initially by parsing other machine readable dictionaries. We are also extending the approach multilingually with other grammars in the DELPH-IN group. We have started with the English Resource Grammar and the Gnu Contemporary International Dictionary of English and are investigating Korean and Norwegian through cooperation with the Korean Research Grammar and NorSource."]},{"title":"6 Conclusion","paragraphs":["In this paper we have described the current state of the Hinoki treebank. We have further showed how it is being used to develop a language-independent system for acquiring thesauruses from machine-readable dictionaries.","With the improved the grammar and ontology, we will use the knowledge learned to extend our model to words not in Lexeed, using denition sentences from machine-readable dictionaries or where they appear within normal text. In this way, we can grow an extensible lexicon and thesaurus from Lexeed. Acknowledgements","We thank the treebankers, Takayuki Kuribayashi, Tomoko Hirata and Koji Yamashita, for their hard work and attention to detail."]},{"title":"References","paragraphs":["Francis Bond, Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004. The Hinoki treebank: A treebank for text understanding. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04). Springer Verlag. (in press).","Christine Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.","Chikara Hashimoto, Francis Bond, Takaaki Tanaka, and Melanie Siegel. 2005. Integration of a lexical type database with a linguistically interpreted corpus. In 6th International Workshop on Linguistically Integrated Corpora (LINC-2005), pages 3140. Cheju, Korea.","Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei A Japanese Lexicon. Iwanami Shoten, Tokyo. 5 volumes/CDROM.","Kaname Kasahara, Hiroshi Sato, Francis Bond, Takaaki Tanaka, Sanae Fujita, Tomoko Kanasugi, and Shigeaki Amano. 2004. Construction of a Japanese semantic lexicon: Lexeed. SIG NLC-159, IPSJ, Tokyo. (in Japanese).","Eric Nichols, Francis Bond, and Daniel Flickinger. 2005. Robust ontology acquisition from machine-readable dictionaries. In Proceedings of the International Joint Conference on Articial Intelligence IJCAI-2005, pages 1111 1116. Edinburgh.","Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christoper D. Manning, Dan Flickinger, and Thorsten Brant. 2002. The LinGO redwoods treebank: Motivation and preliminary applications. In 19th International Conference on Computational Linguistics: COLING-2002, pages 12537. Taipei, Taiwan.","Melanie Siegel. 2000. HPSG analysis of Japanese. In Wolfgang Wahlster, editor, Verbmobil: Foundations of Speech-to-Speech Translation, pages 265 280. Springer, Berlin, Germany.","Takaaki Tanaka, Francis Bond, and Sanae Fujita. 2006. The Hinoki sensebank a large-scale word sense tagged corpus of Japanese . In Frontiers in Linguistically Annotated Corpora 2006. Sydney. (ACL Workshop).","Takaaki Tanaka, Francis Bond, Stephan Oepen, and Sanae Fujita. 2005. High precision treebanking blazing useful trees using POS information. In ACL-2005, pages 330 337. 68"]}],"references":[{"authors":[{"first":"Francis","last":"Bond"},{"first":"Sanae","last":"Fujita"},{"first":"Chikara","last":"Hashimoto"},{"first":"Kaname","last":"Kasahara"},{"first":"Shigeko","last":"Nariyama"},{"first":"Eric","last":"Nichols"},{"first":"Akira","last":"Ohtani"},{"first":"Takaaki","last":"Tanaka"},{"first":"Shigeaki","last":"Amano"}],"year":"2004","title":"The Hinoki treebank: A treebank for text understanding","source":"Francis Bond, Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004. The Hinoki treebank: A treebank for text understanding. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04). Springer Verlag. (in press)."},{"authors":[{"first":"Christine","last":"Fellbaum"},{"last":"editor"}],"year":"1998","title":"WordNet: An Electronic Lexical Database","source":"Christine Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press."},{"authors":[{"first":"Chikara","last":"Hashimoto"},{"first":"Francis","last":"Bond"},{"first":"Takaaki","last":"Tanaka"},{"first":"Melanie","last":"Siegel"}],"year":"2005","title":"Integration of a lexical type database with a linguistically interpreted corpus","source":"Chikara Hashimoto, Francis Bond, Takaaki Tanaka, and Melanie Siegel. 2005. Integration of a lexical type database with a linguistically interpreted corpus. In 6th International Workshop on Linguistically Integrated Corpora (LINC-2005), pages 3140. Cheju, Korea."},{"authors":[{"first":"Satoru","last":"Ikehara"},{"first":"Masahiro","last":"Miyazaki"},{"first":"Satoshi","last":"Shirai"},{"first":"Akio","last":"Yokoo"},{"first":"Hiromi","last":"Nakaiwa"},{"first":"Kentaro","last":"Ogura"},{"first":"Yoshifumi","last":"Ooyama"},{"first":"Yoshihiko","last":"Hayashi"}],"year":"1997","title":"Goi-Taikei A Japanese Lexicon","source":"Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei A Japanese Lexicon. Iwanami Shoten, Tokyo. 5 volumes/CDROM."},{"authors":[{"first":"Kaname","last":"Kasahara"},{"first":"Hiroshi","last":"Sato"},{"first":"Francis","last":"Bond"},{"first":"Takaaki","last":"Tanaka"},{"first":"Sanae","last":"Fujita"},{"first":"Tomoko","last":"Kanasugi"},{"first":"Shigeaki","last":"Amano"}],"year":"2004","title":"Construction of a Japanese semantic lexicon: Lexeed","source":"Kaname Kasahara, Hiroshi Sato, Francis Bond, Takaaki Tanaka, Sanae Fujita, Tomoko Kanasugi, and Shigeaki Amano. 2004. Construction of a Japanese semantic lexicon: Lexeed. SIG NLC-159, IPSJ, Tokyo. (in Japanese)."},{"authors":[{"first":"Eric","last":"Nichols"},{"first":"Francis","last":"Bond"},{"first":"Daniel","last":"Flickinger"}],"year":"2005","title":"Robust ontology acquisition from machine-readable dictionaries","source":"Eric Nichols, Francis Bond, and Daniel Flickinger. 2005. Robust ontology acquisition from machine-readable dictionaries. In Proceedings of the International Joint Conference on Articial Intelligence IJCAI-2005, pages 1111 1116. Edinburgh."},{"authors":[{"first":"Stephan","last":"Oepen"},{"first":"Kristina","last":"Toutanova"},{"first":"Stuart","last":"Shieber"},{"first":"Christoper","middle":"D.","last":"Manning"},{"first":"Dan","last":"Flickinger"},{"first":"Thorsten","last":"Brant"}],"year":"2002","title":"The LinGO redwoods treebank: Motivation and preliminary applications","source":"Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christoper D. Manning, Dan Flickinger, and Thorsten Brant. 2002. The LinGO redwoods treebank: Motivation and preliminary applications. In 19th International Conference on Computational Linguistics: COLING-2002, pages 12537. Taipei, Taiwan."},{"authors":[{"first":"Melanie","last":"Siegel"}],"year":"2000","title":"HPSG analysis of Japanese","source":"Melanie Siegel. 2000. HPSG analysis of Japanese. In Wolfgang Wahlster, editor, Verbmobil: Foundations of Speech-to-Speech Translation, pages 265 280. Springer, Berlin, Germany."},{"authors":[{"first":"Takaaki","last":"Tanaka"},{"first":"Francis","last":"Bond"},{"first":"Sanae","last":"Fujita"}],"year":"2006","title":"The Hinoki sensebank a large-scale word sense tagged corpus of Japanese ","source":"Takaaki Tanaka, Francis Bond, and Sanae Fujita. 2006. The Hinoki sensebank a large-scale word sense tagged corpus of Japanese . In Frontiers in Linguistically Annotated Corpora 2006. Sydney. (ACL Workshop)."},{"authors":[{"first":"Takaaki","last":"Tanaka"},{"first":"Francis","last":"Bond"},{"first":"Stephan","last":"Oepen"},{"first":"Sanae","last":"Fujita"}],"year":"2005","title":"High precision treebanking blazing useful trees using POS information","source":"Takaaki Tanaka, Francis Bond, Stephan Oepen, and Sanae Fujita. 2005. High precision treebanking blazing useful trees using POS information. In ACL-2005, pages 330 337. 68"}],"cites":[{"style":0,"text":"Kasahara et al., 2004","origin":{"pointer":"/sections/2/paragraphs/1","offset":168,"length":21},"authors":[{"last":"Kasahara"},{"last":"al."}],"year":"2004","references":["/references/4"]},{"style":0,"text":"Kasahara et al., 2004","origin":{"pointer":"/sections/3/paragraphs/0","offset":143,"length":21},"authors":[{"last":"Kasahara"},{"last":"al."}],"year":"2004","references":["/references/4"]},{"style":0,"text":"Oepen et al., 2002","origin":{"pointer":"/sections/4/paragraphs/0","offset":79,"length":18},"authors":[{"last":"Oepen"},{"last":"al."}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Siegel (2000)","origin":{"pointer":"/sections/4/paragraphs/4","offset":202,"length":13},"authors":[{"last":"Siegel"}],"year":"2000","references":["/references/7"]},{"style":0,"text":"Tanaka et al., 2005","origin":{"pointer":"/sections/4/paragraphs/5","offset":1042,"length":19},"authors":[{"last":"Tanaka"},{"last":"al."}],"year":"2005","references":["/references/9"]},{"style":0,"text":"Tanaka et al., 2005","origin":{"pointer":"/sections/4/paragraphs/6","offset":125,"length":19},"authors":[{"last":"Tanaka"},{"last":"al."}],"year":"2005","references":["/references/9"]},{"style":0,"text":"Bond et al. (2004)","origin":{"pointer":"/sections/4/paragraphs/11","offset":253,"length":18},"authors":[{"last":"Bond"},{"last":"al."}],"year":"2004","references":["/references/0"]},{"style":0,"text":"Tanaka et al., 2006","origin":{"pointer":"/sections/4/paragraphs/11","offset":1098,"length":19},"authors":[{"last":"Tanaka"},{"last":"al."}],"year":"2006","references":["/references/8"]},{"style":0,"text":"Nichols et al., 2005","origin":{"pointer":"/sections/5/paragraphs/0","offset":616,"length":20},"authors":[{"last":"Nichols"},{"last":"al."}],"year":"2005","references":["/references/5"]},{"style":0,"text":"Ikehara et al., 1997","origin":{"pointer":"/sections/5/paragraphs/1","offset":165,"length":20},"authors":[{"last":"Ikehara"},{"last":"al."}],"year":"1997","references":["/references/3"]},{"style":0,"text":"Fellbaum, 1998","origin":{"pointer":"/sections/5/paragraphs/1","offset":625,"length":14},"authors":[{"last":"Fellbaum"}],"year":"1998","references":[]},{"style":0,"text":"Hashimoto et al., 2005","origin":{"pointer":"/sections/5/paragraphs/3","offset":587,"length":22},"authors":[{"last":"Hashimoto"},{"last":"al."}],"year":"2005","references":["/references/2"]}]}
