{"sections":[{"title":"","paragraphs":["Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 225–228, Columbus, Ohio, USA, June 2008. c⃝2008 Association for Computational Linguistics"]},{"title":"Enriching spoken language translation with dialog acts Vivek Kumar Rangarajan Sridhar Shrikanth Narayanan Speech Analysis and Interpretation Laboratory University of Southern California","paragraphs":["vrangara@usc.edu,shri@sipi.usc.edu"]},{"title":"Srinivas Bangalore AT&T Labs - Research 180 Park Avenue Florham Park, NJ 07932, U.S.A.","paragraphs":["srini@research.att.com"]},{"title":"Abstract","paragraphs":["Current statistical speech translation approaches predominantly rely on just text transcripts and do not adequately utilize the rich contextual information such as conveyed through prosody and discourse function. In this paper, we explore the role of context characterized through dialog acts (DAs) in statistical translation. We demonstrate the integra-tion of the dialog acts in a phrase-based statistical translation framework, employing 3 limited domain parallel corpora (Farsi-English, Japanese-English and Chinese-English). For all three language pairs, in addition to produc-ing interpretable DA enriched target language translations, we also obtain improvements in terms of objective evaluation metrics such as lexical selection accuracy and BLEU score."]},{"title":"1 Introduction","paragraphs":["Recent approaches to statistical speech translation have relied on improving translation quality with the use of phrase translation (Och and Ney, 2003; Koehn, 2004). The quality of phrase translation is typically measured using n-gram precision based metrics such as BLEU (Papineni et al., 2002) and NIST scores. However, in many dialog based speech translation scenarios, vital information beyond what is robustly captured by words and phrases is carried by the communicative act (e.g., question, acknowledgement, etc.) representing the function of the utterance. Our approach for incorporating dialog act tags in speech translation is motivated by the fact that it is important to capture and convey not only what is being communicated (the words) but how something is being communicated (the context). Augmenting current statistical translation frameworks with dialog acts can potentially improve translation quality and facilitate successful crosslingual interactions in terms of improved information transfer.","Dialog act tags have been previously used in the VERBMOBIL statistical speech-to-speech translation system (Reithinger et al., 1996). In that work, the predicted DA tags were mainly used to improve speech recognition, semantic evaluation, and information extraction modules. Discourse information in the form of speech acts has also been used in in-terlingua translation systems (Mayfield et al., 1995) to map input text to semantic concepts, which are then translated to target text.","In contrast with previous work, in this paper we demonstrate how dialog act tags can be directly exploited in phrase based statistical speech translation systems (Koehn, 2004). The framework presented in this paper is particularly suited for human-human and human-computer interactions in a dialog set-ting, where information loss due to erroneous content may be compensated to some extent through the correct transfer of the appropriate dialog act. The dialog acts can also be potentially used for impart-ing correct utterance level intonation during speech synthesis in the target language. Figure 1 shows an example where the detection and transfer of dialog act information is beneficial in resolving ambiguous intention associated with the translation output. Figure 1: Example of speech translation output enriched with dialog act","The remainder of this paper is organized as follows: Section 2 describes the dialog act tagger used in this work, Section 3 formulates the problem, Section 4 describes the parallel corpora used in our experiments, Section 5 summarizes our experimental results and Section 6 concludes the paper with a brief discussion and outline for future work."]},{"title":"2 Dialog act tagger","paragraphs":["In this work, we use a dialog act tagger trained on the Switchboard DAMSL corpus (Jurafsky et al., 225 1998) using a maximum entropy (maxent) model. The Switchboard-DAMSL (SWBD-DAMSL) corpus consists of 1155 dialogs and 218,898 utterances from the Switchboard corpus of telephone conversations, tagged with discourse labels from a shallow discourse tagset. The original tagset of 375 unique tags was clustered to obtain 42 dialog tags as in (Jurafsky et al., 1998). In addition, we also grouped the 42 tags into 7 disjoint classes, based on the frequency of the classes and grouped the remaining classes into an “Other” category constitut-ing less than 3% of the entire data. The simplified tagset consisted of the following classes: statement, acknowledgment, abandoned, agreement, question, appreciation, other.","We use a maximum entropy sequence tagging model for the automatic DA tagging. Given a sequence of utterances U = u1, u2, · · ·, un and a dialog act vocabulary (di ε D, |D|= K), we need to assign the best dialog act sequence D∗","= d1, d2, · · ·, dn. The classifier is used to assign to each utterance a dialog act label conditioned on a vector of local contextual feature vectors comprising the lexical, syntactic and acoustic information. We used the machine learning toolkit LLAMA (Haffner, 2006) to estimate the conditional distribution using maxent. The performance of the maxent dialog act tagger on a test set comprising 29K utterances of SWBD-DAMSL is shown in Table 1.","Accuracy (%) Cues used (current utterance) 42 tags 7 tags Lexical 69.7 81.9 Lexical+Syntactic 70.0 82.4 Lexical+Syntactic+Prosodic 70.4 82.9 Table 1: Dialog act tagging accuracies for various cues on the SWBD-DAMSL corpus."]},{"title":"3 Enriched translation using DAs","paragraphs":["If Ss, Ts and St, Tt are the speech signals and equivalent textual transcription in the source and target language, and Ls the enriched representation for the source speech, we formalize our proposed enriched S2S translation in the following manner:","S∗","t = arg max","St P (St|Ss) (1) P (St|Ss) = ∑ Tt,Ts,Ls P (St, Tt, Ts, Ls|Ss) (2) ≈ ∑ Tt,Ts,Ls P (St|Tt, Ls).P (Tt, Ts, Ls|Ss) (3) where Eq.(3) is obtained through conditional independence assumptions. Even though the recognition and translation can be performed jointly (Matusov et al., 2005), typical S2S translation frameworks compartmentalize the ASR, MT and TTS, with each component maximized for performance individually. max St","P (St|Ss) ≈ max St","P (St|T ∗ t , L∗","s)","× max Tt","P (Tt|T ∗ s , L∗","s) (4)","× max Ls","P (Ls|T ∗ s , Ss) × max","Ts P (Ts|Ss) where T ∗","s , T ∗","t and S∗","t are the arguments maximiz-ing each of the individual components in the translation engine. L∗","s is the rich annotation detected from the source speech signal and text, Ss and T ∗","s respectively. In this work, we do not address the speech synthesis part and assume that we have access to the reference transcripts or 1-best recognition hypothesis of the source utterances. The rich annotations (Ls) can be syntactic or semantic concepts (Gu et al., 2006), prosody (Agüero et al., 2006), or, as in this work, dialog act tags. 3.1 Phrase-based translation with dialog acts One of the currently popular and predominant schemes for statistical translation is the phrase-based approach (Koehn, 2004). Typical phrase-based SMT approaches obtain word-level alignments from a bilingual corpus using tools such as GIZA++ (Och and Ney, 2003) and extract phrase translation pairs from the bilingual word alignment using heuristics. Suppose, the SMT had access to source language dialog acts (Ls), the translation problem may be reformulated as,","T ∗","t = arg max","Tt P (Tt|Ts, Ls)","= arg max Tt P (Ts|Tt, Ls).P (Tt|Ls) (5) The first term in Eq.(5) corresponds to a dialog act specific MT model and the second term to a dialog act specific language model. Given sufficient amount of training data such a system can possibly generate hypotheses that are more accurate than the scheme without the use of dialog acts. However, for small scale and limited domain applications, Eq.(5) leads to an implicit partitioning of the data corpus 226","Training Test","Farsi Eng Jap Eng Chinese Eng Farsi Eng Jap Eng Chinese Eng Sentences 8066 12239 46311 925 604 506 Running words 76321 86756 64096 77959 351060 376615 5442 6073 4619 6028 3826 3897 Vocabulary 6140 3908 4271 2079 11178 11232 1487 1103 926 567 931 898 Singletons 2819 1508 2749 1156 4348 4866 903 573 638 316 600 931 Table 2: Statistics of the training and test data used in the experiments. and might generate inferioir translations in terms of lexical selection accuracy or BLEU score.","A natural step to overcome the sparsity issue is to employ an appropriate back-off mechanism that would exploit the phrase translation pairs derived from the complete data. A typical phrase translation table consists of 5 phrase translation scores for each pair of phrases, source-to-target phrase translation probability (λ1), target-to-source phrase translation probability (λ2), source-to-target lexical weight (λ3), target-to-word lexical weight (λ4) and phrase penalty (λ5= 2.718). The lexical weights are the product of word translation probabilities obtained from the word alignments. To each phrase translation table belonging to a particular DA-specific translation model, we append those entries from the baseline model that are not present in phrase table of the DA-specific translation model. The appended entries are weighted by a factor α.","(Ts → Tt)L∗","s = (Ts → Tt)Ls ∪ {α.(Ts → Tt)","s.t. (Ts → Tt) ̸∈ (Ts → Tt)Ls} (6) where (Ts → Tt) is a short-hand1","notation for a phrase translation table. (Ts → Tt)Ls is the DA-specific phrase translation table, (Ts → Tt) is the phrase translation table constructed from entire data and (Ts → Tt)L∗","s is the newly interpolated phrase translation table. The interpolation factor α is used to weight each of the four translation scores (phrase translation and lexical probabilities for the bilanguage) with the phrase penalty remaining a constant. Such a scheme ensures that phrase translation pairs belonging to a specific DA model are weighted higher and also ensures better coverage than a partitioned data set."]},{"title":"4 Data","paragraphs":["We report experiments on three different paral-","lel corpora: Farsi-English, Japanese-English and 1 (Ts → Tt) represents the mapping between source alpha-","bet sequences to target alphabet sequences, where every pair","(ts 1, · · · , ts","n, tt","1, · · · , tt","m) has a weight sequence λ1, · · · , λ5 (five weights). Chinese-English. The Farsi-English data used in this paper was collected for human-mediated doctor-patient mediated interactions in which an English speaking doctor interacts with a Persian speaking patient (Narayanan et al., 2006). We used a subset of this corpus consisting of 9315 parallel sentences.","The Japanese-English parallel corpus is a part of the “How May I Help You” (HMIHY) (Gorin et al., 1997) corpus of operator-customer conversations related to telephone services. The corpus consists of 12239 parallel sentences. The conversations are spontaneous even though the domain is limited. The Chinese-English corpus corresponds to the IWSLT06 training and 2005 development set comprising 46K and 506 sentences respectively (Paul, 2006)."]},{"title":"5 Experiments and Results","paragraphs":["In all our experiments we assume that the same dialog act is shared by a parallel sentence pair. Thus, even though the dialog act prediction is performed for English, we use the predicted dialog act as the dialog act for the source language sentence. We used the Moses2","toolkit for statistical phrase-based translation. The language models were trigram models created only from the training portion of each corpus. Due to the relatively small size of the corpora used in the experiments, we could not devote a separate development set for tuning the parameters of the phrase-based translation scheme. Hence, the experiments are strictly performed on the training and test sets reported in Table 23",".","The lexical selection accuracy and BLEU scores for the three parallel corpora is presented in Table 3. Lexical selection accuracy is measured in terms of the F-measure derived from recall (","|Res∩Ref| |Ref| ∗ 100) and precision ( |Res∩Ref|","|Res| ∗ 100), where Ref is the","set of words in the reference translation and Res is 2 http://www.statmt.org/moses 3 A very small subset of the data was reserved for optimizing","the interpolation factor (α) described in Section 3.1 227","F-score (%) BLEU (%)","w/o DA tags w/ DA tags w/o DA tags w/ DA tags Language pair 7tags 42tags 7tags 42tags Farsi-English 56.46 57.32 57.74 22.90 23.50 23.75 Japanese-English 79.05 79.40 79.51 54.15 54.21 54.32 Chinese-English 65.85 67.24 67.49 48.59 52.12 53.04 Table 3: F-measure and BLEU scores with and without use of dialog act tags. the set of words in the translation output. Adding dialog act tags (either 7 or 42 tag vocabulary) consistently improves both the lexical selection accuracy and BLEU score for all the language pairs. The improvements for Farsi-English and Chinese-English corpora are more pronounced than the improvements in Japanese-English corpus. This is due to the skewed distribution of dialog acts in the Japanese-English corpus; 80% of the test data are statements while other and questions category make up 16% and 3.5% of the data respectively. The important observation here is that, appending DA tags in the form described in this work, can improve translation performance even in terms of conventional objective evaluation metrics. However, the performance gain measured in terms of objective metrics that are designed to reflect only the orthographic accuracy during translation is not a complete evaluation of the translation quality of the proposed framework. We are currently planning of adding human evaluation to bring to fore the usefulness of such rich annotations in interpreting and supplementing typically noisy translations."]},{"title":"6 Discussion and Future Work","paragraphs":["It is important to note that the dialog act tags used in our translation system are predictions from the maxent based DA tagger described in Section 2. We do not have access to the reference tags; thus, some amount of error is to be expected in the DA tagging. Despite the lack of reference DA tags, we are still able to achieve modest improvements in the translation quality. Improving the current DA tagger and developing suitable adaptation techniques are part of future work.","While we have demonstrated here that using dialog act tags can improve translation quality in terms of word based automatic evaluation metrics, the real benefits of such a scheme would be attested through further human evaluations. We are currently work-ing on conducting subjective evaluations."]},{"title":"References","paragraphs":["P. D. Agüero, J. Adell, and A. Bonafonte. 2006. Prosody generation for speech-to-speech translation. In Proc. of ICASSP, Toulouse, France, May.","A. Gorin, G. Riccardi, and J. Wright. 1997. How May I Help You? Speech Communication, 23:113–127.","L. Gu, Y. Gao, F. H. Liu, and M. Picheny. 2006. Concept-based speech-to-speech translation using maximum entropy models for statistical natural concept generation. IEEE Transactions on Audio, Speech and Language Processing, 14(2):377–392, March.","P. Haffner. 2006. Scaling large margin classifiers for spoken language understanding. Speech Communication, 48(iv):239–261.","D. Jurafsky, R. Bates, N. Coccaro, R. Martin, M. Meteer, K. Ries, E. Shriberg, S. Stolcke, P. Taylor, and C. Van Ess-Dykema. 1998. Switchboard discourse language modeling project report. Technical report research note 30, Johns Hopkins University, Baltimore, MD.","P. Koehn. 2004. Pharaoh: A beam search decoder for phrasebased statistical machine translation models. In Proc. of AMTA-04, pages 115–124.","E. Matusov, S. Kanthak, and H. Ney. 2005. On the in-tegration of speech recognition and statistical machine translation. In Proc. of Eurospeech.","L. Mayfield, M. Gavalda, W. Ward, and A. Waibel. 1995. Concept-based speech translation. In Proc. of ICASSP, volume 1, pages 97–100, May.","S. Narayanan et al. 2006. Speech recognition engineer-ing issues in speech to speech translation system design for low resource languages and domains. In Proc. of ICASSP, Toulose, France, May.","F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.","K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. Technical report, IBM T.J. Watson Research Center.","M. Paul. 2006. Overview of the IWSLT 2006 Evaluation Campaign. In Proc. of the IWSLT, pages 1–15, Kyoto, Japan.","N. Reithinger, R. Engel, M. Kipp, and M. Klesen. 1996. Predicting dialogue acts for a speech-to-speech translation system. In Proc. of ICSLP, volume 2, pages 654–657, Oct. 228"]}],"references":[{"authors":[{"first":"P.","middle":"D.","last":"Agüero"},{"first":"J.","last":"Adell"},{"first":"A.","last":"Bonafonte"}],"year":"2006","title":"Prosody generation for speech-to-speech translation","source":"P. D. Agüero, J. Adell, and A. Bonafonte. 2006. Prosody generation for speech-to-speech translation. In Proc. of ICASSP, Toulouse, France, May."},{"authors":[{"first":"A.","last":"Gorin"},{"first":"G.","last":"Riccardi"},{"first":"J.","last":"Wright"}],"year":"1997","title":"How May I Help You? Speech Communication, 23:113–127","source":"A. Gorin, G. Riccardi, and J. Wright. 1997. How May I Help You? Speech Communication, 23:113–127."},{"authors":[{"first":"L.","last":"Gu"},{"first":"Y.","last":"Gao"},{"first":"F.","middle":"H.","last":"Liu"},{"first":"M.","last":"Picheny"}],"year":"2006","title":"Concept-based speech-to-speech translation using maximum entropy models for statistical natural concept generation","source":"L. Gu, Y. Gao, F. H. Liu, and M. Picheny. 2006. Concept-based speech-to-speech translation using maximum entropy models for statistical natural concept generation. IEEE Transactions on Audio, Speech and Language Processing, 14(2):377–392, March."},{"authors":[{"first":"P.","last":"Haffner"}],"year":"2006","title":"Scaling large margin classifiers for spoken language understanding","source":"P. Haffner. 2006. Scaling large margin classifiers for spoken language understanding. Speech Communication, 48(iv):239–261."},{"authors":[{"first":"D.","last":"Jurafsky"},{"first":"R.","last":"Bates"},{"first":"N.","last":"Coccaro"},{"first":"R.","last":"Martin"},{"first":"M.","last":"Meteer"},{"first":"K.","last":"Ries"},{"first":"E.","last":"Shriberg"},{"first":"S.","last":"Stolcke"},{"first":"P.","last":"Taylor"},{"first":"C.","last":"Van Ess-Dykema"}],"year":"1998","title":"Switchboard discourse language modeling project report","source":"D. Jurafsky, R. Bates, N. Coccaro, R. Martin, M. Meteer, K. Ries, E. Shriberg, S. Stolcke, P. Taylor, and C. Van Ess-Dykema. 1998. Switchboard discourse language modeling project report. Technical report research note 30, Johns Hopkins University, Baltimore, MD."},{"authors":[{"first":"P.","last":"Koehn"}],"year":"2004","title":"Pharaoh: A beam search decoder for phrasebased statistical machine translation models","source":"P. Koehn. 2004. Pharaoh: A beam search decoder for phrasebased statistical machine translation models. In Proc. of AMTA-04, pages 115–124."},{"authors":[{"first":"E.","last":"Matusov"},{"first":"S.","last":"Kanthak"},{"first":"H.","last":"Ney"}],"year":"2005","title":"On the in-tegration of speech recognition and statistical machine translation","source":"E. Matusov, S. Kanthak, and H. Ney. 2005. On the in-tegration of speech recognition and statistical machine translation. In Proc. of Eurospeech."},{"authors":[{"first":"L.","last":"Mayfield"},{"first":"M.","last":"Gavalda"},{"first":"W.","last":"Ward"},{"first":"A.","last":"Waibel"}],"year":"1995","title":"Concept-based speech translation","source":"L. Mayfield, M. Gavalda, W. Ward, and A. Waibel. 1995. Concept-based speech translation. In Proc. of ICASSP, volume 1, pages 97–100, May."},{"authors":[{"first":"S.","last":"Narayanan"},{"last":"al"}],"year":"2006","title":"Speech recognition engineer-ing issues in speech to speech translation system design for low resource languages and domains","source":"S. Narayanan et al. 2006. Speech recognition engineer-ing issues in speech to speech translation system design for low resource languages and domains. In Proc. of ICASSP, Toulose, France, May."},{"authors":[{"first":"F.","middle":"J.","last":"Och"},{"first":"H.","last":"Ney"}],"year":"2003","title":"A systematic comparison of various statistical alignment models","source":"F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51."},{"authors":[{"first":"K.","last":"Papineni"},{"first":"S.","last":"Roukos"},{"first":"T.","last":"Ward"},{"first":"W.","middle":"J.","last":"Zhu"}],"year":"2002","title":"BLEU: a method for automatic evaluation of machine translation","source":"K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. Technical report, IBM T.J. Watson Research Center."},{"authors":[{"first":"M.","last":"Paul"}],"year":"2006","title":"Overview of the IWSLT 2006 Evaluation Campaign","source":"M. Paul. 2006. Overview of the IWSLT 2006 Evaluation Campaign. In Proc. of the IWSLT, pages 1–15, Kyoto, Japan."},{"authors":[{"first":"N.","last":"Reithinger"},{"first":"R.","last":"Engel"},{"first":"M.","last":"Kipp"},{"first":"M.","last":"Klesen"}],"year":"1996","title":"Predicting dialogue acts for a speech-to-speech translation system","source":"N. Reithinger, R. Engel, M. Kipp, and M. Klesen. 1996. Predicting dialogue acts for a speech-to-speech translation system. In Proc. of ICSLP, volume 2, pages 654–657, Oct. 228"}],"cites":[{"style":0,"text":"Och and Ney, 2003","origin":{"pointer":"/sections/4/paragraphs/0","offset":133,"length":17},"authors":[{"last":"Och"},{"last":"Ney"}],"year":"2003","references":["/references/9"]},{"style":0,"text":"Koehn, 2004","origin":{"pointer":"/sections/4/paragraphs/0","offset":152,"length":11},"authors":[{"last":"Koehn"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Papineni et al., 2002","origin":{"pointer":"/sections/4/paragraphs/0","offset":273,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"2002","references":["/references/10"]},{"style":0,"text":"Reithinger et al., 1996","origin":{"pointer":"/sections/4/paragraphs/1","offset":108,"length":23},"authors":[{"last":"Reithinger"},{"last":"al."}],"year":"1996","references":["/references/12"]},{"style":0,"text":"Mayfield et al., 1995","origin":{"pointer":"/sections/4/paragraphs/1","offset":380,"length":21},"authors":[{"last":"Mayfield"},{"last":"al."}],"year":"1995","references":["/references/7"]},{"style":0,"text":"Koehn, 2004","origin":{"pointer":"/sections/4/paragraphs/2","offset":163,"length":11},"authors":[{"last":"Koehn"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Jurafsky et al., 1998","origin":{"pointer":"/sections/5/paragraphs/0","offset":442,"length":21},"authors":[{"last":"Jurafsky"},{"last":"al."}],"year":"1998","references":["/references/4"]},{"style":0,"text":"Haffner, 2006","origin":{"pointer":"/sections/5/paragraphs/2","offset":255,"length":13},"authors":[{"last":"Haffner"}],"year":"2006","references":["/references/3"]},{"style":0,"text":"Matusov et al., 2005","origin":{"pointer":"/sections/6/paragraphs/3","offset":256,"length":20},"authors":[{"last":"Matusov"},{"last":"al."}],"year":"2005","references":["/references/6"]},{"style":0,"text":"Gu et al., 2006","origin":{"pointer":"/sections/6/paragraphs/17","offset":258,"length":15},"authors":[{"last":"Gu"},{"last":"al."}],"year":"2006","references":["/references/2"]},{"style":0,"text":"Agüero et al., 2006","origin":{"pointer":"/sections/6/paragraphs/17","offset":285,"length":19},"authors":[{"last":"Agüero"},{"last":"al."}],"year":"2006","references":["/references/0"]},{"style":0,"text":"Koehn, 2004","origin":{"pointer":"/sections/6/paragraphs/17","offset":502,"length":11},"authors":[{"last":"Koehn"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Och and Ney, 2003","origin":{"pointer":"/sections/6/paragraphs/17","offset":633,"length":17},"authors":[{"last":"Och"},{"last":"Ney"}],"year":"2003","references":["/references/9"]},{"style":0,"text":"Narayanan et al., 2006","origin":{"pointer":"/sections/7/paragraphs/6","offset":264,"length":22},"authors":[{"last":"Narayanan"},{"last":"al."}],"year":"2006","references":[]},{"style":0,"text":"Gorin et al., 1997","origin":{"pointer":"/sections/7/paragraphs/7","offset":84,"length":18},"authors":[{"last":"Gorin"},{"last":"al."}],"year":"1997","references":["/references/1"]},{"style":0,"text":"Paul, 2006","origin":{"pointer":"/sections/7/paragraphs/7","offset":430,"length":10},"authors":[{"last":"Paul"}],"year":"2006","references":["/references/11"]}]}
