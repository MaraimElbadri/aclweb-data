{"sections":[{"title":"","paragraphs":["Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 856–863, Prague, Czech Republic, June 2007. c⃝2007 Association for Computational Linguistics"]},{"title":"Pivot Language Approach for Phrase-Based Statistical Machine Translation Hua Wu and Haifeng Wang Toshiba (China) Research and Development Center 5/F., Tower W2, Oriental Plaza, No.1, East Chang An Ave., Dong Cheng District Beijing, 100738, China {wuhua,wanghaifeng}@rdc.toshiba.com.cn   Abstract","paragraphs":["This paper proposes a novel method for phrase-based statistical machine translation by using pivot language. To conduct translation between languages Lf and Le with a small bilingual corpus, we bring in a third language Lp, which is named the pivot language. For Lf-Lp and Lp-Le, there exist large bilingual corpora. Using only Lf-Lp and Lp-Le bilingual corpora, we can build a translation model for Lf-Le. The advantage of this method lies in that we can perform translation between Lf and Le even if there is no bilingual corpus available for this language pair. Using BLEU as a metric, our pivot language method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly trained with 5,000 Lf-Le sentence pairs for French-Spanish translation. Moreover, with a small Lf-Le bilingual corpus available, our method can further improve the translation quality by using the additional Lf-Lp and Lp-Le bilingual corpora."]},{"title":"1 Introduction","paragraphs":["For statistical machine translation (SMT), phrase-based methods (Koehn et al., 2003; Och and Ney, 2004) and syntax-based methods (Wu, 1997; Alshawi et al. 2000; Yamada and Knignt, 2001; Melamed, 2004; Chiang, 2005; Quick et al., 2005; Mellebeek et al., 2006) outperform word-based methods (Brown et al., 1993). These methods need large bilingual corpora. However, for some languages pairs, only a small bilingual corpus is available, which will degrade the performance of statistical translation systems.","To solve this problem, this paper proposes a novel method for phrase-based SMT by using a pivot language. To perform translation between languages Lf and Le, we bring in a pivot language Lp, for which there exist large bilingual corpora for language pairs Lf-Lp and Lp-Le. With the Lf-Lp and Lp-Le bilingual corpora, we can build a translation model for Lf-Le by using Lp as the pivot language. We name the translation model pivot model. The advantage of this method lies in that we can conduct translation between Lf and Le even if there is no bilingual corpus available for this language pair. Moreover, if a small corpus is available for Lf-Le, we build another translation model, which is named standard model. Then, we build an interpolated model by performing linear interpolation on the standard model and the pivot model. Thus, the interpolated model can employ both the small Lf-Le corpus and the large Lf-Lp and Lp-Le corpora.","We perform experiments on the Europarl corpus (Koehn, 2005). Using BLEU (Papineni et al., 2002) as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 Lf-Le sentence pairs for French-Spanish translation. The translation quality is comparable with that of the model trained with a bilingual corpus of 30,000 Lf-Le sentence pairs. Moreover, translation quality is further boosted by using both the small Lf-Le bilingual corpus and the large Lf-Lp and Lp-Le corpora.","Experimental results on Chinese-Japanese translation also indicate that our method achieves satisfactory results using English as the pivot language. 856","The remainder of this paper is organized as follows. In section 2, we describe the related work. Section 3 briefly introduces phrase-based SMT. Section 4 and Section 5 describes our method for phrase-based SMT using pivot language. We describe the experimental results in sections 6 and 7. Lastly, we conclude in section 8."]},{"title":"2 Related Work","paragraphs":["Our method is mainly related to two kinds of methods: those using pivot language and those using a small bilingual corpus or scarce resources.","For the first kind, pivot languages are employed to translate queries in cross-language information retrieval (CLIR) (Gollins and Sanderson, 2001; Kishida and Kando, 2003). These methods only used the available dictionaries to perform word by word translation. In addition, NTCIR 4 workshop organized a shared task for CLIR using pivot language. Machine translation systems are used to translate queries into pivot language sentences, and then into target sentences (Sakai et al., 2004).","Callison-Burch et al. (2006) used pivot languages for paraphrase extraction to handle the unseen phrases for phrase-based SMT. Borin (2000) and Wang et al. (2006) used pivot languages to improve word alignment. Borin (2000) used multilingual corpora to increase alignment coverage. Wang et al. (2006) induced alignment models by using two additional bilingual corpora to improve word alignment quality. Pivot Language methods were also used for translation dictionary induction (Schafer and Yarowsky, 2002), word sense disambiguation (Diab and Resnik, 2002), and so on.","For the second kind, Niessen and Ney (2004) used morpho-syntactic information for translation between language pairs with scarce resources. Vandeghinste et al. (2006) used translation dictionaries and shallow analysis tools for translation between the language pair with low resources. A shared task on word alignment was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (Martin et al., 2005). This task focused on languages with scarce resources. For the subtask of unlimited resources, some researchers (Aswani and Gaizauskas, 2005; Lopez and Resnik, 2005; Tufis et al., 2005) used language-dependent resources such as dictionary, the-saurus, and dependency parser to improve word alignment results.","In this paper, we address the translation problem for language pairs with scarce resources by bringing in a pivot language, via which we can make use of large bilingual corpora. Our method does not need language-dependent resources or deep linguistic processing. Thus, the method is easy to be adapted to any language pair where a pivot language and corresponding large bilingual corpora are available."]},{"title":"3 Phrase-Based SMT","paragraphs":["According to the translation model presented in (Koehn et al., 2003), given a source sentence f , the best target translation beste can be obtained according to the following model",")( )()|(maxarg )|(maxarg e e e eef fee length LM best ωpp p = = (1) Where the translation model )|( efp can be decomposed into"]},{"title":"∏","paragraphs":["= −−= I i","i iiii","i II aefpbadef efp 1 1","1 1 ),|()()|( )|(","λ φ w (2) Where )|( ii efφ and )( 1−− ii bad denote phrase translation probability and distortion probability, respectively. ),|( aefp iiw is the lexical weight, and λ is the strength of the lexical weight."]},{"title":"4 Phrase-Based SMT Via Pivot Language","paragraphs":["This section will introduce the method that performs phrase-based SMT for the language pair Lf-Le by using the two bilingual corpora of Lf-Lp and Lp-Le. With the two additional bilingual corpora, we train two translation models for Lf-Lp and Lp-Le, respectively. Based on these two models, we build a pivot translation model for Lf-Le, with Lp as a pivot language.","According to equation (2), the phrase translation probability and the lexical weight are language dependent. We will introduce them in sections 4.1 and 4.2, respectively. 4.1 Phrase Translation Probability Using the Lf-Lp and Lp-Le bilingual corpora, we train two phrase translation probabilities 857",")|( ii pfφ and )|( ii epφ , where ip is the phrase in the pivot language Lp. Given the phrase translation probabilities )|( ii pfφ and )|( ii epφ , we obtain the phrase translation probability",")|( ii efφ according to the following model."]},{"title":"∑","paragraphs":["= ip i","ii","iii","i epepfef )|(),|()|( φφφ (3)","The phrase translation probability ),|( i ii epfφ does not depend on the phase ie in the language Le, since it is estimated from the Lf-Lp bilingual corpus. Thus, equation (3) can be rewritten as"]},{"title":"∑","paragraphs":["= ip i","iiii","i eppfef )|()|()|( φφφ (4) 4.2 Lexical Weight Given a phrase pair ),( ef and a word alignment"]},{"title":"a","paragraphs":["between the source word positions ni ,...,1= and the target word positions mj ,...,1= , the lexical weight can be estimated according to the following method (Koehn et al., 2003)."]},{"title":"∏ ∑","paragraphs":["= ∈∀∈ = n i aji ji efw ajij aefp 1 ),( )|( ),(| 1 ),|(w (5)","In order to estimate the lexical weight, we first need to obtain the alignment information a between the two phrases f and e , and then estimate the lexical translation probability )|( efw according to the alignment information. The alignment information of the phrase pair ),( ef can be induced from the two phrase pairs ),( pf and ),( ep .  Figure 1. Alignment Information Induction Let 1a and 2a represent the word alignment information inside the phrase pairs ),( pf and ),( ep respectively, then the alignment information a inside ),( ef can be obtained as shown in (6). An example is shown in Figure 1. }),(&),(:|),{( 21 aepapfpefa ∈∈∃= (6)","With the induced alignment information, this paper proposes a method to estimate the probability directly from the induced phrase pairs. We name this method phrase method. If we use K to denote the number of the induced phrase pairs, we estimate the co-occurring frequency of the word pair ),( ef according to the following model."]},{"title":"∑∑","paragraphs":["== = n i ai K k k ieeffef efcount 11 ),(),()|( ),( δδφ (7) Where )|( efkφ is the phrase translation probability for phrase pair k . 1),( =yxδ if yx = ; other-wise, 0),( =yxδ . Thus, lexical translation probability can be estimated as in (8)."]},{"title":"∑","paragraphs":["= ' ),'( ),( )|( f","efcount efcount efw (8)","We also estimate the lexical translation probability )|( efw using the method described in (Wang et al., 2006), which is shown in (9). We named it word method in this paper.",");,()|()|()|( pefsimepwpfwefw p"]},{"title":"∑","paragraphs":["= (9) Where )|( pfw and )|( epw are two lexical probabilities, and );,( pefsim is the cross-language word similarity."]},{"title":"5 Interpolated Model","paragraphs":["If we have a small Lf-Le bilingual corpus, we can employ this corpus to estimate a translation model as described in section 3. However, this model may perform poorly due to the sparseness of the data. In order to improve its performance, we can employ the additional Lf-Lp and Lp-Le bilingual corpora. Moreover, we can use more than one pivot language to improve the translation performance if the corresponding bilingual corpora exist. Different pivot languages may catch different linguistic phe-858 nomena, and improve translation quality for the desired language pair Lf-Le in different ways.","If we include n pivot languages, n pivot models can be estimated using the method as described in section 4. In order to combine these"]},{"title":"n","paragraphs":["pivot models with the standard model trained with the Lf-Le corpus, we use the linear interpolation method. The phrase translation probability and the lexical weight are estimated as shown in (10) and (11), respectively."]},{"title":"∑","paragraphs":["= = n i ii efef 0 )|()|( φαφ (10)"]},{"title":"∑","paragraphs":["= = n i ii aefpaefp 0 ),|(),|( w,w β (11)","Where )|(0 efφ and ),|( aefpw,0 denote the phrase translation probability and lexical weight trained with the Lf-Le bilingual corpus, respectively. )|( efiφ and ),|( aefp iw, ( ni ,...,1= ) are the phrase translation probability and lexical weight estimated by using the pivot languages. iα and iβ are the interpolation coefficients."]},{"title":"6 Experiments on the Europarl Corpus 6.1 Data","paragraphs":["A shared task to evaluate machine translation performance was organized as part of the NAACL/HLT 2006 Workshop on Statistical Machine Translation (Koehn and Monz, 2006). The shared task used the Europarl corpus (Koehn, 2005), in which four languages are involved: English, French, Spanish, and German. The shared task performed translation between English and the other three languages. In our work, we perform translation from French to the other three languages. We select French to Spanish and French to German translation that are not in the shared task because we want to use English as the pivot language. In general, for most of the languages, there exist bilingual corpora between these languages and English since English is an internationally used language.","Table 1 shows the information about the bilingual training data. In the table, \"Fr\", \"En\", \"Es\", and \"De\" denotes \"French\", \"English\", \"Spanish\", and \"German\", respectively. For the language pairs Lf-Le not including English, the bilingual corpus is","Language Pairs","Sentence Pairs Source Words","Target","Words Fr-En 688,031 15,323,737 13,808,104 Fr-Es 640,661 14,148,926 13,134,411 Fr-De 639,693 14,215,058 12,155,876 Es-En 730,740 15,676,710 15,222,105 De-En 751,088 15,256,793 16,052,269 De-Es 672,813 13,246,255 14,362,615 Table 1. Training Corpus for European Languages extracted from Lf-English and English-Le since Europarl corpus is a multilingual corpus.","For the language models, we use the same data provided in the shared task. We also use the same development set and test set provided by the shared task. The in-domain test set includes 2,000 sentences and the out-of-domain test set includes 1,064 sentences for each language.","6.2 Translation System and Evaluation Method To perform phrase-based SMT, we use Koehn's training scripts1","and the Pharaoh decoder (Koehn, 2004). We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set.","The translation quality was evaluated using a well-established automatic measure: BLEU score (Papineni et al., 2002). And we also use the tool provided in the NAACL/HLT 2006 shared task on SMT to calculate the BLEU scores. 6.3 Comparison of Different Lexical Weights As described in section 4, we employ two methods to estimate the lexical weight in the translation model. In order to compare the two methods, we translate from French to Spanish, using English as the pivot language. We use the French-English and English-Spanish corpora described in Table 1 as training data. During training, before estimating the Spanish to French phrase translation probability, we filter those French-English and English-Spanish phrase pairs whose translation probabilities are below a fixed threshold 0.001.2","The translation results are shown in Table 2. 1","It is located at http://www.statmt.org/wmt06/shared-task/baseline.htm 2 In the following experiments using pivot languages, we use the same filtering threshold for all of the language pairs. 859","The phrase method proposed in this paper performs better than the word method proposed in (Wang et al., 2006). This is because our method uses phrase translation probability as a confidence weight to estimate the lexical translation probability. It strengthens the frequently aligned pairs and weakens the infrequently aligned pairs. Thus, the following sections will use the phrase method to estimate the lexical weight.","Method In-Domain Out-of-Domain","Phrase 0.3212 0.2098","Word 0.2583 0.1672 Table 2. Results with Different Lexical Weights 6.4 Results of Using One Pivot Language This section describes the translation results by using only one pivot language. For the language pair French and Spanish, we use English as the pivot language. The entire French-English and English-Spanish corpora as described in section 4 are used to train a pivot model for French-Spanish.","As described in section 5, if we have a small Lf-Le bilingual corpus and large Lf-Lp and Lp-Le bilingual corpora, we can obtain interpolated models.","In order to conduct the experiments, we randomly select 5K, 10K, 20K, 30K, 40K, 50K, and 100K sentence pairs from the French-Spanish corpus. Using each of these corpora, we train a standard translation model.","For each standard model, we interpolate it with the pivot model to get an interpolated model. The interpolation weights are tuned using the development set. For all the interpolated models, we set","9.00 =α , 1.01 =α , 9.00 =β , and 1.01 =β . We test the three kinds of models on both the in-domain and out-of-domain test sets. The results are shown in Figures 2 and 3.","The pivot model achieves BLEU scores of 0.3212 and 0.2098 on the in-domain and out-of-domain test set, respectively. It achieves an absolute improvement of 0.05 on both test sets (16.92% and 35.35% relative) over the standard model trained with 5,000 French-Spanish sentence pairs. And the performance of the pivot models are comparable with that of the standard models trained with 20,000 and 30,000 sentence pairs on the in-domain and out-of-domain test set, respectively. When the French-Spanish training corpus is in-creased, the standard models quickly outperform the pivot model. 25272931333537","5 1020304050100 Fr-Es Data (k pairs) BLEU ( % ) Interpolated Standard Pivot"," Figure 2. In-Domain French-Spanish Results 14161820222426","5 1020304050100 Fr-Es Data (K pairs)","BLEU (%) Interpolated Standard Pivot"," Figure 3. Out-of-Domain French-Spanish Results 18202224262830","5 1020304050100 Fr-En Data (k Pairs)","BLEU (%) Interpolated Standard Pivot"," Figure 4. In-Domain French-English Results 91011121314151617","5 1020304050100 Fr-De Data (k Pairs)","BLEU (%) Interpolated Standard Pivot"," Figure 5. In-Domain French-German Results","When only a very small French-Spanish bilingual corpus is available, the interpolated method can greatly improve the translation quality. For example, when only 5,000 French-Spanish sentence pairs are available, the interpolated model outperforms the standard model by achieving a relative improvement of 17.55%, with the BLEU score improved from 0.2747 to 0.3229. With 50,000 French-Spanish sentence pairs available, the interpolated model significantly3","improves the translation quality by achieving an absolute im-3 We conduct the significance test using the same method as described in (Koehn and Monz, 2006). 860 provement of 0.01 BLEU. When the French-Spanish training corpus increases to 100,000 sentence pairs, the interpolated model achieves almost the same result as the standard model. This indicates that our pivot language method is suitable for the language pairs with small quantities of training data available.","Besides experiments on French-Spanish translation, we also conduct translation from French to English and French to German, using German and English as the pivot language, respectively. The results on the in-domain test set4","are shown in Figures 4 and 5. The tendency of the results is similar to that in Figure 2.","6.5 Results of Using More Than One Pivot Language For French to Spanish translation, we also introduce German as a pivot language besides English. Using these two pivot languages, we build two different pivot models, and then perform linear interpolation on them. The interpolation weights for the English pivot model and the German pivot model are set to 0.6 and 0.4 respectively5",". The translation results on the in-domain test set are 0.3212, 0.3077, and 0.3355 for the pivot models using English, German, and both German and English as pivot languages, respectively.","With the pivot model using both English and German as pivot languages, we interpolate it with the standard models trained with French-Spanish corpora of different sizes as described in the above section. The comparison of the translation results among the interpolated models, standard models, and the pivot model are shown in Figure 6.","It can be seen that the translation results can be further improved by using more than one pivot language. The pivot model \"Pivot-En+De\" using two pivot languages achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 sentence pairs. And it achieves comparable translation result as compared with the standard model trained with 30,000 French-Spanish sentence pairs.","The results in Figure 6 also indicate the interpolated models using two pivot languages achieve the 4 The results on the out-of-domain test set are similar to that in Figure 3. We only show the in-domain translation results in all of the following experiments because of space limit. 5 The weights are tuned on the development set. best results of all. Significance test shows that the interpolated models using two pivot languages significantly outperform those using one pivot language when less than 50,000 French-Spanish sentence pairs are available. 2728293031323334353637","5 1020304050100 Fr-Es Data (k Pairs)","BLEU (%) Interpolated-En+De Interpolated-En Interpolated-De Standard Pivot-En+De","","Figure 6. In-Domain French-Spanish Translation Results by Using Two Pivot Languages","6.6 Results by Using Pivot Language Related Corpora of Different Sizes In all of the above results, the corpora used to train the pivot models are not changed. In order to examine the effect of the size of the pivot corpora, we decrease the French-English and English-French corpora. We randomly select 200,000 and 400,000 sentence pairs from both of them to train two pivot models, respectively. The translation results on the in-domain test set are 0.2376, 0.2954, and 0.3212 for the pivot models trained with 200,000, 400,000, and the entire French-English and English-Spanish corpora, respectively. The results of the interpolated models and the standard models are shown in Figure 7. The results indicate that the larger the training corpora used to train the pivot model are, the better the translation quality is. 2728293031323334353637","5 1020304050100 Fr-Es Data (k pairs) BLEU (%) Interpolated-All interpolated-400k Interpolated-200k Standard"," Figure 7. In-Domain French-Spanish Results by Using Lf-Lp and Lp-Le Corpora of Different Sizes 861"]},{"title":"7 Experiments on Chinese to Japanese Translation","paragraphs":["In section 6, translation results on the Europarl multilingual corpus indicate the effectiveness of our method. To investigate the effectiveness of our method by using independently sourced parallel corpora, we conduct Chinese-Japanese translation using English as a pivot language in this section, where the training data are not limited to a specific domain.","The data used for this experiment is the same as those used in (Wang et al., 2006). There are 21,977, 329,350, and 160,535 sentence pairs for the language pairs Chinese-Japanese, Chinese-English, and English-Japanese, respectively. The development data and testing data include 500 and 1,000 Chinese sentences respectively, with one reference for each sentence. For Japanese language model training, we use about 100M bytes Japanese corpus.","The translation result is shown in Figure 8. The pivot model only outperforms the standard model trained with 2,500 sentence pairs. This is because (1) the corpora used to train the pivot model are smaller as compared with the Europarl corpus; (2) the training data and the testing data are not limited to a specific domain; (3) The languages are not closely related. 6 8 10 12 14 16 18","2.5 5 10 21.9 Chinese-Japanese Data (k pairs) BLEU ( % ) Interpolated Standard Pivot  Figure 8. Chinese-Japanese Translation Results","The interpolated models significantly outperform the other models. When only 5,000 sentence pairs are available, the BLEU score increases relatively by 20.53%. With the entire (21,977 pairs) Chinese-Japanese available, the interpolated model relatively increases the BLEU score by 5.62%, from 0.1708 to 0.1804."]},{"title":"8 Conclusion","paragraphs":["This paper proposed a novel method for phrase-based SMT on language pairs with a small bilingual corpus by bringing in pivot languages. To perform translation between Lf and Le, we bring in a pivot language Lp, via which the large corpora of Lf-Lp and Lp-Le can be used to induce a translation model for Lf-Le. The advantage of this method is that it can perform translation between the language pair Lf-Le even if no bilingual corpus for this pair is available. Using BLEU as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly trained with 5,000 sentence pairs for French-Spanish translation. And the translation quality is comparable with that of the model directly trained with 30,000 French-Spanish sentence pairs. The results also indicate that using more pivot languages leads to better translation quality.","With a small bilingual corpus available for Lf-Le, we built a translation model, and interpolated it with the pivot model trained with the large Lf-Lp and Lp-Le bilingual corpora. The results on both the Europarl corpus and Chinese-Japanese translation indicate that the interpolated models achieve the best results. Results also indicate that our pivot language approach is suitable for translation on language pairs with a small bilingual corpus. The less the Lf-Le bilingual corpus is, the bigger the improvement is.","We also performed experiments using Lf-Lp and Lp-Le corpora of different sizes. The results indicate that using larger training corpora to train the pivot model leads to better translation quality."]},{"title":"References","paragraphs":["Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas. 2000. Learning Dependency Translation Models as Collections of Finite-State Head Transducers. Computational Linguistics, 26(1):45-60.","Niraj Aswani and Robert Gaizauskas. 2005. Aligning Words in English-Hindi Parallel Corpora. In Proc. of the ACL 2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 115-118.","Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2): 263-311.","Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved Statistical Machine Transla-862 tion Using Paraphrases. In Proc. of NAACL-2006, pages 17-24.","Lars Borin. 2000. You'll Take the High Road and I'll Take the Low Road: Using a Third Language to Improve Bilingual Word Alignment. In Proc. of COL-ING-2000, pages 97-103.","David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proc. of ACL-2005, pages 263-270.","Mona Diab and Philip Resnik. 2002. An Unsupervised Method for Word Sense Tagging using Parallel Corpora. In Proc. of ACL-2002, pages 255-262.","Tim Gollins and Mark Sanderson. 2001. Improving Cross Language Information Retrieval with Triangu-lated Translation. In Proc. of ACM SIGIR-2001, pages 90-95.","Kazuaki Kishida and Noriko Kando. 2003. Two-Stage Refinement of Query Translation in a Pivot Language Approach to Cross-Lingual Information Retrieval: An Experiment at CLEF 2003. In Proc. of CLEF-2003. pages 253-262.","Philipp Koehn. 2004. Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. In Proc. of AMTA-2004, pages 115-124.","Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proc. of MT Summit X, pages 79-86.","Philipp Koehn and Christof Monz. 2006. Manual and Automatic Evaluation of Machine Translation between European Languages. In Proc. of the 2006 HLT-NAACL Workshop on Statistical Machine Translation, pages 102-121.","Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proc. of HLT-NAAC- 2003, pages 127-133.","Adam Lopez and Philip Resnik. 2005. Improved HMM Alignment Models for Languages with Scarce Resources. In Proc. of the ACL-2005 Work-shop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 83-86.","Joel Martin, Rada Mihalcea, and Ted Pedersen. 2005. Word Alignment for Languages with Scarce Resources. In Proc. of the ACL-2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 65-74.","Dan Melamed. 2004. Statistical Machine Translation by Parsing. In Proc. of ACL-2004, pages 653-660.","Bart Mellebeek, Karolina Owczarzak, Declan Groves, Josef Van Genabith, and Andy Way. 2006. A Syntactic Skeleton for Statistical Machine Translation. In Proc. of EAMT-2006, pages 195-202.","Sonja Niessen and Hermann Ney. 2004. Statistical Machine Translation with Scarce Resources Using Morpho-Syntactic Information. Computational linguistics, 30(2): 181-204.","Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proc. of ACL-2003, pages 160-167.","Franz Josef Och and Hermann Ney. 2004. The Alignment Template Approach to Statistical Machine Translation. Computational Linguistics, 30(4):417-449.","Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proc. of ACL-2002, pages 311-318.","Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency Treelet Translation: Syntactically In-formed Phrasal SMT. In Proc. of ACL-2005, pages 271-279.","Tetsuya Sakai, Makoto Koyama, Akira Kumano, and Toshihiko Manabe. 2004. Toshiba BRIDJE at NTCIR-4 CLIR: Monolingual/Bilingual IR and Flexible Feedback. In Proc. of NTCIR 4.","Charles Schafer and David Yarowsky. 2002. Inducing Translation Lexicons via Diverse Similarity Measures and Bridge Languages. In Proc. of CoNLL-2002, pages 1-7.","Haifeng Wang, Hua Wu, and Zhanyi Liu. 2006. Word Alignment for Languages with Scarce Resources Using Bilingual Corpora of Other Language Pairs. In Proc. of COLING/ACL-2006 Main Conference Poster Sessions, pages 874-881.","Dan Tufis, Radu Ion, Alexandru Ceausu, and Dan Stefanescu. 2005. Combined Word Alignments. In Proc. of the ACL-2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 107-110.","Vincent Vandeghinste, Ineka Schuurman, Michael Carl, Stella Markantonatou, and Toni Badia. 2006. METIS-II: Machine Translation for Low-Resource Languages. In Proc. of LREC-2006, pages 1284-1289.","Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora. Computational Linguistics, 23(3):377-403.","Kenji Yamada and Kevin Knight. 2001. A Syntax Based Statistical Translation Model. In Proc. of ACL-2001, pages 523-530. 863"]}],"references":[{"authors":[{"first":"Hiyan","last":"Alshawi"},{"first":"Srinivas","last":"Bangalore"},{"first":"Shona","last":"Douglas"}],"year":"2000","title":"Learning Dependency Translation Models as Collections of Finite-State Head Transducers","source":"Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas. 2000. Learning Dependency Translation Models as Collections of Finite-State Head Transducers. Computational Linguistics, 26(1):45-60."},{"authors":[{"first":"Niraj","last":"Aswani"},{"first":"Robert","last":"Gaizauskas"}],"year":"2005","title":"Aligning Words in English-Hindi Parallel Corpora","source":"Niraj Aswani and Robert Gaizauskas. 2005. Aligning Words in English-Hindi Parallel Corpora. In Proc. of the ACL 2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 115-118."},{"authors":[{"first":"Peter","middle":"F.","last":"Brown"},{"first":"Stephen","middle":"A. Della","last":"Pietra"},{"first":"Vincent","middle":"J. Della","last":"Pietra"},{"first":"Robert","middle":"L.","last":"Mercer"}],"year":"1993","title":"The Mathematics of Statistical Machine Translation: Parameter Estimation","source":"Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2): 263-311."},{"authors":[{"first":"Chris","last":"Callison-Burch"},{"first":"Philipp","last":"Koehn"},{"first":"Miles","last":"Osborne"}],"year":"2006","title":"Improved Statistical Machine Transla-862 tion Using Paraphrases","source":"Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved Statistical Machine Transla-862 tion Using Paraphrases. In Proc. of NAACL-2006, pages 17-24."},{"authors":[{"first":"Lars","last":"Borin"}],"year":"2000","title":"You'll Take the High Road and I'll Take the Low Road: Using a Third Language to Improve Bilingual Word Alignment","source":"Lars Borin. 2000. You'll Take the High Road and I'll Take the Low Road: Using a Third Language to Improve Bilingual Word Alignment. In Proc. of COL-ING-2000, pages 97-103."},{"authors":[{"first":"David","last":"Chiang"}],"year":"2005","title":"A Hierarchical Phrase-Based Model for Statistical Machine Translation","source":"David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proc. of ACL-2005, pages 263-270."},{"authors":[{"first":"Mona","last":"Diab"},{"first":"Philip","last":"Resnik"}],"year":"2002","title":"An Unsupervised Method for Word Sense Tagging using Parallel Corpora","source":"Mona Diab and Philip Resnik. 2002. An Unsupervised Method for Word Sense Tagging using Parallel Corpora. In Proc. of ACL-2002, pages 255-262."},{"authors":[{"first":"Tim","last":"Gollins"},{"first":"Mark","last":"Sanderson"}],"year":"2001","title":"Improving Cross Language Information Retrieval with Triangu-lated Translation","source":"Tim Gollins and Mark Sanderson. 2001. Improving Cross Language Information Retrieval with Triangu-lated Translation. In Proc. of ACM SIGIR-2001, pages 90-95."},{"authors":[{"first":"Kazuaki","last":"Kishida"},{"first":"Noriko","last":"Kando"}],"year":"2003","title":"Two-Stage Refinement of Query Translation in a Pivot Language Approach to Cross-Lingual Information Retrieval: An Experiment at CLEF 2003","source":"Kazuaki Kishida and Noriko Kando. 2003. Two-Stage Refinement of Query Translation in a Pivot Language Approach to Cross-Lingual Information Retrieval: An Experiment at CLEF 2003. In Proc. of CLEF-2003. pages 253-262."},{"authors":[{"first":"Philipp","last":"Koehn"}],"year":"2004","title":"Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models","source":"Philipp Koehn. 2004. Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. In Proc. of AMTA-2004, pages 115-124."},{"authors":[{"first":"Philipp","last":"Koehn"}],"year":"2005","title":"Europarl: A Parallel Corpus for Statistical Machine Translation","source":"Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proc. of MT Summit X, pages 79-86."},{"authors":[{"first":"Philipp","last":"Koehn"},{"first":"Christof","last":"Monz"}],"year":"2006","title":"Manual and Automatic Evaluation of Machine Translation between European Languages","source":"Philipp Koehn and Christof Monz. 2006. Manual and Automatic Evaluation of Machine Translation between European Languages. In Proc. of the 2006 HLT-NAACL Workshop on Statistical Machine Translation, pages 102-121."},{"authors":[{"first":"Philipp","last":"Koehn"},{"first":"Franz","middle":"Josef","last":"Och"},{"first":"Daniel","last":"Marcu"}],"year":"2003","title":"Statistical Phrase-Based Translation","source":"Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proc. of HLT-NAAC- 2003, pages 127-133."},{"authors":[{"first":"Adam","last":"Lopez"},{"first":"Philip","last":"Resnik"}],"year":"2005","title":"Improved HMM Alignment Models for Languages with Scarce Resources","source":"Adam Lopez and Philip Resnik. 2005. Improved HMM Alignment Models for Languages with Scarce Resources. In Proc. of the ACL-2005 Work-shop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 83-86."},{"authors":[{"first":"Joel","last":"Martin"},{"first":"Rada","last":"Mihalcea"},{"first":"Ted","last":"Pedersen"}],"year":"2005","title":"Word Alignment for Languages with Scarce Resources","source":"Joel Martin, Rada Mihalcea, and Ted Pedersen. 2005. Word Alignment for Languages with Scarce Resources. In Proc. of the ACL-2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 65-74."},{"authors":[{"first":"Dan","last":"Melamed"}],"year":"2004","title":"Statistical Machine Translation by Parsing","source":"Dan Melamed. 2004. Statistical Machine Translation by Parsing. In Proc. of ACL-2004, pages 653-660."},{"authors":[{"first":"Bart","last":"Mellebeek"},{"first":"Karolina","last":"Owczarzak"},{"first":"Declan","last":"Groves"},{"first":"Josef","last":"Van Genabith"},{"first":"Andy","last":"Way"}],"year":"2006","title":"A Syntactic Skeleton for Statistical Machine Translation","source":"Bart Mellebeek, Karolina Owczarzak, Declan Groves, Josef Van Genabith, and Andy Way. 2006. A Syntactic Skeleton for Statistical Machine Translation. In Proc. of EAMT-2006, pages 195-202."},{"authors":[{"first":"Sonja","last":"Niessen"},{"first":"Hermann","last":"Ney"}],"year":"2004","title":"Statistical Machine Translation with Scarce Resources Using Morpho-Syntactic Information","source":"Sonja Niessen and Hermann Ney. 2004. Statistical Machine Translation with Scarce Resources Using Morpho-Syntactic Information. Computational linguistics, 30(2): 181-204."},{"authors":[{"first":"Franz","middle":"Josef","last":"Och"}],"year":"2003","title":"Minimum Error Rate Training in Statistical Machine Translation","source":"Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proc. of ACL-2003, pages 160-167."},{"authors":[{"first":"Franz","middle":"Josef","last":"Och"},{"first":"Hermann","last":"Ney"}],"year":"2004","title":"The Alignment Template Approach to Statistical Machine Translation","source":"Franz Josef Och and Hermann Ney. 2004. The Alignment Template Approach to Statistical Machine Translation. Computational Linguistics, 30(4):417-449."},{"authors":[{"first":"Kishore","last":"Papineni"},{"first":"Salim","last":"Roukos"},{"first":"Todd","last":"Ward"},{"first":"Wei-Jing","last":"Zhu"}],"year":"2002","title":"BLEU: a Method for Automatic Evaluation of Machine Translation","source":"Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proc. of ACL-2002, pages 311-318."},{"authors":[{"first":"Chris","last":"Quirk"},{"first":"Arul","last":"Menezes"},{"first":"Colin","last":"Cherry"}],"year":"2005","title":"Dependency Treelet Translation: Syntactically In-formed Phrasal SMT","source":"Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency Treelet Translation: Syntactically In-formed Phrasal SMT. In Proc. of ACL-2005, pages 271-279."},{"authors":[{"first":"Tetsuya","last":"Sakai"},{"first":"Makoto","last":"Koyama"},{"first":"Akira","last":"Kumano"},{"first":"Toshihiko","last":"Manabe"}],"year":"2004","title":"Toshiba BRIDJE at NTCIR-4 CLIR: Monolingual/Bilingual IR and Flexible Feedback","source":"Tetsuya Sakai, Makoto Koyama, Akira Kumano, and Toshihiko Manabe. 2004. Toshiba BRIDJE at NTCIR-4 CLIR: Monolingual/Bilingual IR and Flexible Feedback. In Proc. of NTCIR 4."},{"authors":[{"first":"Charles","last":"Schafer"},{"first":"David","last":"Yarowsky"}],"year":"2002","title":"Inducing Translation Lexicons via Diverse Similarity Measures and Bridge Languages","source":"Charles Schafer and David Yarowsky. 2002. Inducing Translation Lexicons via Diverse Similarity Measures and Bridge Languages. In Proc. of CoNLL-2002, pages 1-7."},{"authors":[{"first":"Haifeng","last":"Wang"},{"first":"Hua","last":"Wu"},{"first":"Zhanyi","last":"Liu"}],"year":"2006","title":"Word Alignment for Languages with Scarce Resources Using Bilingual Corpora of Other Language Pairs","source":"Haifeng Wang, Hua Wu, and Zhanyi Liu. 2006. Word Alignment for Languages with Scarce Resources Using Bilingual Corpora of Other Language Pairs. In Proc. of COLING/ACL-2006 Main Conference Poster Sessions, pages 874-881."},{"authors":[{"first":"Dan","last":"Tufis"},{"first":"Radu","last":"Ion"},{"first":"Alexandru","last":"Ceausu"},{"first":"Dan","last":"Stefanescu"}],"year":"2005","title":"Combined Word Alignments","source":"Dan Tufis, Radu Ion, Alexandru Ceausu, and Dan Stefanescu. 2005. Combined Word Alignments. In Proc. of the ACL-2005 Workshop on Building and Using Parallel Texts: Data-driven Machine Translation and Beyond, pages 107-110."},{"authors":[{"first":"Vincent","last":"Vandeghinste"},{"first":"Ineka","last":"Schuurman"},{"first":"Michael","last":"Carl"},{"first":"Stella","last":"Markantonatou"},{"first":"Toni","last":"Badia"}],"year":"2006","title":"METIS-II: Machine Translation for Low-Resource Languages","source":"Vincent Vandeghinste, Ineka Schuurman, Michael Carl, Stella Markantonatou, and Toni Badia. 2006. METIS-II: Machine Translation for Low-Resource Languages. In Proc. of LREC-2006, pages 1284-1289."},{"authors":[{"first":"Dekai","last":"Wu"}],"year":"1997","title":"Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora","source":"Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora. Computational Linguistics, 23(3):377-403."},{"authors":[{"first":"Kenji","last":"Yamada"},{"first":"Kevin","last":"Knight"}],"year":"2001","title":"A Syntax Based Statistical Translation Model","source":"Kenji Yamada and Kevin Knight. 2001. A Syntax Based Statistical Translation Model. In Proc. of ACL-2001, pages 523-530. 863"}],"cites":[{"style":0,"text":"Koehn et al., 2003","origin":{"pointer":"/sections/2/paragraphs/0","offset":65,"length":18},"authors":[{"last":"Koehn"},{"last":"al."}],"year":"2003","references":["/references/12"]},{"style":0,"text":"Och and Ney, 2004","origin":{"pointer":"/sections/2/paragraphs/0","offset":85,"length":17},"authors":[{"last":"Och"},{"last":"Ney"}],"year":"2004","references":["/references/19"]},{"style":0,"text":"Wu, 1997","origin":{"pointer":"/sections/2/paragraphs/0","offset":130,"length":8},"authors":[{"last":"Wu"}],"year":"1997","references":["/references/27"]},{"style":0,"text":"Yamada and Knignt, 2001","origin":{"pointer":"/sections/2/paragraphs/0","offset":161,"length":23},"authors":[{"last":"Yamada"},{"last":"Knignt"}],"year":"2001","references":[]},{"style":0,"text":"Melamed, 2004","origin":{"pointer":"/sections/2/paragraphs/0","offset":186,"length":13},"authors":[{"last":"Melamed"}],"year":"2004","references":["/references/15"]},{"style":0,"text":"Chiang, 2005","origin":{"pointer":"/sections/2/paragraphs/0","offset":201,"length":12},"authors":[{"last":"Chiang"}],"year":"2005","references":["/references/5"]},{"style":0,"text":"Quick et al., 2005","origin":{"pointer":"/sections/2/paragraphs/0","offset":215,"length":18},"authors":[{"last":"Quick"},{"last":"al."}],"year":"2005","references":[]},{"style":0,"text":"Mellebeek et al., 2006","origin":{"pointer":"/sections/2/paragraphs/0","offset":235,"length":22},"authors":[{"last":"Mellebeek"},{"last":"al."}],"year":"2006","references":["/references/16"]},{"style":0,"text":"Brown et al., 1993","origin":{"pointer":"/sections/2/paragraphs/0","offset":290,"length":18},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1993","references":["/references/2"]},{"style":0,"text":"Koehn, 2005","origin":{"pointer":"/sections/2/paragraphs/2","offset":47,"length":11},"authors":[{"last":"Koehn"}],"year":"2005","references":["/references/10"]},{"style":0,"text":"Papineni et al., 2002","origin":{"pointer":"/sections/2/paragraphs/2","offset":73,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"2002","references":["/references/20"]},{"style":0,"text":"Gollins and Sanderson, 2001","origin":{"pointer":"/sections/3/paragraphs/1","offset":118,"length":27},"authors":[{"last":"Gollins"},{"last":"Sanderson"}],"year":"2001","references":["/references/7"]},{"style":0,"text":"Kishida and Kando, 2003","origin":{"pointer":"/sections/3/paragraphs/1","offset":147,"length":23},"authors":[{"last":"Kishida"},{"last":"Kando"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Sakai et al., 2004","origin":{"pointer":"/sections/3/paragraphs/1","offset":467,"length":18},"authors":[{"last":"Sakai"},{"last":"al."}],"year":"2004","references":["/references/22"]},{"style":0,"text":"Callison-Burch et al. (2006)","origin":{"pointer":"/sections/3/paragraphs/2","offset":0,"length":28},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2006","references":["/references/3"]},{"style":0,"text":"Borin (2000)","origin":{"pointer":"/sections/3/paragraphs/2","offset":127,"length":12},"authors":[{"last":"Borin"}],"year":"2000","references":["/references/4"]},{"style":0,"text":"Wang et al. (2006)","origin":{"pointer":"/sections/3/paragraphs/2","offset":144,"length":18},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2006","references":["/references/24"]},{"style":0,"text":"Borin (2000)","origin":{"pointer":"/sections/3/paragraphs/2","offset":211,"length":12},"authors":[{"last":"Borin"}],"year":"2000","references":["/references/4"]},{"style":0,"text":"Wang et al. (2006)","origin":{"pointer":"/sections/3/paragraphs/2","offset":282,"length":18},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2006","references":["/references/24"]},{"style":0,"text":"Schafer and Yarowsky, 2002","origin":{"pointer":"/sections/3/paragraphs/2","offset":479,"length":26},"authors":[{"last":"Schafer"},{"last":"Yarowsky"}],"year":"2002","references":["/references/23"]},{"style":0,"text":"Diab and Resnik, 2002","origin":{"pointer":"/sections/3/paragraphs/2","offset":535,"length":21},"authors":[{"last":"Diab"},{"last":"Resnik"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Niessen and Ney (2004)","origin":{"pointer":"/sections/3/paragraphs/3","offset":21,"length":22},"authors":[{"last":"Niessen"},{"last":"Ney"}],"year":"2004","references":["/references/17"]},{"style":0,"text":"Vandeghinste et al. (2006)","origin":{"pointer":"/sections/3/paragraphs/3","offset":140,"length":26},"authors":[{"last":"Vandeghinste"},{"last":"al."}],"year":"2006","references":["/references/26"]},{"style":0,"text":"Martin et al., 2005","origin":{"pointer":"/sections/3/paragraphs/3","offset":403,"length":19},"authors":[{"last":"Martin"},{"last":"al."}],"year":"2005","references":["/references/14"]},{"style":0,"text":"Aswani and Gaizauskas, 2005","origin":{"pointer":"/sections/3/paragraphs/3","offset":537,"length":27},"authors":[{"last":"Aswani"},{"last":"Gaizauskas"}],"year":"2005","references":["/references/1"]},{"style":0,"text":"Lopez and Resnik, 2005","origin":{"pointer":"/sections/3/paragraphs/3","offset":566,"length":22},"authors":[{"last":"Lopez"},{"last":"Resnik"}],"year":"2005","references":["/references/13"]},{"style":0,"text":"Tufis et al., 2005","origin":{"pointer":"/sections/3/paragraphs/3","offset":590,"length":18},"authors":[{"last":"Tufis"},{"last":"al."}],"year":"2005","references":["/references/25"]},{"style":0,"text":"Koehn et al., 2003","origin":{"pointer":"/sections/4/paragraphs/0","offset":49,"length":18},"authors":[{"last":"Koehn"},{"last":"al."}],"year":"2003","references":["/references/12"]},{"style":0,"text":"Koehn et al., 2003","origin":{"pointer":"/sections/9/paragraphs/0","offset":159,"length":18},"authors":[{"last":"Koehn"},{"last":"al."}],"year":"2003","references":["/references/12"]},{"style":0,"text":"Wang et al., 2006","origin":{"pointer":"/sections/12/paragraphs/2","offset":92,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2006","references":["/references/24"]},{"style":0,"text":"Koehn and Monz, 2006","origin":{"pointer":"/sections/18/paragraphs/0","offset":147,"length":20},"authors":[{"last":"Koehn"},{"last":"Monz"}],"year":"2006","references":["/references/11"]},{"style":0,"text":"Koehn, 2005","origin":{"pointer":"/sections/18/paragraphs/0","offset":212,"length":11},"authors":[{"last":"Koehn"}],"year":"2005","references":["/references/10"]},{"style":0,"text":"Koehn, 2004","origin":{"pointer":"/sections/18/paragraphs/8","offset":25,"length":11},"authors":[{"last":"Koehn"}],"year":"2004","references":["/references/9"]},{"style":0,"text":"Och, 2003","origin":{"pointer":"/sections/18/paragraphs/8","offset":152,"length":9},"authors":[{"last":"Och"}],"year":"2003","references":["/references/18"]},{"style":0,"text":"Papineni et al., 2002","origin":{"pointer":"/sections/18/paragraphs/9","offset":94,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"2002","references":["/references/20"]},{"style":0,"text":"Wang et al., 2006","origin":{"pointer":"/sections/18/paragraphs/12","offset":91,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2006","references":["/references/24"]},{"style":0,"text":"Koehn and Monz, 2006","origin":{"pointer":"/sections/18/paragraphs/33","offset":135,"length":20},"authors":[{"last":"Koehn"},{"last":"Monz"}],"year":"2006","references":["/references/11"]},{"style":0,"text":"Wang et al., 2006","origin":{"pointer":"/sections/19/paragraphs/1","offset":64,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2006","references":["/references/24"]}]}
