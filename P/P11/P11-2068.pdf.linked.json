{"sections":[{"title":"","paragraphs":["Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 389–394, Portland, Oregon, June 19-24, 2011. c⃝2011 Association for Computational Linguistics"]},{"title":"Improving On-line Handwritten Recognition using Translation Models in Multimodal Interactive Machine Translation Vicent Alabau, Alberto Sanchis, Francisco Casacuberta Institut Tecnològic d’Informàtica Universitat Politècnica de València Camı́ de Vera, s/n, Valencia, Spain {valabau,asanchis,fcn}@iti.upv.es Abstract","paragraphs":["In interactive machine translation (IMT), a human expert is integrated into the core of a machine translation (MT) system. The human expert interacts with the IMT system by partially correcting the errors of the system’s output. Then, the system proposes a new solution. This process is repeated until the output meets the desired quality. In this scenario, the interaction is typically performed using the keyboard and the mouse. In this work, we present an alternative modality to interact within IMT systems by writing on a tactile display or using an electronic pen. An on-line handwritten text recognition (HTR) system has been specifically designed to operate with IMT systems. Our HTR system improves previous approaches in two main aspects. First, HTR decoding is tightly coupled with the IMT system. Second, the language models proposed are context aware, in the sense that they take into account the partial corrections and the source sentence by using a combination of n-grams and word-based IBM models. The proposed system achieves an important boost in performance with respect to previous work."]},{"title":"1 Introduction","paragraphs":["Although current state-of-the-art machine translation (MT) systems have improved greatly in the last ten years, they are not able to provide the high quality results that are needed for industrial and business purposes. For that reason, a new interactive paradigm has emerged recently. In interactive machine translation (IMT) (Foster et al., 1998; Barrachina et al., 2009; Koehn and Haddow, 2009) the system goal is not to produce “perfect” translations in a completely automatic way, but to help the user build the translation with the least effort possible.","A typical approach to IMT is shown in Fig. 1. A source sentence f is given to the IMT system. First, the system outputs a translation hypothesis ês in the target language, which would correspond to the output of fully automated MT system. Next, the user analyses the source sentence and the decoded hypothesis, and validates the longest error-free prefix ep finding the first error. The user, then, corrects the erroneous word by typing some keystrokes κ, and sends them along with ep to the system, as a new validated prefix ep, κ. With that information, the system is able to produce a new, hopefully improved, suffix ês that continues the previous validated prefix. This process is repeated until the user agrees with the quality of the resulting translation. system user f es ep , Figure 1: Diagram of a typical approach to IMT","The usual way in which the user introduces the corrections κ is by means of the keyboard. However, other interaction modalities are also possible. For example, the use of speech interaction was studied in (Vidal et al., 2006). In that work, several sce-389 narios were proposed, where the user was expected to speak aloud parts of the current hypothesis and possibly one or more corrections. On-line HTR for interactive systems was first explored for interactive transcription of text images (Toselli et al., 2010). Later, we proposed an adaptation to IMT in (Alabau et al., 2010). For both cases, the decoding of the on-line handwritten text is performed independently as a previous step of the suffixes decoding. To our knowledge, (Alabau et al., 2010) has been the first and sole approach to the use of on-line handwriting in IMT so far. However, that work did not exploit the specific particularities of the MT scenario.","The novelties of this paper with respect to previous work are summarised in the following items:","• in previous formalisations of the problem, the HTR decoding and the IMT decoding were performed in two steps. Here, a sound statistical formalisation is presented where both systems are tightly coupled.","• the use of specific language modelling for on-line HTR decoding that take into account the previous validated prefix ep, κ, and the source sentence f . A decreasing in error of 2% absolute has been achieved with respect to previous work.","• additionally, a thorough study of the errors committed by the HTR subsystem is presented.","The remainder of this paper is organised as follows: The statistical framework for multimodal IMT and their alternatives will be studied in Sec. 2. Sec-tion 3 is devoted to the evaluation of the proposed models. Here, the results will be analysed and compared to previous approaches. Finally, conclusions and future work will be discussed in Sec. 4."]},{"title":"2 Multimodal IMT","paragraphs":["In the traditional IMT scenario, the user interacts with the system through a series of corrections introduced with the keyboard. This iterative nature of the process is emphasised by the loop in Fig. 1, which indicates that, for a source sentence to be translated, several interactions between the user and the system should be performed. In each interaction, the system produces the most probable suffixês that completes the prefix formed by concatenating the longest correct prefix from the previous hypothesis ep and the keyboard correction κ. In addition, the concatena-tion of them, (ep, κ, ês), must be a translation of f . Statistically, this problem can be formulated as","ês = argmax es P r(es|ep, κ, f ) (1)","The multimodal IMT approach differs from Eq. 1 in that the user introduces the correction using a touch-screen or an electronic pen, t. Then, Eq. 1 can be rewritten as","ês = argmax es P r(es|ep, t, f ) (2)","As t is a non-deterministic input (contrarily to κ), t needs to be decoded in a word d of the vocabulary. Thus, we must marginalise for every possible decoding:","ês = argmax es ∑ d P r(es, d|ep, t, f ) (3)","Furthermore, by applying simple Bayes transformations and making reasonable assumptions,","ês ≈ argmax es max d P r(t|d) P r(d|ep, f ) P r(es|ep, d, f ) (4)","The first term in Eq. 4 is a morphological model and it can be approximated with hidden Markov models (HMM). The last term is an IMT model as described in (Barrachina et al., 2009). Finally, P r(d|ep, f ) is a constrained language model. Note that the language model is conditioned to the longest correct prefix, just as a regular language model. Besides, it is also conditioned to the source sentence, since d should result of the translation of it.","A typical session of the multimodal IMT is exemplified in Fig. 2. First, the system starts with an empty prefix, so it proposes a full hypothesis. The output would be the same of a fully automated system. Then, the user corrects the first error, not, by writing on a touch-screen. The HTR subsystem mistakenly recognises in. Consequently, the user falls back to the keyboard and types is. Next, the system proposes a new suffix, in which the first word, not, has been automatically corrected. The user amends at by writing the word , which is correctly recognised by the HTR subsystem. Finally, as the new proposed suffix is correct, the process ends. 390 SOURCE (f ): si alguna función no se encuentra disponible en su red TARGET (e): if any feature is not available in your network ITER-0 (ep) ITER-1 (ês) if any feature not is available on your network (ep) if any feature (t) if any feature ( d̂) if any feature in (κ) if any feature is ITER-2 (ês) if any feature is not available at your network (ep) if any feature is not available (t) if any feature is not available ( d̂) if any feature is not available in FINAL","(ês) if any feature is not available in your network (ep ≡ e) if any feature is not available in your network Figure 2: Example of a multimodal IMT session for translating a Spanish sentence f from the Xerox corpus to an English sentence e. If the decoding of the pen strokes d̂ is correct, it is displayed in boldface. On the contrary, if d̂ is incorrect, it is shown crossed out. In this case, the user amends the error with the keyboard κ (in typewriter). 2.1 Decoupled Approach In (Alabau et al., 2010) we proposed a decoupled approach to Eq. 4, where the on-line HTR decoding was a separate problem from the IMT problem. From Eq. 4 a two step process can be performed. First, d̂ is obtained,","d̂ ≈ argmax d P r(t|d) P r(d|ep, f ) (5)","Then, the most likely suffix is obtained as in Eq 1, but taking d̂ as the corrected word instead of κ,","ês = argmax es P r(es|ep, d̂, f ) (6)","Finally, in that work, the terms of Eq. 5 were interpolated with a unigram in a log-linear model. 2.2 Coupled Approach The formulation presented in Eq. 4 can be tackled directly to perform a coupled decoding. The problem resides in how to model the constrained language model. A first approach is to drop either the ep or f terms from the probability. If f is dropped, then P r(d|ep) can be modelled as a regular n-gram model. On the other hand, if ep is dropped, but the position of d in the target sentence i = |ep| + 1 is kept, P r(d|f , i) can be modelled as a word-based translation model. Let us introduce a hidden variable j that accounts for a position of a word in f which is a candidate translation of d. Then, P r(d|f , i) = |f| ∑ j=1 P r(d, j|f , i) (7) ≈ |f| ∑ j=1 P r(j|f , i)P r(d|fj) (8)","Both probabilities, P r(j|f , i) and P r(d|fj), can be estimated using IBM models (Brown et al., 1993). The first term is an alignment probability while the second is a word dictionary. Word dictionary probabilities can be directly estimated by IBM1 models. However, word dictionaries are not symmetric. Alternatively, this probability can be estimated using the inverse dictionary to provide a smoothed dictionary, P r(d|fj) = P r(d) P r(fj|d)","∑ d′ P r(d′",") P r(fj|d′",") (9)","Thus, four word-based translation models have been considered: direct IBM1 and IBM2 models, and inverse IBM1-inv and IBM2-inv models with the inverse dictionary from Eq. 9.","However, a more interesting set up than using language models or translation models alone is to combine both models. Two schemes have been studied. 391 The most formal under a probabilistic point of view is a linear interpolation of the models, P r(d|ep, f ) = αP r(d|ep) + (1 − α)P r(d|f , i)","(10) However, a common approach to combine models nowadays is log-linear interpolation (Berger et al., 1996; Papineni et al., 1998; Och and Ney, 2002), P r(d|ep, f ) =","exp (∑ m λmhm(d, f , ep))","Z (11) λm being a scaling factor for model m, hm the log-probability of each model considered in the loglineal interpolation and Z a normalisation factor.","Finally, to balance the absolute values of the morphological model, the constrained language model and the IMT model, these probabilities are combined in a log-linear manner regardless of the language modelling approach."]},{"title":"3 Experiments","paragraphs":["The Xerox corpus, created on the TT2 project (SchulmbergerSema S.A. et al., 2001), was used for these experiments, since it has been extensively used in the literature to obtain IMT results. The simplified English and Spanish versions were used to estimate the IMT, IBM and language models. The corpus consists of 56k sentences of training and a development and test sets of 1.1k sentences. Test perplexities for Spanish and English are 33 and 48, respectively.","For on-line HTR, the on-line handwritten UNIPEN corpus (Guyon et al., 1994) was used. The morphological models were represented by continuous density left-to-right character HMMs with Gaussian mixtures, as in speech recognition (Rabiner, 1989), but with variable number of states per character. Feature extraction consisted on speed and size normalisation of pen positions and velocities, resulting in a sequence of vectors of six features (Toselli et al., 2007).","The simulation of user interaction was performed in the following way. First, the publicly available IMT decoder Thot (Ortiz-Martı́nez et al., 2005) 1 was used to run an off-line simulation for keyboard-based IMT. As a result, a list of words the system 1 http://sourceforge.net/projects/thot/","System Spanish English","dev test dev test independent HTR (†) 9.6 10.9 7.7 9.6 decoupled (⋆) 9.5 10.8 7.2 9.6 best coupled 6.7 8.9 5.5 7.2 Table 1: Comparison of the CER with previous systems. In boldface the best system. (†) is an independent, context unaware system used as baseline. (⋆) is a model equivalent to (Alabau et al., 2010). failed to predict was obtained. Supposedly, this is the list of words that the user would like to correct with handwriting. Then, from UNIPEN corpus, three users (separated from the training) were selected to simulate user interaction. For each user, the handwritten words were generated by concatenating random character instances from the user’s data to form a single stroke. Finally, the generated handwritten words of the three users were decoded using the corresponding constrained language model with a state-of-the-art HMM decoder, iAtros (Luján-Mares et al., 2008). 3.1 Results Results are presented in classification error rate (CER), i.e. the ratio between the errors committed by the on-line HTR decoder and the number of handwritten words introduced by the user. All the results have been calculated as the average CER of the three users.","Table 1 shows a comparison between the best results in this work and the approaches in previous work. The log-linear and linear weights were obtained with the simplex algorithm (Nelder and Mead, 1965) to optimise the development set. Then, those weights were used for the test set.","Two baseline models have been established for comparison purposes. On the one hand, (†) is a completely independent and context unaware system. That would be the equivalent to decode the handwritten text in a separate on-line HTR decoder. This system obtains the worst results of all. On the other hand, (⋆) is the most similar model to the best system in (Alabau et al., 2010). This system is clearly outperformed by the proposed coupled approach.","A summary of the alternatives to language mod-392","System Spanish English","dev test dev test 4gr 7.8 10.0 6.3 8.9 IBM1 7.9 9.6 7.0 8.2 IBM2 7.1 8.6 6.1 7.9 IBM1-inv 8.4 9.5 7.5 9.2 IBM2-inv 7.9 9.1 7.1 9.1 4gr+IBM2 (L-Linear) 7.0 9.1 6.0 7.9 4gr+IBM2 (Linear) 6.7 8.9 5.5 7.2 Table 2: Summary of the CER results for various language modelling approaches. In boldface the best system. elling is shown in Tab. 2. Up to 5-grams were used in the experiments. However, the results did not show significant differences between them, except for the 1-gram. Thus, context does not seem to improve much the performance. This may be due to the fact that the IMT and the on-line HTR systems use the same language models (5-gram in the case of the IMT system). Hence, if the IMT has failed to predict the correct word because of poor language modelling that will affect on-line HTR decoding as well. In fact, although language perplexities for the test sets are quite low (33 for Spanish and 48 for English), perplexities accounting only erroneous words increase until 305 and 420, respectively.","On the contrary, using IBM models provides a significant boost in performance. Although inverse dictionaries have a better vocabulary coverage (4.7% vs 8.9% in English, 7.4% vs 10.4% in Spanish), they tend to perform worse than their direct dictionary counterparts. Still, inverse IBM models perform better than the n-grams alone. Log-linear models show a bit of improvement with respect to IBM models. However, linear interpolated models perform the best. In the Spanish test set the result is not better that the IBM2 since the linear parameters are clearly over-fitted. Other model combinations (including a combination of all models) were tested. Nevertheless, none of them outperformed the best system in Table 2. 3.2 Error Analysis An analysis of the results showed that 52.2% to 61.7% of the recognition errors were produced by punctuation and other symbols. To circumvent this problem, we proposed a contextual menu in (Alabau et al., 2010). With such menu, errors would have been reduced (best test result) to 4.1% in Spanish and 2.8% in English. Out-of-vocabulary (OOV) words also summed up a big percentage of the error (29.1% and 20.4%, respectively). This difference is due to the fact that Spanish is a more inflected language. To solve this problem on-line learning algorithms or methods for dealing with OOV words should be used. Errors in gender, number and verb tenses, which rose up to 7.7% and 5.3% of the errors, could be tackled using linguistic information from both source and target sentences. Finally, the rest of the errors were mostly due to one-to-three letter words, which is basically a problem of handwriting morphological modelling."]},{"title":"4 Conclusions","paragraphs":["In this paper we have described a specific on-line HTR system that can serve as an alternative interaction modality to IMT. We have shown that a tight in-tegration of the HTR and IMT decoding process and the use of the available information can produce significant HTR error reductions. Finally, a study of the system’s errors has revealed the system weaknesses, and how they could be addressed in the future."]},{"title":"5 Acknowledgments","paragraphs":["Work supported by the EC (FEDER/FSE) and the Spanish MEC/MICINN under the MIPRCV ”Consolider Ingenio 2010” program (CSD2007-00018), iTrans2 (TIN2009-14511). Also supported by the Spanish MITyC under the erudito.com (TSI-020110-2009-439) project and by the Generalitat Valenciana under grant Prometeo/2009/014 and GV/2010/067, and by the ”Vicerrectorado de Investigación de la UPV” under grant UPV/2009/2851."]},{"title":"References","paragraphs":["[Alabau et al.2010] V. Alabau, D. Ortiz-Martı́nez, A. Sanchis, and F. Casacuberta. 2010. Multimodal interactive machine translation. In Proceedings of the 2010 International Conference on Multimodal Interfaces (ICMI-MLMI’10), pages 46:1–4, Beijing, China, Nov.","[Barrachina et al.2009] S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. L. 393 Lagarda, H. Ney, J. Tomás, E. Vidal, and J. M. Vilar. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28.","[Berger et al.1996] A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22:39–71.","[Brown et al.1993] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation. 19(2):263–311.","[Foster et al.1998] G. Foster, P. Isabelle, and P. Plamondon. 1998. Target-text mediated interactive machine translation. Machine Translation, 12:175–194.","[Guyon et al.1994] Isabelle Guyon, Lambert Schomaker, Réjean Plamondon, Mark Liberman, and Stan Janet. 1994. Unipen project of on-line data exchange and recognizer benchmarks. In Proceedings of International Conference on Pattern Recognition, pages 29– 33.","[Koehn and Haddow2009] P. Koehn and B. Haddow. 2009. Interactive assistance to human translators using statistical machine translation methods. In Proceedings of MT Summit XII, pages 73–80, Ottawa, Canada.","[Luján-Mares et al.2008] Mı́riam Luján-Mares, Vicent Tamarit, Vicent Alabau, Carlos D. Martı́nez-Hinarejos, Moisés Pastor i Gadea, Alberto Sanchis, and Alejandro H. Toselli. 2008. iATROS: A speech and handwritting recognition system. In V Jornadas en Tecnologı́as del Habla (VJTH’2008), pages 75–78, Bilbao (Spain), Nov.","[Nelder and Mead1965] J. A. Nelder and R. Mead. 1965. A simplex method for function minimization. Computer Journal, 7:308–313.","[Och and Ney2002] F. J. Och and H. Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of the 40th ACL, pages 295–302, Philadelphia, PA, July.","[Ortiz-Martı́nez et al.2005] D. Ortiz-Martı́nez, I. Garcı́a-Varea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proceedings of the MT Summit X, pages 141–148.","[Papineni et al.1998] K. A. Papineni, S. Roukos, and R. T. Ward. 1998. Maximum likelihood and discriminative training of direct translation models. In International Conference on Acoustics, Speech, and Signal Process-ing (ICASSP’98), pages 189–192, Seattle, Washington, USA, May.","[Rabiner1989] L. Rabiner. 1989. A Tutorial of Hidden Markov Models and Selected Application in Speech Recognition. Proceedings IEEE, 77:257–286.","[SchulmbergerSema S.A. et al.2001] SchulmbergerSema S.A., Celer Soluciones, Instituto Técnico de In-formática, R.W.T.H. Aachen - Lehrstuhl für In-formatik VI, R.A.L.I. Laboratory - University of Montreal, Société Gamma, and Xerox Research Centre Europe. 2001. X.R.C.: TT2. TransType2 - Computer assisted translation. Project technical annex.","[Toselli et al.2007] Alejandro H. Toselli, Moisés Pastor i Gadea, and Enrique Vidal. 2007. On-line handwriting recognition system for tamil handwritten characters. In 3rd Iberian Conference on Pattern Recognition and Image Analysis, pages 370–377. Girona (Spain), June.","[Toselli et al.2010] A. H. Toselli, V. Romero, M. Pastor, and E. Vidal. 2010. Multimodal interactive transcription of text images. Pattern Recognition, 43(5):1814– 1825.","[Vidal et al.2006] E. Vidal, F. Casacuberta, L. Rodrı́guez, J. Civera, and C. Martı́nez. 2006. Computer-assisted translation using speech recognition. IEEE Transaction on Audio, Speech and Language Processing, 14(3):941–951. 394"]}],"references":[{"authors":[{"last":"[Alabau"},{"first":"al.2010] V","middle":".","last":"Alabau"},{"first":"D.","last":"Ortiz-Martı́nez"},{"first":"A.","last":"Sanchis"},{"first":"F.","last":"Casacuberta"}],"year":"2010","title":"Multimodal interactive machine translation","source":"[Alabau et al.2010] V. Alabau, D. Ortiz-Martı́nez, A. Sanchis, and F. Casacuberta. 2010. Multimodal interactive machine translation. In Proceedings of the 2010 International Conference on Multimodal Interfaces (ICMI-MLMI’10), pages 46:1–4, Beijing, China, Nov."},{"authors":[{"last":"[Barrachina"},{"first":"al.2009]","middle":"S.","last":"Barrachina"},{"first":"O.","last":"Bender"},{"first":"F.","last":"Casacuberta"},{"first":"J.","last":"Civera"},{"first":"E.","last":"Cubel"},{"first":"S.","last":"Khadivi"},{"first":"A.","middle":"L. 393","last":"Lagarda"},{"first":"H.","last":"Ney"},{"first":"J.","last":"Tomás"},{"first":"E.","last":"Vidal"},{"first":"J.","middle":"M.","last":"Vilar"}],"year":"2009","title":"Statistical approaches to computer-assisted translation","source":"[Barrachina et al.2009] S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. L. 393 Lagarda, H. Ney, J. Tomás, E. Vidal, and J. M. Vilar. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28."},{"authors":[{"last":"[Berger"},{"first":"al.1996]","middle":"A. L.","last":"Berger"},{"first":"S.","middle":"A. Della","last":"Pietra"},{"first":"V.","middle":"J. Della","last":"Pietra"}],"year":"1996","title":"A maximum entropy approach to natural language processing","source":"[Berger et al.1996] A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22:39–71."},{"authors":[{"last":"[Brown"},{"first":"al.1993]","middle":"P. F.","last":"Brown"},{"first":"S.","middle":"A. Della","last":"Pietra"},{"first":"V.","middle":"J. Della","last":"Pietra"},{"first":"R.","middle":"L.","last":"Mercer"}],"year":"1993","title":"The mathematics of machine translation","source":"[Brown et al.1993] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation. 19(2):263–311."},{"authors":[{"last":"[Foster"},{"first":"al.1998]","middle":"G.","last":"Foster"},{"first":"P.","last":"Isabelle"},{"first":"P.","last":"Plamondon"}],"year":"1998","title":"Target-text mediated interactive machine translation","source":"[Foster et al.1998] G. Foster, P. Isabelle, and P. Plamondon. 1998. Target-text mediated interactive machine translation. Machine Translation, 12:175–194."},{"authors":[{"last":"[Guyon"},{"first":"al.1994]","middle":"Isabelle","last":"Guyon"},{"first":"Lambert","last":"Schomaker"},{"first":"Réjean","last":"Plamondon"},{"first":"Mark","last":"Liberman"},{"first":"Stan","last":"Janet"}],"year":"1994","title":"Unipen project of on-line data exchange and recognizer benchmarks","source":"[Guyon et al.1994] Isabelle Guyon, Lambert Schomaker, Réjean Plamondon, Mark Liberman, and Stan Janet. 1994. Unipen project of on-line data exchange and recognizer benchmarks. In Proceedings of International Conference on Pattern Recognition, pages 29– 33."},{"authors":[{"last":"[Koehn"},{"first":"Haddow2009]","middle":"P.","last":"Koehn"},{"first":"B.","last":"Haddow"}],"year":"2009","title":"Interactive assistance to human translators using statistical machine translation methods","source":"[Koehn and Haddow2009] P. Koehn and B. Haddow. 2009. Interactive assistance to human translators using statistical machine translation methods. In Proceedings of MT Summit XII, pages 73–80, Ottawa, Canada."},{"authors":[{"last":"[Luján-Mares"},{"first":"al.2008]","middle":"Mı́riam","last":"Luján-Mares"},{"first":"Vicent","last":"Tamarit"},{"first":"Vicent","last":"Alabau"},{"first":"Carlos","middle":"D.","last":"Martı́nez-Hinarejos"},{"first":"Moisés","middle":"Pastor i","last":"Gadea"},{"first":"Alberto","last":"Sanchis"},{"first":"Alejandro","middle":"H.","last":"Toselli"}],"year":"2008","title":"iATROS: A speech and handwritting recognition system","source":"[Luján-Mares et al.2008] Mı́riam Luján-Mares, Vicent Tamarit, Vicent Alabau, Carlos D. Martı́nez-Hinarejos, Moisés Pastor i Gadea, Alberto Sanchis, and Alejandro H. Toselli. 2008. iATROS: A speech and handwritting recognition system. In V Jornadas en Tecnologı́as del Habla (VJTH’2008), pages 75–78, Bilbao (Spain), Nov."},{"authors":[{"last":"[Nelder"},{"first":"Mead1965]","middle":"J. A.","last":"Nelder"},{"first":"R.","last":"Mead"}],"year":"1965","title":"A simplex method for function minimization","source":"[Nelder and Mead1965] J. A. Nelder and R. Mead. 1965. A simplex method for function minimization. Computer Journal, 7:308–313."},{"authors":[{"last":"[Och"},{"first":"Ney2002]","middle":"F. J.","last":"Och"},{"first":"H.","last":"Ney"}],"year":"2002","title":"Discriminative training and maximum entropy models for statistical machine translation","source":"[Och and Ney2002] F. J. Och and H. Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of the 40th ACL, pages 295–302, Philadelphia, PA, July."},{"authors":[{"last":"[Ortiz-Martı́nez"},{"first":"al.2005]","middle":"D.","last":"Ortiz-Martı́nez"},{"first":"I.","last":"Garcı́a-Varea"},{"first":"F.","last":"Casacuberta"}],"year":"2005","title":"Thot: a toolkit to train phrase-based statistical translation models","source":"[Ortiz-Martı́nez et al.2005] D. Ortiz-Martı́nez, I. Garcı́a-Varea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proceedings of the MT Summit X, pages 141–148."},{"authors":[{"last":"[Papineni"},{"first":"al.1998]","middle":"K. A.","last":"Papineni"},{"first":"S.","last":"Roukos"},{"first":"R.","middle":"T.","last":"Ward"}],"year":"1998","title":"Maximum likelihood and discriminative training of direct translation models","source":"[Papineni et al.1998] K. A. Papineni, S. Roukos, and R. T. Ward. 1998. Maximum likelihood and discriminative training of direct translation models. In International Conference on Acoustics, Speech, and Signal Process-ing (ICASSP’98), pages 189–192, Seattle, Washington, USA, May."},{"authors":[{"first":"[Rabiner1989]","middle":"L.","last":"Rabiner"}],"year":"1989","title":"A Tutorial of Hidden Markov Models and Selected Application in Speech Recognition","source":"[Rabiner1989] L. Rabiner. 1989. A Tutorial of Hidden Markov Models and Selected Application in Speech Recognition. Proceedings IEEE, 77:257–286."},{"authors":[{"first":"[SchulmbergerSema","middle":"S.","last":"A."},{"first":"al.2001]","middle":"SchulmbergerSema S.","last":"A."},{"first":"Celer","last":"Soluciones"},{"first":"Instituto","middle":"Técnico","last":"de In-formática"},{"first":"R.","middle":"W. T. H. Aachen - Lehrstuhl für","last":"In-formatik VI"},{"first":"R.","middle":"A. L. I. Laboratory - University of","last":"Montreal"},{"first":"Société","last":"Gamma"},{"first":"Xerox","middle":"Research Centre","last":"Europe"}],"year":"2001","title":"X","source":"[SchulmbergerSema S.A. et al.2001] SchulmbergerSema S.A., Celer Soluciones, Instituto Técnico de In-formática, R.W.T.H. Aachen - Lehrstuhl für In-formatik VI, R.A.L.I. Laboratory - University of Montreal, Société Gamma, and Xerox Research Centre Europe. 2001. X.R.C.: TT2. TransType2 - Computer assisted translation. Project technical annex."},{"authors":[{"last":"[Toselli"},{"first":"al.2007]","middle":"Alejandro H.","last":"Toselli"},{"first":"Moisés","middle":"Pastor i","last":"Gadea"},{"first":"Enrique","last":"Vidal"}],"year":"2007","title":"On-line handwriting recognition system for tamil handwritten characters","source":"[Toselli et al.2007] Alejandro H. Toselli, Moisés Pastor i Gadea, and Enrique Vidal. 2007. On-line handwriting recognition system for tamil handwritten characters. In 3rd Iberian Conference on Pattern Recognition and Image Analysis, pages 370–377. Girona (Spain), June."},{"authors":[{"last":"[Toselli"},{"first":"al.2010]","middle":"A. H.","last":"Toselli"},{"first":"V.","last":"Romero"},{"first":"M.","last":"Pastor"},{"first":"E.","last":"Vidal"}],"year":"2010","title":"Multimodal interactive transcription of text images","source":"[Toselli et al.2010] A. H. Toselli, V. Romero, M. Pastor, and E. Vidal. 2010. Multimodal interactive transcription of text images. Pattern Recognition, 43(5):1814– 1825."},{"authors":[{"last":"[Vidal"},{"first":"al.2006]","middle":"E.","last":"Vidal"},{"first":"F.","last":"Casacuberta"},{"first":"L.","last":"Rodrı́guez"},{"first":"J.","last":"Civera"},{"first":"C.","last":"Martı́nez"}],"year":"2006","title":"Computer-assisted translation using speech recognition","source":"[Vidal et al.2006] E. Vidal, F. Casacuberta, L. Rodrı́guez, J. Civera, and C. Martı́nez. 2006. Computer-assisted translation using speech recognition. IEEE Transaction on Audio, Speech and Language Processing, 14(3):941–951. 394"}],"cites":[{"style":0,"text":"Foster et al., 1998","origin":{"pointer":"/sections/2/paragraphs/0","offset":328,"length":19},"authors":[{"last":"Foster"},{"last":"al."}],"year":"1998","references":[]},{"style":0,"text":"Barrachina et al., 2009","origin":{"pointer":"/sections/2/paragraphs/0","offset":349,"length":23},"authors":[{"last":"Barrachina"},{"last":"al."}],"year":"2009","references":[]},{"style":0,"text":"Koehn and Haddow, 2009","origin":{"pointer":"/sections/2/paragraphs/0","offset":374,"length":22},"authors":[{"last":"Koehn"},{"last":"Haddow"}],"year":"2009","references":[]},{"style":0,"text":"Vidal et al., 2006","origin":{"pointer":"/sections/2/paragraphs/2","offset":206,"length":18},"authors":[{"last":"Vidal"},{"last":"al."}],"year":"2006","references":[]},{"style":0,"text":"Toselli et al., 2010","origin":{"pointer":"/sections/2/paragraphs/2","offset":493,"length":20},"authors":[{"last":"Toselli"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/2/paragraphs/2","offset":560,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/2/paragraphs/2","offset":734,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Barrachina et al., 2009","origin":{"pointer":"/sections/3/paragraphs/8","offset":156,"length":23},"authors":[{"last":"Barrachina"},{"last":"al."}],"year":"2009","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/3/paragraphs/10","offset":486,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Brown et al., 1993","origin":{"pointer":"/sections/3/paragraphs/15","offset":83,"length":18},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1993","references":[]},{"style":0,"text":"Berger et al., 1996","origin":{"pointer":"/sections/3/paragraphs/21","offset":88,"length":19},"authors":[{"last":"Berger"},{"last":"al."}],"year":"1996","references":[]},{"style":0,"text":"Papineni et al., 1998","origin":{"pointer":"/sections/3/paragraphs/21","offset":109,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"1998","references":[]},{"style":0,"text":"Och and Ney, 2002","origin":{"pointer":"/sections/3/paragraphs/21","offset":132,"length":17},"authors":[{"last":"Och"},{"last":"Ney"}],"year":"2002","references":[]},{"style":0,"text":"S.A. et al., 2001","origin":{"pointer":"/sections/4/paragraphs/0","offset":63,"length":17},"authors":[{"first":"S.","last":"A."},{"last":"al."}],"year":"2001","references":["/references/13"]},{"style":0,"text":"Guyon et al., 1994","origin":{"pointer":"/sections/4/paragraphs/1","offset":56,"length":18},"authors":[{"last":"Guyon"},{"last":"al."}],"year":"1994","references":[]},{"style":0,"text":"Rabiner, 1989","origin":{"pointer":"/sections/4/paragraphs/1","offset":229,"length":13},"authors":[{"last":"Rabiner"}],"year":"1989","references":["/references/12"]},{"style":0,"text":"Toselli et al., 2007","origin":{"pointer":"/sections/4/paragraphs/1","offset":441,"length":20},"authors":[{"last":"Toselli"},{"last":"al."}],"year":"2007","references":[]},{"style":0,"text":"Ortiz-Martı́nez et al., 2005","origin":{"pointer":"/sections/4/paragraphs/2","offset":119,"length":28},"authors":[{"last":"Ortiz-Martı́nez"},{"last":"al."}],"year":"2005","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/4/paragraphs/4","offset":292,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Luján-Mares et al., 2008","origin":{"pointer":"/sections/4/paragraphs/4","offset":861,"length":24},"authors":[{"last":"Luján-Mares"},{"last":"al."}],"year":"2008","references":[]},{"style":0,"text":"Nelder and Mead, 1965","origin":{"pointer":"/sections/4/paragraphs/5","offset":178,"length":21},"authors":[{"last":"Nelder"},{"last":"Mead"}],"year":"1965","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/4/paragraphs/6","offset":357,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]},{"style":0,"text":"Alabau et al., 2010","origin":{"pointer":"/sections/4/paragraphs/10","offset":928,"length":19},"authors":[{"last":"Alabau"},{"last":"al."}],"year":"2010","references":[]}]}
