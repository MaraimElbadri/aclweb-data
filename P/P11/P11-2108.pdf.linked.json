{"sections":[{"title":"","paragraphs":["Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 614–619, Portland, Oregon, June 19-24, 2011. c⃝2011 Association for Computational Linguistics"]},{"title":"Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport Siwei Wang Department of Psychology University of Chicago Chicago, IL 60637 USA siweiw@cs.uchicago.edu Gina-Anne Levow Department of Linguistics University of Washington Seattle, WA 98195 USA levow@uw.edu Abstract","paragraphs":["Verbal feedback is an important information source in establishing interactional rapport. However, predicting verbal feedback across languages is challenging due to language-specific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback. In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations. This approach improves the prediction of verbal feedback, up to 6-fold, while maintaining a high overall accuracy. Analyzing highly weighted features highlights widespread use of pitch, with more varied use of intensity and duration."]},{"title":"1 Introduction","paragraphs":["Culture-specific aspects of speech and nonverbal be-havior enable creation and maintenance of a sense of rapport. Rapport is important because it is known to enhance goal-directed interactions and also to promote learning. Previous work has identified cross-cultural differences in a variety of behaviors, for example, nodding (Maynard, 1990), facial expression (Matsumoto et al., 2005), gaze (Watson, 1970), cues to vocal back-channel (Ward and Tsukuhara, 2000; Ward and Al Bayyari, 2007; Rivera and Ward, 2007), nonverbal back-channel (Bertrand et al., 2007)), and coverbal gesturing (Kendon, 2004).","Here we focus on the automatic prediction of listener verbal feedback in dyadic unrehearsed story-telling to elucidate the similarities and differences in three language/cultural groups: Iraqi Arabic-, Mexican Spanish-, and American English-speaking cultures. (Tickle-Degnen and Rosenthal, 1990) identified coordination, along with positive emotion and mutual attention, as a key element of interactional rapport. In the verbal channel, this coordination manifests in the timing of contributions from the conversational participants, through turn-taking and back-channels. (Duncan, 1972) proposed an analysis of turn-taking as rule-governed, supported by a range of prosodic and non-verbal cues. Several computational approaches have investigated prosodic and verbal cues to these phenomena. (Shriberg et al., 2001) found that prosodic cues could aid in the identification of jump-in points in multi-party meetings. (Cathcart et al., 2003) employed features such as pause duration and part-of-speech (POS) tag sequences for back-channel prediction. (Gravano and Hirschberg, 2009) investigated back-channel-inviting cues in task-oriented dialog, identifying increases in pitch and intensity as well as certain POS patterns as key contributors. In multi-lingual comparisons, (Ward and Tsukuhara, 2000; Ward and Al Bayyari, 2007; Rivera and Ward, 2007) found pitch patterns, including periods of low pitch or drops in pitch, to be associated with eliciting back-channels across Japanese, English, Arabic, and Spanish. (Herrera et al., 2010) collected a corpus of multi-party interactions among American English, Mexican Spanish, and Arabic speakers to investigate cross-cultural differences in proxemics, gaze, and turn-taking. (Levow et al., 2010) identified contrasts in narrative length and rate of verbal feedback in recordings of American English-, Mexi-614 can Spanish-, and Iraqi Arabic-speaking dyads. This work also identified reductions in pitch and intensity associated with instances of verbal feedback as common, but not uniform, across these groups."]},{"title":"2 Multi-modal Rapport Corpus","paragraphs":["To enable a more controlled comparison of listener behavior, we collected a multi-modal dyadic corpus of unrehearsed story-telling. We audio- and videorecorded pairs of individuals who were close acquaintances or family members with, we assumed, well-established rapport. One participant viewed a six minute film, the “Pear Film” (Chafe, 1975), developed for language-independent elicitation. In the role of Speaker, this participant then related the story to the active and engaged Listener, who understood that they would need to retell the story themselves later. We have collected 114 elicitations: 45 Arabic, 32 Mexican Spanish, and 37 American English.","All recordings have been fully transcribed and time-aligned to the audio using a semi-automated procedure. We convert an initial manual coarse transcription at the phrase level to a full word and phone alignment using CUSonic (Pellom et al., 2001), applying its language porting functionality to Spanish and Arabic. In addition, word and phrase level English glosses were manually created for the Spanish and Arabic data. Manual annotation of a broad range of nonverbal cues, including gaze, blink, head nod and tilt, fidget, and coverbal gestures, is under-way. For the experiments presented in the remainder of this paper, we employ a set of 45 vetted dyads, 15 in each language.","Analysis of cross-cultural differences in narrative length, rate of listener verbal contributions, and the use of pitch and intensity in eliciting listener vocalizations appears in (Levow et al., 2010). That work found that the American English-speaking dyads produced significantly longer narratives than the other language/cultural groups, while Arabic listeners provided a significantly higher rate of verbal contributions than those in the other groups. Finally, all three groups exhibited significantly lower speaker pitch preceding listener verbal feedback than in other contexts, while only English and Spanish exhibited significant reductions in intensity. The current paper aims to extend and enhance these find-ings by exploring automatic recognition of speaker prosodic contexts associated with listener verbal feedback."]},{"title":"3 Challenges in Predicting Verbal Feedback","paragraphs":["Predicting verbal feedback in dyadic rapport in diverse language/cultural groups presents a number of challenges. In addition to the cross-linguistic, cross-cultural differences which are the focus of our study, it is also clear that there are substantial inter-speaker differences in verbal feedback, both in frequency and, we expect, in signalling. Furthermore, while the rate of verbal feedback differs across language and speaker, it is, overall, a relatively infrequent phenomenon, occurring in as little as zero percent of pausal intervals for some dyads and only at an average of 13-30% of pausal intervals across the three languages. As a result, the substantial class imbalance and relative sparsity of listener verbal feedback present challenges for data-driven machine learning methods. Finally, as prior researchers have observed, provision of verbal feedback can be viewed as optional. The presence of feedback, we assume, indicates the presence of a suitable context; the absence of feedback, however, does not guarantee that feedback would have been inappropriate, only that the conversant did not provide it.","We address each of these issues in our experimental process. We employ a leave-one-dyad-out cross-validation framework that allows us to determine overall accuracy while highlighting the different characteristics of the dyads. We employ and evaluate both an oversampling technique (Chawla et al., 2002) and class weighting to compensate for class imbalance. Finally, we tune our classification for the recognition of the feedback class."]},{"title":"4 Experimental Setting","paragraphs":["We define a Speaker pausal region as an interval in the Speaker’s channel annotated with a contiguous span of silence and/or non-speech sounds. These Speaker pausal regions are tagged as ’Feedback (FB)’ if the participant in the Listener role initiates verbal feedback during that interval and as ’No Feedback (NoFB)’ if the Listener does not. We aim to characterize and automatically classify each such 615","Arabic English Spanish 0.30 (0.21) 0.152 (0.10) 0.136 (0.12) Table 1: Mean and standard deviation of proportion of pausal regions associated with listener verbal feedback region. We group the dyads by language/cultural group to contrast the prosodic characteristics of the speech that elicit listener feedback and to assess the effectiveness of these prosodic cues for classification. The proportion of regions with listener feedback for each language appears in Table 1. 4.1 Feature Extraction For each Speaker pausal region, we extract features from the Speaker’s words immediately preceding and following the non-speech interval, as well as computing differences between some of these measures. We extract a set of 39 prosodic features motivated by (Shriberg et al., 2001), using Praat’s (Boersma, 2001) “To Pitch...” and “To Intensity...”. All durational measures and word positions are based on the semi-automatic alignment described above. All measures are log-scaled and zscore normalized per speaker. The full feature set appears in Table 2. 4.2 Classification and Analysis For classification, we employ Support Vector Machines (SVM), using the LibSVM implementation (C-C.Cheng and Lin, 2001) with an RBF kernel. For each language/cultural group, we perform ’leaveone-dyad-out’ cross-validation based on F-measure as implemented in that toolkit. For each fold, training on 14 dyads and testing on the last, we determine not only accuracy but also the weight-based ranking of each feature described above. Managing Class Imbalance Since listener verbal feedback occurs in only 14-30% of candidate positions, classification often predicts only the majority ’NoFB’ class. To compensate for this imbalance, we apply two strategies: reweighting and oversampling. We explore increasing the weight on the minority class in the classifier by a factor of two or four. We also apply SMOTE (Chawla et al., 2002) oversampling to double or quadruple the number of minority class training instances. SMOTE oversampling creates new synthetic minority class instances by identifying k = 3 nearest neighbors and inducing a new instance by taking the difference between a sample and its neighbor, multiplying by a factor between 0 and 1, and adding that value to the original instance."]},{"title":"5 Results","paragraphs":["Table 4 presents the classification accuracy for distinguishing FB and NoFB contexts. We present the overall class distribution for each language. We then contrast the minority FB class and overall accuracy under each of three weighting and oversampling set-tings. The second row has no weighting or oversampling; the third has no weighting with quadruple oversampling on all folds, a setting in which the largest number of Arabic dyads achieves their best performance. The last row indicates the oracle performance when the best weighting and oversampling setting is chosen for each fold.","We find that the use of reweighting and oversampling dramatically improves the recognition of the minority class, with only small reductions in overall accuracy of 3-7%. Under a uniform setting of quadruple oversampling and no reweighting, the number of correctly recognized Arabic and English FB samples nearly triples, while the number of Spanish FB samples doubles. We further see that if we can dynamically select the optimal training settings, we can achieve even greater improvements. Here the number of correctly recognized FB examples increases between 3- (Spanish) and 6-fold (Arabic) with only a reduction of 1-4% in overall accuracy. These accuracy levels correspond to recognizing between 38% (English, Spanish) and 73% (Arabic) of the FB instances. Even under these tuned conditions, the sparseness and variability of the English and Spanish data continue to present challenges.","Finally, Table 3 illustrates the impact of the full range of reweighting and oversampling conditions. Each cell indicates the number of folds in each of Arabic, English, and Spanish respectively, for which that training condition yields the highest accuracy. We can see that the different dyads achieve optimal results under a wide range of training conditions. 616","Feature Type Description Feature IDs","Pitch 5 uniform points across word pre 0,pre 0.25,pre 0.5,pre 0.75,pre 1","post 0,post 0.25,post 0.5,post 0.75,post 1 Maximum, minimum, mean pre pmax, pre pmin, pre pmean","post pmax, post pmin, post pmean Differences in max, min, mean diff pmax, diff pmin, diff pmean Difference b/t boundaries diff pitch endbeg Start and end slope pre bslope, pre eslope, post bslope, post eslope Difference b/t slopes diff slope endbeg","Intensity Maximum, minimum, mean pre imax, pre imin, pre imean","post imax,post imin, post imean Difference in maxima diff imax","Duration Last rhyme, last vowel, pause pre rdur, pre vdur, post rdur, post vdur, pause dur","Voice Quality Doubling & halving pre doub, pre half,post doub,post half Table 2: Prosodic features for classification and analysis. Features tagged ’pre’ are extracted from the word immediately preceding the Speaker pausal region; those tagged ’post’ are extracted from the word immediatey following.","weight 1 2 4 no SMOTE 1,2,3 2,2,2 1,0,3 SMOTE Double 1,0,2 1,2,0 2,2,1 SMOTE Quad 3,0,0 1,2,2 3,6,2 Table 3: Varying SVM weight and SMOTE ratio. Each cell shows # dyads in each language (Arabic, English, Spanish) with their best performance with this setting.","Arabic English Spanish Overall 478 (1405) 395 (2659) 173 (1226) Baseline 53 (950) 23 (2167) 23 (1066) S=2, W=1 145 (878) 67 (2120) 47 (1023) Oracle 347 (918) 152 (2033) 68 (1059) Table 4: Row 1: Class distribution: # FB instances (# total instances). Rows 2-4: Recognition under different settings: # FB correctly recognized (total # correct)"]},{"title":"6 Discussion: Feature Analysis","paragraphs":["To investigate the cross-language variation in speaker cues eliciting listener verbal feedback, we conduct a feature analysis. Table 5 presents the features with highest average weight for each language assigned by the classifier across folds, as well as those distinctive features highly ranked for only one language.","We find that the Arabic dyads make extensive and distinctive use of pitch in cuing verbal feedback, from both preceding and following words, while placing little weight on other feature types. In contrast, both English and Spanish dyads exploit both pitch and intensity features from surrounding words. Spanish alone makes significant use of both vocalic and pause duration. We also observe that, although there is substantial variation in feature ranking across speakers, the highly ranked features are robustly employed across almost all folds."]},{"title":"7 Conclusion","paragraphs":["Because of the size of our data set, it may be pre-mature to draw firm conclusion about differences between these three language groups based on this analysis. The SVM weighting and SMOTE oversampling strategy discussed here is promising for improving recognition on imbalanced class data. This strategy substantially improves the prediction 617","Most Important Features Arabic English Spanish pre pmax pre pmean pre min pre pmean post pmean post 0.5 pre 0.25 post 0.5 post 0.75 pre 0.5 post 0.75 post 1 pre 0.75 post 1 pre imax pre 1 diff pmin pre imean post pmin pre imax post imax post bslope pre imean pause dur diff pmin post imean pre vdur","Most Distinctive Features Arabic English Spanish post pmin post pmean post 0 post bslope post 0.25 post eslope pre 0.25 pre eslope pre 0.5 post vdur pre 1 pre imean Table 5: Highest ranked and distinctive features for each language/cultural group of verbal feedback. The resulting feature ranking also provides insight into the contrasts in the use of prosodic cues among these language cultural groups, while highlighting the widespread, robust use of pitch features.","In future research, we would like to extend our work to exploit sequential learning frameworks to predict verbal feedback. We also plan to explore the fusion of multi-modal features to enhance recognition and increase our understanding of multi-modal rapport behavior. We will also work to analyze how quickly people can establish rapport, as the short duration of our Spanish dyads poses substantial challenges."]},{"title":"8 Acknowledgments","paragraphs":["We would like to thank our team of annotator/analysts for their efforts in creating this corpus, and Danial Parvaz for the development of the Arabic transliteration tool. We are grateful for the insights of Susan Duncan, David McNeill, and Dan Loehr. This work was supported by NSF BCS#: 0729515. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation."]},{"title":"References","paragraphs":["R. Bertrand, G. Ferre, P. Blache, R. Espesser, and S. Rauzy. 2007. Backchannels revisited from a multimodal perspective. In Auditory-visual Speech Processing, The Netherlands. Hilvarenbeek.","P. Boersma. 2001. Praat, a system for doing phonetics by computer. Glot International, 5(9–10):341–345.","C-C.Cheng and C-J. Lin. 2001. LIBSVM:a library for support vector machines. Software available at: http://www.csie.ntu.edu.tw/ cjlin/libsvm.","N. Cathcart, J. Carletta, and E. Klein. 2003. A shallow model of backchannel continuers in spoken dialogue. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume 1, pages 51–58.","W. Chafe. 1975. The Pear Film.","Nitesh Chawla, Kevin Bowyer, Lawrence O. Hall, and W. Philip Legelmeyer. 2002. SMOTE: Synthetic minority over-sampling technique. Journal of Artificial Intelligence Research, 16:321–357.","S. Duncan. 1972. Some signals and rules for taking speaking turns in conversations. Journal of Personality and Social Psychology, 23(2):283–292.","A. Gravano and J. Hirschberg. 2009. Backchannelinviting cues in task-oriented dialogue. In Proceedings of Interspeech 2009, pages 1019–1022.","David Herrera, David Novick, Dusan Jan, and David Traum. 2010. The UTEP-ICT cross-cultural multiparty multimodal dialog corpus. In Proceedings of the Multimodal Corpora Workshop: Advances in Capturing, Coding and Analyzing Multimodality (MMC 2010).","A. Kendon. 2004. Gesture: Visible Action as Utterance. Cambridge University Press.","G.-A. Levow, S. Duncan, and E. King. 2010. Cross-cultural investigation of prosody in verbal feedback in interactional rapport. In Proceedings of Interspeech 2010.","D. Matsumoto, S. H. Yoo, S. Hirayama, and G. Petrova. 2005. Validation of an individual-level measure of display rules: The display rule assessment inventory (DRAI). Emotion, 5:23–40.","S. Maynard. 1990. Conversation management in contrast: listener response in Japanese and American English. Journal of Pragmatics, 14:397–412.","B. Pellom, W. Ward, J. Hansen, K. Hacioglu, J. Zhang, X. Yu, and S. Pradhan. 2001. University of Colorado dialog systems for travel and navigation. 618","A. Rivera and N. Ward. 2007. Three prosodic features that cue back-channel in Northern Mexican Spanish. Technical Report UTEP-CS-07-12, University of Texas, El Paso.","E. Shriberg, A. Stolcke, and D. Baron. 2001. Can prosody aid the automatic processing of multi-party meetings? evidence from predicting punctuation, disfluencies, and overlapping speech. In Proc. of ISCA Tutorial and Research Workshop on Prosody in Speech Recognition and Understanding.","Linda Tickle-Degnen and Robert Rosenthal. 1990. The nature of rapport and its nonverbal correlates. Psychological Inquiry, 1(4):285–293.","N. Ward and Y. Al Bayyari. 2007. A prosodic feature that invites back-channels in Egyptian Arabic. Perspectives in Arabic Linguistics XX.","N. Ward and W. Tsukuhara. 2000. Prosodic features which cue back-channel responses in English and Japanese. Journal of Pragmatics, 32(8):1177–1207.","O. M. Watson. 1970. Proxemic Behavior: A Cross-cultural Study. Mouton, The Hague. 619"]}],"references":[{"authors":[{"first":"R.","last":"Bertrand"},{"first":"G.","last":"Ferre"},{"first":"P.","last":"Blache"},{"first":"R.","last":"Espesser"},{"first":"S.","last":"Rauzy"}],"year":"2007","title":"Backchannels revisited from a multimodal perspective","source":"R. Bertrand, G. Ferre, P. Blache, R. Espesser, and S. Rauzy. 2007. Backchannels revisited from a multimodal perspective. In Auditory-visual Speech Processing, The Netherlands. Hilvarenbeek."},{"authors":[{"first":"P.","last":"Boersma"}],"year":"2001","title":"Praat, a system for doing phonetics by computer","source":"P. Boersma. 2001. Praat, a system for doing phonetics by computer. Glot International, 5(9–10):341–345."},{"authors":[{"last":"C-C.Cheng"},{"first":"C-J.","last":"Lin"}],"year":"2001","title":"LIBSVM:a library for support vector machines","source":"C-C.Cheng and C-J. Lin. 2001. LIBSVM:a library for support vector machines. Software available at: http://www.csie.ntu.edu.tw/ cjlin/libsvm."},{"authors":[{"first":"N.","last":"Cathcart"},{"first":"J.","last":"Carletta"},{"first":"E.","last":"Klein"}],"year":"2003","title":"A shallow model of backchannel continuers in spoken dialogue","source":"N. Cathcart, J. Carletta, and E. Klein. 2003. A shallow model of backchannel continuers in spoken dialogue. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume 1, pages 51–58."},{"authors":[{"first":"W.","last":"Chafe"}],"year":"1975","title":"The Pear Film","source":"W. Chafe. 1975. The Pear Film."},{"authors":[{"first":"Nitesh","last":"Chawla"},{"first":"Kevin","last":"Bowyer"},{"first":"Lawrence","middle":"O.","last":"Hall"},{"first":"W.","middle":"Philip","last":"Legelmeyer"}],"year":"2002","title":"SMOTE: Synthetic minority over-sampling technique","source":"Nitesh Chawla, Kevin Bowyer, Lawrence O. Hall, and W. Philip Legelmeyer. 2002. SMOTE: Synthetic minority over-sampling technique. Journal of Artificial Intelligence Research, 16:321–357."},{"authors":[{"first":"S.","last":"Duncan"}],"year":"1972","title":"Some signals and rules for taking speaking turns in conversations","source":"S. Duncan. 1972. Some signals and rules for taking speaking turns in conversations. Journal of Personality and Social Psychology, 23(2):283–292."},{"authors":[{"first":"A.","last":"Gravano"},{"first":"J.","last":"Hirschberg"}],"year":"2009","title":"Backchannelinviting cues in task-oriented dialogue","source":"A. Gravano and J. Hirschberg. 2009. Backchannelinviting cues in task-oriented dialogue. In Proceedings of Interspeech 2009, pages 1019–1022."},{"authors":[{"first":"David","last":"Herrera"},{"first":"David","last":"Novick"},{"first":"Dusan","last":"Jan"},{"first":"David","last":"Traum"}],"year":"2010","title":"The UTEP-ICT cross-cultural multiparty multimodal dialog corpus","source":"David Herrera, David Novick, Dusan Jan, and David Traum. 2010. The UTEP-ICT cross-cultural multiparty multimodal dialog corpus. In Proceedings of the Multimodal Corpora Workshop: Advances in Capturing, Coding and Analyzing Multimodality (MMC 2010)."},{"authors":[{"first":"A.","last":"Kendon"}],"year":"2004","title":"Gesture: Visible Action as Utterance","source":"A. Kendon. 2004. Gesture: Visible Action as Utterance. Cambridge University Press."},{"authors":[{"first":"G.","middle":"-A.","last":"Levow"},{"first":"S.","last":"Duncan"},{"first":"E.","last":"King"}],"year":"2010","title":"Cross-cultural investigation of prosody in verbal feedback in interactional rapport","source":"G.-A. Levow, S. Duncan, and E. King. 2010. Cross-cultural investigation of prosody in verbal feedback in interactional rapport. In Proceedings of Interspeech 2010."},{"authors":[{"first":"D.","last":"Matsumoto"},{"first":"S.","middle":"H.","last":"Yoo"},{"first":"S.","last":"Hirayama"},{"first":"G.","last":"Petrova"}],"year":"2005","title":"Validation of an individual-level measure of display rules: The display rule assessment inventory (DRAI)","source":"D. Matsumoto, S. H. Yoo, S. Hirayama, and G. Petrova. 2005. Validation of an individual-level measure of display rules: The display rule assessment inventory (DRAI). Emotion, 5:23–40."},{"authors":[{"first":"S.","last":"Maynard"}],"year":"1990","title":"Conversation management in contrast: listener response in Japanese and American English","source":"S. Maynard. 1990. Conversation management in contrast: listener response in Japanese and American English. Journal of Pragmatics, 14:397–412."},{"authors":[{"first":"B.","last":"Pellom"},{"first":"W.","last":"Ward"},{"first":"J.","last":"Hansen"},{"first":"K.","last":"Hacioglu"},{"first":"J.","last":"Zhang"},{"first":"X.","last":"Yu"},{"first":"S.","last":"Pradhan"}],"year":"2001","title":"University of Colorado dialog systems for travel and navigation","source":"B. Pellom, W. Ward, J. Hansen, K. Hacioglu, J. Zhang, X. Yu, and S. Pradhan. 2001. University of Colorado dialog systems for travel and navigation. 618"},{"authors":[{"first":"A.","last":"Rivera"},{"first":"N.","last":"Ward"}],"year":"2007","title":"Three prosodic features that cue back-channel in Northern Mexican Spanish","source":"A. Rivera and N. Ward. 2007. Three prosodic features that cue back-channel in Northern Mexican Spanish. Technical Report UTEP-CS-07-12, University of Texas, El Paso."},{"authors":[{"first":"E.","last":"Shriberg"},{"first":"A.","last":"Stolcke"},{"first":"D.","last":"Baron"}],"year":"2001","title":"Can prosody aid the automatic processing of multi-party meetings? evidence from predicting punctuation, disfluencies, and overlapping speech","source":"E. Shriberg, A. Stolcke, and D. Baron. 2001. Can prosody aid the automatic processing of multi-party meetings? evidence from predicting punctuation, disfluencies, and overlapping speech. In Proc. of ISCA Tutorial and Research Workshop on Prosody in Speech Recognition and Understanding."},{"authors":[{"first":"Linda","last":"Tickle-Degnen"},{"first":"Robert","last":"Rosenthal"}],"year":"1990","title":"The nature of rapport and its nonverbal correlates","source":"Linda Tickle-Degnen and Robert Rosenthal. 1990. The nature of rapport and its nonverbal correlates. Psychological Inquiry, 1(4):285–293."},{"authors":[{"first":"N.","last":"Ward"},{"first":"Y.","middle":"Al","last":"Bayyari"}],"year":"2007","title":"A prosodic feature that invites back-channels in Egyptian Arabic","source":"N. Ward and Y. Al Bayyari. 2007. A prosodic feature that invites back-channels in Egyptian Arabic. Perspectives in Arabic Linguistics XX."},{"authors":[{"first":"N.","last":"Ward"},{"first":"W.","last":"Tsukuhara"}],"year":"2000","title":"Prosodic features which cue back-channel responses in English and Japanese","source":"N. Ward and W. Tsukuhara. 2000. Prosodic features which cue back-channel responses in English and Japanese. Journal of Pragmatics, 32(8):1177–1207."},{"authors":[{"first":"O.","middle":"M.","last":"Watson"}],"year":"1970","title":"Proxemic Behavior: A Cross-cultural Study","source":"O. M. Watson. 1970. Proxemic Behavior: A Cross-cultural Study. Mouton, The Hague. 619"}],"cites":[{"style":0,"text":"Maynard, 1990","origin":{"pointer":"/sections/2/paragraphs/0","offset":328,"length":13},"authors":[{"last":"Maynard"}],"year":"1990","references":["/references/12"]},{"style":0,"text":"Matsumoto et al., 2005","origin":{"pointer":"/sections/2/paragraphs/0","offset":363,"length":22},"authors":[{"last":"Matsumoto"},{"last":"al."}],"year":"2005","references":["/references/11"]},{"style":0,"text":"Watson, 1970","origin":{"pointer":"/sections/2/paragraphs/0","offset":394,"length":12},"authors":[{"last":"Watson"}],"year":"1970","references":["/references/19"]},{"style":0,"text":"Ward and Tsukuhara, 2000","origin":{"pointer":"/sections/2/paragraphs/0","offset":437,"length":24},"authors":[{"last":"Ward"},{"last":"Tsukuhara"}],"year":"2000","references":["/references/18"]},{"style":0,"text":"Bayyari, 2007","origin":{"pointer":"/sections/2/paragraphs/0","offset":475,"length":13},"authors":[{"last":"Bayyari"}],"year":"2007","references":[]},{"style":0,"text":"Rivera and Ward, 2007","origin":{"pointer":"/sections/2/paragraphs/0","offset":490,"length":21},"authors":[{"last":"Rivera"},{"last":"Ward"}],"year":"2007","references":["/references/14"]},{"style":0,"text":"Bertrand et al., 2007","origin":{"pointer":"/sections/2/paragraphs/0","offset":538,"length":21},"authors":[{"last":"Bertrand"},{"last":"al."}],"year":"2007","references":["/references/0"]},{"style":0,"text":"Kendon, 2004","origin":{"pointer":"/sections/2/paragraphs/0","offset":587,"length":12},"authors":[{"last":"Kendon"}],"year":"2004","references":["/references/9"]},{"style":0,"text":"Tickle-Degnen and Rosenthal, 1990","origin":{"pointer":"/sections/2/paragraphs/1","offset":261,"length":33},"authors":[{"last":"Tickle-Degnen"},{"last":"Rosenthal"}],"year":"1990","references":["/references/16"]},{"style":0,"text":"Duncan, 1972","origin":{"pointer":"/sections/2/paragraphs/1","offset":574,"length":12},"authors":[{"last":"Duncan"}],"year":"1972","references":["/references/6"]},{"style":0,"text":"Shriberg et al., 2001","origin":{"pointer":"/sections/2/paragraphs/1","offset":793,"length":21},"authors":[{"last":"Shriberg"},{"last":"al."}],"year":"2001","references":["/references/15"]},{"style":0,"text":"Cathcart et al., 2003","origin":{"pointer":"/sections/2/paragraphs/1","offset":917,"length":21},"authors":[{"last":"Cathcart"},{"last":"al."}],"year":"2003","references":["/references/3"]},{"style":0,"text":"Gravano and Hirschberg, 2009","origin":{"pointer":"/sections/2/paragraphs/1","offset":1050,"length":28},"authors":[{"last":"Gravano"},{"last":"Hirschberg"}],"year":"2009","references":["/references/7"]},{"style":0,"text":"Ward and Tsukuhara, 2000","origin":{"pointer":"/sections/2/paragraphs/1","offset":1274,"length":24},"authors":[{"last":"Ward"},{"last":"Tsukuhara"}],"year":"2000","references":["/references/18"]},{"style":0,"text":"Bayyari, 2007","origin":{"pointer":"/sections/2/paragraphs/1","offset":1312,"length":13},"authors":[{"last":"Bayyari"}],"year":"2007","references":[]},{"style":0,"text":"Rivera and Ward, 2007","origin":{"pointer":"/sections/2/paragraphs/1","offset":1327,"length":21},"authors":[{"last":"Rivera"},{"last":"Ward"}],"year":"2007","references":["/references/14"]},{"style":0,"text":"Herrera et al., 2010","origin":{"pointer":"/sections/2/paragraphs/1","offset":1516,"length":20},"authors":[{"last":"Herrera"},{"last":"al."}],"year":"2010","references":["/references/8"]},{"style":0,"text":"Levow et al., 2010","origin":{"pointer":"/sections/2/paragraphs/1","offset":1726,"length":18},"authors":[{"last":"Levow"},{"last":"al."}],"year":"2010","references":["/references/10"]},{"style":0,"text":"Chafe, 1975","origin":{"pointer":"/sections/3/paragraphs/0","offset":331,"length":11},"authors":[{"last":"Chafe"}],"year":"1975","references":["/references/4"]},{"style":0,"text":"Pellom et al., 2001","origin":{"pointer":"/sections/3/paragraphs/1","offset":227,"length":19},"authors":[{"last":"Pellom"},{"last":"al."}],"year":"2001","references":["/references/13"]},{"style":0,"text":"Levow et al., 2010","origin":{"pointer":"/sections/3/paragraphs/2","offset":182,"length":18},"authors":[{"last":"Levow"},{"last":"al."}],"year":"2010","references":["/references/10"]},{"style":0,"text":"Chawla et al., 2002","origin":{"pointer":"/sections/4/paragraphs/1","offset":282,"length":19},"authors":[{"last":"Chawla"},{"last":"al."}],"year":"2002","references":["/references/5"]},{"style":0,"text":"Shriberg et al., 2001","origin":{"pointer":"/sections/5/paragraphs/1","offset":753,"length":21},"authors":[{"last":"Shriberg"},{"last":"al."}],"year":"2001","references":["/references/15"]},{"style":0,"text":"Boersma, 2001","origin":{"pointer":"/sections/5/paragraphs/1","offset":792,"length":13},"authors":[{"last":"Boersma"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"C-C.Cheng and Lin, 2001","origin":{"pointer":"/sections/5/paragraphs/1","offset":1176,"length":23},"authors":[{"last":"C-C.Cheng"},{"last":"Lin"}],"year":"2001","references":["/references/2"]},{"style":0,"text":"Chawla et al., 2002","origin":{"pointer":"/sections/5/paragraphs/1","offset":1888,"length":19},"authors":[{"last":"Chawla"},{"last":"al."}],"year":"2002","references":["/references/5"]}]}
