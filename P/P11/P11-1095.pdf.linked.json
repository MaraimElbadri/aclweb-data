{"sections":[{"title":"","paragraphs":["Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 945–954, Portland, Oregon, June 19-24, 2011. c⃝2011 Association for Computational Linguistics"]},{"title":"A Generative Entity-Mention Model for Linking Entities with Knowledge Base Xianpei Han Le Sun Institute of Software, Chinese Academy of Sciences HaiDian District, Beijing, China. {xianpei, sunle}@nfs.iscas.ac.cn  Abstract","paragraphs":["Linking entities with knowledge base (entity linking) is a key issue in bridging the textual data with the structural knowledge base. Due to the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the heterogenous knowledge of entities. In this paper, we propose a generative probabilistic model, called entity-mention model, which can leverage heterogenous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task. In our model, each name mention to be linked is modeled as a sample generated through a three-step generative story, and the entity knowledge is encoded in the distribution of entities in document P(e), the distribution of possible names of a specific entity P(s|e), and the distribution of possible contexts of a specific entity P(c|e). To find the referent entity of a name mention, our method combines the evidences from all the three distributions P(e), P(s|e) and P(c|e). Experimental results show that our method can significantly outperform the traditional methods."]},{"title":"1 Introduction","paragraphs":["In recent years, due to the proliferation of knowledge-sharing communities like Wikipedia","1"," and the many research efforts for the automated knowledge base population from Web like the Read the Web","2","project, more and more large-scale knowledge bases are available. These knowledge bases contain rich knowledge about the world’s entities, their semantic properties, and the semantic relations between each other. One of the most notorious examples is Wikipedia: its 2010 English  1 http://www.wikipedia.org/ 2 http://rtw.ml.cmu.edu/ version contains more than 3 million entities and 20 million semantic relations. Bridging these knowledge bases with the textual data can facilitate many different tasks such as entity search, information extraction and text classification. For example, as shown in Figure 1, knowing the word Jordan in the document refers to a basketball player and the word Bulls refers to a NBA team would be helpful in classifying this document into the Sport/Basketball class.","Aftera standoutcareerattheUniversity,","joinedthe in 1984.","M","i","c","h","a e l  J e f f r e y  J","o","r","d","a","n","N B A  Pl a y e","r","B","a","s k e t b a l l  Pl a","y","e","r","C","h i c a g o  B u l","l","s N B A","Spo","r","t  O r g a n i z a t","i","o","n","N B A  T e a m Knowledge Base","Em p l o y e r - of IS - A","IS","-","A","IS","-","A IS - A IS - A P a r t - of Jordan Bulls  Figure 1. A Demo of Entity Linking","A key issue in bridging the knowledge base with the textual data is linking the entities in a document with their referents in a knowledge base, which is usually referred to as the Entity Linking task. Given a set of name mentions M = {m1, m2, ..., mk} contained in documents and a knowledge base KB containing a set of entities E = {e1, e2, ..., en}, an entity linking system is a function : ME  which links these name mentions to their referent entities in KB. For example, in Figure 1 an entity linking system should link the name mention Jordan to the entity Michael Jeffrey Jordan and the name mention Bulls to the entity Chicago Bulls.","The entity linking task, however, is not trivial due to the name variation problem and the name ambiguity problem. Name variation means that an entity can be mentioned in different ways such as full name, aliases, acronyms and misspellings. For 945 example, the entity Michael Jeffrey Jordan can be mentioned using more than 10 names, such as Michael Jordan, MJ and Jordan. The name ambiguity problem is related to the fact that a name may refer to different entities in different contexts. For example, the name Bulls can refer to more than 20 entities in Wikipedia, such as the NBA team Chicago Bulls, the football team Belfast Bulls and the cricket team Queensland Bulls.","Complicated by the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the knowledge of entities (Li et al., 2004; Bunescu & Pasca, 2006; Cucerzan, 2007; Milne & Witten, 2008 and Fader et al., 2009). Based on the previous work, we found that the following three types of entity knowledge can provide critical evidence for the entity linking decisions:"," Popularity Knowledge. The popularity knowledge of entities tells us the likelihood of an entity appearing in a document. In entity linking, the entity popularity knowledge can provide a priori information to the possible referent entities of a name mention. For example, without any other information, the popularity knowledge can tell that in a Web page the name “Michael Jordan” will more likely refer to the notorious basketball player Michael Jeffrey Jordan, rather than the less popular Berkeley professor Michael I. Jordan."," Name Knowledge. The name knowledge tells us the possible names of an entity and the likelihood of a name referring to a specific entity. For example, we would expect the name knowledge tells that both the “MJ” and “Michael Jordan” are possible names of the basketball player Michael Jeffrey Jordan, but the “Michael Jordan” has a larger likelihood. The name knowledge plays the central role in resolving the name variation problem, and is also helpful in resolving the name ambiguity problem."," Context Knowledge. The context knowledge tells us the likelihood of an entity appearing in a specific context. For example, given the context “__wins NBA MVP”, the name “Michael Jordan” should more likely refer to the basketball player Michael Jeffrey Jordan than the Berkeley professor Michael I. Jordan. Context knowledge is crucial in solving the name ambiguities.","Unfortunately, in entity linking system, the modeling and exploitation of these types of entity knowledge is not straightforward. As shown above, these types of knowledge are heterogenous, making it difficult to be incorporated in the same model. Furthermore, in most cases the knowledge of entities is not explicitly given, making it challenging to extract the entity knowledge from data.","To resolve the above problems, this paper proposes a generative probabilistic model, called entity-mention model, which can leverage the heterogeneous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task. In our model, each name mention is modeled as a sample generated through a three-step generative story, where the entity knowledge is encoded in three distributions: the entity popularity knowledge is encoded in the distribution of entities in document P(e), the entity name knowledge is encoded in the distribution of possible names of a specific entity P(s|e), and the entity context knowledge is encoded in the distribution of possible contexts of a specific entity P(c|e). The P(e), P(s|e) and P(c|e) are respectively called the entity popularity model, the entity name model and the entity context model. To find the referent entity of a name mention, our method combines the evidences from all the three distributions P(e), P(s|e) and P(c|e). We evaluate our method on both Wikipedia articles and general newswire documents. Experimental results show that our method can significantly improve the entity linking accuracy. Our Contributions. Specifically, the main contributions of this paper are as follows:","1) We propose a new generative model, the entity-mention model, which can leverage heterogenous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task;","2) By modeling the entity knowledge as probabilistic distributions, our model has a statistical foundation, making it different from most previous ad hoc approaches.","This paper is organized as follows. The entity-mention model is described in Section 2. The model estimation is described in Section 3. The experimental results are presented and discussed in Section 4. The related work is reviewed in Section 5. Finally we conclude this paper in Section 6. 946"]},{"title":"2 The Generative Entity-Mention Model for Entity Linking","paragraphs":["In this section we describe the generative entity-mention model. We first describe the generative story of our model, then formulate the model and show how to apply it to the entity linking task."]},{"title":"2.1 The Generative Story","paragraphs":["In the entity mention model, each name mention is modeled as a generated sample. For demonstration, Figure 2 shows two examples of name mention generation. As shown in Figure 2, the generative story of a name mention is composed of three steps, which are detailed as follows:","(i) Firstly, the model chooses the referent entity e of the name mention from the given knowledge base, according to the distribution of entities in document P(e). In Figure 2, the model chooses the entity “Michael Jeffrey Jordan” for the first name mention, and the entity “Michael I. Jordan” for the second name mention;","(ii) Secondly, the model outputs the name s of the name mention according to the distribution of possible names of the referent entity P(s|e). In Figure 2, the model outputs “Jordan” as the name of the entity “Michael Jeffrey Jordan”, and the “Michael Jordan” as the name of the entity “Michael I. Jordan”;","(iii) Finally, the model outputs the context c of the name mention according to the distribution of possible contexts of the referent entity P(c|e). In Figure 2, the model outputs the context “joins Bulls in 1984” for the first name mention, and the context “is a professor in UC Berkeley” for the second name mention."]},{"title":"2.2 Model","paragraphs":["Based on the above generative story, the probability of a name mention m (its context is c and its name is s) referring to a specific entity e can be expressed as the following formula (here we assume that s and c are independent given e): ( , , )P(m,e)= P s c e = P(e)P(s | e)P(c | e) This model incorporates the three types of entity knowledge we explained earlier: P(e) corresponds to the popularity knowledge, P(s|e) corresponds to the name knowledge and P(c|e) corresponds to the context knowledge. Knowledge Base Michael Jeffrey Jordan Michael I. Jordan Jordan Michael Jordan","Jordan joins Bulls in 1984. Michael Jordan is a professor in UC Berkeley. Entity Name Mention","","Figure 2. Two examples of name mention generation Given a name mention m, to perform entity linking, we need to find the entity e which maximizes the probability P(e|m). Then we can resolve the entity linking task as follows:","( , ) e arg max arg max ( ) ( | ) ( | )","() ee P m e P e P s e P c e Pm Therefore, the main problem of entity linking is to estimate the three distributions P(e), P(s|e) and P(c|e), i.e., to extract the entity knowledge from data. In Section 3, we will show how to estimate these three distributions. Candidate Selection. Because a knowledge base usually contains millions of entities, it is timeconsuming to compute all P(m,e) scores between a name mention and all the entities contained in a knowledge base. To reduce the time required, the entity linking system employs a candidate selection process to filter out the impossible referent candidates of a name mention. In this paper, we adopt the candidate selection method of NLPR_KBP system (Han and Zhao, 2009), the main idea of which is first building a name-to-entity dictionary using the redirect links, disambiguation pages, anchor texts of Wikipedia, then the candidate entities of a name mention are selected by finding its name’s corresponding entry in the dictionary."]},{"title":"3 Model Estimation","paragraphs":["Section 2 shows that the entity mention model can decompose the entity linking task into the estimation of three distributions P(e), P(s|e) and P(c|e). In this section, we describe the details of the estimation of these three distributions. We first 947 introduce the training data, then describe the estimation methods."]},{"title":"3.1 Training Data","paragraphs":["In this paper, the training data of our model is a set of annotated name mentions M = {m1, m2, ..., mn}. Each annotated name mention is a triple m={s, e, c}, where s is the name, e is the referent entity and c is the context. For example, two annotated name mentions are as follows:  Jordan | Michael Jeffrey Jordan | ... wins his first NBA","MVP in 1991.  NBA | National Basketball Association | ... is the pre-","eminent men's professional basketball league.","In this paper, we focus on the task of linking entities with Wikipedia, even though the proposed method can be applied to other resources. We will only show how to get the training data from Wikipedia. In Wikipedia, a hyperlink between two articles is an annotated name mention (Milne & Witten, 2008): its anchor text is the name and its target article is the referent entity. For example, in following hyperlink (in Wiki syntax), the NBA is the name and the National Basketball Association is the referent entity. “He won his first [[National Basketball Association |","NBA]] championship with the Bulls” Therefore, we can get the training data by collecting all annotated name mentions from the hyperlink data of Wikipedia. In total, we collected more than 23,000,000 annotated name mentions."]},{"title":"3.2 Entity Popularity Model","paragraphs":["The distribution P(e) encodes the popularity knowledge as a distribution of entities, i.e., the P(e1) should be larger than P(e2) if e1 is more popular than e2. For example, on the Web the P(Michael Jeffrey Jordan) should be higher than the P(Michael I. Jordan). In this section, we estimate the distribution P(e) using a model called entity popularity model.","Given a knowledge base KB which contains N entities, in its simplest form, we can assume that all entities have equal popularity, and the distribution P(e) can be estimated as:","( ) 1P e N However, this does not reflect well the real situation because some entities are obviously more popular than others. To get a more precise estimation, we observed that a more popular entity usually appears more times than a less popular entity in a large text corpus, i.e., more name mentions refer to this entity. For example, in Wikipedia the NBA player Michael Jeffrey Jordan appears more than 10 times than the Berkeley professor Michael I. Jordan. Based on the above observation, our entity popularity model uses the entity frequencies in the name mention data set M to estimate the distribution P(e) as follows:","( ) 1 () Count e Pe MN   ","where Count(e) is the count of the name mentions","whose referent entity is e, and the |M| is the total","name mention size. The estimation is further","smoothed using the simple add-one smoothing","method for the zero probability problem. For","illustration, Table 1 shows three selected entities’","popularity. Entity Popularity National Basketball Association 1.73*10-5"," Michael Jeffrey Jordan(NBA player) 8.21*10-6"," Michael I. Jordan(Berkeley Professor) 7.50*10-8"," Table 1. Three examples of entity popularity"]},{"title":"3.3 Entity Name Model","paragraphs":["The distribution P(s|e) encodes the name knowledge of entities, i.e., for a specific entity e, its more frequently used name should be assigned a higher P(s|e) value than the less frequently used name, and a zero P(s|e) value should be assigned to those never used names. For instance, we would expect the P(Michael Jordan|Michael Jeffrey Jordan) to be high, P(MJ|Michael Jeffrey Jordan) to be relative high and P(Michael I. Jordan|Michael Jeffrey Jordan) to be zero.","Intuitively, the name model can be estimated by first collecting all (entity, name) pairs from the name mention data set, then using the maximum likelihood estimation: ( , ) ( | ) ( , ) s Count e s P s e Count e s "]},{"title":" ","paragraphs":["where the Count(e,s) is the count of the name mentions whose referent entity is e and name is s. However, this method does not work well because it cannot correctly deal with an unseen entity or an unseen name. For example, because the name “MJ” doesn’t refer to the Michael Jeffrey Jordan in Wikipedia, the name model will not be able to identify “MJ” as a name of him, even “MJ” is a popular name of Michael Jeffrey Jordan on Web. 948","To better estimate the distribution P(s|e), this paper proposes a much more generic model, called entity name model, which can capture the variations (including full name, aliases, acronyms and misspellings) of an entity's name using a statistical translation model. Given an entity’s name s, our model assumes that it is a translation of this entity’s full name f using the IBM model 1 (Brown, et al., 1993). Let ∑ be the vocabulary containing all words may be used in the name of entities, the entity name model assumes that a word in ∑ can be translated through the following four ways: 1) It is retained (translated into itself); 2) It is translated into its acronym; 3) It is omitted(translated into the word NULL); 4) It is translated into another word (misspelling","or alias). In this way, all name variations of an entity are captured as the possible translations of its full name. To illustrate, Figure 3 shows how the full name “Michael Jeffrey Jordan” can be transalted into its misspelling name “Micheal Jordan”.","","Figure 3. The translation from Michael Jefferey Jordan to Micheal Jordan Based on the translation model, P(s|e) can be written as: 01 ( | ) ( 1)","f s s ll","ijl ijfP(s | e) t s f","l    "]},{"title":"","paragraphs":["where  is a normalization factor, f is the full name of entity e, lf is the length of f, ls is the length of the name s, si the i th word of s, fj is the j th","word of f and t(si|fj) is the lexical translation probability which indicates the probability of a word fj in the full name will be written as si in the output name.","Now the main problem is to estimate the lexical translation probability t(si|fj). In this paper, we first collect the (name, entity full name) pairs from all annotated name mentions, then get the lexical translation probability by feeding this data set into an IBM model 1 training system (we use the GIZA++ Toolkit","3",").","Table 2 shows several resulting lexical translation probabilities through the above process.  3 http://fjoch.com/GIZA++.html","We can see that the entity name model can capture","the different name variations, such as the acronym","(MichaelM), the misspelling (MichaelMicheal)","and the omission (St.  NULL).","Full name word Name word Probability Michael Michael 0.77 Michael M 0.008 Michael Micheal 2.64*10-4"," Jordan Jordan 0.96 Jordan J 6.13*10-4","","St. NULL 0.14 Sir NULL 0.02","Table 2. Several lexical translation probabilities"]},{"title":"3.4 Entity Context Model","paragraphs":["The distribution P(c|e) encodes the context knowledge of entities, i.e., it will assign a high P(c|e) value if the entity e frequently appears in the context c, and will assign a low P(c|e) value if the entity e rarely appears in the context c. For example, given the following two contexts:","C1: __wins NBA MVP.","C2: __is a researcher in machine learning. Then P(C1|Michael Jeffrey Jordan) should be high because the NBA player Michael Jeffrey Jordan often appears in C1 and the P(C2|Michael Jeffrey Jordan) should be extremely low because he rarely appears in C2.","__ wins NBA MVP. __is a professor in UC","Berkeley.","Michael Jeffrey Jordan (NBA Player) NBA=0.03 MVP=0.008 Basketball=0.02 player=0.005 win=0.00008 professor=0 ... Michael I. Jordan (Berkeley Professor) professor=0.003 Berkeley=0.002 machine learning=0.1 researcher = 0.006 NBA = 0 MVP=0 ..."," Figure 4. Two entity context models","To estimate the distribution P(c|e), we propose a method based on language modeling, called entity context model. In our model, the context of each name mention m is the word window surrounding m, and the window size is set to 50 according to the experiments in (Pedersen et al., 2005). Specifically, the context knowledge of an entity e is encoded in an unigram language model:","{ ( )}eeM P t where Pe(t) is the probability of the term t appearing in the context of e. In our model, the term may indicate a word, a named entity (extracted using the Stanford Named Entity Michael Jeffrey Jordan Micheal Jordan NULL Full Name Name 949 Recognizer 4",") or a Wikipedia concept (extracted using the method described in (Han and Zhao, 2010)). Figure 4 shows two entity context models and the contexts generated using them.","Now, given a context c containing n terms t1t2...tn, the entity context model estimates the probability P(c|e) as:","1 2 1 2( | ) ( ... | ) ( ) ( ).... ( )n e e e e nP c e P t t t M P t P t P t So the main problem is to estimate Pe(t), the probability of a term t appearing in the context of the entity e.","Using the annotated name mention data set M, we can get the maximum likelihood estimation of Pe(t) as follows: _ () () () e e ML e t Count t Pt Count t "]},{"title":" ","paragraphs":["where Counte(t) is the frequency of occurrences of a term t in the contexts of the name mentions whose referent entity is e. Because an entity e’s name mentions are usually not enough to support a robust estimation of Pe(t) due to the sparse data problem (Chen and Goodman, 1999), we further smooth Pe(t) using the Jelinek-Mercer smoothing method (Jelinek and Mercer, 1980):","_( ) ( ) (1 ) ( )e e ML gP t P t P t   where Pg(t) is a general language model which is estimated using the whole Wikipedia data, and the optimal value of λ is set to 0.2 through a learning process shown in Section 4."]},{"title":"3.5 The NIL Entity Problem","paragraphs":["By estimating P(e), P(s|e) and P(c|e), our method can effectively link a name mention to its referent entity contained in a knowledge base. Unfortunately, there is still the NIL entity problem (McNamee and Dang, 2009), i.e., the referent entity may not be contained in the given knowledge base. In this situation, the name mention should be linked to the NIL entity. Traditional methods usually resolve this problem with an additional classification step (Zheng et al. 2010): a classifier is trained to identify whether a name mention should be linked to the NIL entity.","Rather than employing an additional step, our entity mention model seamlessly takes into account the NIL entity problem. The start assumption of  4 http://nlp.stanford.edu/software/CRF-NER.shtml our solution is that “If a name mention refers to a specific entity, then the probability of this name mention is generated by the specific entity’s model should be significantly higher than the probability it is generated by a general language model”. Based on the above assumption, we first add a pseudo entity, the NIL entity, into the knowledge base and assume that the NIL entity generates a name mention according to the general language model Pg, without using any entity knowledge; then we treat the NIL entity in the same way as other entities: if the probability of a name mention is generated by the NIL entity is higher than all other entities in Knowledge base, we link the name mention to the NIL entity. Based on the above discussion, we compute the three probabilities of the NIL entity: P(e), P(s|e) and P(c|e) as follows: 1 P(NIL) MN    ()g tsP(s | NIL) P t "]},{"title":"","paragraphs":["()g tcP(c | NIL) P t "]},{"title":" 4 Experiments","paragraphs":["In this section, we assess the performance of our method and compare it with the traditional methods. In following, we first explain the experimental settings in Section 4.1, 4.2 and 4.3, then evaluate and discuss the results in Section 4.4."]},{"title":"4.1 Knowledge Base","paragraphs":["In our experiments, we use the Jan. 30, 2010 English version of Wikipedia as the knowledge base, which contains over 3 million distinct entities."]},{"title":"4.2 Data Sets","paragraphs":["To evaluate the entity linking performance, we adopted two data sets: the first is WikiAmbi, which is used to evaluate the performance on Wikipedia articles; the second is TAC_KBP, which is used to evaluate the performance on general newswire documents. In following, we describe these two data sets in detail.","WikiAmbi: The WikiAmbi data set contains 1000 annotated name mentions which are randomly selected from Wikipedia hyperlinks data set (as shown in Section 3.1, the hyperlinks between Wikipedia articles are manually annotated name mentions). In WikiAmbi, there were 207 distinct 950 names and each name contains at least two possible referent entities (on average 6.7 candidate referent entities for each name) 5",". In our experiments, the name mentions contained in the WikiAmbi are removed from the training data.","TAC_KBP: The TAC_KBP is the standard data set used in the Entity Linking task of the TAC 2009 (McNamee and Dang, 2009). The TAC_KBP contains 3904 name mentions which are selected from English newswire articles. For each name mention, its referent entity in Wikipedia is manually annotated. Overall, 57% (2229 of 3904) name mentions’s referent entities are missing in Wikipedia, so TAC_KBP is also suitable to evaluate the NIL entity detection performance.","The above two data sets can provide a standard testbed for the entity linking task. However, there were still some limitations of these data sets: First, these data sets only annotate the salient name mentions in a document, meanwhile many NLP applications need all name mentions are linked. Second, these data sets only contain well-formed documents, but in many real-world applications the entity linking often be applied to noisy documents such as product reviews and microblog messages. In future, we want to develop a data set which can reflect these real-world settings."]},{"title":"4.3 Evaluation Criteria","paragraphs":["We adopted the standard performance metrics used in the Entity Linking task of the TAC 2009 (McNamee and Dang, 2009). These metrics are:"," Micro-Averaged Accuracy (Micro-Accuracy): measures entity linking accuracy averaged over all the name mentions;"," Macro-Averaged Accuracy (Macro-Accuracy): measures entity linking accuracy averaged over all the target entities. As in TAC 2009, we used Micro-Accuracy as the primary performance metric."]},{"title":"4.4 Experimental Results","paragraphs":["We compared our method with three baselines: (1) The first is the traditional Bag of Words based method (Cucerzan, 2007): a name mention’s referent entity is the entity which has the highest cosine similarity with its context – we denoted it as BoW; (2) The second is the method described in  5 This is because we want to create a highly ambiguous test data set (Medelyan et al., 2008), where a name mention’s referent entity is the entity which has the largest average semantic relatedness with the name mention’s unambiguous context entities – we denoted it as TopicIndex. (3) The third one is the same as the method described in (Milne & Witten, 2008), which uses learning techniques to balance the semantic relatedness, commoness and context quality – we denoted it as Learning2Link. 4.4.1 Overall Performance We conduct experiments on both WikiAmbi and TAC_KBP datasets with several methods: the baseline BoW; the baseline TopicIndex; the baseline Learning2Link; the proposed method using only popularity knowledge (Popu), i.e., the P(m,e)=P(e); the proposed method with one component of the model is ablated(this is used to evaluate the independent contributions of the three components), correspondingly Popu+Name(i.e., the P(m,e)=P(e)P(s|e)), Name+Context(i.e., the P(m,e)=P(c|e)P(s|e)) and Popu+Context (i.e., the P(m,e)=P(e)P(c|e)); and the full entity mention model (Full Model). For all methods, the parameters were configured through 10-fold cross validation. The overall performance results are shown in Table 3 and 4. Micro-Accuracy Macro-Accuracy BoW 0.60 0.61 TopicIndex 0.66 0.49 Learning2Link 0.70 0.54 Popu 0.39 0.24 Popu + Name 0.50 0.31 Name+Context 0.70 0.68 Popu+Context 0.72 0.73 Full Model 0.80 0.77 Table 3. The overall results on WikiAmbi dataset Micro-Accuracy Macro-Accuracy BoW 0.72 0.75 TopicIndex 0.80 0.76 Learning2Link 0.83 0.79 Popu 0.60 0.53 Popu + Name 0.63 0.59 Name+Context 0.81 0.78 Popu+Context 0.84 0.83 Full Model 0.86 0.88 Table 4. The overall results on TAC-KBP dataset From the results in Table 3 and 4, we can make the following observations:","1) Compared with the traditional methods, our entity mention model can achieve a significant 951 performance improvement: In WikiAmbi and TAC_KBP datasets, compared with the BoW baseline, our method respectively gets 20% and 14% micro-accuracy improvement; compared with the TopicIndex baseline, our method respectively gets 14% and 6% micro-accuracy improvement; compared with the Learning2Link baseline, our method respectively gets 10% and 3% micro-accuracy improvement.","2) By incorporating more entity knowledge, our method can significantly improve the entity linking performance: When only using the popularity knowledge, our method can only achieve 49.5% micro-accuracy. By adding the name knowledge, our method can achieve 56.5% micro-accuracy, a 7% improvement over the Popu. By further adding the context knowledge, our method can achieve 83% micro-accuracy, a 33.5% improvement over Popu and a 26.5% improvement over Popu+Name.","3) All three types of entity knowledge contribute to the final performance improvement, and the context knowledge contributes the most: By respectively ablating the popularity knowledge, the name knowledge and the context knowledge, the performance of our model correspondingly reduces 7.5%, 5% and 26.5%.","NIL Entity Detection Performance. To compare the performances of resolving the NIL entity problem, Table 5 shows the microaccuracies of different systems on the TAC_KBP data set (where All is the whole data set, NIL only contains the name mentions whose referent entity is NIL, InKB only contains the name mentions whose referent entity is contained in the knowledge base). From Table 5 we can see that our method can effectively detect the NIL entity meanwhile retaining the high InKB accuracy. All NIL InKB BoW 0.72 0.77 0.65 TopicIndex 0.80 0.91 0.65 Learning2Link 0.83 0.90 0.73 Full Model 0.86 0.90 0.79","Table 5. The NIL entity detection performance on the TAC_KBP data set 4.4.2 Optimizing Parameters Our model needs to tune one parameter: the Jelinek-Mercer smoothing parameter λ used in the entity context model. Intuitively, a smaller λ means that the general language model plays a more important role. Figure 5 plots the tradeoff. In both WikiAmbi and TAC_KBP data sets, Figure 5 shows that a λ value 0.2 will result in the best performance.  Figure 5. The micro-accuracy vs. λ 4.4.3 Detailed Analysis To better understand the reasons why and how the proposed method works well, in this Section we analyze our method in detail. The Effect of Incorporating Heterogenous Entity Knowledge. The first advantage of our method is the entity mention model can incorporate heterogeneous entity knowledge. The Table 3 and 4 have shown that, by incorporating heterogenous entity knowledge (including the name knowledge, the popularity knowledge and the context knowledge), the entity linking performance can obtain a significant improvement.","","Figure 6. The performance vs. training mention size on WikiAmbi data set The Effect of Better Entity Knowledge Extraction. The second advantage of our method is that, by representing the entity knowledge as probabilistic distributions, our model has a statistical foundation and can better extract the entity knowledge using more training data through the entity popularity model, the entity name model and the entity context model. For instance, we can train a better entity context model P(c|e) using more name mentions. To find whether a better 952 entity knowledge extraction will result in a better performance, Figure 6 plots the micro-accuray along with the size of the training data on name mentions for P(c|e) of each entity e. From Figure 6, we can see that when more training data is used, the performance increases.","4.4.4 Comparision with State-of-the-Art Performance We also compared our method with the state-of-the-art entity linking systems in the TAC 2009 KBP track (McNamee and Dang, 2009). Figure 7 plots the comparison with the top five performances in TAC 2009 KBP track. From Figure 7, we can see that our method can outperform the state-of-the-art approaches: compared with the best ranking system, our method can achieve a 4% performance improvement.","","Figure 7. A comparison with top 5 TAC 2009 KBP systems"]},{"title":"5 Related Work","paragraphs":["In this section, we briefly review the related work. To the date, most entity linking systems employed the context similarity based methods. The essential idea was to extract the discriminative features of an entity from its description, then link a name mention to the entity which has the largest context similarity with it. Cucerzan (2007) proposed a Bag of Words based method, which represents each target entity as a vector of terms, then the similarity between a name mention and an entity was computed using the cosine similarity measure. Mihalcea & Csomai (2007), Bunescu & Pasca (2006), Fader et al. (2009) extended the BoW model by incorporating more entity knowledge such as popularity knowledge, entity category knowledge, etc. Zheng et al. (2010), Dredze et al. (2010), Zhang et al. (2010) and Zhou et al. (2010) employed the learning to rank techniques which can further take the relations between candidate entities into account. Because the context similarity based methods can only represent the entity knowledge as features, the main drawback of it was the difficulty to incorporate heterogenous entity knowledge.","Recently there were also some entity linking methods based on inter-dependency. These methods assumed that the entities in the same document are related to each other, thus the referent entity of a name mention is the entity which is most related to its contextual entities. Medelyan et al. (2008) found the referent entity of a name mention by computing the weighted average of semantic relatedness between the candidate entity and its unambiguous contextual entities. Milne and Witten (2008) extended Medelyan et al. (2008) by adopting learning-based techniques to balance the semantic relatedness, commoness and context quality. Kulkarni et al. (2009) proposed a method which collectively resolves the entity linking tasks in a document as an optimization problem. The drawback of the inter-dependency based methods is that they are usually specially designed to the leverage of semantic relations, doesn’t take the other types of entity knowledge into consideration."]},{"title":"6 Conclusions and Future Work","paragraphs":["This paper proposes a generative probabilistic model, the entity-mention model, for the entity linking task. The main advantage of our model is it can incorporate multiple types of heterogenous entity knowledge. Furthermore, our model has a statistical foundation, making the entity knowledge extraction approach different from most previous ad hoc approaches. Experimental results show that our method can achieve competitive performance.","In our method, we did not take into account the dependence between entities in the same document. This aspect could be complementary to those we considered in this paper. For our future work, we can integrate such dependencies in our model."]},{"title":"Acknowledgments","paragraphs":["The work is supported by the National Natural Science Foundation of China under Grants no. 60773027, 60736044, 90920010, 61070106 and 61003117, and the National High Technology Development 863 Program of China under Grants no. 2008AA01Z145. Moreover, we sincerely thank the reviewers for their valuable comments. 953"]},{"title":"References","paragraphs":["Adafre, S. F. & de Rijke, M. 2005. Discovering missing links in Wikipedia. In: Proceedings of the 3rd international workshop on Link discovery.","Bunescu, R. & Pasca, M. 2006. Using encyclopedic knowledge for named entity disambiguation. In: Proceedings of EACL, vol. 6.","Brown, P., Pietra, S. D., Pietra, V. D., and Mercer, R. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2), 263-31.","Chen, S. F. & Goodman, J. 1999. An empirical study of smoothing techniques for language modeling. In Computer Speech and Language, London; Orlando: Academic Press, c1986-, pp. 359-394.","Cucerzan, S. 2007. Large-scale named entity disambiguation based on Wikipedia data. In: Proceedings of EMNLP-CoNLL, pp. 708-716.","Dredze, M., McNamee, P., Rao, D., Gerber, A. & Finin, T. 2010. Entity Disambiguation for Knowledge Base Population. In: Proceedings of the 23rd International Conference on Computational Linguistics.","Fader, A., Soderland, S., Etzioni, O. & Center, T. 2009. Scaling Wikipedia-based named entity disambiguation to arbitrary web text. In: Proceedings of Wiki-AI Workshop at IJCAI, vol. 9.","Han, X. & Zhao, J. 2009. NLPR_KBP in TAC 2009 KBP Track: A Two-Stage Method to Entity Linking. In: Proceeding of Text Analysis Conference.","Han, X. & Zhao, J. 2010. Structural semantic relatedness: a knowledge-based method to named entity disambiguation. In: Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.","Jelinek, Frederick and Robert L. Mercer. 1980. Interpolated estimation of Markov source parameters from sparse data. In: Proceedings of the Workshop on Pattern Recognition in Practice.","Kulkarni, S., Singh, A., Ramakrishnan, G. & Chakrabarti, S. 2009. Collective annotation of Wikipedia entities in web text. In: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 457-466.","Li, X., Morie, P. & Roth, D. 2004. Identification and tracing of ambiguous names: Discriminative and generative approaches. In: Proceedings of the National Conference on Artificial Intelligence, pp. 419-424.","McNamee, P. & Dang, H. T. 2009. Overview of the TAC 2009 Knowledge Base Population Track. In: Proceeding of Text Analysis Conference.","Milne, D. & Witten, I. H. 2008. Learning to link with Wikipedia. In: Proceedings of the 17th ACM conference on Conference on information and knowledge management.","Milne, D., et al. 2006. Mining Domain-Specific Thesauri from Wikipedia: A case study. In Proc. of IEEE/WIC/ACM WI.","Medelyan, O., Witten, I. H. & Milne, D. 2008. Topic indexing with Wikipedia. In: Proceedings of the AAAI WikiAI workshop.","Mihalcea, R. & Csomai, A. 2007. Wikify!: linking documents to encyclopedic knowledge. In: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pp. 233-242.","Pedersen, T., Purandare, A. & Kulkarni, A. 2005. Name discrimination by clustering similar contexts. Computational Linguistics and Intelligent Text Processing, pp. 226-237.","Zhang, W., Su, J., Tan, Chew Lim & Wang, W. T. 2010. Entity Linking Leveraging Automatically Generated Annotation. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010).","Zheng, Z., Li, F., Huang, M. & Zhu, X. 2010. Learning to Link Entities with Knowledge Base. In: The Proceedings of the Annual Conference of the North American Chapter of the ACL.","Zhou, Y., Nie, L., Rouhani-Kalleh, O., Vasile, F. & Gaffney, S. 2010. Resolving Surface Forms to Wikipedia Topics. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pp. 1335-1343. 954"]}],"references":[{"authors":[{"first":"S.","middle":"F.","last":"Adafre"},{"last":"de Rijke"},{"last":"M"}],"year":"2005","title":"Discovering missing links in Wikipedia","source":"Adafre, S. F. & de Rijke, M. 2005. Discovering missing links in Wikipedia. In: Proceedings of the 3rd international workshop on Link discovery."},{"authors":[{"first":"R.","last":"Bunescu"},{"last":"Pasca"},{"last":"M"}],"year":"2006","title":"Using encyclopedic knowledge for named entity disambiguation","source":"Bunescu, R. & Pasca, M. 2006. Using encyclopedic knowledge for named entity disambiguation. In: Proceedings of EACL, vol. 6."},{"authors":[{"first":"P.","last":"Brown"},{"first":"S.","middle":"D.","last":"Pietra"},{"first":"V.","middle":"D.","last":"Pietra"},{"last":"Mercer"},{"last":"R"}],"year":"1993","title":"The mathematics of statistical machine translation: parameter estimation","source":"Brown, P., Pietra, S. D., Pietra, V. D., and Mercer, R. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2), 263-31."},{"authors":[{"first":"S.","middle":"F.","last":"Chen"},{"last":"Goodman"},{"last":"J"}],"year":"1999","title":"An empirical study of smoothing techniques for language modeling","source":"Chen, S. F. & Goodman, J. 1999. An empirical study of smoothing techniques for language modeling. In Computer Speech and Language, London; Orlando: Academic Press, c1986-, pp. 359-394."},{"authors":[{"last":"Cucerzan"},{"last":"S"}],"year":"2007","title":"Large-scale named entity disambiguation based on Wikipedia data","source":"Cucerzan, S. 2007. Large-scale named entity disambiguation based on Wikipedia data. In: Proceedings of EMNLP-CoNLL, pp. 708-716."},{"authors":[{"first":"M.","last":"Dredze"},{"first":"P.","last":"McNamee"},{"first":"D.","last":"Rao"},{"first":"A.","last":"Gerber"},{"last":"Finin"},{"last":"T"}],"year":"2010","title":"Entity Disambiguation for Knowledge Base Population","source":"Dredze, M., McNamee, P., Rao, D., Gerber, A. & Finin, T. 2010. Entity Disambiguation for Knowledge Base Population. In: Proceedings of the 23rd International Conference on Computational Linguistics."},{"authors":[{"first":"A.","last":"Fader"},{"first":"S.","last":"Soderland"},{"first":"O.","last":"Etzioni"},{"last":"Center"},{"last":"T"}],"year":"2009","title":"Scaling Wikipedia-based named entity disambiguation to arbitrary web text","source":"Fader, A., Soderland, S., Etzioni, O. & Center, T. 2009. Scaling Wikipedia-based named entity disambiguation to arbitrary web text. In: Proceedings of Wiki-AI Workshop at IJCAI, vol. 9."},{"authors":[{"first":"X.","last":"Han"},{"last":"Zhao"},{"last":"J"}],"year":"2009","title":"NLPR_KBP in TAC 2009 KBP Track: A Two-Stage Method to Entity Linking","source":"Han, X. & Zhao, J. 2009. NLPR_KBP in TAC 2009 KBP Track: A Two-Stage Method to Entity Linking. In: Proceeding of Text Analysis Conference."},{"authors":[{"first":"X.","last":"Han"},{"last":"Zhao"},{"last":"J"}],"year":"2010","title":"Structural semantic relatedness: a knowledge-based method to named entity disambiguation","source":"Han, X. & Zhao, J. 2010. Structural semantic relatedness: a knowledge-based method to named entity disambiguation. In: Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics."},{"authors":[{"last":"Jelinek"},{"last":"Frederick"},{"first":"Robert","middle":"L.","last":"Mercer"}],"year":"1980","title":"Interpolated estimation of Markov source parameters from sparse data","source":"Jelinek, Frederick and Robert L. Mercer. 1980. Interpolated estimation of Markov source parameters from sparse data. In: Proceedings of the Workshop on Pattern Recognition in Practice."},{"authors":[{"first":"S.","last":"Kulkarni"},{"first":"A.","last":"Singh"},{"first":"G.","last":"Ramakrishnan"},{"last":"Chakrabarti"},{"last":"S"}],"year":"2009","title":"Collective annotation of Wikipedia entities in web text","source":"Kulkarni, S., Singh, A., Ramakrishnan, G. & Chakrabarti, S. 2009. Collective annotation of Wikipedia entities in web text. In: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 457-466."},{"authors":[{"first":"X.","last":"Li"},{"first":"P.","last":"Morie"},{"last":"Roth"},{"last":"D"}],"year":"2004","title":"Identification and tracing of ambiguous names: Discriminative and generative approaches","source":"Li, X., Morie, P. & Roth, D. 2004. Identification and tracing of ambiguous names: Discriminative and generative approaches. In: Proceedings of the National Conference on Artificial Intelligence, pp. 419-424."},{"authors":[{"first":"P.","last":"McNamee"},{"first":"H.","last":"Dang"},{"last":"T"}],"year":"2009","title":"Overview of the TAC 2009 Knowledge Base Population Track","source":"McNamee, P. & Dang, H. T. 2009. Overview of the TAC 2009 Knowledge Base Population Track. In: Proceeding of Text Analysis Conference."},{"authors":[{"first":"D.","last":"Milne"},{"first":"I.","last":"Witten"},{"last":"H"}],"year":"2008","title":"Learning to link with Wikipedia","source":"Milne, D. & Witten, I. H. 2008. Learning to link with Wikipedia. In: Proceedings of the 17th ACM conference on Conference on information and knowledge management."},{"authors":[{"first":"D.","last":"Milne"},{"last":"al"}],"year":"2006","title":"Mining Domain-Specific Thesauri from Wikipedia: A case study","source":"Milne, D., et al. 2006. Mining Domain-Specific Thesauri from Wikipedia: A case study. In Proc. of IEEE/WIC/ACM WI."},{"authors":[{"first":"O.","last":"Medelyan"},{"first":"I.","middle":"H.","last":"Witten"},{"last":"Milne"},{"last":"D"}],"year":"2008","title":"Topic indexing with Wikipedia","source":"Medelyan, O., Witten, I. H. & Milne, D. 2008. Topic indexing with Wikipedia. In: Proceedings of the AAAI WikiAI workshop."},{"authors":[{"first":"R.","last":"Mihalcea"},{"last":"Csomai"},{"last":"A"}],"year":"2007","title":"Wikify!: linking documents to encyclopedic knowledge","source":"Mihalcea, R. & Csomai, A. 2007. Wikify!: linking documents to encyclopedic knowledge. In: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pp. 233-242."},{"authors":[{"first":"T.","last":"Pedersen"},{"first":"A.","last":"Purandare"},{"last":"Kulkarni"},{"last":"A"}],"year":"2005","title":"Name discrimination by clustering similar contexts","source":"Pedersen, T., Purandare, A. & Kulkarni, A. 2005. Name discrimination by clustering similar contexts. Computational Linguistics and Intelligent Text Processing, pp. 226-237."},{"authors":[{"first":"W.","last":"Zhang"},{"first":"J.","last":"Su"},{"last":"Tan"},{"first":"Chew","last":"Lim"},{"first":"W.","last":"Wang"},{"last":"T"}],"year":"2010","title":"Entity Linking Leveraging Automatically Generated Annotation","source":"Zhang, W., Su, J., Tan, Chew Lim & Wang, W. T. 2010. Entity Linking Leveraging Automatically Generated Annotation. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010)."},{"authors":[{"first":"Z.","last":"Zheng"},{"first":"F.","last":"Li"},{"first":"M.","last":"Huang"},{"last":"Zhu"},{"last":"X"}],"year":"2010","title":"Learning to Link Entities with Knowledge Base","source":"Zheng, Z., Li, F., Huang, M. & Zhu, X. 2010. Learning to Link Entities with Knowledge Base. In: The Proceedings of the Annual Conference of the North American Chapter of the ACL."},{"authors":[{"first":"Y.","last":"Zhou"},{"first":"L.","last":"Nie"},{"first":"O.","last":"Rouhani-Kalleh"},{"first":"F.","last":"Vasile"},{"last":"Gaffney"},{"last":"S"}],"year":"2010","title":"Resolving Surface Forms to Wikipedia Topics","source":"Zhou, Y., Nie, L., Rouhani-Kalleh, O., Vasile, F. & Gaffney, S. 2010. Resolving Surface Forms to Wikipedia Topics. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pp. 1335-1343. 954"}],"cites":[{"style":0,"text":"Li et al., 2004","origin":{"pointer":"/sections/2/paragraphs/45","offset":158,"length":15},"authors":[{"last":"Li"},{"last":"al."}],"year":"2004","references":["/references/11"]},{"style":0,"text":"Bunescu & Pasca, 2006","origin":{"pointer":"/sections/2/paragraphs/45","offset":175,"length":21},"authors":[{"last":"Bunescu"},{"last":"Pasca"}],"year":"2006","references":[]},{"style":0,"text":"Cucerzan, 2007","origin":{"pointer":"/sections/2/paragraphs/45","offset":198,"length":14},"authors":[{"last":"Cucerzan"}],"year":"2007","references":[]},{"style":0,"text":"Milne & Witten, 2008","origin":{"pointer":"/sections/2/paragraphs/45","offset":214,"length":20},"authors":[{"last":"Milne"},{"last":"Witten"}],"year":"2008","references":[]},{"style":0,"text":"Fader et al., 2009","origin":{"pointer":"/sections/2/paragraphs/45","offset":239,"length":18},"authors":[{"last":"Fader"},{"last":"al."}],"year":"2009","references":["/references/6"]},{"style":0,"text":"Han and Zhao, 2009","origin":{"pointer":"/sections/5/paragraphs/5","offset":707,"length":18},"authors":[{"last":"Han"},{"last":"Zhao"}],"year":"2009","references":[]},{"style":0,"text":"Milne & Witten, 2008","origin":{"pointer":"/sections/7/paragraphs/3","offset":279,"length":20},"authors":[{"last":"Milne"},{"last":"Witten"}],"year":"2008","references":[]},{"style":0,"text":"Brown, et al., 1993","origin":{"pointer":"/sections/10/paragraphs/1","offset":388,"length":19},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1993","references":["/references/2"]},{"style":0,"text":"Pedersen et al., 2005","origin":{"pointer":"/sections/12/paragraphs/7","offset":263,"length":21},"authors":[{"last":"Pedersen"},{"last":"al."}],"year":"2005","references":["/references/17"]},{"style":0,"text":"Han and Zhao, 2010","origin":{"pointer":"/sections/12/paragraphs/9","offset":67,"length":18},"authors":[{"last":"Han"},{"last":"Zhao"}],"year":"2010","references":[]},{"style":0,"text":"Chen and Goodman, 1999","origin":{"pointer":"/sections/13/paragraphs/0","offset":256,"length":22},"authors":[{"last":"Chen"},{"last":"Goodman"}],"year":"1999","references":[]},{"style":0,"text":"Jelinek and Mercer, 1980","origin":{"pointer":"/sections/13/paragraphs/0","offset":348,"length":24},"authors":[{"last":"Jelinek"},{"last":"Mercer"}],"year":"1980","references":[]},{"style":0,"text":"McNamee and Dang, 2009","origin":{"pointer":"/sections/14/paragraphs/0","offset":194,"length":22},"authors":[{"last":"McNamee"},{"last":"Dang"}],"year":"2009","references":[]},{"style":0,"text":"McNamee and Dang, 2009","origin":{"pointer":"/sections/18/paragraphs/3","offset":95,"length":22},"authors":[{"last":"McNamee"},{"last":"Dang"}],"year":"2009","references":[]},{"style":0,"text":"McNamee and Dang, 2009","origin":{"pointer":"/sections/19/paragraphs/0","offset":93,"length":22},"authors":[{"last":"McNamee"},{"last":"Dang"}],"year":"2009","references":[]},{"style":0,"text":"Cucerzan, 2007","origin":{"pointer":"/sections/20/paragraphs/0","offset":105,"length":14},"authors":[{"last":"Cucerzan"}],"year":"2007","references":[]},{"style":0,"text":"Medelyan et al., 2008","origin":{"pointer":"/sections/20/paragraphs/0","offset":363,"length":21},"authors":[{"last":"Medelyan"},{"last":"al."}],"year":"2008","references":["/references/15"]},{"style":0,"text":"Milne & Witten, 2008","origin":{"pointer":"/sections/20/paragraphs/0","offset":633,"length":20},"authors":[{"last":"Milne"},{"last":"Witten"}],"year":"2008","references":[]},{"style":0,"text":"McNamee and Dang, 2009","origin":{"pointer":"/sections/20/paragraphs/8","offset":156,"length":22},"authors":[{"last":"McNamee"},{"last":"Dang"}],"year":"2009","references":[]},{"style":0,"text":"Cucerzan (2007)","origin":{"pointer":"/sections/21/paragraphs/0","offset":327,"length":15},"authors":[{"last":"Cucerzan"}],"year":"2007","references":[]},{"style":0,"text":"Mihalcea & Csomai (2007)","origin":{"pointer":"/sections/21/paragraphs/0","offset":546,"length":24},"authors":[{"last":"Mihalcea"},{"last":"Csomai"}],"year":"2007","references":[]},{"style":0,"text":"Bunescu & Pasca (2006)","origin":{"pointer":"/sections/21/paragraphs/0","offset":572,"length":22},"authors":[{"last":"Bunescu"},{"last":"Pasca"}],"year":"2006","references":[]},{"style":0,"text":"Fader et al. (2009)","origin":{"pointer":"/sections/21/paragraphs/0","offset":596,"length":19},"authors":[{"last":"Fader"},{"last":"al."}],"year":"2009","references":["/references/6"]},{"style":0,"text":"Zheng et al. (2010)","origin":{"pointer":"/sections/21/paragraphs/0","offset":740,"length":19},"authors":[{"last":"Zheng"},{"last":"al."}],"year":"2010","references":["/references/19"]},{"style":0,"text":"Dredze et al. (2010)","origin":{"pointer":"/sections/21/paragraphs/0","offset":761,"length":20},"authors":[{"last":"Dredze"},{"last":"al."}],"year":"2010","references":["/references/5"]},{"style":0,"text":"Zhang et al. (2010)","origin":{"pointer":"/sections/21/paragraphs/0","offset":783,"length":19},"authors":[{"last":"Zhang"},{"last":"al."}],"year":"2010","references":["/references/18"]},{"style":0,"text":"Zhou et al. (2010)","origin":{"pointer":"/sections/21/paragraphs/0","offset":807,"length":18},"authors":[{"last":"Zhou"},{"last":"al."}],"year":"2010","references":["/references/20"]},{"style":0,"text":"Medelyan et al. (2008)","origin":{"pointer":"/sections/21/paragraphs/1","offset":275,"length":22},"authors":[{"last":"Medelyan"},{"last":"al."}],"year":"2008","references":["/references/15"]},{"style":0,"text":"Milne and Witten (2008)","origin":{"pointer":"/sections/21/paragraphs/1","offset":470,"length":23},"authors":[{"last":"Milne"},{"last":"Witten"}],"year":"2008","references":[]},{"style":0,"text":"Medelyan et al. (2008)","origin":{"pointer":"/sections/21/paragraphs/1","offset":503,"length":22},"authors":[{"last":"Medelyan"},{"last":"al."}],"year":"2008","references":["/references/15"]},{"style":0,"text":"Kulkarni et al. (2009)","origin":{"pointer":"/sections/21/paragraphs/1","offset":632,"length":22},"authors":[{"last":"Kulkarni"},{"last":"al."}],"year":"2009","references":["/references/10"]}]}
