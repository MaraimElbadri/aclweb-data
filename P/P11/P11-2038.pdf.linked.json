{"sections":[{"title":"","paragraphs":["Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 217–222, Portland, Oregon, June 19-24, 2011. c⃝2011 Association for Computational Linguistics"]},{"title":"Judging Grammaticality with Tree Substitution Grammar Derivations Matt Post Human Language Technology Center of Excellence Johns Hopkins University Baltimore, MD 21211 Abstract","paragraphs":["In this paper, we show that local features computed from the derivations of tree substitution grammars — such as the identify of particular fragments, and a count of large and small fragments — are useful in binary grammatical classification tasks. Such features outperform n-gram features and various model scores by a wide margin. Although they fall short of the performance of the hand-crafted feature set of Charniak and Johnson (2005) developed for parse tree reranking, they do so with an order of magnitude fewer features. Further-more, since the TSGs employed are learned in a Bayesian setting, the use of their derivations can be viewed as the automatic discovery of tree patterns useful for classification. On the BLLIP dataset, we achieve an accuracy of 89.9% in discriminating between grammatical text and samples from an n-gram language model."]},{"title":"1 Introduction","paragraphs":["The task of a language model is to provide a measure of the grammaticality of a sentence. Language models are useful in a variety of settings, for both human and machine output; for example, in the automatic grading of essays, or in guiding search in a machine translation system. Language modeling has proved to be quite difficult. The simplest models, n-grams, are self-evidently poor models of language, unable to (easily) capture or enforce long-distance linguistic phenomena. However, they are easy to train, are long-studied and well understood, and can be efficiently incorporated into search procedures, such as for machine translation. As a result, the output of such text generation systems is often very poor grammatically, even if it is understandable.","Since grammaticality judgments are a matter of the syntax of a language, the obvious approach for modeling grammaticality is to start with the extensive work produced over the past two decades in the field of parsing. This paper demonstrates the utility of local features derived from the fragments of tree substitution grammar derivations. Follow-ing Cherry and Quirk (2008), we conduct experiments in a classification setting, where the task is to distinguish between real text and “pseudo-negative” text obtained by sampling from a trigram language model (Okanohara and Tsujii, 2007). Our primary points of comparison are the latent SVM training of Cherry and Quirk (2008), mentioned above, and the extensive set of local and nonlocal feature templates developed by Charniak and Johnson (2005) for parse tree reranking. In contrast to this latter set of features, the feature sets from TSG derivations require no engineering; instead, they are obtained directly from the identity of the fragments used in the derivation, plus simple statistics computed over them. Since these fragments are in turn learned automatically from a Treebank with a Bayesian model, their usefulness here suggests a greater potential for adapting to other languages and datasets."]},{"title":"2 Tree substitution grammars","paragraphs":["Tree substitution grammars (Joshi and Schabes, 1997) generalize context-free grammars by allow-ing nonterminals to rewrite as tree fragments of arbitrary size, instead of as only a sequence of one or 217 ....S. ........NP. ..VP. ........VBD. ....said . ..NP. ..SBAR . ... Figure 1: A Tree Substitution Grammar fragment. more children. Evaluated by parsing accuracy, these grammars are well below state of the art. However, they are appealing in a number of ways. Larger fragments better match linguists’ intuitions about what the basic units of grammar should be, capturing, for example, the predicate-argument structure of a verb (Figure 1). The grammars are context-free and thus retain cubic-time inference procedures, yet they reduce the independence assumptions in the model’s generative story by virtue of using fewer fragments (compared to a standard CFG) to generate a tree."]},{"title":"3 A spectrum of grammaticality","paragraphs":["The use of large fragments in TSG grammar derivations provides reason to believe that such grammars might do a better job at language modeling tasks. Consider an extreme case, in which a grammar consists entirely of complete parse trees. In this case, ungrammaticality is synonymous with parser failure. Such a classifier would have perfect precision but very low recall, since it could not generalize at all. On the other extreme, a context-free grammar containing only depth-one rules can basically produce an analysis over any sequence of words. However, such grammars are notoriously leaky, and the existence of an analysis does not correlate with grammaticality. Context-free grammars are too poor models of language for the linguistic definition of grammaticality (a sequence of words in the language of the grammar) to apply.","TSGs permit us to posit a spectrum of grammaticality in between these two extremes. If we have a grammar comprising small and large fragments, we might consider that larger fragments should be less likely to fit into ungrammatical situations, whereas small fragments could be employed almost any-where as a sort of ungrammatical glue. Thus, on average, grammatical sentences will license derivations with larger fragments, whereas ungrammatical sentences will be forced to resort to small fragments. This is the central idea explored in this paper.","This raises the question of what exactly the larger fragments are. A fundamental problem with TSGs is that they are hard to learn, since there is no annotated corpus of TSG derivations and the number of possible derivations is exponential in the size of a tree. The most popular TSG approach has been Data-Oriented Parsing (Scha, 1990; Bod, 1993), which takes all fragments in the training data. The large size of such grammars (exponential in the size of the training data) forces either implicit representations (Goodman, 1996; Bansal and Klein, 2010) — which do not permit arbitrary probability distributions over the grammar fragments — or explicit approxima-tions to all fragments (Bod, 2001). A number of researchers have presented ways to address the learning problems for explicitly represented TSGs (Zollmann and Sima’an, 2005; Zuidema, 2007; Cohn et al., 2009; Post and Gildea, 2009a). Of these approaches, work in Bayesian learning of TSGs produces intuitive grammars in a principled way, and has demonstrated potential in language modeling tasks (Post and Gildea, 2009b; Post, 2010). Our experiments make use of Bayesian-learned TSGs."]},{"title":"4 Experiments","paragraphs":["We experiment with a binary classification task, de-fined as follows: given a sequence of words, determine whether it is grammatical or not. We use two datasets: the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), and the BLLIP ’99 dataset,1","a collection of automatically-parsed sentences from three years of articles from the Wall Street Journal.","For both datasets, positive examples are obtained from the leaves of the parse trees, retaining their to-kenization. Negative examples were produced from a trigram language model by randomly generating sentences of length no more than 100 so as to match the size of the positive data. The language model was built with SRILM (Stolcke, 2002) using interpolated Kneser-Ney smoothing. The average sentence lengths for the positive and negative data were 23.9 and 24.7, respectively, for the Treebank data 1 LDC Catalog No. LDC2000T43. 218 dataset training devel. test Treebank 3,836 2,690 3,398","91,954 65,474 79,998 BLLIP 100,000 6,000 6,000","2,596,508 155,247 156,353 Table 1: The number of sentences (first line) and words (second line) using for training, development, and test-ing of the classifier. Each set of sentences is evenly split between positive and negative examples. and 25.6 and 26.2 for the BLLIP data.","Each dataset is divided into training, development, and test sets. For the Treebank, we trained the n-gram language model on sections 2 - 21. The classifier then used sections 0, 24, and 22 for training, development, and testing, respectively. For the BLLIP dataset, we followed Cherry and Quirk (2008): we randomly selected 450K sentences to train the n-gram language model, and 50K, 3K, and 3K sentences for classifier training, development, and testing, respectively. All sentences have 100 or fewer words. Table 1 contains statistics of the datasets used in our experiments.","To build the classifier, we used liblinear (Fan et al., 2008). A bias of 1 was added to each feature vector. We varied a cost or regularization parameter between 1e − 5 and 100 in orders of magnitude; at each step, we built a model, evaluating it on the development set. The model with the highest score was then used to produce the result on the test set. 4.1 Base models and features Our experiments compare a number of different feature sets. Central to these feature sets are features computed from the output of four language models.","1. Bigram and trigram language models (the same ones used to generate the negative data) 2. A Treebank grammar (Charniak, 1996)","3. A Bayesian-learned tree substitution grammar (Post and Gildea, 2009a)2","2","The sampler was run with the default settings for 1,000 iterations, and a grammar of 192,667 fragments was then extracted from counts taken from every 10th iteration between iterations 500 and 1,000, inclusive. Code was obtained from http://github.com/mjpost/dptsg.","4. The Charniak parser (Charniak, 2000), run in language modeling mode The parsing models for both datasets were built from sections 2 - 21 of the WSJ portion of the Treebank. These models were used to score or parse the training, development, and test data for the classifier. From the output, we extract the following feature sets used in the classifier. • Sentence length (l). • Model scores (S). Model log probabilities.","• Rule features (R). These are counter features based on the atomic unit of the analysis, i.e., in-dividual n-grams for the n-gram models, PCFG rules, and TSG fragments.","• Reranking features (C&J). From the Charniak parser output we extract the complete set of reranking features of Charniak and Johnson (2005), and just the local ones (C&J local).3","• Frontier size (Fn, F l","n). Instances of this feature class count the number of TSG fragments having frontier size n, 1 ≤ n ≤ 9.4","Instances of F l","n count only lexical items for 0 ≤ n ≤ 5. 4.2 Results Table 2 contains the classification results. The first block of models all perform at chance. We experimented with SVM classifiers instead of maximum entropy, and the only real change across all the models was for these first five models, which saw classification rise to 55 to 60%.","On the BLLIP dataset, the C&J feature sets perform the best, even when the set of features is restricted to local ones. However, as shown in Table 3, this performance comes at a cost of using ten times as many features. The classifiers with TSG features outperform all the other models.","The (near)-perfect performance of the TSG models on the Treebank is a result of the large number of features relative to the size of the training data:","3","Local features can be computed in a bottom-up manner. See Huang (2008, §3.2) for more detail.","4","A fragment’s frontier is the number of terminals and nonterminals among its leaves, also known its rank. For example, the fragment in Figure 1 has a frontier size of 5. 219 feature set Treebank BLLIP length (l) 50.0 46.4 3-gram score ( S3) 50.0 50.1 PCFG score (SP ) 49.5 50.0 TSG score (ST ) 49.5 49.7 Charniak score (SC ) 50.0 50.0 l + S3 61.0 64.3 l + SP 75.6 70.4 l + ST 82.4 76.2 l + SC 76.3 69.1 l + R2 62.4 70.6 l + R3 61.3 70.7 l + RP 60.4 85.0 l + RT 99.4 89.3 l + C&J (local) 89.1 92.5 l + C&J 88.6 93.0 l + RT + F∗ + F l","∗ 100.0 89.9 Table 2: Classification accuracy. feature set Treebank BLLIP l + R3 18K 122K l + RP 15K 11K l + RT 14K 60K l + C&J (local) 24K 607K l + C&J 58K 959K l + RT + F∗ 14K 60K Table 3: Model size. the positive and negative data really do evince different fragments, and there are enough such features relative to the size of the training data that very high weights can be placed on them. Manual examination of feature weights bears this out. Despite having more features available, the Charniak & Johnson feature set has significantly lower accuracy on the Treebank data, which suggests that the TSG features are more strongly associated with a particular (positive or negative) outcome.","For comparison, Cherry and Quirk (2008) report a classification accuracy of 81.42 on BLLIP. We exclude it from the table because a direct comparison is not possible, since we did not have access to the split on the BLLIP used in their experiments, but only repeated the process they described to generate it."]},{"title":"5 Analysis","paragraphs":["Table 4 lists the highest-weighted TSG features associated with each outcome, taken from the BLLIP model in the last row of Table 2. The learned weights accord with the intuitions presented in Section 3. Ungrammatical sentences use smaller, abstract (unlexicalized) rules, whereas grammatical sentences use higher rank rules and are more lexicalized. Looking at the fragments themselves, we see that sensible patterns such as balanced parenthetical expressions or verb predicate-argument structures are associated with grammaticality, while many of the ungrammatical fragments contain unbalanced quotations and unlikely configurations.","Table 5 contains the most probable depth-one rules for each outcome. The unary rules associated with ungrammatical sentences show some interest-ing patterns. For example, the rule NP → DT occurs 2,344 times in the training portion of the Treebank. Most of these occurrences are in subject settings over articles that aren’t required to modify a noun, such as that, some, this, and all. However, in the BLLIP n-gram data, this rule is used over the definite article the 465 times – the second-most common use. Yet this rule occurs only nine times in the Treebank where the grammar was learned. The small fragment size, together with the coarseness of the nonterminal, permit the fragment to be used in distributional settings where it should not be licensed. This suggests some complementarity between fragment learning and work in using nonterminal refine-ments (Johnson, 1998; Petrov et al., 2006)."]},{"title":"6 Related work","paragraphs":["Past approaches using parsers as language models in discriminative settings have seen varying degrees of success. Och et al. (2004) found that the score of a bilexicalized parser was not useful in distinguishing machine translation (MT) output from human reference translations. Cherry and Quirk (2008) addressed this problem by using a latent SVM to adjust the CFG rule weights such that the parser score was a much more useful discriminator between grammatical text and n-gram samples. Mutton et al. (2007) also addressed this problem by combining scores from different parsers using an SVM and showed an improved metric of fluency. 220 grammatical ungrammatical (VP VBD (NP CD) PP) F l 0 (S (NP PRP) VP) (NP (NP CD) PP) (S NP (VP TO VP)) (TOP (NP NP NP .)) F l 2 F5 (NP NP (VP VBG NP)) (S (NP (NNP UNK-CAPS-NUM))) (SBAR (S (NP PRP) VP)) (TOP (S NP VP (. .))) (SBAR (IN that) S) (TOP (PP IN NP .)) (TOP (S NP (VP (VBD said) NP SBAR) .)) (TOP (S “ NP VP (. .))) (NP (NP DT JJ NN) PP) (TOP (S PP NP VP .)) (NP (NP NNP NNP) , NP ,) (TOP (NP NP PP .)) (TOP (S NP (ADVP (RB also)) VP .)) F4 (VP (VB be) VP) (NP (DT that) NN) (NP (NP NNS) PP) (TOP (S NP VP . ”)) (NP NP , (SBAR WHNP (S VP)) ,) (TOP (NP NP , NP .)) (TOP (S SBAR , NP VP .)) (QP CD (CD million)) (ADJP (QP $ CD (CD million))) (NP NP (CC and) NP) (SBAR (IN that) (S NP VP)) (PP (IN In) NP)","F8 (QP $ CD (CD million)) Table 4: Highest-weighted TSG features.","Outside of MT, Foster and Vogel (2004) argued for parsers that do not assume the grammaticality of their input. Sun et al. (2007) used a set of templates to extract labeled sequential part-of-speech patterns together with some other linguistic features) which were then used in an SVM setting to classify sentences in Japanese and Chinese learners’ English corpora. Wagner et al. (2009) and Foster and Andersen (2009) attempt finer-grained, more realistic (and thus more difficult) classifications against ungrammatical text modeled on the sorts of mistakes made by language learners using parser probabilities. More recently, some researchers have shown that using features of parse trees (such as the rules grammatical ungrammatical (WHNP CD) (NN UNK-CAPS) (NP JJ NNS) (S VP) (PRT RP) (S NP) (WHNP WP NN) (TOP FRAG) (SBAR WHNP S) (NP DT JJ) (WHNP WDT NN) (NP DT) Table 5: Highest-weighted depth-one rules. used) is fruitful (Wong and Dras, 2010; Post, 2010)."]},{"title":"7 Summary","paragraphs":["Parsers were designed to discriminate among structures, whereas language models discriminate among strings. Small fragments, abstract rules, independence assumptions, and errors or peculiarities in the training corpus allow probable structures to be produced over ungrammatical text when using models that were optimized for parser accuracy.","The experiments in this paper demonstrate the utility of tree-substitution grammars in discriminating between grammatical and ungrammatical sentences. Features are derived from the identities of the fragments used in the derivations above a sequence of words; particular fragments are associated with each outcome, and simple statistics computed over those fragments are also useful. The most complicated aspect of using TSGs is grammar learning, for which there are publicly available tools.","Looking forward, we believe there is significant potential for TSGs in more subtle discriminative tasks, for example, in discriminating between finer grained and more realistic grammatical errors (Foster and Vogel, 2004; Wagner et al., 2009), or in discriminating among translation candidates in a machine translation framework. In another line of potential work, it could prove useful to incorporate into the grammar learning procedure some knowledge of the sorts of fragments and features shown here to be helpful for discriminating grammatical and ungrammatical text."]},{"title":"References","paragraphs":["Mohit Bansal and Dan Klein. 2010. Simple, accurate parsing with an all-fragments grammar. In Proc. ACL, Uppsala, Sweden, July. 221","Rens Bod. 1993. Using an annotated corpus as a stochas-tic grammar. In Proc. ACL, Columbus, Ohio, USA.","Rens Bod. 2001. What is the minimal set of fragments that achieves maximal parse accuracy? In Proc. ACL, Toulouse, France, July.","Eugene Charniak and Mark Johnson. 2005. Coarse-to-fine n-best parsing and MaxEnt discriminative reranking. In Proc. ACL, Ann Arbor, Michigan, USA, June.","Eugene Charniak. 1996. Tree-bank grammars. In Proc. of the National Conference on Artificial Intelligence.","Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proc. NAACL, Seattle, Washington, USA, April–May.","Colin Cherry and Chris Quirk. 2008. Discriminative, syntactic language modeling through latent svms. In Proc. AMTA, Waikiki, Hawaii, USA, October.","Trevor Cohn, Sharon. Goldwater, and Phil Blunsom. 2009. Inducing compact but accurate tree-substitution grammars. In Proc. NAACL, Boulder, Colorado, USA, June.","Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.","Jennifer Foster and Øistein E. Andersen. 2009. Generrate: generating errors for use in grammatical error detection. In Proceedings of the fourth workshop on innovative use of nlp for building educational applications, pages 82–90. Association for Computational Linguistics.","Jennifer Foster and Carl Vogel. 2004. Good reasons for noting bad grammar: Constructing a corpus of ungrammatical language. In Pre-Proceedings of the International Conference on Linguistic Evidence: Empirical, Theoretical and Computational Perspectives.","Joshua Goodman. 1996. Efficient algorithms for parsing the DOP model. In Proc. EMNLP, Philadelphia, Pennsylvania, USA, May.","Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), Columbus, Ohio, June.","Mark Johnson. 1998. PCFG models of linguistic tree representations. Computational Linguistics, 24(4):613–632.","Aravind K. Joshi and Yves Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages: Beyond Words, volume 3, pages 71–122.","Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics, 19(2):330.","Andrew Mutton, Mark Dras, Stephen Wan, and Robert Dale. 2007. Gleu: Automatic evaluation of sentencelevel fluency. In Proc. ACL, volume 45, page 344.","Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, et al. 2004. A smorgasbord of features for statistical machine translation. In Proc. NAACL.","Daisuke Okanohara and Jun’ichi Tsujii. 2007. A discriminative language model with pseudo-negative samples. In Proc. ACL, Prague, Czech Republic, June.","Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proc. COLING/ACL, Sydney, Australia, July.","Matt Post and Daniel Gildea. 2009a. Bayesian learning of a tree substitution grammar. In Proc. ACL (short paper track), Suntec, Singapore, August.","Matt Post and Daniel Gildea. 2009b. Language modeling with tree substitution grammars. In NIPS workshop on Grammar Induction, Representation of Language, and Language Learning, Whistler, British Columbia.","Matt Post. 2010. Syntax-based Language Models for Statistical Machine Translation. Ph.D. thesis, University of Rochester.","Remko Scha. 1990. Taaltheorie en taaltechnologie; competence en performance. In R. de Kort and G.L.J. Leerdam, editors, Computertoepassingen in de neerlandistiek, pages 7–22, Almere, the Netherlands.","Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proc. International Conference on Spoken Language Processing.","Ghihua Sun, Xiaohua Liu, Gao Cong, Ming Zhou, Zhongyang Xiong, John Lee, and Chin-Yew Lin. 2007. Detecting erroneous sentences using automatically mined sequential patterns. In Proc. ACL, volume 45.","Joachim Wagner, Jennifer Foster, and Josef van Genabith. 2009. Judging grammaticality: Experiments in sentence classification. CALICO Journal, 26(3):474–490.","Sze-Meng Jojo Wong and Mark Dras. 2010. Parser features for sentence grammaticality classification. In Proc. Australasian Language Technology Association Workshop, Melbourne, Australia, December.","Andreas Zollmann and Khalil Sima’an. 2005. A consistent and efficient estimator for Data-Oriented Parsing. Journal of Automata, Languages and Combinatorics, 10(2/3):367–388.","Willem Zuidema. 2007. Parsimonious Data-Oriented Parsing. In Proc. EMNLP, Prague, Czech Republic, June. 222"]}],"references":[{"authors":[{"first":"Mohit","last":"Bansal"},{"first":"Dan","last":"Klein"}],"year":"2010","title":"Simple, accurate parsing with an all-fragments grammar","source":"Mohit Bansal and Dan Klein. 2010. Simple, accurate parsing with an all-fragments grammar. In Proc. ACL, Uppsala, Sweden, July. 221"},{"authors":[{"first":"Rens","last":"Bod"}],"year":"1993","title":"Using an annotated corpus as a stochas-tic grammar","source":"Rens Bod. 1993. Using an annotated corpus as a stochas-tic grammar. In Proc. ACL, Columbus, Ohio, USA."},{"authors":[{"first":"Rens","last":"Bod"}],"year":"2001","title":"What is the minimal set of fragments that achieves maximal parse accuracy? In Proc","source":"Rens Bod. 2001. What is the minimal set of fragments that achieves maximal parse accuracy? In Proc. ACL, Toulouse, France, July."},{"authors":[{"first":"Eugene","last":"Charniak"},{"first":"Mark","last":"Johnson"}],"year":"2005","title":"Coarse-to-fine n-best parsing and MaxEnt discriminative reranking","source":"Eugene Charniak and Mark Johnson. 2005. Coarse-to-fine n-best parsing and MaxEnt discriminative reranking. In Proc. ACL, Ann Arbor, Michigan, USA, June."},{"authors":[{"first":"Eugene","last":"Charniak"}],"year":"1996","title":"Tree-bank grammars","source":"Eugene Charniak. 1996. Tree-bank grammars. In Proc. of the National Conference on Artificial Intelligence."},{"authors":[{"first":"Eugene","last":"Charniak"}],"year":"2000","title":"A maximum-entropy-inspired parser","source":"Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proc. NAACL, Seattle, Washington, USA, April–May."},{"authors":[{"first":"Colin","last":"Cherry"},{"first":"Chris","last":"Quirk"}],"year":"2008","title":"Discriminative, syntactic language modeling through latent svms","source":"Colin Cherry and Chris Quirk. 2008. Discriminative, syntactic language modeling through latent svms. In Proc. AMTA, Waikiki, Hawaii, USA, October."},{"authors":[{"first":"Trevor","last":"Cohn"},{"first":"Sharon.","last":"Goldwater"},{"first":"Phil","last":"Blunsom"}],"year":"2009","title":"Inducing compact but accurate tree-substitution grammars","source":"Trevor Cohn, Sharon. Goldwater, and Phil Blunsom. 2009. Inducing compact but accurate tree-substitution grammars. In Proc. NAACL, Boulder, Colorado, USA, June."},{"authors":[{"first":"Rong-En","last":"Fan"},{"first":"Kai-Wei","last":"Chang"},{"first":"Cho-Jui","last":"Hsieh"},{"first":"Xiang-Rui","last":"Wang"},{"first":"Chih-Jen","last":"Lin"}],"year":"2008","title":"LIBLINEAR: A library for large linear classification","source":"Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874."},{"authors":[{"first":"Jennifer","last":"Foster"},{"first":"Øistein","middle":"E.","last":"Andersen"}],"year":"2009","title":"Generrate: generating errors for use in grammatical error detection","source":"Jennifer Foster and Øistein E. Andersen. 2009. Generrate: generating errors for use in grammatical error detection. In Proceedings of the fourth workshop on innovative use of nlp for building educational applications, pages 82–90. Association for Computational Linguistics."},{"authors":[{"first":"Jennifer","last":"Foster"},{"first":"Carl","last":"Vogel"}],"year":"2004","title":"Good reasons for noting bad grammar: Constructing a corpus of ungrammatical language","source":"Jennifer Foster and Carl Vogel. 2004. Good reasons for noting bad grammar: Constructing a corpus of ungrammatical language. In Pre-Proceedings of the International Conference on Linguistic Evidence: Empirical, Theoretical and Computational Perspectives."},{"authors":[{"first":"Joshua","last":"Goodman"}],"year":"1996","title":"Efficient algorithms for parsing the DOP model","source":"Joshua Goodman. 1996. Efficient algorithms for parsing the DOP model. In Proc. EMNLP, Philadelphia, Pennsylvania, USA, May."},{"authors":[{"first":"Liang","last":"Huang"}],"year":"2008","title":"Forest reranking: Discriminative parsing with non-local features","source":"Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), Columbus, Ohio, June."},{"authors":[{"first":"Mark","last":"Johnson"}],"year":"1998","title":"PCFG models of linguistic tree representations","source":"Mark Johnson. 1998. PCFG models of linguistic tree representations. Computational Linguistics, 24(4):613–632."},{"authors":[{"first":"Aravind","middle":"K.","last":"Joshi"},{"first":"Yves","last":"Schabes"}],"year":"1997","title":"Tree-adjoining grammars","source":"Aravind K. Joshi and Yves Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages: Beyond Words, volume 3, pages 71–122."},{"authors":[{"first":"Mitchell","middle":"P.","last":"Marcus"},{"first":"Mary","middle":"Ann","last":"Marcinkiewicz"},{"first":"Beatrice","last":"Santorini"}],"year":"1993","title":"Building a large annotated corpus of English: The Penn Treebank","source":"Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics, 19(2):330."},{"authors":[{"first":"Andrew","last":"Mutton"},{"first":"Mark","last":"Dras"},{"first":"Stephen","last":"Wan"},{"first":"Robert","last":"Dale"}],"year":"2007","title":"Gleu: Automatic evaluation of sentencelevel fluency","source":"Andrew Mutton, Mark Dras, Stephen Wan, and Robert Dale. 2007. Gleu: Automatic evaluation of sentencelevel fluency. In Proc. ACL, volume 45, page 344."},{"authors":[{"first":"Franz","middle":"Josef","last":"Och"},{"first":"Daniel","last":"Gildea"},{"first":"Sanjeev","last":"Khudanpur"},{"first":"Anoop","last":"Sarkar"},{"first":"Kenji","last":"Yamada"},{"first":"Alex","last":"Fraser"},{"first":"Shankar","last":"Kumar"},{"first":"Libin","last":"Shen"},{"first":"David","last":"Smith"},{"first":"Katherine","last":"Eng"},{"last":"al"}],"year":"2004","title":"A smorgasbord of features for statistical machine translation","source":"Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, et al. 2004. A smorgasbord of features for statistical machine translation. In Proc. NAACL."},{"authors":[{"first":"Daisuke","last":"Okanohara"},{"first":"Jun’ichi","last":"Tsujii"}],"year":"2007","title":"A discriminative language model with pseudo-negative samples","source":"Daisuke Okanohara and Jun’ichi Tsujii. 2007. A discriminative language model with pseudo-negative samples. In Proc. ACL, Prague, Czech Republic, June."},{"authors":[{"first":"Slav","last":"Petrov"},{"first":"Leon","last":"Barrett"},{"first":"Romain","last":"Thibaux"},{"first":"Dan","last":"Klein"}],"year":"2006","title":"Learning accurate, compact, and interpretable tree annotation","source":"Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proc. COLING/ACL, Sydney, Australia, July."},{"authors":[{"first":"Matt","last":"Post"},{"first":"Daniel","last":"Gildea"}],"year":"2009a","title":"Bayesian learning of a tree substitution grammar","source":"Matt Post and Daniel Gildea. 2009a. Bayesian learning of a tree substitution grammar. In Proc. ACL (short paper track), Suntec, Singapore, August."},{"authors":[{"first":"Matt","last":"Post"},{"first":"Daniel","last":"Gildea"}],"year":"2009b","title":"Language modeling with tree substitution grammars","source":"Matt Post and Daniel Gildea. 2009b. Language modeling with tree substitution grammars. In NIPS workshop on Grammar Induction, Representation of Language, and Language Learning, Whistler, British Columbia."},{"authors":[{"first":"Matt","last":"Post"}],"year":"2010","title":"Syntax-based Language Models for Statistical Machine Translation","source":"Matt Post. 2010. Syntax-based Language Models for Statistical Machine Translation. Ph.D. thesis, University of Rochester."},{"authors":[{"first":"Remko","last":"Scha"}],"year":"1990","title":"Taaltheorie en taaltechnologie; competence en performance","source":"Remko Scha. 1990. Taaltheorie en taaltechnologie; competence en performance. In R. de Kort and G.L.J. Leerdam, editors, Computertoepassingen in de neerlandistiek, pages 7–22, Almere, the Netherlands."},{"authors":[{"first":"Andreas","last":"Stolcke"}],"year":"2002","title":"SRILM – an extensible language modeling toolkit","source":"Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proc. International Conference on Spoken Language Processing."},{"authors":[{"first":"Ghihua","last":"Sun"},{"first":"Xiaohua","last":"Liu"},{"first":"Gao","last":"Cong"},{"first":"Ming","last":"Zhou"},{"first":"Zhongyang","last":"Xiong"},{"first":"John","last":"Lee"},{"first":"Chin-Yew","last":"Lin"}],"year":"2007","title":"Detecting erroneous sentences using automatically mined sequential patterns","source":"Ghihua Sun, Xiaohua Liu, Gao Cong, Ming Zhou, Zhongyang Xiong, John Lee, and Chin-Yew Lin. 2007. Detecting erroneous sentences using automatically mined sequential patterns. In Proc. ACL, volume 45."},{"authors":[{"first":"Joachim","last":"Wagner"},{"first":"Jennifer","last":"Foster"},{"first":"Josef","last":"van Genabith"}],"year":"2009","title":"Judging grammaticality: Experiments in sentence classification","source":"Joachim Wagner, Jennifer Foster, and Josef van Genabith. 2009. Judging grammaticality: Experiments in sentence classification. CALICO Journal, 26(3):474–490."},{"authors":[{"first":"Sze-Meng","middle":"Jojo","last":"Wong"},{"first":"Mark","last":"Dras"}],"year":"2010","title":"Parser features for sentence grammaticality classification","source":"Sze-Meng Jojo Wong and Mark Dras. 2010. Parser features for sentence grammaticality classification. In Proc. Australasian Language Technology Association Workshop, Melbourne, Australia, December."},{"authors":[{"first":"Andreas","last":"Zollmann"},{"first":"Khalil","last":"Sima’an"}],"year":"2005","title":"A consistent and efficient estimator for Data-Oriented Parsing","source":"Andreas Zollmann and Khalil Sima’an. 2005. A consistent and efficient estimator for Data-Oriented Parsing. Journal of Automata, Languages and Combinatorics, 10(2/3):367–388."},{"authors":[{"first":"Willem","last":"Zuidema"}],"year":"2007","title":"Parsimonious Data-Oriented Parsing","source":"Willem Zuidema. 2007. Parsimonious Data-Oriented Parsing. In Proc. EMNLP, Prague, Czech Republic, June. 222"}],"cites":[{"style":0,"text":"Charniak and Johnson (2005)","origin":{"pointer":"/sections/1/paragraphs/0","offset":412,"length":27},"authors":[{"last":"Charniak"},{"last":"Johnson"}],"year":"2005","references":["/references/3"]},{"style":0,"text":"Cherry and Quirk (2008)","origin":{"pointer":"/sections/2/paragraphs/1","offset":352,"length":23},"authors":[{"last":"Cherry"},{"last":"Quirk"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Okanohara and Tsujii, 2007","origin":{"pointer":"/sections/2/paragraphs/1","offset":559,"length":26},"authors":[{"last":"Okanohara"},{"last":"Tsujii"}],"year":"2007","references":["/references/18"]},{"style":0,"text":"Cherry and Quirk (2008)","origin":{"pointer":"/sections/2/paragraphs/1","offset":652,"length":23},"authors":[{"last":"Cherry"},{"last":"Quirk"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Charniak and Johnson (2005)","origin":{"pointer":"/sections/2/paragraphs/1","offset":769,"length":27},"authors":[{"last":"Charniak"},{"last":"Johnson"}],"year":"2005","references":["/references/3"]},{"style":0,"text":"Joshi and Schabes, 1997","origin":{"pointer":"/sections/3/paragraphs/0","offset":28,"length":23},"authors":[{"last":"Joshi"},{"last":"Schabes"}],"year":"1997","references":["/references/14"]},{"style":0,"text":"Scha, 1990","origin":{"pointer":"/sections/4/paragraphs/2","offset":324,"length":10},"authors":[{"last":"Scha"}],"year":"1990","references":["/references/23"]},{"style":0,"text":"Bod, 1993","origin":{"pointer":"/sections/4/paragraphs/2","offset":336,"length":9},"authors":[{"last":"Bod"}],"year":"1993","references":["/references/1"]},{"style":0,"text":"Goodman, 1996","origin":{"pointer":"/sections/4/paragraphs/2","offset":515,"length":13},"authors":[{"last":"Goodman"}],"year":"1996","references":["/references/11"]},{"style":0,"text":"Bansal and Klein, 2010","origin":{"pointer":"/sections/4/paragraphs/2","offset":530,"length":22},"authors":[{"last":"Bansal"},{"last":"Klein"}],"year":"2010","references":["/references/0"]},{"style":0,"text":"Bod, 2001","origin":{"pointer":"/sections/4/paragraphs/2","offset":687,"length":9},"authors":[{"last":"Bod"}],"year":"2001","references":["/references/2"]},{"style":0,"text":"Zollmann and Sima’an, 2005","origin":{"pointer":"/sections/4/paragraphs/2","offset":809,"length":26},"authors":[{"last":"Zollmann"},{"last":"Sima’an"}],"year":"2005","references":["/references/28"]},{"style":0,"text":"Zuidema, 2007","origin":{"pointer":"/sections/4/paragraphs/2","offset":837,"length":13},"authors":[{"last":"Zuidema"}],"year":"2007","references":["/references/29"]},{"style":0,"text":"Cohn et al., 2009","origin":{"pointer":"/sections/4/paragraphs/2","offset":852,"length":17},"authors":[{"last":"Cohn"},{"last":"al."}],"year":"2009","references":["/references/7"]},{"style":0,"text":"Post and Gildea, 2009a","origin":{"pointer":"/sections/4/paragraphs/2","offset":871,"length":22},"authors":[{"last":"Post"},{"last":"Gildea"}],"year":"2009a","references":["/references/20"]},{"style":0,"text":"Post and Gildea, 2009b","origin":{"pointer":"/sections/4/paragraphs/2","offset":1059,"length":22},"authors":[{"last":"Post"},{"last":"Gildea"}],"year":"2009b","references":["/references/21"]},{"style":0,"text":"Post, 2010","origin":{"pointer":"/sections/4/paragraphs/2","offset":1083,"length":10},"authors":[{"last":"Post"}],"year":"2010","references":["/references/22"]},{"style":0,"text":"Marcus et al., 1993","origin":{"pointer":"/sections/5/paragraphs/0","offset":216,"length":19},"authors":[{"last":"Marcus"},{"last":"al."}],"year":"1993","references":["/references/15"]},{"style":0,"text":"Stolcke, 2002","origin":{"pointer":"/sections/5/paragraphs/2","offset":326,"length":13},"authors":[{"last":"Stolcke"}],"year":"2002","references":["/references/24"]},{"style":0,"text":"Cherry and Quirk (2008)","origin":{"pointer":"/sections/5/paragraphs/5","offset":279,"length":23},"authors":[{"last":"Cherry"},{"last":"Quirk"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Fan et al., 2008","origin":{"pointer":"/sections/5/paragraphs/6","offset":44,"length":16},"authors":[{"last":"Fan"},{"last":"al."}],"year":"2008","references":["/references/8"]},{"style":0,"text":"Charniak, 1996","origin":{"pointer":"/sections/5/paragraphs/7","offset":112,"length":14},"authors":[{"last":"Charniak"}],"year":"1996","references":["/references/4"]},{"style":0,"text":"Post and Gildea, 2009a","origin":{"pointer":"/sections/5/paragraphs/8","offset":49,"length":22},"authors":[{"last":"Post"},{"last":"Gildea"}],"year":"2009a","references":["/references/20"]},{"style":0,"text":"Charniak, 2000","origin":{"pointer":"/sections/5/paragraphs/11","offset":24,"length":14},"authors":[{"last":"Charniak"}],"year":"2000","references":["/references/5"]},{"style":0,"text":"Charniak and Johnson (2005)","origin":{"pointer":"/sections/5/paragraphs/13","offset":113,"length":27},"authors":[{"last":"Charniak"},{"last":"Johnson"}],"year":"2005","references":["/references/3"]},{"style":0,"text":"Cherry and Quirk (2008)","origin":{"pointer":"/sections/5/paragraphs/25","offset":16,"length":23},"authors":[{"last":"Cherry"},{"last":"Quirk"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Johnson, 1998","origin":{"pointer":"/sections/6/paragraphs/1","offset":863,"length":13},"authors":[{"last":"Johnson"}],"year":"1998","references":["/references/13"]},{"style":0,"text":"Petrov et al., 2006","origin":{"pointer":"/sections/6/paragraphs/1","offset":878,"length":19},"authors":[{"last":"Petrov"},{"last":"al."}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Och et al. (2004)","origin":{"pointer":"/sections/7/paragraphs/0","offset":114,"length":17},"authors":[{"last":"Och"},{"last":"al."}],"year":"2004","references":["/references/17"]},{"style":0,"text":"Cherry and Quirk (2008)","origin":{"pointer":"/sections/7/paragraphs/0","offset":279,"length":23},"authors":[{"last":"Cherry"},{"last":"Quirk"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Mutton et al. (2007)","origin":{"pointer":"/sections/7/paragraphs/0","offset":488,"length":20},"authors":[{"last":"Mutton"},{"last":"al."}],"year":"2007","references":["/references/16"]},{"style":0,"text":"Foster and Vogel (2004)","origin":{"pointer":"/sections/7/paragraphs/2","offset":15,"length":23},"authors":[{"last":"Foster"},{"last":"Vogel"}],"year":"2004","references":["/references/10"]},{"style":0,"text":"Sun et al. (2007)","origin":{"pointer":"/sections/7/paragraphs/2","offset":112,"length":17},"authors":[{"last":"Sun"},{"last":"al."}],"year":"2007","references":["/references/25"]},{"style":0,"text":"Wagner et al. (2009)","origin":{"pointer":"/sections/7/paragraphs/2","offset":366,"length":20},"authors":[{"last":"Wagner"},{"last":"al."}],"year":"2009","references":["/references/26"]},{"style":0,"text":"Foster and Andersen (2009)","origin":{"pointer":"/sections/7/paragraphs/2","offset":391,"length":26},"authors":[{"last":"Foster"},{"last":"Andersen"}],"year":"2009","references":["/references/9"]},{"style":0,"text":"Wong and Dras, 2010","origin":{"pointer":"/sections/7/paragraphs/2","offset":927,"length":19},"authors":[{"last":"Wong"},{"last":"Dras"}],"year":"2010","references":["/references/27"]},{"style":0,"text":"Post, 2010","origin":{"pointer":"/sections/7/paragraphs/2","offset":948,"length":10},"authors":[{"last":"Post"}],"year":"2010","references":["/references/22"]},{"style":0,"text":"Foster and Vogel, 2004","origin":{"pointer":"/sections/8/paragraphs/2","offset":197,"length":22},"authors":[{"last":"Foster"},{"last":"Vogel"}],"year":"2004","references":["/references/10"]},{"style":0,"text":"Wagner et al., 2009","origin":{"pointer":"/sections/8/paragraphs/2","offset":221,"length":19},"authors":[{"last":"Wagner"},{"last":"al."}],"year":"2009","references":["/references/26"]}]}
