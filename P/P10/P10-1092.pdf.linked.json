{"sections":[{"title":"","paragraphs":["Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 897–906, Uppsala, Sweden, 11-16 July 2010. c⃝2010 Association for Computational Linguistics"]},{"title":"String Extension Learning Jeffrey Heinz University of Delaware Newark, Delaware, USA heinz@udel.edu Abstract","paragraphs":["This paper provides a unified, learning-theoretic analysis of several learnable classes of languages discussed previously in the literature. The analysis shows that for these classes an incremental, globally consistent, locally conservative, set-driven learner always exists. Additionally, the analysis provides a recipe for constructing new learnable classes. Potential applications include learnable models for aspects of natural language and cognition."]},{"title":"1 Introduction","paragraphs":["The problem of generalizing from examples to patterns is an important one in linguistics and computer science. This paper shows that many disparate language classes, many previously discussed in the literature, have a simple, natural and interesting (because non-enumerative) learner which exactly identifies the class in the limit from distribution-free, positive evidence in the sense of Gold (Gold, 1967).1","These learners are called String Extension Learners because each string in the language can be mapped (extended) to an element of the grammar, which in every case, is conceived as a finite set of elements. These learners have desirable properties: they are incremental, globally consistent, and locally conservative.","Classes previously discussed in the literature which are string extension learnable include the Locally Testable (LT) languages, the Locally Testable Languages in the Strict Sense","1","The allowance of negative evidence (Gold, 1967) or restricting the kinds of texts the learner is required to succeed on (i.e. non-distribution-free evidence) (Gold, 1967; Horn-ing, 1969; Angluin, 1988) admits the learnability of the class of recursively enumerable languages. Classes of languages learnable in the harder, distribution-free, positive-evidence-only settings are due to structural properties of the language classes that permit generalization (Angluin, 1980b; Blumer et al., 1989). That is the central interest here. (Strictly Local, SL) (McNaughton and Papert, 1971; Rogers and Pullum, to appear), the Piecewise Testable (PT) languages (Simon, 1975), the Piecewise Testable languages in the Strict Sense (Strictly Piecewise, SP) (Rogers et al., 2009), the Strongly Testable languages (Beauquier and Pin, 1991), the Definite languages (Brzozowski, 1962), and the Finite languages, among others. To our knowledge, this is the first analysis which identifies the common structural elements of these language classes which allows them to be identifiable in the limit from positive data: each language class induces a natural partition over all logically possible strings and each language in the class is the union of finitely many blocks of this partition.","One consequence of this analysis is a recipe for constructing new learnable classes. One no-table case is the Strictly Piecewise (SP) languages, which was originally motivated for two reasons: the learnability properties discussed here and its ability to describe long-distance dependencies in natural language phonology (Heinz, 2007; Heinz, to appear). Later this class was discovered to have several independent characterizations and form the basis of another subregular hierarchy (Rogers et al., 2009).","It is expected string extension learning will have applications in linguistic and cognitive models. As mentioned, the SP languages already provide a novel hypothesis of how long-distance dependencies in sound patterns are learned. Another example is the Strictly Local (SL) languages which are the categorical, symbolic version of n-gram models, which are widely used in natural language processing (Jurafsky and Martin, 2008). Since the SP languages also admit a probabilistic variant which describe an efficiently estimable class of distribu-tions (Heinz and Rogers, 2010), it is plausible to expect the other classes will as well, though this is left for future research.","String extension learners are also simple, mak-897 ing them accessible to linguists without a rigorous mathematical background.","This paper is organized as follow. §2 goes over basic notation and definitions. §3 defines string extension grammars, languages, and language classes and proves some of their fundamental properties. §4 defines string extension learners and proves their behavior. §5 shows how important subregular classes are string extension language classes. §6 gives examples of nonregular and infinite language classes which are string extension learnable. §7 summarizes the results, and discusses lines of inquiry for future research."]},{"title":"2 Preliminaries","paragraphs":["This section establishes notation and recalls basic definitions for formal languages, the paradigm of identification in the limit from positive data (Gold, 1967). Familiarity with the basic concepts of sets, functions, and sequences is assumed.","For some set A, P(A) denotes the set of all subsets of A and Pfin(A) denotes the set of all finite subsets of A. If f is a function such that f : A → B then let f ⋄","(a) = {f (a)}. Thus, f ⋄",": A → P(B) (note f ⋄","is not surjective). A set π of nonempty subsets of S is a partition of S iff the elements of π (called blocks) are pairwise disjoint and their union equals S.","Σ denotes a fixed finite set of symbols, the alphabet. Let Σn",", Σ≤n",", Σ∗",", Σ+","denote all strings formed over this alphabet of length n, of length less than or equal to n, of any finite length, and of any finite length strictly greater than zero, respectively. The term word is used interchangeably with string. The range of a string w is the set of symbols which are in w. The empty string is the unique string of length zero denoted λ. Thus range(λ) = ∅. The length of a string u is denoted by |u|, e.g. |λ| = 0. A language L is some subset of Σ∗",". The reverse of a language Lr","= {wr",": w ∈ L}.","Gold (1967) establishes a learning paradigm known as identification in the limit from positive data. A text is an infinite sequence whose elements are drawn from Σ∗","∪ {#} where # represents a non-expression. The ith element of t is denoted t(i), and t[i] denotes the finite sequence t(0), t(1), . . . t(i). Following Jain et al. (1999), let SEQ denote the set of all possible finite sequences:","SEQ = {t[i] : t is a text and i ∈ } The content of a text is defined below.","content(t) =","{w ∈ Σ∗",": ∃n ∈","such that t(n) = w}","A text t is a positive text for a language L iff content(t) = L. Thus there is only one text t for the empty language: for all i, t(i) = #.","A learner is a function φ which maps initial finite sequences of texts to grammars, i.e. φ : SEQ → G. The elements of G (the grammars) generate languages in some well-defined way. A learner converges on a text t iff there exists i ∈","and a grammar G such that for all j > i, φ(t[j]) = G.","For any grammar G, the language it generates is denoted L(G). A learner φ identifies a language L in the limit iff for any positive text t for L, φ converges on t to grammar G and L(G) = L. Finally, a learner φ identifies a class of languages L in the limit iff for any L ∈ L, φ identifies L in the limit. Angluin (1980b) provides necessary and sufficient properties of language classes which are identifiable in the limit from positive data.","A learner φ of language class L is globally consistent iff for each i and for all texts t for some L ∈ L, content(t[i]) ⊆ L(φ(t[i])). A learner φ is locally conservative iff for each i and for all texts t for some L ∈ L, whenever φ(t[i]) ̸= φ(t[i − 1]), it is the case that t(i) ̸∈ L(φ([i−1])). These terms are from Jain et al. (2007). Also, learners which do not depend on the order of the text are called set-driven (Jain et al., 1999, p. 99)."]},{"title":"3 Grammars and Languages","paragraphs":["Consider some set A. A string extension function is a total function f : Σ∗","→ Pfin(A). It is not required that f be onto. Denote the class of functions which have this general form SEF .","Each string extension function is naturally as-sociated with some formal class of grammars and languages. These functions, grammars, and languages are called string extension functions, grammars, and languages, respectively. Definition 1 Let f ∈ SEF . 1. A grammar is a finite subset of A. 2. The language of grammar G is","Lf (G) = {w ∈ Σ∗ : f (w) ⊆ G} 898","3. The class of languages obtained by all possible grammars is Lf = {Lf (G) : G ∈ Pfin(A)} The subscript f is omitted when it is understood from context.","A function f ∈ SEF naturally induces a partition πf over Σ∗",". Strings u and v are equivalent (u ∼f v) iff f (u) = f (v). Theorem 1 Every language L ∈ Lf is a finite union of blocks of πf . Proof: Follows directly from the definition of ∼f and the finiteness of string extension grammars. We return to this result in §6. Theorem 2 Lf is closed under intersection. Proof: We show L1∩L2 = L(G1∩G2). Consider any word w belonging to L1 and L2. Then f (w) is a subset of G1 and of G2. Thus f (w) ⊆ G1 ∩ G2, and therefore w ∈ L(G1 ∩ G2). The other inclusion follows similarly. String extension language classes are not in general closed under union or reversal (counterexamples to union closure are given in §5.1 and to reversal closure in §6.)","It is useful to extend the domain of the function f from strings to languages. f (L) = ⋃ w∈L f (w) (1)","An element g of grammar G for language L = Lf (G) is useful iff g ∈ f (L). An element is useless if it is not useful. A grammar with no useless elements is called canonical. Remark 1 Fix a function f ∈ SEF . For every L ∈ Lf , there is a canonical grammar, namely f (L). In other words, L = L(f (L)). Lemma 1 Let L, L′","∈ L","f . L ⊆ L′ iff f (L) ⊆","f (L′ )","Proof: (⇒) Suppose L ⊆ L′","and consider any","g ∈ f (L). Since g is useful, there is a w ∈ L such","that g ∈ f (w). But f (w) ⊆ f (L′",") since w ∈ L′",". (⇐) Suppose f (L) ⊆ f (L′",") and consider any","w ∈ L. Then f (w) ⊆ f (L) so by transitivity,","f (w) ⊆ f (L′","). Therefore w ∈ L′",". The significance of this result is that as the grammar G monotonically increases, the language L(G) monotonically increases too. The following result can now be proved, used in the next section on learning.2 Theorem 3 For any finite L0 ⊆ Σ∗",", L = L(f (L0)) is the smallest language in Lf containing L0. Proof: Clearly L0 ⊆ L. Suppose L′","∈ L","f and","L0 ⊆ L′ . It follows directly from Lemma 1 that","L ⊆ L′ (since f (L) = f (L","0) ⊆ f (L′ ))."]},{"title":"4 String Extension Learning","paragraphs":["Learning string extension classes is simple. The initial hypothesis of the learner is the empty grammar. The learner’s next hypothesis is obtained by applying function f to the current observation and taking the union of that set with the previous one. Definition 2 For all f ∈ SEF and for all t ∈ SEQ, define φf as follows: φf (t[i]) =    ∅ if i = −1 φf (t[i − 1]) if t(i) = # φf (t[i − 1]) ∪ f (t(i)) otherwise","By convention, the initial state of the grammar is given by φ(t[−1]) = ∅. The learner φf exemplifies string extension learning. Each individual string in the text reveals, by extension with f , aspects of the canonical grammar for L ∈ Lf . Theorem 4 φf is globally consistent, locally conservative, and set-driven. Proof: Global consistness and local conservativeness follow immediately from Definition 2. For set-drivenness, witness (by Definition 2) it is the case that for any text t and any i ∈",", φ(t[i]) = f (content(t[i])).","The key to the proof that φf identifies Lf in the limit from positive data is the finiteness of G for all L(G) ∈ L. The idea is that there is a point in the text in which every element of the grammar has been seen because (1) there are only finitely many useful elements of G, and (2) the learner is guaranteed to see a word in L which yields (via f ) each element of G at some point (since the learner receives a positive text for L). Thus at this point","2","The requirement in Theorem 3 that L0 be finite can be dropped if the qualifier “in Lf ” be dropped as well. This can be seen when one considers the identity function and the class of finite languages. (The identity function is a string extension function, see §6.) In this case, id(Σ∗",") = Σ∗",", but Σ∗","is not a member of Lfin. However since the interest here is learners which generalize on the basis of finite experience, Theorem 3 is sufficient as is. 899 the learner φ is guaranteed to have converged to the target G as no additional words will add any more elements to the learner’s grammar. Lemma 2 For all L ∈ Lf , there is a finite sample S such that L is the smallest language in Lf containing S. S is called a characteristic sample of L in Lf (S is also called a tell-tale). Proof: For L ∈ Lf , construct the sample S as follows. For each g ∈ f (L), choose some word w ∈ L such that g ∈ f (w). Since f (L) is finite (Remark 1), S is finite. Clearly f (S) = f (L) and thus L = L(f (S)). Therefore, by Theorem 3, L is the smallest language in Lf containing S. Theorem 5 Fix f ∈ SEF . Then φf identifies Lf in the limit. Proof: For any L ∈ Lf , there is a characteristic finite sample S for L (Lemma 2). Thus for any text t for L, there is i such that S ⊆ content(t[i]). Thus for any j > i, φ(t(j)) is the smallest language in Lf containing S by Theorem 3 and Lemma 2. Thus, φ(t(j)) = f (S) = f (L).","An immediate corollary is the efficiency of φf in the length of the sample, provided f is efficient in the length of the string (de la Higuera, 1997). Corollary 1 φf is efficient in the length of the sample iff f is efficiently computable in the length of a string.","To summarize: string extension grammars are finite subsets of some set A. The class of languages they generate are determined by a function f which maps strings to finite subsets of A (chunks of grammars). Since the size of the canonical grammars is finite, a learner which develops a grammar on the basis of the observed words and the function f identifies this class exactly in the limit from positive data. It also follows that if f is efficient in the length of the string then φf is efficient in the length of the sample and that φf is globally consistent, locally conservative, and set-driven. It is striking that such a natural and general framework for generalization exists and that, as will be shown, a variety of language classes can be expressed given the choice of f ."]},{"title":"5 Subregular examples","paragraphs":["This section shows how classes which make up the subregular hierarchies (McNaughton and Papert, 1971) are string extension language classes. Readers are referred to Rogers and Pullum (2007) and Rogers et al. (2009) for an introduction to the subregular hierarchies, as well as their relevance to linguistics and cognition. 5.1 K-factor languages The k-factors of a word are the contiguous subsequences of length k in w. Consider the following string extension function. Definition 3 For some k ∈",", let","f ack(w) = {x ∈ Σk",": ∃u, v ∈ Σ∗ such that w = uxv} when k ≤ |w| and {w} otherwise","Following the earlier definitions, for some k, a grammar G is a subset of Σ≤k","and a word w belongs to the language of G iff f ack(w) ⊆ G. Example 1 Let Σ = {a, b} and consider grammars G = {λ, a, aa, ab, ba}. Then L(G) = {λ, a} ∪ {w : |w| ≥ 2 and w ̸∈ Σ∗","bbΣ∗","}. The 2-factor bb is a prohibited 2-factor for L(G). Clearly, L(G) ∈ Lfac2 .","Languages in Lfack make distinctions based on which k-factors are permitted or prohibited. Since f ack ∈ SEF , it follows immediately from the results in §§3-4 that the k-factor languages are closed under intersection, and each has a characteristic sample. For example, a characteristic sample for the 2-factor language in Example 1 is {λ, a, ab, ba, aa}; i.e. the canonical grammar itself. It follows from Theorem 5 that the class of k-factor languages is identifiable in the limit by φfack . The learner φfac2 with a text from the language in Example 1 is illustrated in Table 1.","The class Lfack is not closed under union. For example for k = 2, consider L1 = L({λ, a, b, aa, bb, ba}) and L2 = L({λ, a, b, aa, ab, bb}). Then L1 ∪ L2 excludes string aba, but includes ab and ba, which is not possible for any L ∈ Lfack .","K-factors are used to define other language classes, such as the Strictly Local and Locally Testable languages (McNaughton and Papert, 1971), discussed in §5.4 and §5.5. 5.2 Strictly k-Piecewise languages The Strictly k-Piecewise (SPk) languages (Rogers et al., 2009) can be defined with a function whose co-domain is P(Σ≤k","). However unlike the function f ack, the function SPk, does not require that the k-length subsequences be contiguous. 900 i t(i) f ac2(t(i)) Grammar G L(G) -1 ∅ ∅ 0 aaaa {aa} {aa} aaa∗ 1 aab {aa, ab} {aa, ab} aaa∗","∪ aaa∗","b 2 a {a} {a, aa, ab} aa∗","∪ aa∗","b . . . Table 1: The learner φfac2 with a text from the language in Example 1. Boldtype indicates newly added elements to the grammar.","A string u = a1 . . . ak is a subsequence of string w iff ∃ v0, v1, . . . vk ∈ Σ∗","such that w = v0a1v1 . . . akvk. The empty string λ is a subsequence of every string. When u is a subsequence of w we write u ⊑ w.","Definition 4 For some k ∈ ,","SPk(w) = {u ∈ Σ≤k : u ⊑ w}","In other words, SPk(w) returns all subsequences, contiguous or not, in w up to length k. Thus, for some k, a grammar G is a subset of Σ≤k",". Following Definition 1, a word w belongs to the language of G only if SP2(w) ⊆ G.3","Example 2 Let Σ = {a, b} and consider the","grammar G = {λ, a, b, aa, ab, ba}. Then L(G) =","Σ∗ \\(Σ∗","bΣ∗","bΣ∗","). As seen from Example 2, SP languages encode long-distance dependencies. In Example 2, L prohibits a b from following another b in a word, no matter how distant. Table 2 illustrates φSP2 learning the language in Example 2.","Heinz (2007,2009a) shows that consonantal harmony patterns in natural language are describable by such SP2 languages and hypothesizes that humans learn them in the way suggested by φSP2. Strictly 2-Piecewise languages have also been used in models of reading comprehension (Whitney, 2001; Grainger and Whitney, 2004; Whitney and Cornelissen, 2008) as well as text classification(Lodhi et al., 2002; Cancedda et al., 2003) (see also (Shawe-Taylor and Christianini, 2005, chap. 11)). 5.3 K-Piecewise Testable languages A language L is k-Piecewise Testable iff whenever strings u and v have the same subsequences","3","In earlier work, the function SP2 has been described as returning the set of precedence relations in w, and the language class LSP","2 was called the precedence languages (Heinz, 2007; Heinz, to appear). of length at most k and u is in L, then v is in L as well (Simon, 1975; Simon, 1993; Lothaire, 2005).","A language L is said to be Piecewise-Testable (PT) if it is k-Piecewise Testable for some k ∈",". If k is fixed, the k-Piecewise Testable languages are identifiable in the limit from positive data (Garcı́a and Ruiz, 1996; Garcı́a and Ruiz, 2004). More recently, the Piecewise Testable languages has been shown to be linearly separable with a subsequence kernel (Kontorovich et al., 2008).","The k-Piecewise Testable languages can also be described with the function SP ⋄","k . Recall that f ⋄","(a) = {f (a)}. Thus functions SP ⋄","k define grammars as a finite list of sets of subsequences up to length k that may occur in words in the language. This reflects the fact that the k-Piecewise Testable languages are the boolean closure of the Strictly k-Piecewise languages.4 5.4 Strictly k-Local languages To define the Strictly k-Local languages, it is necessary to make a pointwise extension to the definitions in §3. Definition 5 For sets A1, . . . , An, suppose for each i, fi : Σ∗","→ Pfin(Ai), and let f = (f1, . . . , fn).","1. A grammar G is a tuple (G1, . . . , Gn) where G1 ∈ Pfin(A1), . . . , Gn ∈ Pfin(An).","2. If for any w ∈ Σ∗ , each f","i(w) ⊆ Gi for all 1 ≤ i ≤ n, then f (w) is a pointwise subset of G, written f (w) ⊆· G. 3. The language of grammar G is Lf (G) = {w : f (w) ⊆· G}","4. The class of languages obtained by all such possible grammars G is Lf . 4 More generally, it is not hard to show that Lf⋄","is the","boolean closure of Lf . 901 i t(i) SP2(t(i)) Grammar G Language of G","-1 ∅ ∅","0 aaaa {λ, a, aa} {λ, a, aa} a∗","1 aab {λ, a, b, aa, ab} {λ, a, aa, b, ab} a∗ ∪ a∗","b","2 baa {λ, a, b, aa, ba} {λ, a, b, aa, ab, ba} Σ∗ \\(Σ∗","bΣ∗","bΣ∗",")","3 aba {λ, a, b, ab, ba} {λ, a, b, aa, ab, ba} Σ∗ \\(Σ∗","bΣ∗","bΣ∗",")",". . . Table 2: The learner φSP2 with a text from the language in Example 2. Boldtype indicates newly added elements to the grammar.","These definitions preserve the learning results of §4. Note that the characteristic sample of L ∈ Lf will be the union of the characteristic samples of each fi and the language Lf (G) is the intersection of Lfi(Gi).","Locally k-Testable Languages in the Strict Sense (Strictly k-Local) have been studied by several researchers (McNaughton and Papert, 1971; Garcia et al., 1990; Caron, 2000; Rogers and Pullum, to appear), among others. We follow the definitions from (McNaughton and Papert, 1971, p. 14), effectively encoded in the following functions.","Definition 6 Fix k ∈",". Then the (left-edge) pre-","fix of length k, the (right-edge) suffix of length k,","and the interior k-factors of a word w are","Lk(w) = {u ∈ Σk",": ∃v ∈ Σ∗","such that w = uv}","Rk(w) = {u ∈ Σk",": ∃v ∈ Σ∗","such that w = vu} Ik(w) = f ack(w)\\(Lk(w) ∪ Rk(w)) Example 3 Suppose w = abcba. Then L2(w) = {ab}, R2(w) = {ba} and I2(w) = {bc, cb}. Example 4 Suppose |w| = k. Then Lk(w) = Rk(w) = {w} and Ik(w) = ∅. Example 5 Suppose |w| is less than k. Then Lk(w) = Rk(w) = ∅ and Ik(w) = {w}.","A language L is k-Strictly Local (k-SL) iff for all w ∈ L, there exist sets L, R, and I such that w ∈ L iff Lk(w) ⊆ L, Rk(w) ⊆ R, and Ik(w) ⊆ I. McNaughton and Papert note that if w is of length less than k than L may be perfectly arbitrary about w.","This can now be expressed as the string extension function: LRIk(w) = (Lk(w), Rk(w), Ik(w))","Thus for some k, a grammar G is triple formed","by taking subsets of Σk",", Σk",", and Σ≤k",", respec-","tively. A word w belongs to the language of G only if LRIk(w) ⊆· G. Clearly, LLRIk = k-SL, and henceforth we refer to this class as k-SL. Since, for fixed k, LRIk ∈ SEF , all of the learning results in §4 apply. 5.5 Locally k-Testable languages The Locally k-testable languages (k-LT) are originally defined in McNaughton and Papert (1971) and are the subject of several studies (Brzozowski and Simon, 1973; McNaughton, 1974; Kim et al., 1991; Caron, 2000; Garcı́a and Ruiz, 2004; Rogers and Pullum, to appear).","A language L is k-testable iff for all w1, w2 ∈ Σ∗","such that |w1| ≥ k and |w2| ≥ k, and LRIk(w1) = LRIk(w2) then either both w1, w2 belong to L or neither do. Clearly, every language in k-SL belongs to k-LT. However k-LT properly include k-SL because a k-testable language only distinguishes words whenever LRIk(w1) ̸= LRIk(w2). It is known that the k-LT languages are the boolean closure of the k-SL (McNaughton and Papert, 1971).","The function LRI⋄","k exactly expresses k-testable languages. Informally, each word w is mapped to a set containing a single element, this element is the triple LRIk(w). Thus a grammar G is a subset of the triples used to define k-SL. Clearly, LLRI⋄","k = k-LT since it is the boolean closure of LLRIk . Henceforth we refer to LLRI⋄","k as the k-Locally Testable (k-LT) languages. 5.6 Generalized subsequence languages Here we introduce generalized subsequence functions, a general class of functions to which the SPk and f ack functions belong. Like those functions, generalized subsequence functions map words to a set of subsequences found within the words. These functions are instantiated by a vector whose number of coordinates determine how many times a subsequence may be discontiguous 902 and whose coordinate values determine the length of each contiguous part of the subsequence. Definition 7 For some n ∈",", let ⃗v = ⟨v0, v1, . . . , vn⟩, where each vi ∈",". Let k be the length of the subsequences; i.e. k =","∑n 0 vi.","f⃗v(w) = {u ∈ Σk",": ∃x 0, . . . , xn, u0, . . . , un+1 ∈ Σ∗ such that w = u0x0u1x1, . . . , unxnun+1 and |xi| = vi for all 0 ≤ i ≤ n} when k ≤ |w|, and{w} otherwise","The following examples help make the generalized subsequence functions clear. Example 6 Let ⃗v = ⟨2⟩. Then f⟨2⟩ = f ac2. Generally, f⟨k⟩ = f ack. Example 7 Let ⃗v = ⟨1, 1⟩. Then f⟨1,1⟩ = SP2. Generally, if ⃗v = ⟨1, . . . 1⟩ with |⃗v| = k. Then f⃗v = SPk. Example 8 Let ⃗v = ⟨3, 2, 1⟩ and a, b, c, d, e, f ∈ Σ. Then Lf⟨3,2,1⟩ includes languages which prohibit strings w which contain subsequences abcdef where abc and de must be contiguous in w and abcdef is a subsequence of w.","Generalized subsequence languages make different kinds of distinctions to be made than PT and LT languages. For example, the language in Example 8 is neither k-LT nor k′","-PT for any values k, k′",". Generalized subsequence languages properly include the k-SP and k-SL classes (Examples 6 and 7), and the boolean closure of the subsequence languages (f ⋄","⃗v ) properly includes the LT and PT classes.","Since for any ⃗v, f⃗v and f ⋄","⃗v are string extension functions the learning results in §4 apply. Note that f⃗v(w) is computable in time O(|w|k",") where k is the length of the maximal subsequences determined by ⃗v."]},{"title":"6 Other examples","paragraphs":["This section provides examples of infinite and nonregular language classes that are string extension learnable. Recall from Theorem 1 that string extension languages are finite unions of blocks of the partition of Σ∗","induced by f . Assuming the blocks of this partition can be enumerated, the range of f can be construed as Pfin(","). grammar G Language of G ∅ ∅ {0} an","bn {1} Σ∗","\\an","bn {0, 1} Σ∗ Table 3: The language class Lf from Example 9","In the examples considered so far, the enumera-tion of the blocks is essentially encoded in particular substrings (or tuples of substrings). However, much less clever enumerations are available. Example 9 Let A = {0,1} and consider the following function: f (w) = { 0 iff w ∈ an","bn 1 otherwise The function f belongs to SEF because it is maps strings to a finite co-domain. Lf has four languages shown in Table 3. The language class in Example 9 is not regular because it includes the well-known context-free language an","bn",". This collection of languages is also not closed under reversal.","There are also infinite language classes that are string extension language classes. Arguably the simplest example is the class of finite languages, denoted Lfin. Example 10 Consider the function id which maps words in Σ∗","to their singleton sets, i.e. id(w) = {w}.5","A grammar G is then a finite subset of Σ∗",", and so L(G) is just a finite set of words in Σ∗","; in fact, L(G) = G. It follows that Lid = Lfin. It can be easily seen that the function id induces the trivial partition over Σ∗",", and languages are just finite unions of these blocks. The learner φid makes no generalizations at all, and only remembers what it has observed.","There are other more interesting infinite string extension classes. Here is one relating to the Parikh map (Parikh, 1966). For all a ∈ Σ, let fa(w) be the set containing n where n is the number of times the letter a occurs in the string w. For","5","Strictly speaking, this is not the identity function per se, but it is as close to the identity function as one can get since string extension functions are defined as mappings from strings to sets. However, once the domain of the function is extended (Equation 1), then it follows that id is the identity function when its argument is a set of strings. 903 example fa(babab) = {2}. Thus fa is a total function mapping strings to singleton sets of natural numbers, so it is a string extension function. This function induces an infinite partition of Σ∗",", where the words in any particular block have the same number of letters a. It is convenient to enumerate the blocks according to how many occurrences of the letter a may occur in words within the block. Hence, B0 is the block whose words have no occurrences of a, B1 is the block whose words have one occurrence of a, and so on.","In this case, a grammar G is a finite subset of",", e.g. {2, 3, 4}. L(G) is simply those words which have either 2, 3, or 4, occurrences of the letter a. Thus Lfa is an infinite class, which contains languages of infinite size, which is easily identified in the limit from positive data by φfa .","This section gave examples of nonregular and nonfinite string extension classes by pursuing the implications of Theorem 1, which established that f ∈ SEF partition Σ∗","into blocks of which languages are finite unions thereof. The string extension function f provides an effective way of encoding all languages L in Lf because f (L) encodes a finite set, the grammar."]},{"title":"7 Conclusion and open questions","paragraphs":["One contribution of this paper is a unified way of thinking about many formal language classes, all of which have been shown to be identifiable in the limit from positive data by a string extension learner. Another contribution is a recipe for defining classes of languages identifiable in the limit from positive data by this kind of learner.","As shown, these learners have many desirable properties. In particular, they are globally consistent, locally conservative, and set-driven. Additionally, the learner is guaranteed to be efficient in the size of the sample, provided the function f itself is efficient in the length of the string.","Several additional questions of interest remain open for theoretical linguistics, theoretical computer science, and computational linguistics.","For theoretical linguistics, it appears that the string extension function f = (LRI3, P2), which defines a class of languages which obey restric-tions on both contiguous subsequences of length 3 and on discontiguous subsequences of length 2, provides a good first approximation to the segmental phonotactic patterns in natural languages (Heinz, 2007). The string extension learner for this class is essentially two learners: φLRI3 and φP2, operating simultaneously.6","The learners make predictions about generalizations, which can be tested in artificial language learning experiments on adults and infants (Rogers and Pullum, to appear; Chambers et al., 2002; Onishi et al., 2003; Cristiá and Seidl, 2008).7","For theoretical computer science, it remains an open question what property holds of functions f in SEF to ensure that Lf is regular, context-free, or context-sensitive. For known subregular classes, there are constructions that provide deterministic automata that suggest the relevant properties. (See, for example, Garcia et al. (1990) and Garica and Ruiz (1996).)","Also, Timo K ötzing and Samuel Moelius (p.c.) suggest that the results here may be generalized along the following lines. Instead of defining the function f as a map from strings to finite subsets, let f be a function from strings to elements of a lattice. A grammar G is an element of the lattice and the language of the G are all strings w such that f maps w to a grammar less than G. Learners φf are defined as the least upper bound of its current hypothesis and the grammar to which f maps the current word.8","Kasprzik and K ötzing (2010) develop this idea and demonstrate additional properties of string extension classes and learning, and show that the pattern languages (Angluin, 1980a) form a string extension class.9","Also, hyperplane learning (Clark et al., 2006a; Clark et al., 2006b) and function-distinguishable learning (Fernau, 2003) similarly associate language classes with functions. How those analyses relate to the current one remains open.","Finally, since the stochastic counterpart of k-SL class is the n-gram model, it is plausible that probabilistic string extension language classes can form the basis of new natural language process-ing techniques. (Heinz and Rogers, 2010) show","6","This learner resembles what learning theorists call parallel learning (Case and Moelius, 2007) and what cognitive scientists call modular learning (Gallistel and King, 2009).","7","I conjecture that morphological and syntactic patterns are generally not amenable to a string extension learning analysis because these patterns appear to require a paradigm, i.e. a set of data points, before any conclusion can be confidently drawn about the generating grammar. Stress patterns also do not appear to be amenable to a string extension learning (Heinz, 2007; Edlefsen et al., 2008; Heinz, 2009).","8","See also Lange et al. (2008, Theorem 15) and Case et al. (1999, pp.101-103).","9","The basic idea is to consider the lattice","= ⟨Lfin, ⊇⟩. Each element of","is a finite set of strings representing the intersection of all pattern languages consistent with this set. 904 how to efficiently estimate k-SP distributions, and it is conjectured that the other string extension language classes can be recast as classes of distributions, which can also be successfully estimated from positive evidence."]},{"title":"Acknowledgments","paragraphs":["This work was supported by a University of Delaware Research Fund grant during the 2008-2009 academic year. I would like to thank John Case, Alexander Clark, Timo K ötzing, Samuel Moelius, James Rogers, and Edward Stabler for valuable discussion. I would also like to thank Timo K ötzing for careful reading of an earlier draft and for catching some errors. Remaining errors are my responsibility."]},{"title":"References","paragraphs":["Dana Angluin. 1980a. Finding patterns common to a set of strings. Journal of Computer and System Sciences, 21:46–62.","Dana Angluin. 1980b. Inductive inference of formal languages from positive data. Information Control, 45:117–135.","Dana Angluin. 1988. Identifying languages from stochastic examples. Technical Report 614, Yale University, New Haven, CT.","D. Beauquier and J.E. Pin. 1991. Languages and scanners. Theoretical Computer Science, 84:3–21.","Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. 1989. Learnability and the Vapnik-Chervonenkis dimension. J. ACM, 36(4):929–965.","J.A. Brzozowski and I. Simon. 1973. Characterization of locally testable events. Discrete Math, 4:243– 271.","J.A. Brzozowski. 1962. Canonical regular expressions and minimal state graphs for definite events. In Mathematical Theory of Automata, pages 529–561. New York.","Nicola Cancedda, Eric Gaussier, Cyril Goutte, and Jean-Michel Renders. 2003. Word-sequence kernels. Journal of Machine Learning Research, 3:1059–1082.","Pascal Caron. 2000. Families of locally testable languages. Theoretical Computer Science, 242:361– 376.","John Case and Sam Moelius. 2007. Parallelism increases iterative learning power. In 18th Annual Conference on Algorithmic Learning Theory (ALT07), volume 4754 of Lecture Notes in Artificial Intelligence, pages 49–63. Springer-Verlag, Berlin.","John Case, Sanjay Jain, Steffen Lange, and Thomas Zeugmann. 1999. Incremental concept learning for bounded data mining. Information and Computa-tion, 152:74–110.","Kyle E. Chambers, Kristine H. Onishi, and Cynthia Fisher. 2002. Learning phonotactic constraints from brief auditory experience. Cognition, 83:B13–B23.","Alexander Clark, Christophe Costa Florêncio, and Chris Watkins. 2006a. Languages as hyperplanes: grammatical inference with string kernels. In Proceedings of the European Conference on Machine Learning (ECML), pages 90–101.","Alexander Clark, Christophe Costa Florêncio, Chris Watkins, and Mariette Serayet. 2006b. Planar languages and learnability. In Proceedings of the 8th International Colloquium on Grammatical Inference (ICGI), pages 148–160.","Alejandrina Cristiá and Amanda Seidl. 2008. Phonological features in infants phonotactic learning: Evidence from artificial grammar learning. Language, Learning, and Development, 4(3):203–227.","Colin de la Higuera. 1997. Characteristic sets for polynomial grammatical inference. Machine Learning, 27:125–138.","Matt Edlefsen, Dylan Leeman, Nathan Myers, Nathaniel Smith, Molly Visscher, and David Wellcome. 2008. Deciding strictly local (SL) languages. In Jon Breitenbucher, editor, Proceedings of the Midstates Conference for Undergraduate Research in Computer Science and Mathematics, pages 66–73.","Henning Fernau. 2003. Identification of function distinguishable languages. Theoretical Computer Science, 290:1679–1711.","C.R. Gallistel and Adam Philip King. 2009. Memory and the Computational Brain. Wiley-Blackwell.","Pedro Garcı́a and José Ruiz. 1996. Learning k-piecewise testable languages from positive data. In Laurent Miclet and Colin de la Higuera, editors, Grammatical Interference: Learning Syntax from Sentences, volume 1147 of Lecture Notes in Computer Science, pages 203–210. Springer.","Pedro Garcı́a and José Ruiz. 2004. Learning k-testable and k-piecewise testable languages from positive data. Grammars, 7:125–140.","Pedro Garcia, Enrique Vidal, and José Oncina. 1990. Learning locally testable languages in the strict sense. In Proceedings of the Workshop on Algorithmic Learning Theory, pages 325–338.","E.M. Gold. 1967. Language identification in the limit. Information and Control, 10:447–474.","J. Grainger and C. Whitney. 2004. Does the huamn mnid raed wrods as a wlohe? Trends in Cognitive Science, 8:58–59. 905","Jeffrey Heinz and James Rogers. 2010. Estimating strictly piecewise distributions. In Proceedings of the ACL.","Jeffrey Heinz. 2007. The Inductive Learning of Phonotactic Patterns. Ph.D. thesis, University of California, Los Angeles.","Jeffrey Heinz. 2009. On the role of locality in learning stress patterns. Phonology, 26(2):303–351.","Jeffrey Heinz. to appear. Learning long distance phonotactics. Linguistic Inquiry.","J. J. Horning. 1969. A Study of Grammatical Inference. Ph.D. thesis, Stanford University.","Sanjay Jain, Daniel Osherson, James S. Royer, and Arun Sharma. 1999. Systems That Learn: An Introduction to Learning Theory (Learning, Development and Conceptual Change). The MIT Press, 2nd edition.","Sanjay Jain, Steffen Lange, and Sandra Zilles. 2007. Some natural conditions on incremental learning. Information and Computation, 205(11):1671–1684.","Daniel Jurafsky and James Martin. 2008. Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics. Prentice-Hall, Upper Saddle River, NJ, 2nd edition.","Anna Kasprzik and Timo Kötzing. to appear. String extension learning using lattices. In Proceedings of the 4th International Conference on Language and Automata Theory and Applications (LATA 2010), Trier, Germany.","S.M. Kim, R. McNaughton, and R. McCloskey. 1991. A polynomial time algorithm for the local testability problem of deterministic finite automata. IEEE Trans. Comput., 40(10):1087–1093.","Leonid (Aryeh) Kontorovich, Corinna Cortes, and Mehryar Mohri. 2008. Kernel methods for learning languages. Theoretical Computer Science, 405(3):223 – 236. Algorithmic Learning Theory.","Steffen Lange, Thomas Zeugmann, and Sandra Zilles. 2008. Learning indexed families of recursive languages from positive data: A survey. Theoretical Computer Science, 397:194–232.","H. Lodhi, N. Cristianini, J. Shawe-Taylor, and C. Watkins. 2002. Text classification using string kernels. Journal of Machine Language Research, 2:419–444.","M. Lothaire, editor. 2005. Applied Combinatorics on Words. Cmbridge University Press, 2nd edition.","Robert McNaughton and Seymour Papert. 1971. Counter-Free Automata. MIT Press.","R. McNaughton. 1974. Algebraic decision procedures for local testability. Math. Systems Theory, 8:60–76.","Kristine H. Onishi, Kyle E. Chambers, and Cynthia Fisher. 2003. Infants learn phonotactic regularities from brief auditory experience. Cognition, 87:B69– B77.","R. J. Parikh. 1966. On context-free languages. Journal of the ACM, 13, 570581., 13:570–581.","James Rogers and Geoffrey Pullum. to appear. Aural pattern recognition experiments and the subregular hierarchy. Journal of Logic, Language and Information.","James Rogers, Jeffrey Heinz, Gil Bailey, Matt Edlefsen, Molly Visscher, David Wellcome, and Sean Wibel. 2009. On languages piecewise testable in the strict sense. In Proceedings of the 11th Meeting of the Assocation for Mathematics of Language.","John Shawe-Taylor and Nello Christianini. 2005. Kernel Methods for Pattern Analysis. Cambridge University Press.","Imre Simon. 1975. Piecewise testable events. In Automata Theory and Formal Languages, pages 214– 222.","Imre Simon. 1993. The product of rational languages. In ICALP ’93: Proceedings of the 20th International Colloquium on Automata, Languages and Programming, pages 430–444, London, UK. Springer-Verlag.","Carol Whitney and Piers Cornelissen. 2008. SERIOL reading. Language and Cognitive Processes, 23:143–164.","Carol Whitney. 2001. How the brain encodes the order of letters in a printed word: the SERIOL model and selective literature review. Psychonomic Bulletin Review, 8:221–243. 906"]}],"references":[{"authors":[{"first":"Dana","last":"Angluin"}],"year":"1980a","title":"Finding patterns common to a set of strings","source":"Dana Angluin. 1980a. Finding patterns common to a set of strings. Journal of Computer and System Sciences, 21:46–62."},{"authors":[{"first":"Dana","last":"Angluin"}],"year":"1980b","title":"Inductive inference of formal languages from positive data","source":"Dana Angluin. 1980b. Inductive inference of formal languages from positive data. Information Control, 45:117–135."},{"authors":[{"first":"Dana","last":"Angluin"}],"year":"1988","title":"Identifying languages from stochastic examples","source":"Dana Angluin. 1988. Identifying languages from stochastic examples. Technical Report 614, Yale University, New Haven, CT."},{"authors":[{"first":"D.","last":"Beauquier"},{"first":"J.","middle":"E.","last":"Pin"}],"year":"1991","title":"Languages and scanners","source":"D. Beauquier and J.E. Pin. 1991. Languages and scanners. Theoretical Computer Science, 84:3–21."},{"authors":[{"first":"Anselm","last":"Blumer"},{"first":"Andrzej","last":"Ehrenfeucht"},{"first":"David","last":"Haussler"},{"first":"Manfred","middle":"K.","last":"Warmuth"}],"year":"1989","title":"Learnability and the Vapnik-Chervonenkis dimension","source":"Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. 1989. Learnability and the Vapnik-Chervonenkis dimension. J. ACM, 36(4):929–965."},{"authors":[{"first":"J.","middle":"A.","last":"Brzozowski"},{"first":"I.","last":"Simon"}],"year":"1973","title":"Characterization of locally testable events","source":"J.A. Brzozowski and I. Simon. 1973. Characterization of locally testable events. Discrete Math, 4:243– 271."},{"authors":[{"first":"J.","middle":"A.","last":"Brzozowski"}],"year":"1962","title":"Canonical regular expressions and minimal state graphs for definite events","source":"J.A. Brzozowski. 1962. Canonical regular expressions and minimal state graphs for definite events. In Mathematical Theory of Automata, pages 529–561. New York."},{"authors":[{"first":"Nicola","last":"Cancedda"},{"first":"Eric","last":"Gaussier"},{"first":"Cyril","last":"Goutte"},{"first":"Jean-Michel","last":"Renders"}],"year":"2003","title":"Word-sequence kernels","source":"Nicola Cancedda, Eric Gaussier, Cyril Goutte, and Jean-Michel Renders. 2003. Word-sequence kernels. Journal of Machine Learning Research, 3:1059–1082."},{"authors":[{"first":"Pascal","last":"Caron"}],"year":"2000","title":"Families of locally testable languages","source":"Pascal Caron. 2000. Families of locally testable languages. Theoretical Computer Science, 242:361– 376."},{"authors":[{"first":"John","last":"Case"},{"first":"Sam","last":"Moelius"}],"year":"2007","title":"Parallelism increases iterative learning power","source":"John Case and Sam Moelius. 2007. Parallelism increases iterative learning power. In 18th Annual Conference on Algorithmic Learning Theory (ALT07), volume 4754 of Lecture Notes in Artificial Intelligence, pages 49–63. Springer-Verlag, Berlin."},{"authors":[{"first":"John","last":"Case"},{"first":"Sanjay","last":"Jain"},{"first":"Steffen","last":"Lange"},{"first":"Thomas","last":"Zeugmann"}],"year":"1999","title":"Incremental concept learning for bounded data mining","source":"John Case, Sanjay Jain, Steffen Lange, and Thomas Zeugmann. 1999. Incremental concept learning for bounded data mining. Information and Computa-tion, 152:74–110."},{"authors":[{"first":"Kyle","middle":"E.","last":"Chambers"},{"first":"Kristine","middle":"H.","last":"Onishi"},{"first":"Cynthia","last":"Fisher"}],"year":"2002","title":"Learning phonotactic constraints from brief auditory experience","source":"Kyle E. Chambers, Kristine H. Onishi, and Cynthia Fisher. 2002. Learning phonotactic constraints from brief auditory experience. Cognition, 83:B13–B23."},{"authors":[{"first":"Alexander","last":"Clark"},{"first":"Christophe","middle":"Costa","last":"Florêncio"},{"first":"Chris","last":"Watkins"}],"year":"2006a","title":"Languages as hyperplanes: grammatical inference with string kernels","source":"Alexander Clark, Christophe Costa Florêncio, and Chris Watkins. 2006a. Languages as hyperplanes: grammatical inference with string kernels. In Proceedings of the European Conference on Machine Learning (ECML), pages 90–101."},{"authors":[{"first":"Alexander","last":"Clark"},{"first":"Christophe","middle":"Costa","last":"Florêncio"},{"first":"Chris","last":"Watkins"},{"first":"Mariette","last":"Serayet"}],"year":"2006b","title":"Planar languages and learnability","source":"Alexander Clark, Christophe Costa Florêncio, Chris Watkins, and Mariette Serayet. 2006b. Planar languages and learnability. In Proceedings of the 8th International Colloquium on Grammatical Inference (ICGI), pages 148–160."},{"authors":[{"first":"Alejandrina","last":"Cristiá"},{"first":"Amanda","last":"Seidl"}],"year":"2008","title":"Phonological features in infants phonotactic learning: Evidence from artificial grammar learning","source":"Alejandrina Cristiá and Amanda Seidl. 2008. Phonological features in infants phonotactic learning: Evidence from artificial grammar learning. Language, Learning, and Development, 4(3):203–227."},{"authors":[{"first":"Colin","middle":"de la","last":"Higuera"}],"year":"1997","title":"Characteristic sets for polynomial grammatical inference","source":"Colin de la Higuera. 1997. Characteristic sets for polynomial grammatical inference. Machine Learning, 27:125–138."},{"authors":[{"first":"Matt","last":"Edlefsen"},{"first":"Dylan","last":"Leeman"},{"first":"Nathan","last":"Myers"},{"first":"Nathaniel","last":"Smith"},{"first":"Molly","last":"Visscher"},{"first":"David","last":"Wellcome"}],"year":"2008","title":"Deciding strictly local (SL) languages","source":"Matt Edlefsen, Dylan Leeman, Nathan Myers, Nathaniel Smith, Molly Visscher, and David Wellcome. 2008. Deciding strictly local (SL) languages. In Jon Breitenbucher, editor, Proceedings of the Midstates Conference for Undergraduate Research in Computer Science and Mathematics, pages 66–73."},{"authors":[{"first":"Henning","last":"Fernau"}],"year":"2003","title":"Identification of function distinguishable languages","source":"Henning Fernau. 2003. Identification of function distinguishable languages. Theoretical Computer Science, 290:1679–1711."},{"authors":[{"first":"C.","middle":"R.","last":"Gallistel"},{"first":"Adam","middle":"Philip","last":"King"}],"year":"2009","title":"Memory and the Computational Brain","source":"C.R. Gallistel and Adam Philip King. 2009. Memory and the Computational Brain. Wiley-Blackwell."},{"authors":[{"first":"Pedro","last":"Garcı́a"},{"first":"José","last":"Ruiz"}],"year":"1996","title":"Learning k-piecewise testable languages from positive data","source":"Pedro Garcı́a and José Ruiz. 1996. Learning k-piecewise testable languages from positive data. In Laurent Miclet and Colin de la Higuera, editors, Grammatical Interference: Learning Syntax from Sentences, volume 1147 of Lecture Notes in Computer Science, pages 203–210. Springer."},{"authors":[{"first":"Pedro","last":"Garcı́a"},{"first":"José","last":"Ruiz"}],"year":"2004","title":"Learning k-testable and k-piecewise testable languages from positive data","source":"Pedro Garcı́a and José Ruiz. 2004. Learning k-testable and k-piecewise testable languages from positive data. Grammars, 7:125–140."},{"authors":[{"first":"Pedro","last":"Garcia"},{"first":"Enrique","last":"Vidal"},{"first":"José","last":"Oncina"}],"year":"1990","title":"Learning locally testable languages in the strict sense","source":"Pedro Garcia, Enrique Vidal, and José Oncina. 1990. Learning locally testable languages in the strict sense. In Proceedings of the Workshop on Algorithmic Learning Theory, pages 325–338."},{"authors":[{"first":"E.","middle":"M.","last":"Gold"}],"year":"1967","title":"Language identification in the limit","source":"E.M. Gold. 1967. Language identification in the limit. Information and Control, 10:447–474."},{"authors":[{"first":"J.","last":"Grainger"},{"first":"C.","last":"Whitney"}],"year":"2004","title":"Does the huamn mnid raed wrods as a wlohe? Trends in Cognitive Science, 8:58–59","source":"J. Grainger and C. Whitney. 2004. Does the huamn mnid raed wrods as a wlohe? Trends in Cognitive Science, 8:58–59. 905"},{"authors":[{"first":"Jeffrey","last":"Heinz"},{"first":"James","last":"Rogers"}],"year":"2010","title":"Estimating strictly piecewise distributions","source":"Jeffrey Heinz and James Rogers. 2010. Estimating strictly piecewise distributions. In Proceedings of the ACL."},{"authors":[{"first":"Jeffrey","last":"Heinz"}],"year":"2007","title":"The Inductive Learning of Phonotactic Patterns","source":"Jeffrey Heinz. 2007. The Inductive Learning of Phonotactic Patterns. Ph.D. thesis, University of California, Los Angeles."},{"authors":[{"first":"Jeffrey","last":"Heinz"}],"year":"2009","title":"On the role of locality in learning stress patterns","source":"Jeffrey Heinz. 2009. On the role of locality in learning stress patterns. Phonology, 26(2):303–351."},{"authors":[],"source":"Jeffrey Heinz. to appear. Learning long distance phonotactics. Linguistic Inquiry."},{"authors":[{"first":"J.","middle":"J.","last":"Horning"}],"year":"1969","title":"A Study of Grammatical Inference","source":"J. J. Horning. 1969. A Study of Grammatical Inference. Ph.D. thesis, Stanford University."},{"authors":[{"first":"Sanjay","last":"Jain"},{"first":"Daniel","last":"Osherson"},{"first":"James","middle":"S.","last":"Royer"},{"first":"Arun","last":"Sharma"}],"year":"1999","title":"Systems That Learn: An Introduction to Learning Theory (Learning, Development and Conceptual Change)","source":"Sanjay Jain, Daniel Osherson, James S. Royer, and Arun Sharma. 1999. Systems That Learn: An Introduction to Learning Theory (Learning, Development and Conceptual Change). The MIT Press, 2nd edition."},{"authors":[{"first":"Sanjay","last":"Jain"},{"first":"Steffen","last":"Lange"},{"first":"Sandra","last":"Zilles"}],"year":"2007","title":"Some natural conditions on incremental learning","source":"Sanjay Jain, Steffen Lange, and Sandra Zilles. 2007. Some natural conditions on incremental learning. Information and Computation, 205(11):1671–1684."},{"authors":[{"first":"Daniel","last":"Jurafsky"},{"first":"James","last":"Martin"}],"year":"2008","title":"Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics","source":"Daniel Jurafsky and James Martin. 2008. Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics. Prentice-Hall, Upper Saddle River, NJ, 2nd edition."},{"authors":[],"source":"Anna Kasprzik and Timo Kötzing. to appear. String extension learning using lattices. In Proceedings of the 4th International Conference on Language and Automata Theory and Applications (LATA 2010), Trier, Germany."},{"authors":[{"first":"S.","middle":"M.","last":"Kim"},{"first":"R.","last":"McNaughton"},{"first":"R.","last":"McCloskey"}],"year":"1991","title":"A polynomial time algorithm for the local testability problem of deterministic finite automata","source":"S.M. Kim, R. McNaughton, and R. McCloskey. 1991. A polynomial time algorithm for the local testability problem of deterministic finite automata. IEEE Trans. Comput., 40(10):1087–1093."},{"authors":[{"first":"Leonid","middle":"(Aryeh)","last":"Kontorovich"},{"first":"Corinna","last":"Cortes"},{"first":"Mehryar","last":"Mohri"}],"year":"2008","title":"Kernel methods for learning languages","source":"Leonid (Aryeh) Kontorovich, Corinna Cortes, and Mehryar Mohri. 2008. Kernel methods for learning languages. Theoretical Computer Science, 405(3):223 – 236. Algorithmic Learning Theory."},{"authors":[{"first":"Steffen","last":"Lange"},{"first":"Thomas","last":"Zeugmann"},{"first":"Sandra","last":"Zilles"}],"year":"2008","title":"Learning indexed families of recursive languages from positive data: A survey","source":"Steffen Lange, Thomas Zeugmann, and Sandra Zilles. 2008. Learning indexed families of recursive languages from positive data: A survey. Theoretical Computer Science, 397:194–232."},{"authors":[{"first":"H.","last":"Lodhi"},{"first":"N.","last":"Cristianini"},{"first":"J.","last":"Shawe-Taylor"},{"first":"C.","last":"Watkins"}],"year":"2002","title":"Text classification using string kernels","source":"H. Lodhi, N. Cristianini, J. Shawe-Taylor, and C. Watkins. 2002. Text classification using string kernels. Journal of Machine Language Research, 2:419–444."},{"authors":[{"first":"M.","last":"Lothaire"},{"last":"editor"}],"year":"2005","title":"Applied Combinatorics on Words","source":"M. Lothaire, editor. 2005. Applied Combinatorics on Words. Cmbridge University Press, 2nd edition."},{"authors":[{"first":"Robert","last":"McNaughton"},{"first":"Seymour","last":"Papert"}],"year":"1971","title":"Counter-Free Automata","source":"Robert McNaughton and Seymour Papert. 1971. Counter-Free Automata. MIT Press."},{"authors":[{"first":"R.","last":"McNaughton"}],"year":"1974","title":"Algebraic decision procedures for local testability","source":"R. McNaughton. 1974. Algebraic decision procedures for local testability. Math. Systems Theory, 8:60–76."},{"authors":[{"first":"Kristine","middle":"H.","last":"Onishi"},{"first":"Kyle","middle":"E.","last":"Chambers"},{"first":"Cynthia","last":"Fisher"}],"year":"2003","title":"Infants learn phonotactic regularities from brief auditory experience","source":"Kristine H. Onishi, Kyle E. Chambers, and Cynthia Fisher. 2003. Infants learn phonotactic regularities from brief auditory experience. Cognition, 87:B69– B77."},{"authors":[{"first":"R.","middle":"J.","last":"Parikh"}],"year":"1966","title":"On context-free languages","source":"R. J. Parikh. 1966. On context-free languages. Journal of the ACM, 13, 570581., 13:570–581."},{"authors":[],"source":"James Rogers and Geoffrey Pullum. to appear. Aural pattern recognition experiments and the subregular hierarchy. Journal of Logic, Language and Information."},{"authors":[{"first":"James","last":"Rogers"},{"first":"Jeffrey","last":"Heinz"},{"first":"Gil","last":"Bailey"},{"first":"Matt","last":"Edlefsen"},{"first":"Molly","last":"Visscher"},{"first":"David","last":"Wellcome"},{"first":"Sean","last":"Wibel"}],"year":"2009","title":"On languages piecewise testable in the strict sense","source":"James Rogers, Jeffrey Heinz, Gil Bailey, Matt Edlefsen, Molly Visscher, David Wellcome, and Sean Wibel. 2009. On languages piecewise testable in the strict sense. In Proceedings of the 11th Meeting of the Assocation for Mathematics of Language."},{"authors":[{"first":"John","last":"Shawe-Taylor"},{"first":"Nello","last":"Christianini"}],"year":"2005","title":"Kernel Methods for Pattern Analysis","source":"John Shawe-Taylor and Nello Christianini. 2005. Kernel Methods for Pattern Analysis. Cambridge University Press."},{"authors":[{"first":"Imre","last":"Simon"}],"year":"1975","title":"Piecewise testable events","source":"Imre Simon. 1975. Piecewise testable events. In Automata Theory and Formal Languages, pages 214– 222."},{"authors":[{"first":"Imre","last":"Simon"}],"year":"1993","title":"The product of rational languages","source":"Imre Simon. 1993. The product of rational languages. In ICALP ’93: Proceedings of the 20th International Colloquium on Automata, Languages and Programming, pages 430–444, London, UK. Springer-Verlag."},{"authors":[{"first":"Carol","last":"Whitney"},{"first":"Piers","last":"Cornelissen"}],"year":"2008","title":"SERIOL reading","source":"Carol Whitney and Piers Cornelissen. 2008. SERIOL reading. Language and Cognitive Processes, 23:143–164."},{"authors":[{"first":"Carol","last":"Whitney"}],"year":"2001","title":"How the brain encodes the order of letters in a printed word: the SERIOL model and selective literature review","source":"Carol Whitney. 2001. How the brain encodes the order of letters in a printed word: the SERIOL model and selective literature review. Psychonomic Bulletin Review, 8:221–243. 906"}],"cites":[{"style":0,"text":"Gold, 1967","origin":{"pointer":"/sections/2/paragraphs/0","offset":396,"length":10},"authors":[{"last":"Gold"}],"year":"1967","references":["/references/22"]},{"style":0,"text":"Gold, 1967","origin":{"pointer":"/sections/2/paragraphs/4","offset":36,"length":10},"authors":[{"last":"Gold"}],"year":"1967","references":["/references/22"]},{"style":0,"text":"Gold, 1967","origin":{"pointer":"/sections/2/paragraphs/4","offset":159,"length":10},"authors":[{"last":"Gold"}],"year":"1967","references":["/references/22"]},{"style":0,"text":"Horn-ing, 1969","origin":{"pointer":"/sections/2/paragraphs/4","offset":171,"length":14},"authors":[{"last":"Horn-ing"}],"year":"1969","references":[]},{"style":0,"text":"Angluin, 1988","origin":{"pointer":"/sections/2/paragraphs/4","offset":187,"length":13},"authors":[{"last":"Angluin"}],"year":"1988","references":["/references/2"]},{"style":0,"text":"Angluin, 1980b","origin":{"pointer":"/sections/2/paragraphs/4","offset":458,"length":14},"authors":[{"last":"Angluin"}],"year":"1980b","references":["/references/1"]},{"style":0,"text":"Blumer et al., 1989","origin":{"pointer":"/sections/2/paragraphs/4","offset":474,"length":19},"authors":[{"last":"Blumer"},{"last":"al."}],"year":"1989","references":["/references/4"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/2/paragraphs/4","offset":553,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Simon, 1975","origin":{"pointer":"/sections/2/paragraphs/4","offset":652,"length":11},"authors":[{"last":"Simon"}],"year":"1975","references":["/references/45"]},{"style":0,"text":"Rogers et al., 2009","origin":{"pointer":"/sections/2/paragraphs/4","offset":745,"length":19},"authors":[{"last":"Rogers"},{"last":"al."}],"year":"2009","references":["/references/43"]},{"style":0,"text":"Beauquier and Pin, 1991","origin":{"pointer":"/sections/2/paragraphs/4","offset":800,"length":23},"authors":[{"last":"Beauquier"},{"last":"Pin"}],"year":"1991","references":["/references/3"]},{"style":0,"text":"Brzozowski, 1962","origin":{"pointer":"/sections/2/paragraphs/4","offset":850,"length":16},"authors":[{"last":"Brzozowski"}],"year":"1962","references":["/references/6"]},{"style":0,"text":"Heinz, 2007","origin":{"pointer":"/sections/2/paragraphs/5","offset":322,"length":11},"authors":[{"last":"Heinz"}],"year":"2007","references":["/references/25"]},{"style":0,"text":"Rogers et al., 2009","origin":{"pointer":"/sections/2/paragraphs/5","offset":484,"length":19},"authors":[{"last":"Rogers"},{"last":"al."}],"year":"2009","references":["/references/43"]},{"style":0,"text":"Jurafsky and Martin, 2008","origin":{"pointer":"/sections/2/paragraphs/6","offset":400,"length":25},"authors":[{"last":"Jurafsky"},{"last":"Martin"}],"year":"2008","references":["/references/31"]},{"style":0,"text":"Heinz and Rogers, 2010","origin":{"pointer":"/sections/2/paragraphs/6","offset":551,"length":22},"authors":[{"last":"Heinz"},{"last":"Rogers"}],"year":"2010","references":["/references/24"]},{"style":0,"text":"Gold, 1967","origin":{"pointer":"/sections/3/paragraphs/0","offset":150,"length":10},"authors":[{"last":"Gold"}],"year":"1967","references":["/references/22"]},{"style":0,"text":"Gold (1967)","origin":{"pointer":"/sections/3/paragraphs/13","offset":0,"length":11},"authors":[{"last":"Gold"}],"year":"1967","references":["/references/22"]},{"style":0,"text":"Jain et al. (1999)","origin":{"pointer":"/sections/3/paragraphs/14","offset":152,"length":18},"authors":[{"last":"Jain"},{"last":"al."}],"year":"1999","references":["/references/29"]},{"style":0,"text":"Angluin (1980b)","origin":{"pointer":"/sections/3/paragraphs/23","offset":306,"length":15},"authors":[{"last":"Angluin"}],"year":"1980b","references":["/references/1"]},{"style":0,"text":"Jain et al. (2007)","origin":{"pointer":"/sections/3/paragraphs/24","offset":316,"length":18},"authors":[{"last":"Jain"},{"last":"al."}],"year":"2007","references":["/references/30"]},{"style":0,"text":"Jain et al., 1999","origin":{"pointer":"/sections/3/paragraphs/24","offset":419,"length":17},"authors":[{"last":"Jain"},{"last":"al."}],"year":"1999","references":["/references/29"]},{"style":0,"text":"Higuera, 1997","origin":{"pointer":"/sections/5/paragraphs/9","offset":135,"length":13},"authors":[{"last":"Higuera"}],"year":"1997","references":["/references/15"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/6/paragraphs/0","offset":73,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Rogers and Pullum (2007)","origin":{"pointer":"/sections/6/paragraphs/0","offset":165,"length":24},"authors":[{"last":"Rogers"},{"last":"Pullum"}],"year":"2007","references":[]},{"style":0,"text":"Rogers et al. (2009)","origin":{"pointer":"/sections/6/paragraphs/0","offset":194,"length":20},"authors":[{"last":"Rogers"},{"last":"al."}],"year":"2009","references":["/references/43"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/6/paragraphs/10","offset":112,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Rogers et al., 2009","origin":{"pointer":"/sections/6/paragraphs/10","offset":247,"length":19},"authors":[{"last":"Rogers"},{"last":"al."}],"year":"2009","references":["/references/43"]},{"style":0,"text":"Whitney, 2001","origin":{"pointer":"/sections/6/paragraphs/28","offset":274,"length":13},"authors":[{"last":"Whitney"}],"year":"2001","references":["/references/48"]},{"style":0,"text":"Grainger and Whitney, 2004","origin":{"pointer":"/sections/6/paragraphs/28","offset":289,"length":26},"authors":[{"last":"Grainger"},{"last":"Whitney"}],"year":"2004","references":["/references/23"]},{"style":0,"text":"Whitney and Cornelissen, 2008","origin":{"pointer":"/sections/6/paragraphs/28","offset":317,"length":29},"authors":[{"last":"Whitney"},{"last":"Cornelissen"}],"year":"2008","references":["/references/47"]},{"style":0,"text":"Lodhi et al., 2002","origin":{"pointer":"/sections/6/paragraphs/28","offset":379,"length":18},"authors":[{"last":"Lodhi"},{"last":"al."}],"year":"2002","references":["/references/36"]},{"style":0,"text":"Cancedda et al., 2003","origin":{"pointer":"/sections/6/paragraphs/28","offset":399,"length":21},"authors":[{"last":"Cancedda"},{"last":"al."}],"year":"2003","references":["/references/7"]},{"style":0,"text":"Shawe-Taylor and Christianini, 2005","origin":{"pointer":"/sections/6/paragraphs/28","offset":433,"length":35},"authors":[{"last":"Shawe-Taylor"},{"last":"Christianini"}],"year":"2005","references":["/references/44"]},{"style":0,"text":"Heinz, 2007","origin":{"pointer":"/sections/6/paragraphs/31","offset":39,"length":11},"authors":[{"last":"Heinz"}],"year":"2007","references":["/references/25"]},{"style":0,"text":"Simon, 1975","origin":{"pointer":"/sections/6/paragraphs/31","offset":130,"length":11},"authors":[{"last":"Simon"}],"year":"1975","references":["/references/45"]},{"style":0,"text":"Simon, 1993","origin":{"pointer":"/sections/6/paragraphs/31","offset":143,"length":11},"authors":[{"last":"Simon"}],"year":"1993","references":["/references/46"]},{"style":0,"text":"Lothaire, 2005","origin":{"pointer":"/sections/6/paragraphs/31","offset":156,"length":14},"authors":[{"last":"Lothaire"}],"year":"2005","references":[]},{"style":0,"text":"Garcı́a and Ruiz, 1996","origin":{"pointer":"/sections/6/paragraphs/33","offset":102,"length":22},"authors":[{"last":"Garcı́a"},{"last":"Ruiz"}],"year":"1996","references":["/references/19"]},{"style":0,"text":"Garcı́a and Ruiz, 2004","origin":{"pointer":"/sections/6/paragraphs/33","offset":126,"length":22},"authors":[{"last":"Garcı́a"},{"last":"Ruiz"}],"year":"2004","references":["/references/20"]},{"style":0,"text":"Kontorovich et al., 2008","origin":{"pointer":"/sections/6/paragraphs/33","offset":266,"length":24},"authors":[{"last":"Kontorovich"},{"last":"al."}],"year":"2008","references":["/references/34"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/6/paragraphs/59","offset":110,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Garcia et al., 1990","origin":{"pointer":"/sections/6/paragraphs/59","offset":139,"length":19},"authors":[{"last":"Garcia"},{"last":"al."}],"year":"1990","references":["/references/21"]},{"style":0,"text":"Caron, 2000","origin":{"pointer":"/sections/6/paragraphs/59","offset":160,"length":11},"authors":[{"last":"Caron"}],"year":"2000","references":["/references/8"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/6/paragraphs/59","offset":250,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"McNaughton and Papert (1971)","origin":{"pointer":"/sections/6/paragraphs/77","offset":311,"length":28},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Brzozowski and Simon, 1973","origin":{"pointer":"/sections/6/paragraphs/77","offset":380,"length":26},"authors":[{"last":"Brzozowski"},{"last":"Simon"}],"year":"1973","references":["/references/5"]},{"style":0,"text":"McNaughton, 1974","origin":{"pointer":"/sections/6/paragraphs/77","offset":408,"length":16},"authors":[{"last":"McNaughton"}],"year":"1974","references":["/references/39"]},{"style":0,"text":"Kim et al., 1991","origin":{"pointer":"/sections/6/paragraphs/77","offset":426,"length":16},"authors":[{"last":"Kim"},{"last":"al."}],"year":"1991","references":["/references/33"]},{"style":0,"text":"Caron, 2000","origin":{"pointer":"/sections/6/paragraphs/77","offset":444,"length":11},"authors":[{"last":"Caron"}],"year":"2000","references":["/references/8"]},{"style":0,"text":"Garcı́a and Ruiz, 2004","origin":{"pointer":"/sections/6/paragraphs/77","offset":457,"length":22},"authors":[{"last":"Garcı́a"},{"last":"Ruiz"}],"year":"2004","references":["/references/20"]},{"style":0,"text":"McNaughton and Papert, 1971","origin":{"pointer":"/sections/6/paragraphs/79","offset":351,"length":27},"authors":[{"last":"McNaughton"},{"last":"Papert"}],"year":"1971","references":["/references/38"]},{"style":0,"text":"Parikh, 1966","origin":{"pointer":"/sections/7/paragraphs/16","offset":108,"length":12},"authors":[{"last":"Parikh"}],"year":"1966","references":["/references/41"]},{"style":0,"text":"Heinz, 2007","origin":{"pointer":"/sections/8/paragraphs/3","offset":338,"length":11},"authors":[{"last":"Heinz"}],"year":"2007","references":["/references/25"]},{"style":0,"text":"Chambers et al., 2002","origin":{"pointer":"/sections/8/paragraphs/4","offset":170,"length":21},"authors":[{"last":"Chambers"},{"last":"al."}],"year":"2002","references":["/references/11"]},{"style":0,"text":"Onishi et al., 2003","origin":{"pointer":"/sections/8/paragraphs/4","offset":193,"length":19},"authors":[{"last":"Onishi"},{"last":"al."}],"year":"2003","references":["/references/40"]},{"style":0,"text":"Cristiá and Seidl, 2008","origin":{"pointer":"/sections/8/paragraphs/4","offset":214,"length":23},"authors":[{"last":"Cristiá"},{"last":"Seidl"}],"year":"2008","references":["/references/14"]},{"style":0,"text":"Garcia et al. (1990)","origin":{"pointer":"/sections/8/paragraphs/5","offset":317,"length":20},"authors":[{"last":"Garcia"},{"last":"al."}],"year":"1990","references":["/references/21"]},{"style":0,"text":"Garica and Ruiz (1996)","origin":{"pointer":"/sections/8/paragraphs/5","offset":342,"length":22},"authors":[{"last":"Garica"},{"last":"Ruiz"}],"year":"1996","references":[]},{"style":0,"text":"Angluin, 1980a","origin":{"pointer":"/sections/8/paragraphs/7","offset":164,"length":14},"authors":[{"last":"Angluin"}],"year":"1980a","references":["/references/0"]},{"style":0,"text":"Clark et al., 2006a","origin":{"pointer":"/sections/8/paragraphs/8","offset":27,"length":19},"authors":[{"last":"Clark"},{"last":"al."}],"year":"2006a","references":["/references/12"]},{"style":0,"text":"Clark et al., 2006b","origin":{"pointer":"/sections/8/paragraphs/8","offset":48,"length":19},"authors":[{"last":"Clark"},{"last":"al."}],"year":"2006b","references":["/references/13"]},{"style":0,"text":"Fernau, 2003","origin":{"pointer":"/sections/8/paragraphs/8","offset":108,"length":12},"authors":[{"last":"Fernau"}],"year":"2003","references":["/references/17"]},{"style":0,"text":"Heinz and Rogers, 2010","origin":{"pointer":"/sections/8/paragraphs/9","offset":214,"length":22},"authors":[{"last":"Heinz"},{"last":"Rogers"}],"year":"2010","references":["/references/24"]},{"style":0,"text":"Case and Moelius, 2007","origin":{"pointer":"/sections/8/paragraphs/11","offset":71,"length":22},"authors":[{"last":"Case"},{"last":"Moelius"}],"year":"2007","references":["/references/9"]},{"style":0,"text":"Gallistel and King, 2009","origin":{"pointer":"/sections/8/paragraphs/11","offset":148,"length":24},"authors":[{"last":"Gallistel"},{"last":"King"}],"year":"2009","references":["/references/18"]},{"style":0,"text":"Heinz, 2007","origin":{"pointer":"/sections/8/paragraphs/13","offset":361,"length":11},"authors":[{"last":"Heinz"}],"year":"2007","references":["/references/25"]},{"style":0,"text":"Edlefsen et al., 2008","origin":{"pointer":"/sections/8/paragraphs/13","offset":374,"length":21},"authors":[{"last":"Edlefsen"},{"last":"al."}],"year":"2008","references":["/references/16"]},{"style":0,"text":"Heinz, 2009","origin":{"pointer":"/sections/8/paragraphs/13","offset":397,"length":11},"authors":[{"last":"Heinz"}],"year":"2009","references":["/references/26"]}]}
