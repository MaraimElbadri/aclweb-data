{"sections":[{"title":"","paragraphs":["Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1396–1411, Uppsala, Sweden, 11-16 July 2010. c⃝2010 Association for Computational Linguistics"]},{"title":"Supervised Noun Phrase Coreference Research: The First Fifteen Years Vincent Ng Human Language Technology Research Institute University of Texas at Dallas Richardson, TX 75083-0688 vince@hlt.utdallas.edu Abstract","paragraphs":["The research focus of computational coreference resolution has exhibited a shift from heuristic approaches to machine learning approaches in the past decade. This paper surveys the major milestones in supervised coreference research since its inception fifteen years ago."]},{"title":"1 Introduction","paragraphs":["Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue refer to the same real-world entity, has been at the core of natural language processing (NLP) since the 1960s. NP coreference is related to the task of anaphora resolution, whose goal is to identify an antecedent for an anaphoric NP (i.e., an NP that depends on another NP, specifically its antecedent, for its interpretation) [see van Deemter and Kibble (2000) for a detailed discussion of the difference between the two tasks]. Despite its simple task definition, coreference is generally considered a difficult NLP task, typically involving the use of sophisticated knowledge sources and inference procedures (Charniak, 1972). Computational theories of discourse, in particular focusing (see Grosz (1977) and Sidner (1979)) and centering (Grosz et al. (1983; 1995)), have heavily influenced coreference research in the 1970s and 1980s, leading to the development of numerous centering algorithms (see Walker et al. (1998)).","The focus of coreference research underwent a gradual shift from heuristic approaches to machine learning approaches in the 1990s. This shift can be attributed in part to the advent of the statistical NLP era, and in part to the public availability of annotated coreference corpora produced as part of the MUC-6 (1995) and MUC-7 (1998) conferences. Learning-based coreference research has remained vibrant since then, with results regularly published not only in general NLP conferences, but also in specialized conferences (e.g., the biennial Discourse Anaphora and Anaphor Resolution Colloquium (DAARC)) and workshops (e.g., the series of Bergen Workshop on Anaphora Resolution (WAR)). Being inherently a clustering task, coreference has also received a lot of attention in the machine learning community.","Fifteen years have passed since the first paper on learning-based coreference resolution was published (Connolly et al., 1994). Our goal in this paper is to provide NLP researchers with a survey of the major milestones in supervised coreference research, focusing on the computational models, the linguistic features, the annotated corpora, and the evaluation metrics that were developed in the past fifteen years. Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research. This survey paper aims to complement, rather than supersede, these previously published materials. In particular, while existing survey papers discuss learning-based coreference research primarily in the context of the influential mention-pair model, we additionally survey recently proposed learning-based coreference models, which attempt to address the weaknesses of the mention-pair model. Due to space limitations, however, we will restrict our discussion to the most commonly investigated kind of coreference relation: the identity relation for NPs, exclud-ing coreference among clauses and bridging references (e.g., part/whole and set/subset relations)."]},{"title":"2 Annotated Corpora","paragraphs":["The widespread popularity of machine learning approaches to coreference resolution can be attributed in part to the public availability of an-1396 notated coreference corpora. The MUC-6 and MUC-7 corpora, though relatively small (60 documents each) and homogeneous w.r.t. document type (newswire articles only), have been extensively used for training and evaluating coreference models. Equally popular are the corpora produced by the Automatic Content Extraction (ACE1",") evaluations in the past decade: while the earlier ACE corpora (e.g., ACE-2) consist of solely English newswire and broadcast news articles, the later ones (e.g., ACE 2005) have also included Chinese and Arabic documents taken from additional sources such as broadcast conversations, webblog, usenet, and conversational telephone speech.","Coreference annotations are also publicly available in treebanks. These include (1) the English Penn Treebank (Marcus et al., 1993), which is labeled with coreference links as part of the Onto-Notes project (Hovy et al., 2006); (2) the T übingen Treebank (Telljohann et al., 2004), which is a collection of German news articles consisting of 27,125 sentences; (3) the Prague Dependency Treebank (Hajic̆ et al., 2006), which consists of 3168 news articles taken from the Czech National Corpus; (4) the NAIST Text Corpus (Iida et al., 2007b), which consists of 287 Japanese news articles; (5) the AnCora Corpus (Recasens and Martı́, 2009), which consists of Spanish and Catalan journalist texts; and (6) the GENIA corpus (Ohta et al., 2002), which contains 2000 MEDLINE abstracts.","Other publicly available coreference corpora of interest include two annotated by Ruslan Mitkov’s research group: (1) a 55,000-word corpus in the domain of security/terrorism (Hasler et al., 2006); and (2) training data released as part of the 2007 Anaphora Resolution Exercise (Orăsan et al., 2008), a coreference resolution shared task. There are also two that consist of spoken dialogues: the TRAINS93 corpus (Heeman and Allen, 1995) and the Switchboard data set (Calhoun et al., in press).","Additional coreference data will be available in the near future. For instance, the SemEval-2010 shared task on Coreference Resolution in Multiple Languages (Recasens et al., 2009) has promised to release coreference data in six languages. In addi-tion, Massimo Poesio and his colleagues are leading an annotation project that aims to collect large amounts of coreference data for English via a Web Collaboration game called Phrase Detectives2",". 1 http://www.itl.nist.gov/iad/mig/tests/ace/ 2 http://www.phrasedetectives.org"]},{"title":"3 Learning-Based Coreference Models","paragraphs":["In this section, we examine three important classes of coreference models that were developed in the past fifteen years, namely, the mention-pair model, the entity-mention model, and ranking models. 3.1 Mention-Pair Model The mention-pair model is a classifier that determines whether two NPs are coreferent. It was first proposed by Aone and Bennett (1995) and McCarthy and Lehnert (1995), and is one of the most influential learning-based coreference models. Despite its popularity, this binary classification approach to coreference is somewhat undesirable: the transitivity property inherent in the coreference relation cannot be enforced, as it is possible for the model to determine that A and B are coreferent, B and C are coreferent, but A and C are not coreferent. Hence, a separate clustering mechanism is needed to coordinate the pairwise classification decisions made by the model and construct a coreference partition.","Another issue that surrounds the acquisition of the mention-pair model concerns the way training instances are created. Specifically, to determine whether a pair of NPs is coreferent or not, the mention-pair model needs to be trained on a data set where each instance represents two NPs and possesses a class value that indicates whether the two NPs are coreferent. Hence, a natural way to assemble a training set is to create one instance from each pair of NPs appearing in a training document. However, this instance creation method is rarely employed: as most NP pairs in a text are not coreferent, this method yields a training set with a skewed class distribution, where the negative instances significantly outnumber the positives.","As a result, in practical implementations of the mention-pair model, one needs to specify not only the learning algorithm for training the model and the linguistic features for representing an instance, but also the training instance creation method for reducing class skewness and the clustering algorithm for constructing a coreference partition. 3.1.1 Creating Training Instances As noted above, the primary purpose of training instance creation is to reduce class skewness. Many heuristic instance creation methods have been proposed, among which Soon et al.’s (1999; 2001) is arguably the most popular choice. Given 1397 an anaphoric noun phrase3",", NPk, Soon et al.’s method creates a positive instance between NPk and its closest preceding antecedent, NPj , and a negative instance by pairing NPk with each of the intervening NPs, NPj+1, . . ., NPk−1.","With an eye towards improving the precision of a coreference resolver, Ng and Cardie (2002c) propose an instance creation method that involves a single modification to Soon et al.’s method: if NPk is non-pronominal, a positive instance should be formed between NPk and its closest preceding non-pronominal antecedent instead. This modification is motivated by the observation that it is not easy for a human, let alone a machine learner, to learn from a positive instance where the antecedent of a non-pronominal NP is a pronoun.","To further reduce class skewness, some researchers employ a filtering mechanism on top of an instance creation method, thereby disallowing the creation of training instances from NP pairs that are unlikely to be coreferent, such as NP pairs that violate gender and number agreement (e.g., Strube et al. (2002), Yang et al. (2003)).","While many instance creation methods are heuristic in nature (see Uryupina (2004) and Hoste and Daelemans (2005)), some are learning-based. For example, motivated by the fact that some coreference relations are harder to identify than the others (see Harabagiu et al. (2001)), Ng and Cardie (2002a) present a method for mining easy positive instances, in an attempt to avoid the inclusion of hard training instances that may complicate the acquisition of an accurate coreference model. 3.1.2 Training a Coreference Classifier Once a training set is created, we can train a coreference model using an off-the-shelf learning algorithm. Decision tree induction systems (e.g., C5 (Quinlan, 1993)) are the first and one of the most widely used learning algorithms by coreference researchers, although rule learners (e.g., RIPPER (Cohen, 1995)) and memory-based learners (e.g., TiMBL (Daelemans and Van den Bosch, 2005)) are also popular choices, especially in early applications of machine learning to coreference resolution. In recent years, statistical learners such as maximum entropy models (Berger et al., 1996), voted perceptrons (Freund and Schapire, 1999),","3","In this paper, we use the term anaphoric to describe any NP that is part of a coreference chain but is not the head of the chain. Hence, proper names can be anaphoric under this overloaded definition, but linguistically, they are not. and support vector machines (Joachims, 1999) have been increasingly used, in part due to their ability to provide a confidence value (e.g., in the form of a probability) associated with a classification, and in part due to the fact that they can be easily adapted to train recently proposed ranking-based coreference models (see Section 3.3). 3.1.3 Generating an NP Partition After training, we can apply the resulting model to a test text, using a clustering algorithm to coordinate the pairwise classification decisions and impose an NP partition. Below we describe some commonly used coreference clustering algorithms.","Despite their simplicity, closest-first clustering (Soon et al., 2001) and best-first clustering (Ng and Cardie, 2002c) are arguably the most widely used coreference clustering algorithms. The closest-first clustering algorithm selects as the antecedent for an NP, NPk, the closest preceding noun phrase that is classified as coreferent with it.4 However, if no such preceding noun phrase exists, no antecedent is selected for NPk. The best-first clustering algorithm aims to improve the precision of closest-first clustering, specifically by selecting as the antecedent of NPk the most probable preceding NP that is classified as coreferent with it.","One criticism of the closest-first and best-first clustering algorithms is that they are too greedy. In particular, clusters are formed based on a small subset of the pairwise decisions made by the model. Moreover, positive pairwise decisions are unjustifiably favored over their negative counterparts. For example, three NPs are likely to end up in the same cluster in the resulting partition even if there is strong evidence that A and C are not coreferent, as long as the other two pairs (i.e., (A,B) and (B,C)) are classified as positive.","Several algorithms that address one or both of these problems have been used for coreference clustering. Correlation clustering (Bansal et al., 2002), which produces a partition that respects as many pairwise decisions as possible, is used by McCallum and Wellner (2004), Zelenko et al. (2004), and Finley and Joachims (2005). Graph partitioning algorithms are applied on a weighted, undirected graph where a vertex corresponds to an NP and an edge is weighted by the pairwise coreference scores between two NPs (e.g., McCallum and Wellner (2004), Nicolae and Nico-","4","If a probabilistic model is used, we can define a threshold above which a pair of NPs is considered coreferent. 1398 lae (2006)). The Dempster-Shafer rule (Dempster, 1968), which combines the positive and negative pairwise decisions to score a partition, is used by Kehler (1997) and Bean and Riloff (2004) to identify the most probable NP partition.","Some clustering algorithms bear a closer resemblance to the way a human creates coreference clusters. In these algorithms, not only are the NPs in a text processed in a left-to-right manner, the later coreference decisions are dependent on the earlier ones (Cardie and Wagstaff, 1999; Klenner and Ailloud, 2008).5","For example, to resolve an NP, NPk, Cardie and Wagstaff’s algorithm considers each preceding NP, NPj , as a candidate antecedent in a right-to-left order. If NPk and NPj are likely to be coreferent, the algorithm imposes an additional check that NPk does not violate any constraint on coreference (e.g., gender agreement) with any NP in the cluster containing NPj before positing that the two NPs are coreferent.","Luo et al.’s (2004) Bell-tree-based algorithm is another clustering algorithm where the later coreference decisions are dependent on the earlier ones. A Bell tree provides an elegant way of organizing the space of NP partitions. Informally, a node in the ith level of a Bell tree corresponds to an ith-order partial partition (i.e., a partition of the first i NPs of the given document), and the ith level of the tree contains all possible ith-order partial partitions. Hence, a leaf node contains a complete partition of the NPs, and the goal is to search for the leaf node that contains the most probable partition. The search starts at the root, and a partitioning of the NPs is incrementally constructed as we move down the tree. Specifically, based on the coreference decisions it has made in the first i−1 levels of the tree, the algorithm determines at the ith level whether the ith NP should start a new cluster, or to which preceding cluster it should be assigned.","While many coreference clustering algorithms have been developed, there have only been a few attempts to compare their effectiveness. For example, Ng and Cardie (2002c) report that best-first clustering is better than closest-first clustering. Nicolae and Nicolae (2006) show that best-first clustering performs similarly to Bell-tree-based clustering, but neither of these algorithms","5","When applying closest-first and best-first clustering, Soon et al. (2001) and Ng and Cardie (2002c) also process the NPs in a sequential manner, but since the later decisions are not dependent on the earlier ones, the order in which the NPs are processed does not affect their clustering results. performs as well as their proposed minimum-cut-based graph partitioning algorithm. 3.1.4 Determining NP Anaphoricity While coreference clustering algorithms attempt to resolve each NP encountered in a document, only a subset of the NPs are anaphoric and therefore need to be resolved. Hence, knowledge of the anaphoricity of an NP can potentially improve the precision of a coreference resolver.","Traditionally, the task of anaphoricity determination has been tackled independently of coreference resolution using a variety of techniques. For example, pleonastic it has been identified using heuristic approaches (e.g., Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996)), supervised approaches (e.g., Evans (2001), Müller (2006), Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al. (2008)); and non-anaphoric definite descriptions have been identified using rule-based techniques (e.g., Vieira and Poesio (2000)) and unsupervised techniques (e.g., Bean and Riloff (1999)).","Recently, anaphoricity determination has been evaluated in the context of coreference resolution, with results showing that training an anaphoricity classifier to identify and filter non-anaphoric NPs prior to coreference resolution can improve a learning-based resolver (e.g., Ng and Cardie (2002b), Uryupina (2003), Poesio et al. (2004b)). Compared to earlier work on anaphoricity determination, recently proposed approaches are more “global” in nature, taking into account the pairwise decisions made by the mention-pair model when making anaphoricity decisions. Examples of such approaches have exploited techniques including integer linear programming (ILP) (Denis and Baldridge, 2007a), label propagation (Zhou and Kong, 2009), and minimum cuts (Ng, 2009). 3.1.5 Combining Classification & Clustering From a learning perspective, a two-step approach to coreference — classification and clustering — is undesirable. Since the classification model is trained independently of the clustering algorithm, improvements in classification accuracy do not guarantee corresponding improvements in clustering-level accuracy. That is, overall performance on the coreference task might not improve.","To address this problem, McCallum and Wellner (2004) and Finley and Joachims (2005) eliminate the classification step entirely, treating coref-1399 erence as a supervised clustering task where a similarity metric is learned to directly maximize clustering accuracy. Klenner (2007) and Finkel and Manning (2008) use ILP to ensure that the pairwise classification decisions satisfy transitivity.6 3.1.6 Weaknesses of the Mention-Pair Model While many of the aforementioned algorithms for clustering and anaphoricity determination have been shown to improve coreference performance, the underlying model with which they are used in combination — the mention-pair model — remains fundamentally weak. The model has two commonly-cited weaknesses. First, since each candidate antecedent for an anaphoric NP to be resolved is considered independently of the others, the model only determines how good a candidate antecedent is relative to the anaphoric NP, but not how good a candidate antecedent is relative to other candidates. In other words, it fails to answer the question of which candidate antecedent is most probable. Second, it has limitations in its expressiveness: the information extracted from the two NPs alone may not be sufficient for making an in-formed coreference decision, especially if the candidate antecedent is a pronoun (which is semantically empty) or a mention that lacks descriptive information such as gender (e.g., “Clinton”). Below we discuss how these weaknesses are addressed by the entity-mention model and ranking models. 3.2 Entity-Mention Model The entity-mention model addresses the expressiveness problem with the mention-pair model. To motivate the entity-mention model, consider an example taken from McCallum and Wellner (2003), where a document consists of three NPs: “Mr. Clinton,” “Clinton,” and “she.” The mention-pair model may determine that “Mr. Clinton” and “Clinton” are coreferent using string-matching features, and that “Clinton” and “she” are coreferent based on proximity and lack of evidence for gender and number disagreement. However, these two pairwise decisions together with transitivity imply that “Mr. Clinton” and “she” will end up in the same cluster, which is incorrect due to gender mismatch. This kind of error arises in part because the later coreference decisions are not dependent on the earlier ones. In particular, had the model taken into consideration that “Mr. Clinton”","6","Recently, however, Klenner and Ailloud (2009) have be-come less optimistic about ILP approaches to coreference. and “Clinton” were in the same cluster, it probably would not have posited that “she” and “Clinton” are coreferent. The aforementioned Cardie and Wagstaff algorithm attempts to address this problem in a heuristic manner. It would be desirable to learn a model that can classify whether an NP to be resolved is coreferent with a preceding, possibly partially-formed, cluster. This model is commonly known as the entity-mention model.","Since the entity-mention model aims to classify whether an NP is coreferent with a preceding cluster, each of its training instances (1) corresponds to an NP, NPk, and a preceding cluster, Cj, and (2) is labeled with either POSITIVE or NEGATIVE, depending on whether NPk should be assigned to Cj. Consequently, we can represent each instance by a set of cluster-level features (i.e., features that are defined over an arbitrary subset of the NPs in Cj). A cluster-level feature can be computed from a feature employed by the mention-pair model by applying a logical predicate. For example, given the NUMBER AGREEMENT feature, which determines whether two NPs agree in number, we can apply the ALL predicate to create a cluster-level feature, which has the value YES if NPk agrees in number with all of the NPs in Cj and NO other-wise. Other commonly-used logical predicates for creating cluster-level features include relaxed versions of the ALL predicate, such as MOST, which is true if NPk agrees in number with more than half of the NPs in Cj, and ANY, which is true as long as NPk agrees in number with just one of the NPs in Cj. The ability of the entity-mention model to employ cluster-level features makes it more expressive than its mention-pair counterpart.","Despite its improved expressiveness, the entity-mention model has not yielded particularly encouraging results. For example, Luo et al. (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model. Yang et al. (2004b; 2008a) also investigate the entity-mention model, which produces results that are only marginally better than those of the mention-pair model. However, it appears that they are not fully exploiting the expressiveness of the entity-mention model, as cluster-level features only comprise a small fraction of their features.","Variants of the entity-mention model have been investigated. For example, Culotta et al. (2007) present a first-order logic model that determines 1400 the probability that an arbitrary set of NPs are all co-referring. Their model resembles the entity-mention model in that it enables the use of cluster-level features. Daumé III and Marcu (2005) propose an online learning model for constructing coreference chains in an incremental fashion, allowing later coreference decisions to be made by exploiting cluster-level features that are computed over the coreference chains created thus far. 3.3 Ranking Models While the entity-mention model addresses the expressiveness problem with the mention-pair model, it does not address the other problem: failure to identify the most probable candidate antecedent. Ranking models, on the other hand, allow us to determine which candidate antecedent is most probable given an NP to be resolved. Ranking is arguably a more natural reformula-tion of coreference resolution than classification, as a ranker allows all candidate antecedents to be considered simultaneously and therefore directly captures the competition among them. Another desirable consequence is that there exists a natural resolution strategy for a ranking approach: an anaphoric NP is resolved to the candidate antecedent that has the highest rank. This contrasts with classification-based approaches, where many clustering algorithms have been employed to coordinate the pairwise classification decisions, and it is still not clear which of them is the best.","The notion of ranking candidate antecedents can be traced back to centering algorithms, many of which use grammatical roles to rank forwardlooking centers (see Walker et al. (1998)). Ranking is first applied to learning-based coreference resolution by Connolly et al. (1994; 1997), where a model is trained to rank two candidate antecedents. Each training instance corresponds to the NP to be resolved, NPk, as well as two candidate antecedents, NPi and NPj , one of which is an antecedent of NPk and the other is not. Its class value indicates which of the two candidates is better. This model is referred to as the tournament model by Iida et al. (2003) and the twin-candidate model by Yang et al. (2003; 2008b). To resolve an NP during testing, one way is to apply the model to each pair of its candidate antecedents, and the candidate that is classified as better the largest number of times is selected as its antecedent.","Advances in machine learning have made it possible to train a mention ranker that ranks all of the candidate antecedents simultaneously. While mention rankers have consistently outperformed the mention-pair model (Versley, 2006; Denis and Baldridge, 2007b), they are not more expressive than the mention-pair model, as they are unable to exploit cluster-level features, unlike the entity-mention model. To enable rankers to employ cluster-level features, Rahman and Ng (2009) propose the cluster-ranking model, which ranks preceding clusters, rather than candidate antecedents, for an NP to be resolved. Cluster rankers therefore address both weaknesses of the mention-pair model, and have been shown to improve mention rankers. Cluster rankers are conceptually similar to Lappin and Leass’s (1994) heuristic pronoun resolver, which resolves an anaphoric pronoun to the most salient preceding cluster.","An important issue with ranking models that we have eluded so far concerns the identification of non-anaphoric NPs. As a ranker simply imposes a ranking on candidate antecedents or preceding clusters, it cannot determine whether an NP is anaphoric (and hence should be resolved). To address this problem, Denis and Baldridge (2008) apply an independently trained anaphoricity classifier to identify non-anaphoric NPs prior to ranking, and Rahman and Ng (2009) propose a model that jointly learns coreference and anaphoricity."]},{"title":"4 Knowledge Sources","paragraphs":["Another thread of supervised coreference research concerns the development of linguistic features. Below we give an overview of these features.","String-matching features can be computed robustly and typically contribute a lot to the performance of a coreference system. Besides simple string-matching operations such as exact string match, substring match, and head noun match for different kinds of NPs (see Daumé III and Marcu (2005)), slightly more sophisticated string-matching facilities have been attempted, including minimum edit distance (Strube et al., 2002) and longest common subsequence (Castaño et al., 2002). Yang et al. (2004a) treat the two NPs involved as two bags of words, and compute their similarity using metrics commonly-used in information retrieval, such as the dot product, with each word weighted by their TF-IDF value.","Syntactic features are computed based on a syntactic parse tree. Ge et al. (1998) implement 1401 a Hobbs distance feature, which encodes the rank assigned to a candidate antecedent for a pronoun by Hobbs’s (1978) seminal syntax-based pronoun resolution algorithm. Luo and Zitouni (2005) extract features from a parse tree for implement-ing Binding Constraints (Chomsky, 1988). Given an automatically parsed corpus, Bergsma and Lin (2006) extract from each parse tree a dependency path, which is represented as a sequence of nodes and dependency labels connecting a pronoun and a candidate antecedent, and collect statistical information from these paths to determine the likelihood that a pronoun and a candidate antecedent connected by a given path are coreferent. Rather than deriving features from parse trees, Iida et al. (2006) and Yang et al. (2006) employ these trees directly as structured features for pronoun resolution. Specifically, Yang et al. define tree kernels for efficiently computing the similarity between two parse trees, and Iida et al. use a boosting-based algorithm to compute the usefulness of a subtree.","Grammatical features encode the grammatical properties of one or both NPs involved in an instance. For example, Ng and Cardie’s (2002c) resolver employs 34 grammatical features. Some features determine NP type (e.g., are both NPs definite or pronouns?). Some determine the grammatical role of one or both of the NPs. Some encode traditional linguistic (hard) constraints on coreference. For example, coreferent NPs have to agree in number and gender and cannot span one another (e.g., “Google” and “Google employees”). There are also features that encode general linguistic preferences either for or against coreference. For example, an indefinite NP (that is not in apposition to an anaphoric NP) is not likely to be coreferent with any NP that precedes it.","There has been an increasing amount of work on investigating semantic features for coreference resolution. One of the earliest kinds of semantic knowledge employed for coreference resolution is perhaps selectional preference (Dagan and Itai, 1990; Kehler et al., 2004b; Yang et al., 2005; Haghighi and Klein, 2009): given a pronoun to be resolved, its governing verb, and its grammatical role, we prefer a candidate antecedent that can be governed by the same verb and be in the same role. Semantic knowledge has also been extracted from WordNet and unannotated corpora for computing the semantic compatibility/similarity between two common nouns (Harabagiu et al., 2001; Versley, 2007) as well as the semantic class of a noun (Ng, 2007a; Huang et al., 2009). One difficulty with deriving knowledge from WordNet is that one has to determine which sense of a given word to use. Some researchers simply use the first sense (Soon et al., 2001) or all possible senses (Ponzetto and Strube, 2006a), while others overcome this problem with word sense disambiguation (Nicolae and Nicolae, 2006). Knowledge has also been mined from Wikipedia for measuring the semantic relatedness of two NPs, NPj and NPk (Ponzetto and Strube (2006a; 2007)), such as: whether NPj/k appears in the first paragraph of the Wiki page that has NPk/j as the title or in the list of categories to which this page belongs, and the degree of overlap between the two pages that have the two NPs as their titles (see Poesio et al. (2007) for other uses of encyclopedic knowledge for coreference resolution). Contextual roles (Bean and Riloff, 2004), semantic relations (Ji et al., 2005), semantic roles (Ponzetto and Strube, 2006b; Kong et al., 2009), and animacy (Orăsan and Evans, 2007) have also been exploited to improve coreference resolution.","Lexico-syntactic patterns have been used to capture the semantic relatedness between two NPs and hence the likelihood that they are coreferent. For instance, given the pattern X is a Y (which is highly indicative that X and Y are coreferent), we can instantiate it with a pair of NPs and search for the instantiated pattern in a large corpus or the Web (Daumé III and Marcu, 2005; Haghighi and Klein, 2009). The more frequently the pattern occurs, the more likely they are coreferent. This technique has been applied to resolve different kinds of anaphoric references, including other-anaphora (Modjeska et al., 2003; Markert and Nissim, 2005) and bridging references (Poesio et al., 2004a). While these patterns are typically hand-crafted (e.g., Garera and Yarowsky (2006)), they can also be learned from an annotated corpus (Yang and Su, 2007) or bootstrapped from an unannotated corpus (Bean and Riloff, 2004).","Despite the large amount of work on discourse-based anaphora resolution in the 1970s and 1980s (see Hirst (1981)), learning-based resolvers have only exploited shallow discourse-based features, which primarily involve characterizing the salience of a candidate antecedent by measuring its distance from the anaphoric NP to be resolved or determining whether it is in a prominent grammatical role (e.g., subject). A notable exception 1402 is Iida et al. (2009), who train a ranker to rank the candidate antecedents for an anaphoric pronoun by their salience. It is worth noting that Tetreault (2005) has employed Grosz and Sidner’s (1986) discourse theory and Veins Theory (Ide and Cristea, 2000) to identify and remove candidate antecedents that are not referentially accessible to an anaphoric pronoun in his heuristic pronoun resolvers. It would be interesting to in-corporate this idea into a learning-based resolver.","There are also features that do not fall into any of the preceding categories. For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance (Bengtson and Roth, 2008). Memoriza-tion features have been used as binary-valued features indicating the presence or absence of their words (Luo et al., 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b). An anaphoricity feature indicates whether an NP to be resolved is anaphoric, and is typically computed using an anaphoricity classifier (Ng, 2004), hand-crafted patterns (Daumé III and Marcu, 2005), and automatically acquired patterns (Bean and Riloff, 1999). Finally, the outputs of rule-based pronoun and coreference resolvers have also been used as features for learning-based coreference resolution (Ng and Cardie, 2002c).","For an empirical evaluation of the contribution of a subset of these features to the mention-pair model, see Bengtson and Roth (2008)."]},{"title":"5 Evaluation Issues","paragraphs":["Two important issues surround the evaluation of a coreference resolver. First, how do we obtain the set of NPs that a resolver will partition? Second, how do we score the partition it produces? 5.1 Extracting Candidate Noun Phrases To obtain the set of NPs to be partitioned by a resolver, three methods are typically used. In the first method, the NPs are extracted automatically from a syntactic parser. The second method involves extracting the NPs directly from the gold standard. In the third method, a mention detector is first trained on the gold-standard NPs in the training texts, and is then applied to automatically extract system mentions in a test text.7","Note that 7 An exception is Daumé III and Marcu (2005), whose","model jointly learns to extract NPs and perform coreference. these three extraction methods typically produce different numbers of NPs: the NPs extracted from a parser tend to significantly outnumber the system mentions, which in turn outnumber the gold NPs. The reasons are two-fold. First, in some coreference corpora (e.g., MUC-6 and MUC-7), the NPs that are not part of any coreference chain are not annotated. Second, in corpora such as those produced by the ACE evaluations, only the NPs that belong to one of the ACE entity types (e.g., PER-SON, ORGANIZATION, LOCATION) are annotated.","Owing in large part to the difference in the number of NPs extracted by these three methods, a coreference resolver can produce substantially different results when applied to the resulting three sets of NPs, with gold NPs yielding the best results and NPs extracted from a parser yielding the worst (Nicolae and Nicolae, 2006). While researchers who evaluate their resolvers on gold NPs point out that the results can more accurately reflect the performance of their coreference algorithm, Stoyanov et al. (2009) argue that such evaluations are unrealistic, as NP extraction is an integral part of an end-to-end fully-automatic resolver.","Whichever NP extraction method is employed, it is clear that the use of gold NPs can considerably simplify the coreference task, and hence resolvers employing different extraction methods should not be compared against each other. 5.2 Scoring a Coreference Partition The MUC scorer (Vilain et al., 1995) is the first program developed for scoring coreference partitions. It has two often-cited weaknesses. As a link-based measure, it does not reward correctly identified singleton clusters since there is no coreference link in these clusters. Also, it tends to underpenalize partitions with overly large clusters.","To address these problems, two coreference scoring programs have been developed: B3 (Bagga and Baldwin, 1998) and CEAF (Luo, 2005). Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition. To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)).","Since coreference is a clustering task, any general-purpose method for evaluating a response partition against a key partition (e.g., Kappa (Carletta, 1996)) can be used for coreference scor-1403 ing (see Popescu-Belis et al. (2004)). In practice, these general-purpose methods are typically used to provide scores that complement those obtained via the three coreference scorers discussed above. It is worth mentioning that there is a trend towards evaluating a resolver against multiple scorers, which can indirectly help to counteract the bias inherent in a particular scorer. For further discussion on evaluation issues, see Byron (2001)."]},{"title":"6 Concluding Remarks","paragraphs":["While we have focused our discussion on supervised approaches, coreference researchers have also attempted to reduce a resolver’s reliance on annotated data by combining a small amount of labeled data and a large amount of unlabeled data using general-purpose semi-supervised learning algorithms such as co-training (Müller et al., 2002), self-training (Kehler et al., 2004a), and EM (Cherry and Bergsma, 2005; Ng, 2008). Interestingly, recent results indicate that unsupervised approaches to coreference resolution (e.g., Haghighi and Klein (2007; 2010), Poon and Domingos (2008)) rival their supervised counterparts, casting doubts on whether supervised resolvers are making effective use of the available labeled data.","Another issue that we have not focused on but which is becoming increasingly important is multilinguality. While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu. y et al. (2009)). In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)).","As Mitkov (2001) puts it, coreference resolution is a “difficult, but not intractable problem,” and we have been making “slow, but steady progress” on improving machine learning approaches to the problem in the past fifteen years. To ensure further progress, researchers should compare their results against a baseline that is stronger than the commonly-used Soon et al. (2001) system, which relies on a weak model (i.e., the mention-pair model) and a small set of linguistic features. As recent systems are becoming more sophisticated, we suggest that researchers make their systems publicly available in order to facilitate performance comparisons. Publicly available coreference systems currently include JavaRAP (Qiu et al., 2004), GuiTaR (Poesio and Kabadjov, 2004), BART (Versley et al., 2008b), CoRTex (Denis and Baldridge, 2008), the Illinois Coreference Package (Bengtson and Roth, 2008), CherryPicker (Rahman and Ng, 2009), Reconcile (Stoyanov et al., 2010), and Charniak and Elsner’s (2009) pronoun resolver.","We conclude with a discussion of two questions regarding supervised coreference research. First, what is the state of the art? This is not an easy question, as researchers have been evaluating their resolvers on different corpora using different evaluation metrics and preprocessing tools. In particular, preprocessing tools can have a large impact on the performance of a resolver (Barbu and Mitkov, 2001). Worse still, assumptions about whether gold or automatically extracted NPs are used are sometimes not explicitly stated, potentially causing results to be interpreted incorrectly. To our knowledge, however, the best results on the MUC-6 and MUC-7 data sets using automatically extracted NPs are reported by Yang et al. (2003) (71.3 MUC F-score) and Ng and Cardie (2002c) (63.4 MUC F-score), respectively;8","and the best results on the ACE data sets using gold NPs can be found in Luo (2007) (88.4 ACE-value).","Second, what lessons can we learn from fifteen years of learning-based coreference research? The mention-pair model is weak because it makes coreference decisions based on local information (i.e., information extracted from two NPs). Expressive models (e.g., those that can exploit cluster-level features) generally offer better performance, and so are models that are “global” in nature. Global coreference models may refer to any kind of models that can exploit non-local information, including models that can consider multiple candidate antecedents simultaneously (e.g., ranking models), models that allow joint learning for coreference resolution and related tasks (e.g., anaphoricity determination), models that can directly optimize clustering-level (rather than classification) accuracy, and models that can coordinate with other components of a resolver, such as training instance creation and clustering.","8","These results by no means suggest that no progress has been made since 2003: most of the recently proposed coreference models were evaluated on the ACE data sets. 1404"]},{"title":"Acknowledgments","paragraphs":["We thank the three anonymous reviewers for their invaluable comments on an earlier draft of the paper. This work was supported in part by NSF Grant IIS-0812261. Any opinions, findings, and conclusions or recommendations expressed are those of the author and do not necessarily reflect the views or official policies, either expressed or implied, of the NSF."]},{"title":"References","paragraphs":["Chinatsu Aone and Scott William Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 122–129.","Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the LREC Workshop on Linguistic Coreference, pages 563–566.","Nikhil Bansal, Avrim Blum, and Shuchi Chawla. 2002. Correlation clustering. In Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, pages 238–247.","Catalina Barbu and Ruslan Mitkov. 2001. Evaluation tool for rule-based anaphora resolution methods. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 34–41.","David Bean and Ellen Riloff. 1999. Corpus-based identification of non-anaphoric noun phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 373– 380.","David Bean and Ellen Riloff. 2004. Unsupervised learning of contextual role knowledge for coreference resolution. In Human Language Technologies 2004: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 297– 304.","Eric Bengtson and Dan Roth. 2008. Understanding the values of features for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 294– 303.","Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.","Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 33–40.","Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Distributional identification of non-referential pronouns. In Proceedings of ACL-08: HLT, pages 10–18.","Donna Byron. 2001. The uncommon denominator: A proposal for consistent reporting of pronoun resolution results. Computational Linguistics, 27(4):569– 578.","Sasha Calhoun, Jean Carletta, Jason Brenier, Neil Mayo, Dan Jurafsky, Mark Steedman, and David Beaver. (in press). The NXT-format Switchboard corpus: A rich resource for investigating the syntax, semantics, pragmatics and prosody of dialogue. Language Resources and Evaluation.","Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 82–89.","Jean Carletta. 1996. Assessing agreement on classification tasks: the kappa statistic. Computational Linguistics, 22(2):249–254.","José Castaño, Jason Zhang, and James Pustejovsky. 2002. Anaphora resolution in biomedical literature. In Proceedings of the 2002 International Symposium on Reference Resolution.","Eugene Charniak and Micha Elsner. 2009. EM works for pronoun anaphora resolution. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 148–156.","Eugene Charniak. 1972. Towards a Model of Children’s Story Comphrension. AI-TR 266, Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA.","Colin Cherry and Shane Bergsma. 2005. An expecta-tion maximization approach to pronoun resolution. In Proceedings of the Ninth Conference on Computational Natural Language Learning, pages 88–95.","Noam Chomsky. 1988. Language and Problems of Knowledge. The Managua Lectures. MIT Press, Cambridge, Massachusetts.","William Cohen. 1995. Fast effective rule induction. In Proceedings of the 12th International Conference on Machine Learning, pages 115–123.","Dennis Connolly, John D. Burger, and David S. Day. 1994. A machine learning approach to anaphoric reference. In Proceedings of International Conference on New Methods in Language Processing, pages 255–261.","Dennis Connolly, John D. Burger, and David S. Day. 1997. A machine learning approach to anaphoric reference. In D. Jones and H. Somers, editors, New Methods in Language Processing, pages 133–144. UCL Press. 1405","Susan Converse. 2006. Pronominal Anaphora Resolution in Chinese. Ph.D. thesis, University of Pennsylvania, USA.","Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 81–88.","Walter Daelemans and Antal Van den Bosch. 2005. Memory-Based Language Processing. Cambridge University Press, Cambridge, UK.","Ido Dagan and Alon Itai. 1990. Automatic processing of large corpora for the resolution of anaphora references. In Proceedings of the 13th International Conference on Computational Linguistics, pages 330–332.","Hal Daumé III and Daniel Marcu. 2005. A large-scale exploration of effective global features for a joint entity detection and tracking model. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 97–104.","Arthur Dempster. 1968. A generalization of Bayesian inference. Journal of the Royal Statistical Society, 30:205–247.","Pascal Denis and Jason Baldridge. 2007a. Global, joint determination of anaphoricity and coreference resolution using integer programming. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 236–243.","Pascal Denis and Jason Baldridge. 2007b. A ranking approach to pronoun resolution. In Proceedings of the Twentieth International Conference on Artificial Intelligence, pages 1588–1593.","Pascal Denis and Jason Baldridge. 2008. Specialized models and ranking for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 660–669.","Richard Evans. 2001. Applying machine learning to-ward an automatic classification of it. Literary and Linguistic Computing, 16(1):45–57.","Jenny Rose Finkel and Christopher Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of ACL-08: HLT, Short Papers, pages 45–48.","Thomas Finley and Thorsten Joachims. 2005. Supervised clustering with support vector machines. In Proceedings of the 22nd International Conference on Machine Learning, pages 217–224.","Yoav Freund and Robert E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning, 37(3):277–296.","Nikesh Garera and David Yarowsky. 2006. Resolving and generating definite anaphora by modeling hypernymy using unlabeled corpora. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 37–44.","Niyu Ge, John Hale, and Eugene Charniak. 1998. A statistical approach to anaphora resolution. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 161–170.","Barbara J. Grosz and Candace L. Sidner. 1986. Atten-tion, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.","Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1983. Providing a unified account of definite noun phrases in discourse. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, pages 44–50.","Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–226.","Barbara J. Grosz. 1977. The representation and use of focus in a system for understanding dialogs. In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, pages 67–76.","Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 848–855.","Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1152–1161.","Aria Haghighi and Dan Klein. 2010. Coreference resolution in a modular, entity-centered model. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics.","Jan Hajic̆, Jarmila Panevová, Eva Hajic̆ová, Jarmila Panevová, Petr Sgall, Petr Pajas, Jan Stĕpánek, Jir̆ı́ Havelka, and Marie Mikulová. 2006. The Prague Dependency Treebank 2.0. In Linguistic Data Consortium.","Sanda Harabagiu, Răzvan Bunescu, and Steven Maiorano. 2001. Text and knowledge mining for coreference resolution. In Proceedings of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics, pages 55–62. 1406","Laura Hasler, Constantin Orasan, and Karin Naumann. 2006. NPs for events: Experiments in coreference annotation. In Proceedings of the 5th International Conference on Language Resources and Evaluation, pages 1167–1172.","Peter Heeman and James Allen. 1995. The TRAINS spoken dialog corpus. CD-ROM, Linguistic Data Consortium.","Graeme Hirst. 1981. Discourse-oriented anaphora resolution in natural language understanding: A review. American Journal of Computational Linguistics, 7(2):85–98.","Jerry Hobbs. 1978. Resolving pronoun references. Lingua, 44:311–338.","Véronique Hoste and Walter Daelemans. 2005. Comparing learning approaches to coreference resolution. There is more to it than bias. In Proceedings of the ICML Workshop on Meta-Learning.","Véronique Hoste. 2005. Optimization Issues in Machine Learning of Coreference Resolution. Ph.D. thesis, University of Antewerp, Belgium.","Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. Ontonotes: The 90% solution. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 57–60.","Zhiheng Huang, Guangping Zeng, Weiqun Xu, and Asli Celikyilmaz. 2009. Accurate semantic class classifier for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1232–1240.","Nancy Ide and Dan Cristea. 2000. A hierarchical account of referential accessibility. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 416–424.","Ryu Iida, Kentaro Inui, Hiroya Takamura, and Yuji Matsumoto. 2003. Incorporating contextual cues in trainable models for coreference resolution. In Proceedings of the EACL Workshop on The Computational Treatment of Anaphora.","Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Exploting syntactic patterns as clues in zero-anaphora resolution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 625–632.","Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007a. Zero-anaphora resolution by learning rich syntactic pattern features. ACM Transactions on Asian Language Information Processing, 6(4).","Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007b. Annotating a Japanese text corpus with predicate-argument and coreference relations. In Proceedings of the ACL Workshop ’Linguistic Annotation Workshop’, pages 132–139.","Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2009. Capturing salience with a trainable cache model for zero-anaphora resolution. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 647–655.","Ryu Iida. 2007. Combining Linguistic Knowledge and Machine Learning for Anaphora Resolution. Ph.D. thesis, Nara Institute of Science and Technology, Japan.","Heng Ji, David Westbrook, and Ralph Grishman. 2005. Using semantic relations to refine coreference decisions. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 17–24.","Thorsten Joachims. 1999. Making large-scale SVM learning practical. In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning, pages 44–56. MIT Press.","Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004a. Competitive self-trained pronoun interpretation. In Proceedings of HLT-NAACL 2004: Short Papers, pages 33–36.","Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004b. The (non)utility of predicate-argument frequencies for pronoun interpretation. In Human Language Technologies 2004: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 289–296.","Andrew Kehler. 1997. Probabilistic coreference in information extraction. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 163–173.","Christopher Kennedy and Branimir Boguraev. 1996. Anaphor for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, pages 113–118.","Manfred Klenner and Étienne Ailloud. 2008. Enhanc-ing coreference clustering. In Proceedings of the Second Workshop on Anaphora Resolution, pages 31–40.","Manfred Klenner and Étienne Ailloud. 2009. Optimization in coreference resolution is not needed: A nearly-optimal algorithm with intensional constraints. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 442–450.","Manfred Klenner. 2007. Enforcing consistency on coreference sets. In Proceedings of Recent Advances in Natural Language Processing. 1407","Fang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009. Employing the centering theory in pronoun resolution from the semantic perspective. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 987–996.","Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535–562.","Xiaoqiang Luo and Imed Zitouni. 2005. Multi-lingual coreference resolution with syntactic features. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 660– 667.","Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mention-synchronous coreference resolution algorithm based on the Bell tree. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 135–142.","Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 25–32.","Xiaoqiang Luo. 2007. Coreference or not: A twin model for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 73–80.","Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.","Katja Markert and Malvina Nissim. 2005. Comparing knowledge sources for nominal anaphora resolution. Computational Linguistics, 31(3):367–402.","Andrew McCallum and Ben Wellner. 2003. Toward conditional models of identity uncertainty with application to proper noun coreference. In Proceedings of the IJCAI Workshop on Information Integra-tion on the Web.","Andrew McCallum and Ben Wellner. 2004. Condi-tional models of identity uncertainty with applica-tion to noun coreference. In Advances in Neural Information Proceesing Systems.","Joseph McCarthy and Wendy Lehnert. 1995. Using decision trees for coreference resolution. In Proceedings of the Fourteenth International Conference on Artificial Intelligence, pages 1050–1055.","Ruslan Mitkov. 1999. Anaphora resolution: The state of the art. Technical Report (Based on the COLING/ACL-98 tutorial on anaphora resolution), University of Wolverhampton, Wolverhampton.","Ruslan Mitkov. 2001. Outstanding issues in anaphora resolution. In Al. Gelbukh, editor, Computational Linguistics and Intelligent Text Processing, pages 110–125. Springer.","Ruslan Mitkov. 2002. Anaphora Resolution. Longman.","Natalia N. Modjeska, Katja Markert, and Malvina Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 176–183.","MUC-6. 1995. Proceedings of the Sixth Message Understanding Conference.","MUC-7. 1998. Proceedings of the Seventh Message Understanding Conference.","Christoph Müller, Stefan Rapp, and Michael Strube. 2002. Applying co-training to reference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 352– 359.","Christoph Müller. 2006. Automatic detection of non-referential it in spoken multi-party dialog. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 49–56.","Vincent Ng and Claire Cardie. 2002a. Combining sample selection and error-driven pruning for machine learning of coreference rules. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 55–62.","Vincent Ng and Claire Cardie. 2002b. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of the 19th International Conference on Computational Linguistics, pages 730–736.","Vincent Ng and Claire Cardie. 2002c. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 104– 111.","Vincent Ng. 2004. Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 151–158.","Vincent Ng. 2007a. Semantic class induction and coreference resolution. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 536–543.","Vincent Ng. 2007b. Shallow semantics for coreference resolution. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, pages 1689–1694. 1408","Vincent Ng. 2008. Unsupervised models for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 640–649.","Vincent Ng. 2009. Graph-cut-based anaphoricity determination for coreference resolution. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 575–583.","Giang Linh Ngu. y, Václav Novák, and Zdeněk Žabokrtský. 2009. Comparison of classification and ranking approaches to pronominal anaphora resolution in Czech. In Proceedings of the SIGDIAL 2009 Conference, pages 276–285.","Cristina Nicolae and Gabriel Nicolae. 2006. Best-Cut: A graph algorithm for coreference resolution. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 275–283.","Kristina Nilsson. 2010. Hybrid Methods for Coreference Resolution in Swedish. Ph.D. thesis, Stockholm University, Sweden.","Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In Proceedings of the Second International Conference on Human Language Technology Research, pages 82–86.","Constantin Orăsan and Richard Evans. 2007. NP animacy identification for anaphora resolution. Journal of Artificial Intelligence Research, 29:79 – 103.","Constantin Orăsan, Dan Cristea, Ruslan Mitkov, and António H. Branco. 2008. Anaphora Resolution Exercise: An overview. In Proceedings of the 6th Language Resources and Evaluation Conference, pages 2801–2805.","Chris Paice and Gareth Husk. 1987. Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun ’it’. Computer Speech and Language, 2:109–132.","Massimo Poesio and Mijail A. Kabadjov. 2004. A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 663–668.","Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet Hitzeman. 2004a. Learning to resolve bridging references. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 143–150.","Massimo Poesio, Olga Uryupina, Renata Vieira, Mijail Alexandrov-Kabadjov, and Rodrigo Goulart. 2004b. Discourse-new detectors for definite description resolution: A survey and a preliminary proposal. In Proeedings of the ACL Workshop on Reference Resolution.","Massimo Poesio, David Day, Ron Artstein, Jason Dun-can, Vladimir Eidelman, Claudio Giuliano, Rob Hall, Janet Hitzeman, Alan Jern, Mijail Kabadjov, Stanley Yong Wai Keong, Gideon Mann, Alessandro Moschitti, Simone Ponzetto, Jason Smith, Josef Steinberger, Michael Strube, Jian Su, Yannick Versley, Xiaofeng Yang, and Michael Wick. 2007. EL-ERFED: Final report of the research group on Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation. Technical report, Summer Workshop on Language Engineering, Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD.","Simone Paolo Ponzetto and Massimo Poesio. 2009. State-of-the-art NLP approaches to coreference resolution: Theory and practical recipes. In Tutorial Abstracts of ACL-IJCNLP 2009, page 6.","Simone Paolo Ponzetto and Michael Strube. 2006a. Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Human Language Technologies 2006: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 192–199.","Simone Paolo Ponzetto and Michael Strube. 2006b. Semantic role labeling for coreference resolution. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 143–146.","Simone Paolo Ponzetto and Michael Strube. 2007. Knowledge derived from Wikipedia for computing semantic relatedness. Journal of Artificial Intelligence Research, 30:181–212.","Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 650–659.","Andrei Popescu-Belis, Loı̈s Rigouste, Susanne Salmon-Alt, and Laurent Romary. 2004. Online evaluation of coreference resolution. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 1507–1510.","Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A public reference implementation of the RAP anaphora resolution algorithm. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 291–294.","John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.","Altaf Rahman and Vincent Ng. 2009. Supervised models for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 968–977. 1409","Marta Recasens and M. Antónia Martı́. 2009. AnCora-CO: Coreferentially annotated corpora for Spanish and Catalan. Language Resources and Evaluation, 43(4).","Marta Recasens, Toni Martı́, Mariona Taulé, Lluı́s Màrquez, and Emili Sapena. 2009. SemEval-2010 Task 1: Coreference resolution in multiple languages. In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009), pages 70–75.","Candace Sidner. 1979. Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Ph.D. thesis, Massachusetts Institute of Technology, USA.","Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 1999. Corpus-based learning for noun phrase coreference resolution. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 285–291.","Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.","Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and Ellen Riloff. 2009. Conundrums in noun phrase coreference resolution: Making sense of the state-of-the-art. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 656–664.","Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff, David Buttler, and David Hysom. 2010. Coreference resolution with Reconcile. In Proceedings of the ACL 2010 Conference Short Papers.","Michael Strube, Stefan Rapp, and Christoph Müller. 2002. The influence of minimum edit distance on reference resolution. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 312–319.","Michael Strube. 2002. NLP approaches to reference resolution. In Tutorial Abstracts of ACL 2002, page 124.","Michael Strube. 2009. Anaphernresolution. In Computerlinguistik und Sprachtechnologie. Eine Einfuhrung. Springer, Heidelberg, Germany, 3rd edi-tion.","Heike Telljohann, Erhard Hinrichs, and Sandra Kübler. 2004. The tüba-d/z treebank: Annotating German with a context-free backbone. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 2229–2235.","Joel Tetreault. 2005. Empirical Evaluations of Pronoun Resolution. Ph.D. thesis, University of Rochester, USA.","Olga Uryupina. 2003. High-precision identification of discourse new and unique noun phrases. In Proceedings of the ACL Student Research Workshop, pages 80–86.","Olga Uryupina. 2004. Linguistically motivated sample selection for coreference resolution. In Proceedings of the 5th Discourse Anaphora and Anaphor Resolution Colloquium.","Kees van Deemter and Rodger Kibble. 2000. On coreferring: Coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629– 637.","Yannick Versley, Alessandro Moschitti, Massimo Poesio, and Xiaofeng Yang. 2008a. Coreference systems based on kernels methods. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 961–968.","Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008b. BART: A modular toolkit for coreference resolution. In Proceedings of the ACL-08: HLT Demo Session, pages 9–12.","Yannick Versley. 2006. A constraint-based approach to noun phrase coreference resolution in German newspaper text. In Konferenz zur Verarbeitung Natürlicher Sprache.","Yannick Versley. 2007. Antecedent selection techniques for high-recall coreference resolution. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 496–505.","Renata Vieira and Massimo Poesio. 2000. Processing definite descriptions in corpora. In S. Botley and A. McEnery, editors, Corpus-based and Computational Approaches to Discourse Anaphora, pages 189–212. UCL Press.","Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of the Sixth Message Understanding Conference, pages 45–52.","Marilyn Walker, Aravind Joshi, and Ellen Prince, editors. 1998. Centering Theory in Discourse. Oxford University Press.","Holger Wunsch. 2010. Rule-based and Memory-based Pronoun Resolution for German: A Comparison and Assessment of Data Sources. Ph.D. thesis, University of Tübingen, Germany.","Xiaofeng Yang and Jian Su. 2007. Coreference resolution using semantic relatedness information from automatically discovered patterns. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 528–535. 1410","Xiaofeng Yang, Guodong Zhou, Jian Su, and Chew Lim Tan. 2003. Coreference resolution using competitive learning approach. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 176–183.","Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2004a. Improving noun phrase coreference resolution by matching strings. In Proceedings of the First International Joint Conference on Natural Language Processing, pages 22–31.","Xiaofeng Yang, Jian Su, GuoDong Zhou, and Chew Lim Tan. 2004b. An NP-cluster based approach to coreference resolution. In Proceedings of the 20th International Conference on Computational Linguistics, pages 226–232.","Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 165–172.","Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2006. Kernel based pronoun resolution with structured syntactic knowledge. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 41–48.","Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan, and Sheng Li. 2008a. An entity-mention model for coreference resolution with inductive logic programming. In Proceedings of ACL-08: HLT, pages 843–851.","Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2008b. A twin-candidate model for learning-based anaphora resolution. Computational Linguistics, 34(3):327– 356.","Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts. 2004. Coreference resolution for information extraction. In Proceedings of the ACL Workshop on Reference Resolution and its Applications, pages 9– 16.","Shanheng Zhao and Hwee Tou Ng. 2007. Identifica-tion and resolution of Chinese zero pronouns: A machine learning approach. In Proceedings of the 2007 Joint Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning, pages 541–550.","GuoDong Zhou and Fang Kong. 2009. Global learning of noun phrase anaphoricity in coreference resolution via label propagation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 978–986. 1411"]}],"references":[{"authors":[{"first":"Chinatsu","last":"Aone"},{"first":"Scott","middle":"William","last":"Bennett"}],"year":"1995","title":"Evaluating automated and manual acquisition of anaphora resolution strategies","source":"Chinatsu Aone and Scott William Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 122–129."},{"authors":[{"first":"Amit","last":"Bagga"},{"first":"Breck","last":"Baldwin"}],"year":"1998","title":"Algorithms for scoring coreference chains","source":"Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the LREC Workshop on Linguistic Coreference, pages 563–566."},{"authors":[{"first":"Nikhil","last":"Bansal"},{"first":"Avrim","last":"Blum"},{"first":"Shuchi","last":"Chawla"}],"year":"2002","title":"Correlation clustering","source":"Nikhil Bansal, Avrim Blum, and Shuchi Chawla. 2002. Correlation clustering. In Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, pages 238–247."},{"authors":[{"first":"Catalina","last":"Barbu"},{"first":"Ruslan","last":"Mitkov"}],"year":"2001","title":"Evaluation tool for rule-based anaphora resolution methods","source":"Catalina Barbu and Ruslan Mitkov. 2001. Evaluation tool for rule-based anaphora resolution methods. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 34–41."},{"authors":[{"first":"David","last":"Bean"},{"first":"Ellen","last":"Riloff"}],"year":"1999","title":"Corpus-based identification of non-anaphoric noun phrases","source":"David Bean and Ellen Riloff. 1999. Corpus-based identification of non-anaphoric noun phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 373– 380."},{"authors":[{"first":"David","last":"Bean"},{"first":"Ellen","last":"Riloff"}],"year":"2004","title":"Unsupervised learning of contextual role knowledge for coreference resolution","source":"David Bean and Ellen Riloff. 2004. Unsupervised learning of contextual role knowledge for coreference resolution. In Human Language Technologies 2004: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 297– 304."},{"authors":[{"first":"Eric","last":"Bengtson"},{"first":"Dan","last":"Roth"}],"year":"2008","title":"Understanding the values of features for coreference resolution","source":"Eric Bengtson and Dan Roth. 2008. Understanding the values of features for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 294– 303."},{"authors":[{"first":"Adam","middle":"L.","last":"Berger"},{"first":"Stephen","middle":"A. Della","last":"Pietra"},{"first":"Vincent","middle":"J. Della","last":"Pietra"}],"year":"1996","title":"A maximum entropy approach to natural language processing","source":"Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71."},{"authors":[{"first":"Shane","last":"Bergsma"},{"first":"Dekang","last":"Lin"}],"year":"2006","title":"Bootstrapping path-based pronoun resolution","source":"Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 33–40."},{"authors":[{"first":"Shane","last":"Bergsma"},{"first":"Dekang","last":"Lin"},{"first":"Randy","last":"Goebel"}],"year":"2008","title":"Distributional identification of non-referential pronouns","source":"Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Distributional identification of non-referential pronouns. In Proceedings of ACL-08: HLT, pages 10–18."},{"authors":[{"first":"Donna","last":"Byron"}],"year":"2001","title":"The uncommon denominator: A proposal for consistent reporting of pronoun resolution results","source":"Donna Byron. 2001. The uncommon denominator: A proposal for consistent reporting of pronoun resolution results. Computational Linguistics, 27(4):569– 578."},{"authors":[],"source":"Sasha Calhoun, Jean Carletta, Jason Brenier, Neil Mayo, Dan Jurafsky, Mark Steedman, and David Beaver. (in press). The NXT-format Switchboard corpus: A rich resource for investigating the syntax, semantics, pragmatics and prosody of dialogue. Language Resources and Evaluation."},{"authors":[{"first":"Claire","last":"Cardie"},{"first":"Kiri","last":"Wagstaff"}],"year":"1999","title":"Noun phrase coreference as clustering","source":"Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 82–89."},{"authors":[{"first":"Jean","last":"Carletta"}],"year":"1996","title":"Assessing agreement on classification tasks: the kappa statistic","source":"Jean Carletta. 1996. Assessing agreement on classification tasks: the kappa statistic. Computational Linguistics, 22(2):249–254."},{"authors":[{"first":"José","last":"Castaño"},{"first":"Jason","last":"Zhang"},{"first":"James","last":"Pustejovsky"}],"year":"2002","title":"Anaphora resolution in biomedical literature","source":"José Castaño, Jason Zhang, and James Pustejovsky. 2002. Anaphora resolution in biomedical literature. In Proceedings of the 2002 International Symposium on Reference Resolution."},{"authors":[{"first":"Eugene","last":"Charniak"},{"first":"Micha","last":"Elsner"}],"year":"2009","title":"EM works for pronoun anaphora resolution","source":"Eugene Charniak and Micha Elsner. 2009. EM works for pronoun anaphora resolution. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 148–156."},{"authors":[{"first":"Eugene","last":"Charniak"}],"year":"1972","title":"Towards a Model of Children’s Story Comphrension","source":"Eugene Charniak. 1972. Towards a Model of Children’s Story Comphrension. AI-TR 266, Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA."},{"authors":[{"first":"Colin","last":"Cherry"},{"first":"Shane","last":"Bergsma"}],"year":"2005","title":"An expecta-tion maximization approach to pronoun resolution","source":"Colin Cherry and Shane Bergsma. 2005. An expecta-tion maximization approach to pronoun resolution. In Proceedings of the Ninth Conference on Computational Natural Language Learning, pages 88–95."},{"authors":[{"first":"Noam","last":"Chomsky"}],"year":"1988","title":"Language and Problems of Knowledge","source":"Noam Chomsky. 1988. Language and Problems of Knowledge. The Managua Lectures. MIT Press, Cambridge, Massachusetts."},{"authors":[{"first":"William","last":"Cohen"}],"year":"1995","title":"Fast effective rule induction","source":"William Cohen. 1995. Fast effective rule induction. In Proceedings of the 12th International Conference on Machine Learning, pages 115–123."},{"authors":[{"first":"Dennis","last":"Connolly"},{"first":"John","middle":"D.","last":"Burger"},{"first":"David","middle":"S.","last":"Day"}],"year":"1994","title":"A machine learning approach to anaphoric reference","source":"Dennis Connolly, John D. Burger, and David S. Day. 1994. A machine learning approach to anaphoric reference. In Proceedings of International Conference on New Methods in Language Processing, pages 255–261."},{"authors":[{"first":"Dennis","last":"Connolly"},{"first":"John","middle":"D.","last":"Burger"},{"first":"David","middle":"S.","last":"Day"}],"year":"1997","title":"A machine learning approach to anaphoric reference","source":"Dennis Connolly, John D. Burger, and David S. Day. 1997. A machine learning approach to anaphoric reference. In D. Jones and H. Somers, editors, New Methods in Language Processing, pages 133–144. UCL Press. 1405"},{"authors":[{"first":"Susan","last":"Converse"}],"year":"2006","title":"Pronominal Anaphora Resolution in Chinese","source":"Susan Converse. 2006. Pronominal Anaphora Resolution in Chinese. Ph.D. thesis, University of Pennsylvania, USA."},{"authors":[{"first":"Aron","last":"Culotta"},{"first":"Michael","last":"Wick"},{"first":"Andrew","last":"McCallum"}],"year":"2007","title":"First-order probabilistic models for coreference resolution","source":"Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 81–88."},{"authors":[{"first":"Walter","last":"Daelemans"},{"first":"Antal","middle":"Van den","last":"Bosch"}],"year":"2005","title":"Memory-Based Language Processing","source":"Walter Daelemans and Antal Van den Bosch. 2005. Memory-Based Language Processing. Cambridge University Press, Cambridge, UK."},{"authors":[{"first":"Ido","last":"Dagan"},{"first":"Alon","last":"Itai"}],"year":"1990","title":"Automatic processing of large corpora for the resolution of anaphora references","source":"Ido Dagan and Alon Itai. 1990. Automatic processing of large corpora for the resolution of anaphora references. In Proceedings of the 13th International Conference on Computational Linguistics, pages 330–332."},{"authors":[{"first":"Hal","last":"Daumé III"},{"first":"Daniel","last":"Marcu"}],"year":"2005","title":"A large-scale exploration of effective global features for a joint entity detection and tracking model","source":"Hal Daumé III and Daniel Marcu. 2005. A large-scale exploration of effective global features for a joint entity detection and tracking model. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 97–104."},{"authors":[{"first":"Arthur","last":"Dempster"}],"year":"1968","title":"A generalization of Bayesian inference","source":"Arthur Dempster. 1968. A generalization of Bayesian inference. Journal of the Royal Statistical Society, 30:205–247."},{"authors":[{"first":"Pascal","last":"Denis"},{"first":"Jason","last":"Baldridge"}],"year":"2007a","title":"Global, joint determination of anaphoricity and coreference resolution using integer programming","source":"Pascal Denis and Jason Baldridge. 2007a. Global, joint determination of anaphoricity and coreference resolution using integer programming. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 236–243."},{"authors":[{"first":"Pascal","last":"Denis"},{"first":"Jason","last":"Baldridge"}],"year":"2007b","title":"A ranking approach to pronoun resolution","source":"Pascal Denis and Jason Baldridge. 2007b. A ranking approach to pronoun resolution. In Proceedings of the Twentieth International Conference on Artificial Intelligence, pages 1588–1593."},{"authors":[{"first":"Pascal","last":"Denis"},{"first":"Jason","last":"Baldridge"}],"year":"2008","title":"Specialized models and ranking for coreference resolution","source":"Pascal Denis and Jason Baldridge. 2008. Specialized models and ranking for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 660–669."},{"authors":[{"first":"Richard","last":"Evans"}],"year":"2001","title":"Applying machine learning to-ward an automatic classification of it","source":"Richard Evans. 2001. Applying machine learning to-ward an automatic classification of it. Literary and Linguistic Computing, 16(1):45–57."},{"authors":[{"first":"Jenny","middle":"Rose","last":"Finkel"},{"first":"Christopher","last":"Manning"}],"year":"2008","title":"Enforcing transitivity in coreference resolution","source":"Jenny Rose Finkel and Christopher Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of ACL-08: HLT, Short Papers, pages 45–48."},{"authors":[{"first":"Thomas","last":"Finley"},{"first":"Thorsten","last":"Joachims"}],"year":"2005","title":"Supervised clustering with support vector machines","source":"Thomas Finley and Thorsten Joachims. 2005. Supervised clustering with support vector machines. In Proceedings of the 22nd International Conference on Machine Learning, pages 217–224."},{"authors":[{"first":"Yoav","last":"Freund"},{"first":"Robert","middle":"E.","last":"Schapire"}],"year":"1999","title":"Large margin classification using the perceptron algorithm","source":"Yoav Freund and Robert E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning, 37(3):277–296."},{"authors":[{"first":"Nikesh","last":"Garera"},{"first":"David","last":"Yarowsky"}],"year":"2006","title":"Resolving and generating definite anaphora by modeling hypernymy using unlabeled corpora","source":"Nikesh Garera and David Yarowsky. 2006. Resolving and generating definite anaphora by modeling hypernymy using unlabeled corpora. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 37–44."},{"authors":[{"first":"Niyu","last":"Ge"},{"first":"John","last":"Hale"},{"first":"Eugene","last":"Charniak"}],"year":"1998","title":"A statistical approach to anaphora resolution","source":"Niyu Ge, John Hale, and Eugene Charniak. 1998. A statistical approach to anaphora resolution. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 161–170."},{"authors":[{"first":"Barbara","middle":"J.","last":"Grosz"},{"first":"Candace","middle":"L.","last":"Sidner"}],"year":"1986","title":"Atten-tion, intentions, and the structure of discourse","source":"Barbara J. Grosz and Candace L. Sidner. 1986. Atten-tion, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204."},{"authors":[{"first":"Barbara","middle":"J.","last":"Grosz"},{"first":"Aravind","middle":"K.","last":"Joshi"},{"first":"Scott","last":"Weinstein"}],"year":"1983","title":"Providing a unified account of definite noun phrases in discourse","source":"Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1983. Providing a unified account of definite noun phrases in discourse. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, pages 44–50."},{"authors":[{"first":"Barbara","middle":"J.","last":"Grosz"},{"first":"Aravind","middle":"K.","last":"Joshi"},{"first":"Scott","last":"Weinstein"}],"year":"1995","title":"Centering: A framework for modeling the local coherence of discourse","source":"Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–226."},{"authors":[{"first":"Barbara","middle":"J.","last":"Grosz"}],"year":"1977","title":"The representation and use of focus in a system for understanding dialogs","source":"Barbara J. Grosz. 1977. The representation and use of focus in a system for understanding dialogs. In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, pages 67–76."},{"authors":[{"first":"Aria","last":"Haghighi"},{"first":"Dan","last":"Klein"}],"year":"2007","title":"Unsupervised coreference resolution in a nonparametric bayesian model","source":"Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 848–855."},{"authors":[{"first":"Aria","last":"Haghighi"},{"first":"Dan","last":"Klein"}],"year":"2009","title":"Simple coreference resolution with rich syntactic and semantic features","source":"Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1152–1161."},{"authors":[{"first":"Aria","last":"Haghighi"},{"first":"Dan","last":"Klein"}],"year":"2010","title":"Coreference resolution in a modular, entity-centered model","source":"Aria Haghighi and Dan Klein. 2010. Coreference resolution in a modular, entity-centered model. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics."},{"authors":[{"first":"Jan","last":"Hajic̆"},{"first":"Jarmila","last":"Panevová"},{"first":"Eva","last":"Hajic̆ová"},{"first":"Jarmila","last":"Panevová"},{"first":"Petr","last":"Sgall"},{"first":"Petr","last":"Pajas"},{"first":"Jan","last":"Stĕpánek"},{"first":"Jir̆ı́","last":"Havelka"},{"first":"Marie","last":"Mikulová"}],"year":"2006","title":"The Prague Dependency Treebank 2","source":"Jan Hajic̆, Jarmila Panevová, Eva Hajic̆ová, Jarmila Panevová, Petr Sgall, Petr Pajas, Jan Stĕpánek, Jir̆ı́ Havelka, and Marie Mikulová. 2006. The Prague Dependency Treebank 2.0. In Linguistic Data Consortium."},{"authors":[{"first":"Sanda","last":"Harabagiu"},{"first":"Răzvan","last":"Bunescu"},{"first":"Steven","last":"Maiorano"}],"year":"2001","title":"Text and knowledge mining for coreference resolution","source":"Sanda Harabagiu, Răzvan Bunescu, and Steven Maiorano. 2001. Text and knowledge mining for coreference resolution. In Proceedings of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics, pages 55–62. 1406"},{"authors":[{"first":"Laura","last":"Hasler"},{"first":"Constantin","last":"Orasan"},{"first":"Karin","last":"Naumann"}],"year":"2006","title":"NPs for events: Experiments in coreference annotation","source":"Laura Hasler, Constantin Orasan, and Karin Naumann. 2006. NPs for events: Experiments in coreference annotation. In Proceedings of the 5th International Conference on Language Resources and Evaluation, pages 1167–1172."},{"authors":[{"first":"Peter","last":"Heeman"},{"first":"James","last":"Allen"}],"year":"1995","title":"The TRAINS spoken dialog corpus","source":"Peter Heeman and James Allen. 1995. The TRAINS spoken dialog corpus. CD-ROM, Linguistic Data Consortium."},{"authors":[{"first":"Graeme","last":"Hirst"}],"year":"1981","title":"Discourse-oriented anaphora resolution in natural language understanding: A review","source":"Graeme Hirst. 1981. Discourse-oriented anaphora resolution in natural language understanding: A review. American Journal of Computational Linguistics, 7(2):85–98."},{"authors":[{"first":"Jerry","last":"Hobbs"}],"year":"1978","title":"Resolving pronoun references","source":"Jerry Hobbs. 1978. Resolving pronoun references. Lingua, 44:311–338."},{"authors":[{"first":"Véronique","last":"Hoste"},{"first":"Walter","last":"Daelemans"}],"year":"2005","title":"Comparing learning approaches to coreference resolution","source":"Véronique Hoste and Walter Daelemans. 2005. Comparing learning approaches to coreference resolution. There is more to it than bias. In Proceedings of the ICML Workshop on Meta-Learning."},{"authors":[{"first":"Véronique","last":"Hoste"}],"year":"2005","title":"Optimization Issues in Machine Learning of Coreference Resolution","source":"Véronique Hoste. 2005. Optimization Issues in Machine Learning of Coreference Resolution. Ph.D. thesis, University of Antewerp, Belgium."},{"authors":[{"first":"Eduard","last":"Hovy"},{"first":"Mitchell","last":"Marcus"},{"first":"Martha","last":"Palmer"},{"first":"Lance","last":"Ramshaw"},{"first":"Ralph","last":"Weischedel"}],"year":"2006","title":"Ontonotes: The 90% solution","source":"Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. Ontonotes: The 90% solution. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 57–60."},{"authors":[{"first":"Zhiheng","last":"Huang"},{"first":"Guangping","last":"Zeng"},{"first":"Weiqun","last":"Xu"},{"first":"Asli","last":"Celikyilmaz"}],"year":"2009","title":"Accurate semantic class classifier for coreference resolution","source":"Zhiheng Huang, Guangping Zeng, Weiqun Xu, and Asli Celikyilmaz. 2009. Accurate semantic class classifier for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1232–1240."},{"authors":[{"first":"Nancy","last":"Ide"},{"first":"Dan","last":"Cristea"}],"year":"2000","title":"A hierarchical account of referential accessibility","source":"Nancy Ide and Dan Cristea. 2000. A hierarchical account of referential accessibility. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 416–424."},{"authors":[{"first":"Ryu","last":"Iida"},{"first":"Kentaro","last":"Inui"},{"first":"Hiroya","last":"Takamura"},{"first":"Yuji","last":"Matsumoto"}],"year":"2003","title":"Incorporating contextual cues in trainable models for coreference resolution","source":"Ryu Iida, Kentaro Inui, Hiroya Takamura, and Yuji Matsumoto. 2003. Incorporating contextual cues in trainable models for coreference resolution. In Proceedings of the EACL Workshop on The Computational Treatment of Anaphora."},{"authors":[{"first":"Ryu","last":"Iida"},{"first":"Kentaro","last":"Inui"},{"first":"Yuji","last":"Matsumoto"}],"year":"2006","title":"Exploting syntactic patterns as clues in zero-anaphora resolution","source":"Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Exploting syntactic patterns as clues in zero-anaphora resolution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 625–632."},{"authors":[{"first":"Ryu","last":"Iida"},{"first":"Kentaro","last":"Inui"},{"first":"Yuji","last":"Matsumoto"}],"year":"2007a","title":"Zero-anaphora resolution by learning rich syntactic pattern features","source":"Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007a. Zero-anaphora resolution by learning rich syntactic pattern features. ACM Transactions on Asian Language Information Processing, 6(4)."},{"authors":[{"first":"Ryu","last":"Iida"},{"first":"Mamoru","last":"Komachi"},{"first":"Kentaro","last":"Inui"},{"first":"Yuji","last":"Matsumoto"}],"year":"2007b","title":"Annotating a Japanese text corpus with predicate-argument and coreference relations","source":"Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007b. Annotating a Japanese text corpus with predicate-argument and coreference relations. In Proceedings of the ACL Workshop ’Linguistic Annotation Workshop’, pages 132–139."},{"authors":[{"first":"Ryu","last":"Iida"},{"first":"Kentaro","last":"Inui"},{"first":"Yuji","last":"Matsumoto"}],"year":"2009","title":"Capturing salience with a trainable cache model for zero-anaphora resolution","source":"Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2009. Capturing salience with a trainable cache model for zero-anaphora resolution. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 647–655."},{"authors":[{"first":"Ryu","last":"Iida"}],"year":"2007","title":"Combining Linguistic Knowledge and Machine Learning for Anaphora Resolution","source":"Ryu Iida. 2007. Combining Linguistic Knowledge and Machine Learning for Anaphora Resolution. Ph.D. thesis, Nara Institute of Science and Technology, Japan."},{"authors":[{"first":"Heng","last":"Ji"},{"first":"David","last":"Westbrook"},{"first":"Ralph","last":"Grishman"}],"year":"2005","title":"Using semantic relations to refine coreference decisions","source":"Heng Ji, David Westbrook, and Ralph Grishman. 2005. Using semantic relations to refine coreference decisions. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 17–24."},{"authors":[{"first":"Thorsten","last":"Joachims"}],"year":"1999","title":"Making large-scale SVM learning practical","source":"Thorsten Joachims. 1999. Making large-scale SVM learning practical. In Bernhard Scholkopf and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning, pages 44–56. MIT Press."},{"authors":[{"first":"Andrew","last":"Kehler"},{"first":"Douglas","last":"Appelt"},{"first":"Lara","last":"Taylor"},{"first":"Aleksandr","last":"Simma"}],"year":"2004a","title":"Competitive self-trained pronoun interpretation","source":"Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004a. Competitive self-trained pronoun interpretation. In Proceedings of HLT-NAACL 2004: Short Papers, pages 33–36."},{"authors":[{"first":"Andrew","last":"Kehler"},{"first":"Douglas","last":"Appelt"},{"first":"Lara","last":"Taylor"},{"first":"Aleksandr","last":"Simma"}],"year":"2004b","title":"The (non)utility of predicate-argument frequencies for pronoun interpretation","source":"Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004b. The (non)utility of predicate-argument frequencies for pronoun interpretation. In Human Language Technologies 2004: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 289–296."},{"authors":[{"first":"Andrew","last":"Kehler"}],"year":"1997","title":"Probabilistic coreference in information extraction","source":"Andrew Kehler. 1997. Probabilistic coreference in information extraction. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 163–173."},{"authors":[{"first":"Christopher","last":"Kennedy"},{"first":"Branimir","last":"Boguraev"}],"year":"1996","title":"Anaphor for everyone: Pronominal anaphora resolution without a parser","source":"Christopher Kennedy and Branimir Boguraev. 1996. Anaphor for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, pages 113–118."},{"authors":[{"first":"Manfred","last":"Klenner"},{"first":"Étienne","last":"Ailloud"}],"year":"2008","title":"Enhanc-ing coreference clustering","source":"Manfred Klenner and Étienne Ailloud. 2008. Enhanc-ing coreference clustering. In Proceedings of the Second Workshop on Anaphora Resolution, pages 31–40."},{"authors":[{"first":"Manfred","last":"Klenner"},{"first":"Étienne","last":"Ailloud"}],"year":"2009","title":"Optimization in coreference resolution is not needed: A nearly-optimal algorithm with intensional constraints","source":"Manfred Klenner and Étienne Ailloud. 2009. Optimization in coreference resolution is not needed: A nearly-optimal algorithm with intensional constraints. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 442–450."},{"authors":[{"first":"Manfred","last":"Klenner"}],"year":"2007","title":"Enforcing consistency on coreference sets","source":"Manfred Klenner. 2007. Enforcing consistency on coreference sets. In Proceedings of Recent Advances in Natural Language Processing. 1407"},{"authors":[{"first":"Fang","last":"Kong"},{"first":"GuoDong","last":"Zhou"},{"first":"Qiaoming","last":"Zhu"}],"year":"2009","title":"Employing the centering theory in pronoun resolution from the semantic perspective","source":"Fang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009. Employing the centering theory in pronoun resolution from the semantic perspective. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 987–996."},{"authors":[{"first":"Shalom","last":"Lappin"},{"first":"Herbert","last":"Leass"}],"year":"1994","title":"An algorithm for pronominal anaphora resolution","source":"Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535–562."},{"authors":[{"first":"Xiaoqiang","last":"Luo"},{"first":"Imed","last":"Zitouni"}],"year":"2005","title":"Multi-lingual coreference resolution with syntactic features","source":"Xiaoqiang Luo and Imed Zitouni. 2005. Multi-lingual coreference resolution with syntactic features. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 660– 667."},{"authors":[{"first":"Xiaoqiang","last":"Luo"},{"first":"Abe","last":"Ittycheriah"},{"first":"Hongyan","last":"Jing"},{"first":"Nanda","last":"Kambhatla"},{"first":"Salim","last":"Roukos"}],"year":"2004","title":"A mention-synchronous coreference resolution algorithm based on the Bell tree","source":"Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mention-synchronous coreference resolution algorithm based on the Bell tree. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 135–142."},{"authors":[{"first":"Xiaoqiang","last":"Luo"}],"year":"2005","title":"On coreference resolution performance metrics","source":"Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing, pages 25–32."},{"authors":[{"first":"Xiaoqiang","last":"Luo"}],"year":"2007","title":"Coreference or not: A twin model for coreference resolution","source":"Xiaoqiang Luo. 2007. Coreference or not: A twin model for coreference resolution. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 73–80."},{"authors":[{"first":"Mitchell","middle":"P.","last":"Marcus"},{"first":"Beatrice","last":"Santorini"},{"first":"Mary","middle":"Ann","last":"Marcinkiewicz"}],"year":"1993","title":"Building a large annotated corpus of English: The Penn Treebank","source":"Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330."},{"authors":[{"first":"Katja","last":"Markert"},{"first":"Malvina","last":"Nissim"}],"year":"2005","title":"Comparing knowledge sources for nominal anaphora resolution","source":"Katja Markert and Malvina Nissim. 2005. Comparing knowledge sources for nominal anaphora resolution. Computational Linguistics, 31(3):367–402."},{"authors":[{"first":"Andrew","last":"McCallum"},{"first":"Ben","last":"Wellner"}],"year":"2003","title":"Toward conditional models of identity uncertainty with application to proper noun coreference","source":"Andrew McCallum and Ben Wellner. 2003. Toward conditional models of identity uncertainty with application to proper noun coreference. In Proceedings of the IJCAI Workshop on Information Integra-tion on the Web."},{"authors":[{"first":"Andrew","last":"McCallum"},{"first":"Ben","last":"Wellner"}],"year":"2004","title":"Condi-tional models of identity uncertainty with applica-tion to noun coreference","source":"Andrew McCallum and Ben Wellner. 2004. Condi-tional models of identity uncertainty with applica-tion to noun coreference. In Advances in Neural Information Proceesing Systems."},{"authors":[{"first":"Joseph","last":"McCarthy"},{"first":"Wendy","last":"Lehnert"}],"year":"1995","title":"Using decision trees for coreference resolution","source":"Joseph McCarthy and Wendy Lehnert. 1995. Using decision trees for coreference resolution. In Proceedings of the Fourteenth International Conference on Artificial Intelligence, pages 1050–1055."},{"authors":[{"first":"Ruslan","last":"Mitkov"}],"year":"1999","title":"Anaphora resolution: The state of the art","source":"Ruslan Mitkov. 1999. Anaphora resolution: The state of the art. Technical Report (Based on the COLING/ACL-98 tutorial on anaphora resolution), University of Wolverhampton, Wolverhampton."},{"authors":[{"first":"Ruslan","last":"Mitkov"}],"year":"2001","title":"Outstanding issues in anaphora resolution","source":"Ruslan Mitkov. 2001. Outstanding issues in anaphora resolution. In Al. Gelbukh, editor, Computational Linguistics and Intelligent Text Processing, pages 110–125. Springer."},{"authors":[{"first":"Ruslan","last":"Mitkov"}],"year":"2002","title":"Anaphora Resolution","source":"Ruslan Mitkov. 2002. Anaphora Resolution. Longman."},{"authors":[{"first":"Natalia","middle":"N.","last":"Modjeska"},{"first":"Katja","last":"Markert"},{"first":"Malvina","last":"Nissim"}],"year":"2003","title":"Using the web in machine learning for other-anaphora resolution","source":"Natalia N. Modjeska, Katja Markert, and Malvina Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 176–183."},{"authors":[{"last":"MUC-6"}],"year":"1995","title":"Proceedings of the Sixth Message Understanding Conference","source":"MUC-6. 1995. Proceedings of the Sixth Message Understanding Conference."},{"authors":[{"last":"MUC-7"}],"year":"1998","title":"Proceedings of the Seventh Message Understanding Conference","source":"MUC-7. 1998. Proceedings of the Seventh Message Understanding Conference."},{"authors":[{"first":"Christoph","last":"Müller"},{"first":"Stefan","last":"Rapp"},{"first":"Michael","last":"Strube"}],"year":"2002","title":"Applying co-training to reference resolution","source":"Christoph Müller, Stefan Rapp, and Michael Strube. 2002. Applying co-training to reference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 352– 359."},{"authors":[{"first":"Christoph","last":"Müller"}],"year":"2006","title":"Automatic detection of non-referential it in spoken multi-party dialog","source":"Christoph Müller. 2006. Automatic detection of non-referential it in spoken multi-party dialog. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 49–56."},{"authors":[{"first":"Vincent","last":"Ng"},{"first":"Claire","last":"Cardie"}],"year":"2002a","title":"Combining sample selection and error-driven pruning for machine learning of coreference rules","source":"Vincent Ng and Claire Cardie. 2002a. Combining sample selection and error-driven pruning for machine learning of coreference rules. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 55–62."},{"authors":[{"first":"Vincent","last":"Ng"},{"first":"Claire","last":"Cardie"}],"year":"2002b","title":"Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution","source":"Vincent Ng and Claire Cardie. 2002b. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of the 19th International Conference on Computational Linguistics, pages 730–736."},{"authors":[{"first":"Vincent","last":"Ng"},{"first":"Claire","last":"Cardie"}],"year":"2002c","title":"Improving machine learning approaches to coreference resolution","source":"Vincent Ng and Claire Cardie. 2002c. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 104– 111."},{"authors":[{"first":"Vincent","last":"Ng"}],"year":"2004","title":"Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization","source":"Vincent Ng. 2004. Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 151–158."},{"authors":[{"first":"Vincent","last":"Ng"}],"year":"2007a","title":"Semantic class induction and coreference resolution","source":"Vincent Ng. 2007a. Semantic class induction and coreference resolution. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 536–543."},{"authors":[{"first":"Vincent","last":"Ng"}],"year":"2007b","title":"Shallow semantics for coreference resolution","source":"Vincent Ng. 2007b. Shallow semantics for coreference resolution. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, pages 1689–1694. 1408"},{"authors":[{"first":"Vincent","last":"Ng"}],"year":"2008","title":"Unsupervised models for coreference resolution","source":"Vincent Ng. 2008. Unsupervised models for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 640–649."},{"authors":[{"first":"Vincent","last":"Ng"}],"year":"2009","title":"Graph-cut-based anaphoricity determination for coreference resolution","source":"Vincent Ng. 2009. Graph-cut-based anaphoricity determination for coreference resolution. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 575–583."},{"authors":[{"first":"Giang","middle":"Linh Ngu.","last":"y"},{"first":"Václav","last":"Novák"},{"first":"Zdeněk","last":"Žabokrtský"}],"year":"2009","title":"Comparison of classification and ranking approaches to pronominal anaphora resolution in Czech","source":"Giang Linh Ngu. y, Václav Novák, and Zdeněk Žabokrtský. 2009. Comparison of classification and ranking approaches to pronominal anaphora resolution in Czech. In Proceedings of the SIGDIAL 2009 Conference, pages 276–285."},{"authors":[{"first":"Cristina","last":"Nicolae"},{"first":"Gabriel","last":"Nicolae"}],"year":"2006","title":"Best-Cut: A graph algorithm for coreference resolution","source":"Cristina Nicolae and Gabriel Nicolae. 2006. Best-Cut: A graph algorithm for coreference resolution. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 275–283."},{"authors":[{"first":"Kristina","last":"Nilsson"}],"year":"2010","title":"Hybrid Methods for Coreference Resolution in Swedish","source":"Kristina Nilsson. 2010. Hybrid Methods for Coreference Resolution in Swedish. Ph.D. thesis, Stockholm University, Sweden."},{"authors":[{"first":"Tomoko","last":"Ohta"},{"first":"Yuka","last":"Tateisi"},{"first":"Jin-Dong","last":"Kim"}],"year":"2002","title":"The GENIA corpus: An annotated research abstract corpus in molecular biology domain","source":"Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In Proceedings of the Second International Conference on Human Language Technology Research, pages 82–86."},{"authors":[{"first":"Constantin","last":"Orăsan"},{"first":"Richard","last":"Evans"}],"year":"2007","title":"NP animacy identification for anaphora resolution","source":"Constantin Orăsan and Richard Evans. 2007. NP animacy identification for anaphora resolution. Journal of Artificial Intelligence Research, 29:79 – 103."},{"authors":[{"first":"Constantin","last":"Orăsan"},{"first":"Dan","last":"Cristea"},{"first":"Ruslan","last":"Mitkov"},{"first":"António","middle":"H.","last":"Branco"}],"year":"2008","title":"Anaphora Resolution Exercise: An overview","source":"Constantin Orăsan, Dan Cristea, Ruslan Mitkov, and António H. Branco. 2008. Anaphora Resolution Exercise: An overview. In Proceedings of the 6th Language Resources and Evaluation Conference, pages 2801–2805."},{"authors":[{"first":"Chris","last":"Paice"},{"first":"Gareth","last":"Husk"}],"year":"1987","title":"Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun ’it’","source":"Chris Paice and Gareth Husk. 1987. Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun ’it’. Computer Speech and Language, 2:109–132."},{"authors":[{"first":"Massimo","last":"Poesio"},{"first":"Mijail","middle":"A.","last":"Kabadjov"}],"year":"2004","title":"A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation","source":"Massimo Poesio and Mijail A. Kabadjov. 2004. A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 663–668."},{"authors":[{"first":"Massimo","last":"Poesio"},{"first":"Rahul","last":"Mehta"},{"first":"Axel","last":"Maroudas"},{"first":"Janet","last":"Hitzeman"}],"year":"2004a","title":"Learning to resolve bridging references","source":"Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet Hitzeman. 2004a. Learning to resolve bridging references. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 143–150."},{"authors":[{"first":"Massimo","last":"Poesio"},{"first":"Olga","last":"Uryupina"},{"first":"Renata","last":"Vieira"},{"first":"Mijail","last":"Alexandrov-Kabadjov"},{"first":"Rodrigo","last":"Goulart"}],"year":"2004b","title":"Discourse-new detectors for definite description resolution: A survey and a preliminary proposal","source":"Massimo Poesio, Olga Uryupina, Renata Vieira, Mijail Alexandrov-Kabadjov, and Rodrigo Goulart. 2004b. Discourse-new detectors for definite description resolution: A survey and a preliminary proposal. In Proeedings of the ACL Workshop on Reference Resolution."},{"authors":[{"first":"Massimo","last":"Poesio"},{"first":"David","last":"Day"},{"first":"Ron","last":"Artstein"},{"first":"Jason","last":"Dun-can"},{"first":"Vladimir","last":"Eidelman"},{"first":"Claudio","last":"Giuliano"},{"first":"Rob","last":"Hall"},{"first":"Janet","last":"Hitzeman"},{"first":"Alan","last":"Jern"},{"first":"Mijail","last":"Kabadjov"},{"first":"Stanley","middle":"Yong Wai","last":"Keong"},{"first":"Gideon","last":"Mann"},{"first":"Alessandro","last":"Moschitti"},{"first":"Simone","last":"Ponzetto"},{"first":"Jason","last":"Smith"},{"first":"Josef","last":"Steinberger"},{"first":"Michael","last":"Strube"},{"first":"Jian","last":"Su"},{"first":"Yannick","last":"Versley"},{"first":"Xiaofeng","last":"Yang"},{"first":"Michael","last":"Wick"}],"year":"2007","title":"EL-ERFED: Final report of the research group on Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation","source":"Massimo Poesio, David Day, Ron Artstein, Jason Dun-can, Vladimir Eidelman, Claudio Giuliano, Rob Hall, Janet Hitzeman, Alan Jern, Mijail Kabadjov, Stanley Yong Wai Keong, Gideon Mann, Alessandro Moschitti, Simone Ponzetto, Jason Smith, Josef Steinberger, Michael Strube, Jian Su, Yannick Versley, Xiaofeng Yang, and Michael Wick. 2007. EL-ERFED: Final report of the research group on Exploiting Lexical and Encyclopedic Resources For Entity Disambiguation. Technical report, Summer Workshop on Language Engineering, Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD."},{"authors":[{"first":"Simone","middle":"Paolo","last":"Ponzetto"},{"first":"Massimo","last":"Poesio"}],"year":"2009","title":"State-of-the-art NLP approaches to coreference resolution: Theory and practical recipes","source":"Simone Paolo Ponzetto and Massimo Poesio. 2009. State-of-the-art NLP approaches to coreference resolution: Theory and practical recipes. In Tutorial Abstracts of ACL-IJCNLP 2009, page 6."},{"authors":[{"first":"Simone","middle":"Paolo","last":"Ponzetto"},{"first":"Michael","last":"Strube"}],"year":"2006a","title":"Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution","source":"Simone Paolo Ponzetto and Michael Strube. 2006a. Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Human Language Technologies 2006: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 192–199."},{"authors":[{"first":"Simone","middle":"Paolo","last":"Ponzetto"},{"first":"Michael","last":"Strube"}],"year":"2006b","title":"Semantic role labeling for coreference resolution","source":"Simone Paolo Ponzetto and Michael Strube. 2006b. Semantic role labeling for coreference resolution. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 143–146."},{"authors":[{"first":"Simone","middle":"Paolo","last":"Ponzetto"},{"first":"Michael","last":"Strube"}],"year":"2007","title":"Knowledge derived from Wikipedia for computing semantic relatedness","source":"Simone Paolo Ponzetto and Michael Strube. 2007. Knowledge derived from Wikipedia for computing semantic relatedness. Journal of Artificial Intelligence Research, 30:181–212."},{"authors":[{"first":"Hoifung","last":"Poon"},{"first":"Pedro","last":"Domingos"}],"year":"2008","title":"Joint unsupervised coreference resolution with Markov Logic","source":"Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 650–659."},{"authors":[{"first":"Andrei","last":"Popescu-Belis"},{"first":"Loı̈s","last":"Rigouste"},{"first":"Susanne","last":"Salmon-Alt"},{"first":"Laurent","last":"Romary"}],"year":"2004","title":"Online evaluation of coreference resolution","source":"Andrei Popescu-Belis, Loı̈s Rigouste, Susanne Salmon-Alt, and Laurent Romary. 2004. Online evaluation of coreference resolution. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 1507–1510."},{"authors":[{"first":"Long","last":"Qiu"},{"first":"Min-Yen","last":"Kan"},{"first":"Tat-Seng","last":"Chua"}],"year":"2004","title":"A public reference implementation of the RAP anaphora resolution algorithm","source":"Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A public reference implementation of the RAP anaphora resolution algorithm. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 291–294."},{"authors":[{"first":"John","middle":"Ross","last":"Quinlan"}],"year":"1993","title":"C4","source":"John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA."},{"authors":[{"first":"Altaf","last":"Rahman"},{"first":"Vincent","last":"Ng"}],"year":"2009","title":"Supervised models for coreference resolution","source":"Altaf Rahman and Vincent Ng. 2009. Supervised models for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 968–977. 1409"},{"authors":[{"first":"Marta","last":"Recasens"},{"first":"M.","middle":"Antónia","last":"Martı́"}],"year":"2009","title":"AnCora-CO: Coreferentially annotated corpora for Spanish and Catalan","source":"Marta Recasens and M. Antónia Martı́. 2009. AnCora-CO: Coreferentially annotated corpora for Spanish and Catalan. Language Resources and Evaluation, 43(4)."},{"authors":[{"first":"Marta","last":"Recasens"},{"first":"Toni","last":"Martı́"},{"first":"Mariona","last":"Taulé"},{"first":"Lluı́s","last":"Màrquez"},{"first":"Emili","last":"Sapena"}],"year":"2009","title":"SemEval-2010 Task 1: Coreference resolution in multiple languages","source":"Marta Recasens, Toni Martı́, Mariona Taulé, Lluı́s Màrquez, and Emili Sapena. 2009. SemEval-2010 Task 1: Coreference resolution in multiple languages. In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009), pages 70–75."},{"authors":[{"first":"Candace","last":"Sidner"}],"year":"1979","title":"Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse","source":"Candace Sidner. 1979. Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Ph.D. thesis, Massachusetts Institute of Technology, USA."},{"authors":[{"first":"Wee","middle":"Meng","last":"Soon"},{"first":"Hwee","middle":"Tou","last":"Ng"},{"first":"Chung","middle":"Yong","last":"Lim"}],"year":"1999","title":"Corpus-based learning for noun phrase coreference resolution","source":"Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 1999. Corpus-based learning for noun phrase coreference resolution. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 285–291."},{"authors":[{"first":"Wee","middle":"Meng","last":"Soon"},{"first":"Hwee","middle":"Tou","last":"Ng"},{"first":"Daniel","middle":"Chung Yong","last":"Lim"}],"year":"2001","title":"A machine learning approach to coreference resolution of noun phrases","source":"Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544."},{"authors":[{"first":"Veselin","last":"Stoyanov"},{"first":"Nathan","last":"Gilbert"},{"first":"Claire","last":"Cardie"},{"first":"Ellen","last":"Riloff"}],"year":"2009","title":"Conundrums in noun phrase coreference resolution: Making sense of the state-of-the-art","source":"Veselin Stoyanov, Nathan Gilbert, Claire Cardie, and Ellen Riloff. 2009. Conundrums in noun phrase coreference resolution: Making sense of the state-of-the-art. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 656–664."},{"authors":[{"first":"Veselin","last":"Stoyanov"},{"first":"Claire","last":"Cardie"},{"first":"Nathan","last":"Gilbert"},{"first":"Ellen","last":"Riloff"},{"first":"David","last":"Buttler"},{"first":"David","last":"Hysom"}],"year":"2010","title":"Coreference resolution with Reconcile","source":"Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff, David Buttler, and David Hysom. 2010. Coreference resolution with Reconcile. In Proceedings of the ACL 2010 Conference Short Papers."},{"authors":[{"first":"Michael","last":"Strube"},{"first":"Stefan","last":"Rapp"},{"first":"Christoph","last":"Müller"}],"year":"2002","title":"The influence of minimum edit distance on reference resolution","source":"Michael Strube, Stefan Rapp, and Christoph Müller. 2002. The influence of minimum edit distance on reference resolution. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 312–319."},{"authors":[{"first":"Michael","last":"Strube"}],"year":"2002","title":"NLP approaches to reference resolution","source":"Michael Strube. 2002. NLP approaches to reference resolution. In Tutorial Abstracts of ACL 2002, page 124."},{"authors":[{"first":"Michael","last":"Strube"}],"year":"2009","title":"Anaphernresolution","source":"Michael Strube. 2009. Anaphernresolution. In Computerlinguistik und Sprachtechnologie. Eine Einfuhrung. Springer, Heidelberg, Germany, 3rd edi-tion."},{"authors":[{"first":"Heike","last":"Telljohann"},{"first":"Erhard","last":"Hinrichs"},{"first":"Sandra","last":"Kübler"}],"year":"2004","title":"The tüba-d/z treebank: Annotating German with a context-free backbone","source":"Heike Telljohann, Erhard Hinrichs, and Sandra Kübler. 2004. The tüba-d/z treebank: Annotating German with a context-free backbone. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 2229–2235."},{"authors":[{"first":"Joel","last":"Tetreault"}],"year":"2005","title":"Empirical Evaluations of Pronoun Resolution","source":"Joel Tetreault. 2005. Empirical Evaluations of Pronoun Resolution. Ph.D. thesis, University of Rochester, USA."},{"authors":[{"first":"Olga","last":"Uryupina"}],"year":"2003","title":"High-precision identification of discourse new and unique noun phrases","source":"Olga Uryupina. 2003. High-precision identification of discourse new and unique noun phrases. In Proceedings of the ACL Student Research Workshop, pages 80–86."},{"authors":[{"first":"Olga","last":"Uryupina"}],"year":"2004","title":"Linguistically motivated sample selection for coreference resolution","source":"Olga Uryupina. 2004. Linguistically motivated sample selection for coreference resolution. In Proceedings of the 5th Discourse Anaphora and Anaphor Resolution Colloquium."},{"authors":[{"first":"Kees","last":"van Deemter"},{"first":"Rodger","last":"Kibble"}],"year":"2000","title":"On coreferring: Coreference in MUC and related annotation schemes","source":"Kees van Deemter and Rodger Kibble. 2000. On coreferring: Coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629– 637."},{"authors":[{"first":"Yannick","last":"Versley"},{"first":"Alessandro","last":"Moschitti"},{"first":"Massimo","last":"Poesio"},{"first":"Xiaofeng","last":"Yang"}],"year":"2008a","title":"Coreference systems based on kernels methods","source":"Yannick Versley, Alessandro Moschitti, Massimo Poesio, and Xiaofeng Yang. 2008a. Coreference systems based on kernels methods. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 961–968."},{"authors":[{"first":"Yannick","last":"Versley"},{"first":"Simone","middle":"Paolo","last":"Ponzetto"},{"first":"Massimo","last":"Poesio"},{"first":"Vladimir","last":"Eidelman"},{"first":"Alan","last":"Jern"},{"first":"Jason","last":"Smith"},{"first":"Xiaofeng","last":"Yang"},{"first":"Alessandro","last":"Moschitti"}],"year":"2008b","title":"BART: A modular toolkit for coreference resolution","source":"Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008b. BART: A modular toolkit for coreference resolution. In Proceedings of the ACL-08: HLT Demo Session, pages 9–12."},{"authors":[{"first":"Yannick","last":"Versley"}],"year":"2006","title":"A constraint-based approach to noun phrase coreference resolution in German newspaper text","source":"Yannick Versley. 2006. A constraint-based approach to noun phrase coreference resolution in German newspaper text. In Konferenz zur Verarbeitung Natürlicher Sprache."},{"authors":[{"first":"Yannick","last":"Versley"}],"year":"2007","title":"Antecedent selection techniques for high-recall coreference resolution","source":"Yannick Versley. 2007. Antecedent selection techniques for high-recall coreference resolution. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 496–505."},{"authors":[{"first":"Renata","last":"Vieira"},{"first":"Massimo","last":"Poesio"}],"year":"2000","title":"Processing definite descriptions in corpora","source":"Renata Vieira and Massimo Poesio. 2000. Processing definite descriptions in corpora. In S. Botley and A. McEnery, editors, Corpus-based and Computational Approaches to Discourse Anaphora, pages 189–212. UCL Press."},{"authors":[{"first":"Marc","last":"Vilain"},{"first":"John","last":"Burger"},{"first":"John","last":"Aberdeen"},{"first":"Dennis","last":"Connolly"},{"first":"Lynette","last":"Hirschman"}],"year":"1995","title":"A model-theoretic coreference scoring scheme","source":"Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of the Sixth Message Understanding Conference, pages 45–52."},{"authors":[{"first":"Marilyn","last":"Walker"},{"first":"Aravind","last":"Joshi"},{"first":"Ellen","last":"Prince"},{"last":"editors"}],"year":"1998","title":"Centering Theory in Discourse","source":"Marilyn Walker, Aravind Joshi, and Ellen Prince, editors. 1998. Centering Theory in Discourse. Oxford University Press."},{"authors":[{"first":"Holger","last":"Wunsch"}],"year":"2010","title":"Rule-based and Memory-based Pronoun Resolution for German: A Comparison and Assessment of Data Sources","source":"Holger Wunsch. 2010. Rule-based and Memory-based Pronoun Resolution for German: A Comparison and Assessment of Data Sources. Ph.D. thesis, University of Tübingen, Germany."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"}],"year":"2007","title":"Coreference resolution using semantic relatedness information from automatically discovered patterns","source":"Xiaofeng Yang and Jian Su. 2007. Coreference resolution using semantic relatedness information from automatically discovered patterns. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 528–535. 1410"},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Guodong","last":"Zhou"},{"first":"Jian","last":"Su"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2003","title":"Coreference resolution using competitive learning approach","source":"Xiaofeng Yang, Guodong Zhou, Jian Su, and Chew Lim Tan. 2003. Coreference resolution using competitive learning approach. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 176–183."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2004a","title":"Improving noun phrase coreference resolution by matching strings","source":"Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2004a. Improving noun phrase coreference resolution by matching strings. In Proceedings of the First International Joint Conference on Natural Language Processing, pages 22–31."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"GuoDong","last":"Zhou"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2004b","title":"An NP-cluster based approach to coreference resolution","source":"Xiaofeng Yang, Jian Su, GuoDong Zhou, and Chew Lim Tan. 2004b. An NP-cluster based approach to coreference resolution. In Proceedings of the 20th International Conference on Computational Linguistics, pages 226–232."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2005","title":"Improving pronoun resolution using statistics-based semantic compatibility information","source":"Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 165–172."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2006","title":"Kernel based pronoun resolution with structured syntactic knowledge","source":"Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2006. Kernel based pronoun resolution with structured syntactic knowledge. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 41–48."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"Jun","last":"Lang"},{"first":"Chew","middle":"Lim","last":"Tan"},{"first":"Sheng","last":"Li"}],"year":"2008a","title":"An entity-mention model for coreference resolution with inductive logic programming","source":"Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan, and Sheng Li. 2008a. An entity-mention model for coreference resolution with inductive logic programming. In Proceedings of ACL-08: HLT, pages 843–851."},{"authors":[{"first":"Xiaofeng","last":"Yang"},{"first":"Jian","last":"Su"},{"first":"Chew","middle":"Lim","last":"Tan"}],"year":"2008b","title":"A twin-candidate model for learning-based anaphora resolution","source":"Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2008b. A twin-candidate model for learning-based anaphora resolution. Computational Linguistics, 34(3):327– 356."},{"authors":[{"first":"Dmitry","last":"Zelenko"},{"first":"Chinatsu","last":"Aone"},{"first":"Jason","last":"Tibbetts"}],"year":"2004","title":"Coreference resolution for information extraction","source":"Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts. 2004. Coreference resolution for information extraction. In Proceedings of the ACL Workshop on Reference Resolution and its Applications, pages 9– 16."},{"authors":[{"first":"Shanheng","last":"Zhao"},{"first":"Hwee","middle":"Tou","last":"Ng"}],"year":"2007","title":"Identifica-tion and resolution of Chinese zero pronouns: A machine learning approach","source":"Shanheng Zhao and Hwee Tou Ng. 2007. Identifica-tion and resolution of Chinese zero pronouns: A machine learning approach. In Proceedings of the 2007 Joint Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning, pages 541–550."},{"authors":[{"first":"GuoDong","last":"Zhou"},{"first":"Fang","last":"Kong"}],"year":"2009","title":"Global learning of noun phrase anaphoricity in coreference resolution via label propagation","source":"GuoDong Zhou and Fang Kong. 2009. Global learning of noun phrase anaphoricity in coreference resolution via label propagation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 978–986. 1411"}],"cites":[{"style":0,"text":"Deemter and Kibble (2000)","origin":{"pointer":"/sections/2/paragraphs/0","offset":434,"length":25},"authors":[{"last":"Deemter"},{"last":"Kibble"}],"year":"2000","references":[]},{"style":0,"text":"Charniak, 1972","origin":{"pointer":"/sections/2/paragraphs/0","offset":711,"length":14},"authors":[{"last":"Charniak"}],"year":"1972","references":["/references/16"]},{"style":0,"text":"Grosz (1977)","origin":{"pointer":"/sections/2/paragraphs/0","offset":793,"length":12},"authors":[{"last":"Grosz"}],"year":"1977","references":["/references/40"]},{"style":0,"text":"Sidner (1979)","origin":{"pointer":"/sections/2/paragraphs/0","offset":810,"length":13},"authors":[{"last":"Sidner"}],"year":"1979","references":["/references/119"]},{"style":0,"text":"Walker et al. (1998)","origin":{"pointer":"/sections/2/paragraphs/0","offset":1002,"length":20},"authors":[{"last":"Walker"},{"last":"al."}],"year":"1998","references":["/references/138"]},{"style":0,"text":"MUC-6 (1995)","origin":{"pointer":"/sections/2/paragraphs/1","offset":306,"length":12},"authors":[{"last":"MUC-6"}],"year":"1995","references":["/references/85"]},{"style":0,"text":"MUC-7 (1998)","origin":{"pointer":"/sections/2/paragraphs/1","offset":323,"length":12},"authors":[{"last":"MUC-7"}],"year":"1998","references":["/references/86"]},{"style":0,"text":"Connolly et al., 1994","origin":{"pointer":"/sections/2/paragraphs/2","offset":104,"length":21},"authors":[{"last":"Connolly"},{"last":"al."}],"year":"1994","references":["/references/20"]},{"style":0,"text":"Mitkov (2002)","origin":{"pointer":"/sections/2/paragraphs/2","offset":493,"length":13},"authors":[{"last":"Mitkov"}],"year":"2002","references":["/references/83"]},{"style":0,"text":"Mitkov (1999)","origin":{"pointer":"/sections/2/paragraphs/2","offset":540,"length":13},"authors":[{"last":"Mitkov"}],"year":"1999","references":["/references/81"]},{"style":0,"text":"Strube (2009)","origin":{"pointer":"/sections/2/paragraphs/2","offset":555,"length":13},"authors":[{"last":"Strube"}],"year":"2009","references":["/references/126"]},{"style":0,"text":"Strube (2002)","origin":{"pointer":"/sections/2/paragraphs/2","offset":602,"length":13},"authors":[{"last":"Strube"}],"year":"2002","references":["/references/125"]},{"style":0,"text":"Ponzetto and Poesio (2009)","origin":{"pointer":"/sections/2/paragraphs/2","offset":617,"length":26},"authors":[{"last":"Ponzetto"},{"last":"Poesio"}],"year":"2009","references":["/references/108"]},{"style":0,"text":"Marcus et al., 1993","origin":{"pointer":"/sections/3/paragraphs/2","offset":111,"length":19},"authors":[{"last":"Marcus"},{"last":"al."}],"year":"1993","references":["/references/76"]},{"style":0,"text":"Hovy et al., 2006","origin":{"pointer":"/sections/3/paragraphs/2","offset":208,"length":17},"authors":[{"last":"Hovy"},{"last":"al."}],"year":"2006","references":["/references/52"]},{"style":0,"text":"Telljohann et al., 2004","origin":{"pointer":"/sections/3/paragraphs/2","offset":256,"length":23},"authors":[{"last":"Telljohann"},{"last":"al."}],"year":"2004","references":["/references/127"]},{"style":0,"text":"Hajic̆ et al., 2006","origin":{"pointer":"/sections/3/paragraphs/2","offset":396,"length":19},"authors":[{"last":"Hajic̆"},{"last":"al."}],"year":"2006","references":["/references/44"]},{"style":0,"text":"Iida et al., 2007b","origin":{"pointer":"/sections/3/paragraphs/2","offset":520,"length":18},"authors":[{"last":"Iida"},{"last":"al."}],"year":"2007b","references":["/references/58"]},{"style":0,"text":"Recasens and Martı́, 2009","origin":{"pointer":"/sections/3/paragraphs/2","offset":610,"length":25},"authors":[{"last":"Recasens"},{"last":"Martı́"}],"year":"2009","references":["/references/117"]},{"style":0,"text":"Ohta et al., 2002","origin":{"pointer":"/sections/3/paragraphs/2","offset":720,"length":17},"authors":[{"last":"Ohta"},{"last":"al."}],"year":"2002","references":["/references/100"]},{"style":0,"text":"Hasler et al., 2006","origin":{"pointer":"/sections/3/paragraphs/3","offset":176,"length":19},"authors":[{"last":"Hasler"},{"last":"al."}],"year":"2006","references":["/references/46"]},{"style":0,"text":"Orăsan et al., 2008","origin":{"pointer":"/sections/3/paragraphs/3","offset":279,"length":19},"authors":[{"last":"Orăsan"},{"last":"al."}],"year":"2008","references":["/references/102"]},{"style":0,"text":"Heeman and Allen, 1995","origin":{"pointer":"/sections/3/paragraphs/3","offset":413,"length":22},"authors":[{"last":"Heeman"},{"last":"Allen"}],"year":"1995","references":["/references/47"]},{"style":0,"text":"Recasens et al., 2009","origin":{"pointer":"/sections/3/paragraphs/4","offset":158,"length":21},"authors":[{"last":"Recasens"},{"last":"al."}],"year":"2009","references":["/references/118"]},{"style":0,"text":"Aone and Bennett (1995)","origin":{"pointer":"/sections/4/paragraphs/0","offset":334,"length":23},"authors":[{"last":"Aone"},{"last":"Bennett"}],"year":"1995","references":["/references/0"]},{"style":0,"text":"McCarthy and Lehnert (1995)","origin":{"pointer":"/sections/4/paragraphs/0","offset":362,"length":27},"authors":[{"last":"McCarthy"},{"last":"Lehnert"}],"year":"1995","references":["/references/80"]},{"style":0,"text":"Ng and Cardie (2002c)","origin":{"pointer":"/sections/4/paragraphs/4","offset":71,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Strube et al. (2002)","origin":{"pointer":"/sections/4/paragraphs/5","offset":289,"length":20},"authors":[{"last":"Strube"},{"last":"al."}],"year":"2002","references":["/references/124"]},{"style":0,"text":"Yang et al. (2003)","origin":{"pointer":"/sections/4/paragraphs/5","offset":311,"length":18},"authors":[{"last":"Yang"},{"last":"al."}],"year":"2003","references":["/references/141"]},{"style":0,"text":"Uryupina (2004)","origin":{"pointer":"/sections/4/paragraphs/6","offset":66,"length":15},"authors":[{"last":"Uryupina"}],"year":"2004","references":["/references/130"]},{"style":0,"text":"Hoste and Daelemans (2005)","origin":{"pointer":"/sections/4/paragraphs/6","offset":86,"length":26},"authors":[{"last":"Hoste"},{"last":"Daelemans"}],"year":"2005","references":["/references/50"]},{"style":0,"text":"Harabagiu et al. (2001)","origin":{"pointer":"/sections/4/paragraphs/6","offset":251,"length":23},"authors":[{"last":"Harabagiu"},{"last":"al."}],"year":"2001","references":["/references/45"]},{"style":0,"text":"Ng and Cardie (2002a)","origin":{"pointer":"/sections/4/paragraphs/6","offset":277,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002a","references":["/references/89"]},{"style":0,"text":"Quinlan, 1993","origin":{"pointer":"/sections/4/paragraphs/6","offset":677,"length":13},"authors":[{"last":"Quinlan"}],"year":"1993","references":["/references/115"]},{"style":0,"text":"Cohen, 1995","origin":{"pointer":"/sections/4/paragraphs/6","offset":825,"length":11},"authors":[{"last":"Cohen"}],"year":"1995","references":["/references/19"]},{"style":0,"text":"Bosch, 2005","origin":{"pointer":"/sections/4/paragraphs/6","offset":901,"length":11},"authors":[{"last":"Bosch"}],"year":"2005","references":[]},{"style":0,"text":"Berger et al., 1996","origin":{"pointer":"/sections/4/paragraphs/6","offset":1091,"length":19},"authors":[{"last":"Berger"},{"last":"al."}],"year":"1996","references":["/references/7"]},{"style":0,"text":"Freund and Schapire, 1999","origin":{"pointer":"/sections/4/paragraphs/6","offset":1132,"length":25},"authors":[{"last":"Freund"},{"last":"Schapire"}],"year":"1999","references":["/references/34"]},{"style":0,"text":"Joachims, 1999","origin":{"pointer":"/sections/4/paragraphs/8","offset":264,"length":14},"authors":[{"last":"Joachims"}],"year":"1999","references":["/references/62"]},{"style":0,"text":"Soon et al., 2001","origin":{"pointer":"/sections/4/paragraphs/9","offset":52,"length":17},"authors":[{"last":"Soon"},{"last":"al."}],"year":"2001","references":["/references/121"]},{"style":0,"text":"Ng and Cardie, 2002c","origin":{"pointer":"/sections/4/paragraphs/9","offset":98,"length":20},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Bansal et al., 2002","origin":{"pointer":"/sections/4/paragraphs/11","offset":129,"length":19},"authors":[{"last":"Bansal"},{"last":"al."}],"year":"2002","references":["/references/2"]},{"style":0,"text":"McCallum and Wellner (2004)","origin":{"pointer":"/sections/4/paragraphs/11","offset":243,"length":27},"authors":[{"last":"McCallum"},{"last":"Wellner"}],"year":"2004","references":["/references/79"]},{"style":0,"text":"Zelenko et al. (2004)","origin":{"pointer":"/sections/4/paragraphs/11","offset":272,"length":21},"authors":[{"last":"Zelenko"},{"last":"al."}],"year":"2004","references":["/references/148"]},{"style":0,"text":"Finley and Joachims (2005)","origin":{"pointer":"/sections/4/paragraphs/11","offset":299,"length":26},"authors":[{"last":"Finley"},{"last":"Joachims"}],"year":"2005","references":["/references/33"]},{"style":0,"text":"McCallum and Wellner (2004)","origin":{"pointer":"/sections/4/paragraphs/11","offset":519,"length":27},"authors":[{"last":"McCallum"},{"last":"Wellner"}],"year":"2004","references":["/references/79"]},{"style":0,"text":"Dempster, 1968","origin":{"pointer":"/sections/4/paragraphs/13","offset":156,"length":14},"authors":[{"last":"Dempster"}],"year":"1968","references":["/references/27"]},{"style":0,"text":"Kehler (1997)","origin":{"pointer":"/sections/4/paragraphs/13","offset":266,"length":13},"authors":[{"last":"Kehler"}],"year":"1997","references":["/references/65"]},{"style":0,"text":"Bean and Riloff (2004)","origin":{"pointer":"/sections/4/paragraphs/13","offset":284,"length":22},"authors":[{"last":"Bean"},{"last":"Riloff"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Cardie and Wagstaff, 1999","origin":{"pointer":"/sections/4/paragraphs/14","offset":258,"length":25},"authors":[{"last":"Cardie"},{"last":"Wagstaff"}],"year":"1999","references":["/references/12"]},{"style":0,"text":"Klenner and Ailloud, 2008","origin":{"pointer":"/sections/4/paragraphs/14","offset":285,"length":25},"authors":[{"last":"Klenner"},{"last":"Ailloud"}],"year":"2008","references":["/references/67"]},{"style":0,"text":"Ng and Cardie (2002c)","origin":{"pointer":"/sections/4/paragraphs/17","offset":147,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Nicolae and Nicolae (2006)","origin":{"pointer":"/sections/4/paragraphs/17","offset":244,"length":26},"authors":[{"last":"Nicolae"},{"last":"Nicolae"}],"year":"2006","references":["/references/98"]},{"style":0,"text":"Soon et al. (2001)","origin":{"pointer":"/sections/4/paragraphs/19","offset":55,"length":18},"authors":[{"last":"Soon"},{"last":"al."}],"year":"2001","references":["/references/121"]},{"style":0,"text":"Ng and Cardie (2002c)","origin":{"pointer":"/sections/4/paragraphs/19","offset":78,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Paice and Husk (1987)","origin":{"pointer":"/sections/4/paragraphs/20","offset":223,"length":21},"authors":[{"last":"Paice"},{"last":"Husk"}],"year":"1987","references":["/references/103"]},{"style":0,"text":"Lappin and Leass (1994)","origin":{"pointer":"/sections/4/paragraphs/20","offset":246,"length":23},"authors":[{"last":"Lappin"},{"last":"Leass"}],"year":"1994","references":["/references/71"]},{"style":0,"text":"Kennedy and Boguraev (1996)","origin":{"pointer":"/sections/4/paragraphs/20","offset":271,"length":27},"authors":[{"last":"Kennedy"},{"last":"Boguraev"}],"year":"1996","references":["/references/66"]},{"style":0,"text":"Evans (2001)","origin":{"pointer":"/sections/4/paragraphs/20","offset":330,"length":12},"authors":[{"last":"Evans"}],"year":"2001","references":["/references/31"]},{"style":0,"text":"Müller (2006)","origin":{"pointer":"/sections/4/paragraphs/20","offset":344,"length":13},"authors":[{"last":"Müller"}],"year":"2006","references":["/references/88"]},{"style":0,"text":"Versley et al. (2008a)","origin":{"pointer":"/sections/4/paragraphs/20","offset":359,"length":22},"authors":[{"last":"Versley"},{"last":"al."}],"year":"2008a","references":["/references/132"]},{"style":0,"text":"Bergsma et al. (2008)","origin":{"pointer":"/sections/4/paragraphs/20","offset":418,"length":21},"authors":[{"last":"Bergsma"},{"last":"al."}],"year":"2008","references":["/references/9"]},{"style":0,"text":"Vieira and Poesio (2000)","origin":{"pointer":"/sections/4/paragraphs/20","offset":538,"length":24},"authors":[{"last":"Vieira"},{"last":"Poesio"}],"year":"2000","references":["/references/136"]},{"style":0,"text":"Bean and Riloff (1999)","origin":{"pointer":"/sections/4/paragraphs/20","offset":599,"length":22},"authors":[{"last":"Bean"},{"last":"Riloff"}],"year":"1999","references":["/references/4"]},{"style":0,"text":"Ng and Cardie (2002b)","origin":{"pointer":"/sections/4/paragraphs/21","offset":278,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002b","references":["/references/90"]},{"style":0,"text":"Uryupina (2003)","origin":{"pointer":"/sections/4/paragraphs/21","offset":301,"length":15},"authors":[{"last":"Uryupina"}],"year":"2003","references":["/references/129"]},{"style":0,"text":"Poesio et al. (2004b)","origin":{"pointer":"/sections/4/paragraphs/21","offset":318,"length":21},"authors":[{"last":"Poesio"},{"last":"al."}],"year":"2004b","references":["/references/106"]},{"style":0,"text":"Denis and Baldridge, 2007a","origin":{"pointer":"/sections/4/paragraphs/21","offset":664,"length":26},"authors":[{"last":"Denis"},{"last":"Baldridge"}],"year":"2007a","references":["/references/28"]},{"style":0,"text":"Zhou and Kong, 2009","origin":{"pointer":"/sections/4/paragraphs/21","offset":712,"length":19},"authors":[{"last":"Zhou"},{"last":"Kong"}],"year":"2009","references":["/references/150"]},{"style":0,"text":"Ng, 2009","origin":{"pointer":"/sections/4/paragraphs/21","offset":752,"length":8},"authors":[{"last":"Ng"}],"year":"2009","references":["/references/96"]},{"style":0,"text":"McCallum and Wellner (2004)","origin":{"pointer":"/sections/4/paragraphs/22","offset":25,"length":27},"authors":[{"last":"McCallum"},{"last":"Wellner"}],"year":"2004","references":["/references/79"]},{"style":0,"text":"Finley and Joachims (2005)","origin":{"pointer":"/sections/4/paragraphs/22","offset":57,"length":26},"authors":[{"last":"Finley"},{"last":"Joachims"}],"year":"2005","references":["/references/33"]},{"style":0,"text":"Klenner (2007)","origin":{"pointer":"/sections/4/paragraphs/22","offset":266,"length":14},"authors":[{"last":"Klenner"}],"year":"2007","references":["/references/69"]},{"style":0,"text":"Finkel and Manning (2008)","origin":{"pointer":"/sections/4/paragraphs/22","offset":285,"length":25},"authors":[{"last":"Finkel"},{"last":"Manning"}],"year":"2008","references":["/references/32"]},{"style":0,"text":"McCallum and Wellner (2003)","origin":{"pointer":"/sections/4/paragraphs/22","offset":1734,"length":27},"authors":[{"last":"McCallum"},{"last":"Wellner"}],"year":"2003","references":["/references/78"]},{"style":0,"text":"Klenner and Ailloud (2009)","origin":{"pointer":"/sections/4/paragraphs/24","offset":19,"length":26},"authors":[{"last":"Klenner"},{"last":"Ailloud"}],"year":"2009","references":["/references/68"]},{"style":0,"text":"Luo et al. (2004)","origin":{"pointer":"/sections/4/paragraphs/26","offset":125,"length":17},"authors":[{"last":"Luo"},{"last":"al."}],"year":"2004","references":["/references/73"]},{"style":0,"text":"Culotta et al. (2007)","origin":{"pointer":"/sections/4/paragraphs/27","offset":74,"length":21},"authors":[{"last":"Culotta"},{"last":"al."}],"year":"2007","references":["/references/23"]},{"style":0,"text":"Daumé III and Marcu (2005)","origin":{"pointer":"/sections/4/paragraphs/27","offset":319,"length":26},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Walker et al. (1998)","origin":{"pointer":"/sections/4/paragraphs/28","offset":160,"length":20},"authors":[{"last":"Walker"},{"last":"al."}],"year":"1998","references":["/references/138"]},{"style":0,"text":"Iida et al. (2003)","origin":{"pointer":"/sections/4/paragraphs/28","offset":637,"length":18},"authors":[{"last":"Iida"},{"last":"al."}],"year":"2003","references":["/references/55"]},{"style":0,"text":"Versley, 2006","origin":{"pointer":"/sections/4/paragraphs/29","offset":214,"length":13},"authors":[{"last":"Versley"}],"year":"2006","references":["/references/134"]},{"style":0,"text":"Denis and Baldridge, 2007b","origin":{"pointer":"/sections/4/paragraphs/29","offset":229,"length":26},"authors":[{"last":"Denis"},{"last":"Baldridge"}],"year":"2007b","references":["/references/29"]},{"style":0,"text":"Rahman and Ng (2009)","origin":{"pointer":"/sections/4/paragraphs/29","offset":455,"length":20},"authors":[{"last":"Rahman"},{"last":"Ng"}],"year":"2009","references":["/references/116"]},{"style":0,"text":"Lappin and Leass’s (1994)","origin":{"pointer":"/sections/4/paragraphs/29","offset":773,"length":25},"authors":[{"last":"Lappin"},{"last":"Leass’s"}],"year":"1994","references":[]},{"style":0,"text":"Denis and Baldridge (2008)","origin":{"pointer":"/sections/4/paragraphs/30","offset":305,"length":26},"authors":[{"last":"Denis"},{"last":"Baldridge"}],"year":"2008","references":["/references/30"]},{"style":0,"text":"Rahman and Ng (2009)","origin":{"pointer":"/sections/4/paragraphs/30","offset":439,"length":20},"authors":[{"last":"Rahman"},{"last":"Ng"}],"year":"2009","references":["/references/116"]},{"style":0,"text":"Daumé III and Marcu (2005)","origin":{"pointer":"/sections/5/paragraphs/1","offset":264,"length":26},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Strube et al., 2002","origin":{"pointer":"/sections/5/paragraphs/1","offset":402,"length":19},"authors":[{"last":"Strube"},{"last":"al."}],"year":"2002","references":["/references/124"]},{"style":0,"text":"Castaño et al., 2002","origin":{"pointer":"/sections/5/paragraphs/1","offset":455,"length":20},"authors":[{"last":"Castaño"},{"last":"al."}],"year":"2002","references":["/references/14"]},{"style":0,"text":"Yang et al. (2004a)","origin":{"pointer":"/sections/5/paragraphs/1","offset":478,"length":19},"authors":[{"last":"Yang"},{"last":"al."}],"year":"2004a","references":["/references/142"]},{"style":0,"text":"Ge et al. (1998)","origin":{"pointer":"/sections/5/paragraphs/2","offset":65,"length":16},"authors":[{"last":"Ge"},{"last":"al."}],"year":"1998","references":["/references/36"]},{"style":0,"text":"Hobbs’s (1978)","origin":{"pointer":"/sections/5/paragraphs/2","offset":198,"length":14},"authors":[{"last":"Hobbs’s"}],"year":"1978","references":[]},{"style":0,"text":"Luo and Zitouni (2005)","origin":{"pointer":"/sections/5/paragraphs/2","offset":264,"length":22},"authors":[{"last":"Luo"},{"last":"Zitouni"}],"year":"2005","references":["/references/72"]},{"style":0,"text":"Chomsky, 1988","origin":{"pointer":"/sections/5/paragraphs/2","offset":361,"length":13},"authors":[{"last":"Chomsky"}],"year":"1988","references":["/references/18"]},{"style":0,"text":"Bergsma and Lin (2006)","origin":{"pointer":"/sections/5/paragraphs/2","offset":415,"length":22},"authors":[{"last":"Bergsma"},{"last":"Lin"}],"year":"2006","references":["/references/8"]},{"style":0,"text":"Iida et al. (2006)","origin":{"pointer":"/sections/5/paragraphs/2","offset":814,"length":18},"authors":[{"last":"Iida"},{"last":"al."}],"year":"2006","references":["/references/56"]},{"style":0,"text":"Yang et al. (2006)","origin":{"pointer":"/sections/5/paragraphs/2","offset":837,"length":18},"authors":[{"last":"Yang"},{"last":"al."}],"year":"2006","references":["/references/145"]},{"style":0,"text":"Ng and Cardie’s (2002c)","origin":{"pointer":"/sections/5/paragraphs/3","offset":112,"length":23},"authors":[{"last":"Ng"},{"last":"Cardie’s"}],"year":"2002c","references":[]},{"style":0,"text":"Dagan and Itai, 1990","origin":{"pointer":"/sections/5/paragraphs/4","offset":226,"length":20},"authors":[{"last":"Dagan"},{"last":"Itai"}],"year":"1990","references":["/references/25"]},{"style":0,"text":"Kehler et al., 2004b","origin":{"pointer":"/sections/5/paragraphs/4","offset":248,"length":20},"authors":[{"last":"Kehler"},{"last":"al."}],"year":"2004b","references":["/references/64"]},{"style":0,"text":"Yang et al., 2005","origin":{"pointer":"/sections/5/paragraphs/4","offset":270,"length":17},"authors":[{"last":"Yang"},{"last":"al."}],"year":"2005","references":["/references/144"]},{"style":0,"text":"Haghighi and Klein, 2009","origin":{"pointer":"/sections/5/paragraphs/4","offset":289,"length":24},"authors":[{"last":"Haghighi"},{"last":"Klein"}],"year":"2009","references":["/references/42"]},{"style":0,"text":"Harabagiu et al., 2001","origin":{"pointer":"/sections/5/paragraphs/4","offset":648,"length":22},"authors":[{"last":"Harabagiu"},{"last":"al."}],"year":"2001","references":["/references/45"]},{"style":0,"text":"Versley, 2007","origin":{"pointer":"/sections/5/paragraphs/4","offset":672,"length":13},"authors":[{"last":"Versley"}],"year":"2007","references":["/references/135"]},{"style":0,"text":"Ng, 2007a","origin":{"pointer":"/sections/5/paragraphs/4","offset":728,"length":9},"authors":[{"last":"Ng"}],"year":"2007a","references":["/references/93"]},{"style":0,"text":"Huang et al., 2009","origin":{"pointer":"/sections/5/paragraphs/4","offset":739,"length":18},"authors":[{"last":"Huang"},{"last":"al."}],"year":"2009","references":["/references/53"]},{"style":0,"text":"Soon et al., 2001","origin":{"pointer":"/sections/5/paragraphs/4","offset":922,"length":17},"authors":[{"last":"Soon"},{"last":"al."}],"year":"2001","references":["/references/121"]},{"style":0,"text":"Ponzetto and Strube, 2006a","origin":{"pointer":"/sections/5/paragraphs/4","offset":965,"length":26},"authors":[{"last":"Ponzetto"},{"last":"Strube"}],"year":"2006a","references":["/references/109"]},{"style":0,"text":"Nicolae and Nicolae, 2006","origin":{"pointer":"/sections/5/paragraphs/4","offset":1061,"length":25},"authors":[{"last":"Nicolae"},{"last":"Nicolae"}],"year":"2006","references":["/references/98"]},{"style":0,"text":"Poesio et al. (2007)","origin":{"pointer":"/sections/5/paragraphs/4","offset":1481,"length":20},"authors":[{"last":"Poesio"},{"last":"al."}],"year":"2007","references":["/references/107"]},{"style":0,"text":"Bean and Riloff, 2004","origin":{"pointer":"/sections/5/paragraphs/4","offset":1590,"length":21},"authors":[{"last":"Bean"},{"last":"Riloff"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Ji et al., 2005","origin":{"pointer":"/sections/5/paragraphs/4","offset":1634,"length":15},"authors":[{"last":"Ji"},{"last":"al."}],"year":"2005","references":["/references/61"]},{"style":0,"text":"Ponzetto and Strube, 2006b","origin":{"pointer":"/sections/5/paragraphs/4","offset":1668,"length":26},"authors":[{"last":"Ponzetto"},{"last":"Strube"}],"year":"2006b","references":["/references/110"]},{"style":0,"text":"Kong et al., 2009","origin":{"pointer":"/sections/5/paragraphs/4","offset":1696,"length":17},"authors":[{"last":"Kong"},{"last":"al."}],"year":"2009","references":["/references/70"]},{"style":0,"text":"Orăsan and Evans, 2007","origin":{"pointer":"/sections/5/paragraphs/4","offset":1729,"length":22},"authors":[{"last":"Orăsan"},{"last":"Evans"}],"year":"2007","references":["/references/101"]},{"style":0,"text":"Daumé III and Marcu, 2005","origin":{"pointer":"/sections/5/paragraphs/5","offset":354,"length":25},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Haghighi and Klein, 2009","origin":{"pointer":"/sections/5/paragraphs/5","offset":381,"length":24},"authors":[{"last":"Haghighi"},{"last":"Klein"}],"year":"2009","references":["/references/42"]},{"style":0,"text":"Modjeska et al., 2003","origin":{"pointer":"/sections/5/paragraphs/5","offset":595,"length":21},"authors":[{"last":"Modjeska"},{"last":"al."}],"year":"2003","references":["/references/84"]},{"style":0,"text":"Markert and Nissim, 2005","origin":{"pointer":"/sections/5/paragraphs/5","offset":618,"length":24},"authors":[{"last":"Markert"},{"last":"Nissim"}],"year":"2005","references":["/references/77"]},{"style":0,"text":"Poesio et al., 2004a","origin":{"pointer":"/sections/5/paragraphs/5","offset":669,"length":20},"authors":[{"last":"Poesio"},{"last":"al."}],"year":"2004a","references":["/references/105"]},{"style":0,"text":"Garera and Yarowsky (2006)","origin":{"pointer":"/sections/5/paragraphs/5","offset":747,"length":26},"authors":[{"last":"Garera"},{"last":"Yarowsky"}],"year":"2006","references":["/references/35"]},{"style":0,"text":"Yang and Su, 2007","origin":{"pointer":"/sections/5/paragraphs/5","offset":827,"length":17},"authors":[{"last":"Yang"},{"last":"Su"}],"year":"2007","references":["/references/140"]},{"style":0,"text":"Bean and Riloff, 2004","origin":{"pointer":"/sections/5/paragraphs/5","offset":890,"length":21},"authors":[{"last":"Bean"},{"last":"Riloff"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Hirst (1981)","origin":{"pointer":"/sections/5/paragraphs/6","offset":100,"length":12},"authors":[{"last":"Hirst"}],"year":"1981","references":["/references/48"]},{"style":0,"text":"Iida et al. (2009)","origin":{"pointer":"/sections/5/paragraphs/6","offset":441,"length":18},"authors":[{"last":"Iida"},{"last":"al."}],"year":"2009","references":["/references/59"]},{"style":0,"text":"Tetreault (2005)","origin":{"pointer":"/sections/5/paragraphs/6","offset":582,"length":16},"authors":[{"last":"Tetreault"}],"year":"2005","references":["/references/128"]},{"style":0,"text":"Grosz and Sidner’s (1986)","origin":{"pointer":"/sections/5/paragraphs/6","offset":612,"length":25},"authors":[{"last":"Grosz"},{"last":"Sidner’s"}],"year":"1986","references":[]},{"style":0,"text":"Ide and Cristea, 2000","origin":{"pointer":"/sections/5/paragraphs/6","offset":673,"length":21},"authors":[{"last":"Ide"},{"last":"Cristea"}],"year":"2000","references":["/references/54"]},{"style":0,"text":"Bengtson and Roth, 2008","origin":{"pointer":"/sections/5/paragraphs/7","offset":197,"length":23},"authors":[{"last":"Bengtson"},{"last":"Roth"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Luo et al., 2004","origin":{"pointer":"/sections/5/paragraphs/7","offset":338,"length":16},"authors":[{"last":"Luo"},{"last":"al."}],"year":"2004","references":["/references/73"]},{"style":0,"text":"Ng, 2007b","origin":{"pointer":"/sections/5/paragraphs/7","offset":478,"length":9},"authors":[{"last":"Ng"}],"year":"2007b","references":["/references/94"]},{"style":0,"text":"Ng, 2004","origin":{"pointer":"/sections/5/paragraphs/7","offset":627,"length":8},"authors":[{"last":"Ng"}],"year":"2004","references":["/references/92"]},{"style":0,"text":"Daumé III and Marcu, 2005","origin":{"pointer":"/sections/5/paragraphs/7","offset":661,"length":25},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Bean and Riloff, 1999","origin":{"pointer":"/sections/5/paragraphs/7","offset":726,"length":21},"authors":[{"last":"Bean"},{"last":"Riloff"}],"year":"1999","references":["/references/4"]},{"style":0,"text":"Ng and Cardie, 2002c","origin":{"pointer":"/sections/5/paragraphs/7","offset":894,"length":20},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Bengtson and Roth (2008)","origin":{"pointer":"/sections/5/paragraphs/8","offset":109,"length":24},"authors":[{"last":"Bengtson"},{"last":"Roth"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Daumé III and Marcu (2005)","origin":{"pointer":"/sections/6/paragraphs/1","offset":28,"length":26},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Nicolae and Nicolae, 2006","origin":{"pointer":"/sections/6/paragraphs/3","offset":301,"length":25},"authors":[{"last":"Nicolae"},{"last":"Nicolae"}],"year":"2006","references":["/references/98"]},{"style":0,"text":"Stoyanov et al. (2009)","origin":{"pointer":"/sections/6/paragraphs/3","offset":491,"length":22},"authors":[{"last":"Stoyanov"},{"last":"al."}],"year":"2009","references":["/references/122"]},{"style":0,"text":"Vilain et al., 1995","origin":{"pointer":"/sections/6/paragraphs/4","offset":283,"length":19},"authors":[{"last":"Vilain"},{"last":"al."}],"year":"1995","references":["/references/137"]},{"style":0,"text":"Bagga and Baldwin, 1998","origin":{"pointer":"/sections/6/paragraphs/5","offset":85,"length":23},"authors":[{"last":"Bagga"},{"last":"Baldwin"}],"year":"1998","references":["/references/1"]},{"style":0,"text":"Luo, 2005","origin":{"pointer":"/sections/6/paragraphs/5","offset":120,"length":9},"authors":[{"last":"Luo"}],"year":"2005","references":["/references/74"]},{"style":0,"text":"Rahman and Ng (2009)","origin":{"pointer":"/sections/6/paragraphs/5","offset":363,"length":20},"authors":[{"last":"Rahman"},{"last":"Ng"}],"year":"2009","references":["/references/116"]},{"style":0,"text":"Stoyanov et al. (2009)","origin":{"pointer":"/sections/6/paragraphs/5","offset":388,"length":22},"authors":[{"last":"Stoyanov"},{"last":"al."}],"year":"2009","references":["/references/122"]},{"style":0,"text":"Carletta, 1996","origin":{"pointer":"/sections/6/paragraphs/6","offset":141,"length":14},"authors":[{"last":"Carletta"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"Popescu-Belis et al. (2004)","origin":{"pointer":"/sections/6/paragraphs/6","offset":205,"length":27},"authors":[{"last":"Popescu-Belis"},{"last":"al."}],"year":"2004","references":["/references/113"]},{"style":0,"text":"Byron (2001)","origin":{"pointer":"/sections/6/paragraphs/6","offset":629,"length":12},"authors":[{"last":"Byron"}],"year":"2001","references":["/references/10"]},{"style":0,"text":"Müller et al., 2002","origin":{"pointer":"/sections/7/paragraphs/0","offset":317,"length":19},"authors":[{"last":"Müller"},{"last":"al."}],"year":"2002","references":["/references/87"]},{"style":0,"text":"Kehler et al., 2004a","origin":{"pointer":"/sections/7/paragraphs/0","offset":354,"length":20},"authors":[{"last":"Kehler"},{"last":"al."}],"year":"2004a","references":["/references/63"]},{"style":0,"text":"Cherry and Bergsma, 2005","origin":{"pointer":"/sections/7/paragraphs/0","offset":385,"length":24},"authors":[{"last":"Cherry"},{"last":"Bergsma"}],"year":"2005","references":["/references/17"]},{"style":0,"text":"Ng, 2008","origin":{"pointer":"/sections/7/paragraphs/0","offset":411,"length":8},"authors":[{"last":"Ng"}],"year":"2008","references":["/references/95"]},{"style":0,"text":"Poon and Domingos (2008)","origin":{"pointer":"/sections/7/paragraphs/0","offset":556,"length":24},"authors":[{"last":"Poon"},{"last":"Domingos"}],"year":"2008","references":["/references/112"]},{"style":0,"text":"Converse (2006)","origin":{"pointer":"/sections/7/paragraphs/1","offset":294,"length":15},"authors":[{"last":"Converse"}],"year":"2006","references":["/references/22"]},{"style":0,"text":"Iida (2007)","origin":{"pointer":"/sections/7/paragraphs/1","offset":328,"length":11},"authors":[{"last":"Iida"}],"year":"2007","references":["/references/60"]},{"style":0,"text":"Luo and Zitouni (2005)","origin":{"pointer":"/sections/7/paragraphs/1","offset":356,"length":22},"authors":[{"last":"Luo"},{"last":"Zitouni"}],"year":"2005","references":["/references/72"]},{"style":0,"text":"Hoste (2005)","origin":{"pointer":"/sections/7/paragraphs/1","offset":394,"length":12},"authors":[{"last":"Hoste"}],"year":"2005","references":["/references/51"]},{"style":0,"text":"Wunsch (2010)","origin":{"pointer":"/sections/7/paragraphs/1","offset":423,"length":13},"authors":[{"last":"Wunsch"}],"year":"2010","references":["/references/139"]},{"style":0,"text":"Nilsson (2010)","origin":{"pointer":"/sections/7/paragraphs/1","offset":454,"length":14},"authors":[{"last":"Nilsson"}],"year":"2010","references":["/references/99"]},{"style":0,"text":"Iida et al. (2007a)","origin":{"pointer":"/sections/7/paragraphs/1","offset":681,"length":19},"authors":[{"last":"Iida"},{"last":"al."}],"year":"2007a","references":["/references/57"]},{"style":0,"text":"Zhao and Ng (2007)","origin":{"pointer":"/sections/7/paragraphs/1","offset":702,"length":18},"authors":[{"last":"Zhao"},{"last":"Ng"}],"year":"2007","references":["/references/149"]},{"style":0,"text":"Mitkov (2001)","origin":{"pointer":"/sections/7/paragraphs/2","offset":3,"length":13},"authors":[{"last":"Mitkov"}],"year":"2001","references":["/references/82"]},{"style":0,"text":"Soon et al. (2001)","origin":{"pointer":"/sections/7/paragraphs/2","offset":359,"length":18},"authors":[{"last":"Soon"},{"last":"al."}],"year":"2001","references":["/references/121"]},{"style":0,"text":"Qiu et al., 2004","origin":{"pointer":"/sections/7/paragraphs/2","offset":717,"length":16},"authors":[{"last":"Qiu"},{"last":"al."}],"year":"2004","references":["/references/114"]},{"style":0,"text":"Poesio and Kabadjov, 2004","origin":{"pointer":"/sections/7/paragraphs/2","offset":744,"length":25},"authors":[{"last":"Poesio"},{"last":"Kabadjov"}],"year":"2004","references":["/references/104"]},{"style":0,"text":"Versley et al., 2008b","origin":{"pointer":"/sections/7/paragraphs/2","offset":778,"length":21},"authors":[{"last":"Versley"},{"last":"al."}],"year":"2008b","references":["/references/133"]},{"style":0,"text":"Denis and Baldridge, 2008","origin":{"pointer":"/sections/7/paragraphs/2","offset":810,"length":25},"authors":[{"last":"Denis"},{"last":"Baldridge"}],"year":"2008","references":["/references/30"]},{"style":0,"text":"Bengtson and Roth, 2008","origin":{"pointer":"/sections/7/paragraphs/2","offset":872,"length":23},"authors":[{"last":"Bengtson"},{"last":"Roth"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Rahman and Ng, 2009","origin":{"pointer":"/sections/7/paragraphs/2","offset":912,"length":19},"authors":[{"last":"Rahman"},{"last":"Ng"}],"year":"2009","references":["/references/116"]},{"style":0,"text":"Stoyanov et al., 2010","origin":{"pointer":"/sections/7/paragraphs/2","offset":945,"length":21},"authors":[{"last":"Stoyanov"},{"last":"al."}],"year":"2010","references":["/references/123"]},{"style":0,"text":"Charniak and Elsner’s (2009)","origin":{"pointer":"/sections/7/paragraphs/2","offset":973,"length":28},"authors":[{"last":"Charniak"},{"last":"Elsner’s"}],"year":"2009","references":[]},{"style":0,"text":"Barbu and Mitkov, 2001","origin":{"pointer":"/sections/7/paragraphs/3","offset":383,"length":22},"authors":[{"last":"Barbu"},{"last":"Mitkov"}],"year":"2001","references":["/references/3"]},{"style":0,"text":"Yang et al. (2003)","origin":{"pointer":"/sections/7/paragraphs/3","offset":715,"length":18},"authors":[{"last":"Yang"},{"last":"al."}],"year":"2003","references":["/references/141"]},{"style":0,"text":"Ng and Cardie (2002c)","origin":{"pointer":"/sections/7/paragraphs/3","offset":757,"length":21},"authors":[{"last":"Ng"},{"last":"Cardie"}],"year":"2002c","references":["/references/91"]},{"style":0,"text":"Luo (2007)","origin":{"pointer":"/sections/7/paragraphs/4","offset":73,"length":10},"authors":[{"last":"Luo"}],"year":"2007","references":["/references/75"]}]}
