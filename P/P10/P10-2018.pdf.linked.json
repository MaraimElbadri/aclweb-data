{"sections":[{"title":"","paragraphs":["Proceedings of the ACL 2010 Conference Short Papers, pages 98–102, Uppsala, Sweden, 11-16 July 2010. c⃝2010 Association for Computational Linguistics"]},{"title":"A Structured Model for Joint Learning of Argument Roles and Predicate Senses Yotaro Watanabe Graduate School of Information Sciences Tohoku University 6-6-05, Aramaki Aza Aoba, Aoba-ku, Sendai 980-8579, Japan yotaro-w@ecei.tohoku.ac.jp Masayuki Asahara Yuji Matsumoto Graduate School of Information Science Nara Institute of Science and Technology 8916-5 Takayama, Ikoma, Nara, 630-0192, Japan { masayu-a, matsu} @is.naist.jp Abstract","paragraphs":["In predicate-argument structure analysis, it is important to capture non-local dependencies among arguments and inter-dependencies between the sense of a predicate and the semantic roles of its arguments. However, no existing approach explicitly handles both non-local dependencies and semantic dependencies between predicates and arguments. In this paper we propose a structured model that overcomes the limitation of existing approaches; the model captures both types of dependencies simultaneously by introducing four types of factors including a global factor type capturing non-local dependencies among arguments and a pairwise factor type capturing local dependencies between a predicate and an argument. In experiments the proposed model achieved competitive results compared to the state-of-the-art systems without applying any feature selection procedure."]},{"title":"1 Introduction","paragraphs":["Predicate-argument structure analysis is a process of assigning who does what to whom, where, when, etc. for each predicate. Arguments of a predicate are assigned particular semantic roles, such as Agent, Theme, Patient, etc. Lately, predicate-argument structure analysis has been regarded as a task of assigning semantic roles of arguments as well as word senses of a predicate (Surdeanu et al., 2008; Hajič et al., 2009).","Several researchers have paid much attention to predicate-argument structure analysis, and the following two important factors have been shown. Toutanova et al. (2008), Johansson and Nugues (2008), and Björkelund et al. (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/Active-PATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined architecture. They reported that incorporating this type of features provides substantial gain of the system performance.","The other factor is inter-dependencies between a predicate sense and argument roles, which relate to selectional preference, and motivated us to jointly identify a predicate sense and its argument roles. This type of dependencies has been explored by Riedel and Meza-Ruiz (2008; 2009b; 2009a), all of which use Markov Logic Networks (MLN). The work uses the global formulae that have atoms in terms of both a predicate sense and each of its argument roles, and the system identifies predicate senses and argument roles simultaneously.","Ideally, we want to capture both types of dependencies simultaneously. The former approaches can not explicitly include features that capture inter-dependencies between a predicate sense and its argument roles. Though these are implicitly in-corporated by re-ranking where the most plausible assignment is selected from a small subset of predicate and argument candidates, which are generated independently. On the other hand, it is difficult to deal with core argument features in MLN. Because the number of core arguments varies with the role assignments, this type of features cannot be expressed by a single formula.","Thompson et al. (2010) proposed a generative model that captures both predicate senses and its argument roles. However, the first-order markov assumption of the model eliminates ability to capture non-local dependencies among arguments. Also, generative models are in general inferior to discriminatively trained linear or log-98          Figure 1: Undirected graphical model representation of the structured model linear models.","In this paper we propose a structured model that overcomes limitations of the previous approaches. For the model, we introduce several types of features including those that capture both non-local dependencies of core arguments, and inter-dependencies between a predicate sense and its argument roles. By doing this, both tasks are mutually influenced, and the model determines the most plausible set of assignments of a predicate sense and its argument roles simultaneously. We present an exact inference algorithm for the model, and a large-margin learning algorithm that can handle both local and global features."]},{"title":"2 Model","paragraphs":["Figure 1 shows the graphical representation of our proposed model. The node p corresponds to a predicate, and the nodes a1, ..., aN to arguments of the predicate. Each node is assigned a particular predicate sense or an argument role label. The black squares are factors which provide scores of label assignments. In the model, the nodes for arguments depend on the predicate sense, and by in-fluencing labels of a predicate sense and its argument roles, the most plausible label assignment of the nodes is determined considering all factors.","In this work, we use linear models. Let x be words in a sentence, p be a sense of a predicate in x, and A = { an} N","1 be a set of possible role label assignments for x. A predicate-argument structure is represented by a pair of p and A. We define the score function for predicate-argument structures as s(p, A) =","∑","Fk∈F Fk(x, p, A). F is a set of all the factors, Fk(x, p, A) corresponds to a particular factor in Figure 1, and gives a score to a predicate or argument label assignments. Since we use linear models, Fk(x, p, A) = w · Φk(x, p, A). 2.1 Factors of the Model We define four types of factors for the model. Predicate Factor FP scores a sense of p, and does not depend on any arguments. The score function is defined by FP (x, p, A) = w·ΦP (x, p). Argument Factor FA scores a label assignment of a particular argument a ∈ A. The score is determined independently from a predicate sense, and is given by FA(x, p, a) = w · ΦA(x, a). Predicate-Argument Pairwise Factor FP A captures inter-dependencies between a predicate sense and one of its argument roles. The score function is defined as FP A(x, p, a) = w · ΦP A(x, p, a). The difference from FA is that FP A influences both the predicate sense and the argument role. By introducing this factor, the role label can be influenced by the predicate sense, and vise versa. Global Factor FG is introduced to capture plausibility of the whole predicate-argument structure. Like the other factors, the score function is defined as FG(x, p, A) = w · ΦG(x, p, A). A possible feature that can be considered by this factor is the mutual dependencies among core arguments. For instance, if a predicate-argument structure has an agent (A0) followed by the predicate and a patient (A1), we encode the structure as a string A0-PRED-A1 and use it as a feature. This type of features provide plausibility of predicate-argument structures. Even if the highest scoring predicate-argument structure with the other factors misses some core arguments, the global feature demands the model to fill the missing arguments.","The numbers of factors for each factor type are: FP and FG are 1, FA and FP A are |A| . By integrating the all factors, the score function becomes s(p, A) = w · ΦP (x, p) + w · ΦG(x, p, A) + w ·∑","a∈A{ ΦA(x, a) + ΦP A(x, p, a)} . 2.2 Inference The crucial point of the model is how to deal with the global factor FG, because enumerating possible assignments is too costly. A number of methods have been proposed for the use of global features for linear models such as (Daumé III and Marcu, 2005; Kazama and Torisawa, 2007). In this work, we use the approach proposed in (Kazama and Torisawa, 2007). Although the approach is proposed for sequence labeling tasks, it 99 can be easily extended to our structured model. That is, for each possible predicate sense p of the predicate, we provide N-best argument role assignments using three local factors FP , FA and FP A, and then add scores of the global factor FG, finally select the argmax from them. In this case, the argmax is selected from |P l| N candidates. 2.3 Learning the Model For learning of the model, we borrow a fundamental idea of Kazama and Torisawa’s perceptron learning algorithm. However, we use a more sophisticated online-learning algorithm based on the Passive-Aggressive Algorithm (PA) (Crammer et al., 2006).","For the sake of simplicity, we introduce some notations. We denote a predicate-argument structure y = ⟨p, A⟩, a local feature vector as ΦL(x, y) = ΦP (x, p) + ∑","a∈A{ ΦA(x, a) + ΦP A(x, p, a)} a feature vector coupling both local and global features as ΦL+G(x, y) = ΦL(x, y) + ΦG(x, p, A), the argmax using ΦL+G as ŷL+G",", the argmax using Φ","L as ŷL",". Also, we","use a loss function ρ(y, y′","), which is a cost func-","tion associated with y and y′",".","The margin perceptron learning proposed by","Kazama and Torisawa can be seen as an optimiza-","tion with the following two constrains.","(A) w· ΦL+G(x, y)−w· ΦL+G(x, ŷL+G",") ≥ ρ(y, ŷL+G",")","(B) w · ΦL(x, y) − w · ΦL(x, ŷL ) ≥ ρ(y, ŷL",")","(A) is the constraint that ensures a sufficient margin ρ(y, ŷL+G",") between y and ŷL+G",". (B) is the constraint that ensures a sufficient margin ρ(y, ŷL",") between y and ŷL",". The necessity of this constraint is that if we apply only (A), the algorithm does not guarantee a sufficient margin in terms of local features, and it leads to poor quality in the N-best assignments. The Kazama and Torisawa’s perceptron algorithm uses constant values for the cost function ρ(y, ŷL+G",") and ρ(y, ŷL",").","The proposed model is trained using the following optimization problem.","wnew = arg min w′","∈Rn 1 2","|| w′ − w|| 2","+ Cξ (","s.t. lL+G ≤ ξ, ξ ≥ 0 if ŷL+G","̸= y","s.t. lL ≤ ξ, ξ ≥ 0 if ŷL+G","= y ̸= ŷL (1)","lL+G = w · ΦL+G(x, ŷL+G",")","− w · ΦL+G(x, y) + ρ(y, ŷL+G",") (2)","lL = w · ΦL(x, ŷL ) − w · ΦL(x, y) + ρ(y, ŷL",") (3)","lL+G is the loss function for the case of using both local and global features, corresponding to the constraint (A), and lL is the loss function for the case of using only local features, corresponding to the constraints (B) provided that (A) is satisfied. 2.4 The Role-less Argument Bias Problem The fact that an argument candidate is not assigned any role (namely it is assigned the label “NONE”) is unlikely to contribute predicate sense disambiguation. However, it remains possible that “NONE” arguments is biased toward a particular predicate sense by FP A (i.e. w · ΦP A(x, sensei, ak= “NONE′′",") > w · ΦP A(x, sensej, ak= “NONE′′",").","In order to avoid this bias, we define a special sense label, senseany, that is used to calculate the score for a predicate and a roll-less argument, regardless of the predicate’s sense. We use the feature vector ΦP A(x, senseany, ak) if ak= “NONE′′","and Φ P A(x, sensei, ak) other-wise."]},{"title":"3 Experiment 3.1 Experimental Settings","paragraphs":["We use the CoNLL-2009 Shared Task dataset (Hajič et al., 2009) for experiments. It is a dataset for multi-lingual syntactic and semantic dependency parsing 1",". In the SRL-only challenge of the task, participants are required to identify predicate-argument structures of only the specified predicates. Therefore the problems to be solved are predicate sense disambiguation and argument role labeling. We use Semantic Labeled F1 for evaluation.","For generating N-bests, we used the beamsearch algorithm, and the number of N-bests was set to N = 64. For learning of the joint model, the loss function ρ(yt, y′",") of the Passive-Aggressive Algorithm was set to the number of incorrect assignments of a predicate sense and its argument roles. Also, the number of iterations of the model used for testing was selected based on the performance on the development data.","Table 1 shows the features used for the structured model. The global features used for FG are based on those used in (Toutanova et al., 2008; Johansson and Nugues, 2008), and the features","1","The dataset consists of seven languages: Catalan, Chinese, Czech, English, German, Japanese and Spanish. 100","FP Plemma of the predicate and predicate’s head, and ppos of the predicate Dependency label between the predicate and predicate’s head The concatenation of the dependency labels of the predicate’s dependents","FA Plemma and ppos of the predicate, the predicate’s head, the argument candidate, and the argument’s head Plemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost sibling The dependency label of predicate, argument candidate and argument candidate’s dependent The position of the argument candidate with respect to the predicate position in the dep. tree (e.g. CHILD) The position of the head of the dependency relation with respect to the predicate position in the sentence The left-to-right chain of the deplabels of the predicate’s dependents Plemma, ppos and dependency label paths between the predicate and the argument candidates The number of dependency edges between the predicate and the argument candidate","FPA Plemma and plemma&ppos of the argument candidate Dependency label path between the predicate and the argument candidates","FG The sequence of the predicate and the argument labels in the predicate-argument structure (e.g. A0-PRED-A1 Whether the semantic roles defined in frames exist in the structure, (e.g. CONTAINS:A1) The conjunction of the predicate sense and the frame information (e.g. wear.01&CONTAINS:A1) Table 1: Features for the Structured Model","Avg. Ca Ch Cz En Ge Jp Sp FP +FA 79.17 78.00 76.02 85.24 83.09 76.76 77.27 77.83 FP +FA+FPA 79.58 78.38 76.23 85.14 83.36 78.31 77.72 77.92 FP +FA+FG 80.42 79.50 76.96 85.88 84.49 78.64 78.32 79.21 ALL 80.75 79.55 77.20 85.94 84.97 79.62 78.69 79.29 Björkelund 80.80 80.01 78.60 85.41 85.63 79.71 76.30 79.91 Zhao 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46 Meza-Ruiz 77.46 78.00 77.73 75.75 83.34 73.52 76.00 77.91 Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1).","SENSE ARG FP +FA 89.65 72.20 FP +FA+FPA 89.78 72.74 FP +FA+FG 89.83 74.11 ALL 90.15 74.46 Table 3: Predicate sense disambiguation and argument role labeling results (average). used for FP A are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRL-only system.","By incorporating FP A, we achieved performance improvement for all languages. This results suggest that it is effective to capture local inter-dependencies between a predicate sense and one of its argument roles. Comparing the results with FP +FA and FP +FA+FG, incorporating FG also contributed performance improvements for all languages, especially the substantial F1 improvement of +1.88 is obtained in German.","Next, we compare our system with top 3 systems in the CoNLL-2009 Shared Task. By incorporating both FP A and FG, our joint model achieved competitive results compared to the top 2 systems (Björkelund and Zhao), and achieved the better results than the Meza-Ruiz’s system 2",". The systems by Björkelund and Zhao applied feature selection algorithms in order to select the best set of feature templates for each language, requiring about 1 to 2 months to obtain the best feature set. On the other hand, our system achieved the competitive results with the top two systems, despite the fact that we used the same feature templates for all languages without applying any feature engineering procedure.","Table 3 shows the performances of predicate sense disambiguation and argument role labeling separately. In terms of sense disambiguation results, incorporating FP A and FG worked well. Although incorporating either of FP A and FG provided improvements of +0.13 and +0.18 on average, adding both factors provided improvements of +0.50. We compared the predicate sense dis-","2","The result of Meza-Ruiz for Czech is substantially worse than the other systems because of inappropriate preprocess-ing for predicate sense disambiguation. Excepting Czech, the average F1 value of the Meza-Ruiz is 77.75, where as our system is 79.89. 101 ambiguation results of FP + FA and ALL with the McNemar test, and the difference was statistically significant (p < 0.01). This result suggests that combination of these factors is effective for sense disambiguation.","As for argument role labeling results, incorporating FP A and FG contributed positively for all languages. Especially, we obtained a substantial gain (+4.18) in German. By incorporating FP A, the system achieved the F1 improvements of +0.54 on average. This result shows that capturing inter-dependencies between a predicate and its arguments contributes to argument role labeling. By incorporating FG, the system achieved the substantial improvement of F1 (+1.91).","Since both tasks improved by using all factors, we can say that the proposed joint model succeeded in joint learning of predicate senses and its argument roles."]},{"title":"4 Conclusion","paragraphs":["In this paper, we proposed a structured model that captures both non-local dependencies between arguments, and inter-dependencies between a predicate sense and its argument roles. We designed a linear model-based structured model, and defined four types of factors: predicate factor, argument factor, predicate-argument pairwise factor and global factor for the model. In the experiments, the proposed model achieved competitive results compared to the state-of-the-art systems without any feature engineering.","A further research direction we are investigating is exploitation of unlabeled texts. Semi-supervised semantic role labeling methods have been explored by (Collobert and Weston, 2008; Deschacht and Moens, 2009; Fürstenau and Lapata, 2009), and they have achieved successful outcomes. However, we believe that there is still room for further improvement."]},{"title":"References","paragraphs":["Anders Björkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In CoNLL-2009.","Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML 2008. Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585.","Hal Daumé III and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In ICML-2005.","Koen Deschacht and Marie-Francine Moens. 2009. Semi-supervised semantic role labeling using the latent words language model. In EMNLP-2009.","Hagen Fürstenau and Mirella Lapata. 2009. Graph alignment for semi-supervised semantic role labeling. In EMNLP-2009.","Jan Hajič, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s Màrquez, Adam Meyers, Joakim Nivre, Sebastian Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In CoNLL-2009, Boulder, Colorado, USA.","Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic-semantic analysis with propbank and nombank. In CoNLL-2008.","Jun’Ichi Kazama and Kentaro Torisawa. 2007. A new perceptron algorithm for sequence labeling with non-local features. In EMNLP-CoNLL 2007.","Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly identifying predicates, arguments and senses using markov logic. In HLT/NAACL-2009.","Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multilingual semantic role labelling with markov logic. In CoNLL-2009.","Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collective semantic role labelling with markov logic. In CoNLL-2008.","Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluı́s Màrquez, and Joakim Nivre. 2008. The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL-2008.","Synthia A. Thompson, Roger Levy, and Christopher D. Manning. 2010. A generative model for semantic role labeling. In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics (to appear).","Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2008. A global joint model for semantic role labeling. Computational Linguistics, 34(2). 102"]}],"references":[{"authors":[{"first":"Anders","last":"Björkelund"},{"first":"Love","last":"Hafdell"},{"first":"Pierre","last":"Nugues"}],"year":"2009","title":"Multilingual semantic role labeling","source":"Anders Björkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In CoNLL-2009."},{"authors":[{"first":"Ronan","last":"Collobert"},{"first":"Jason","last":"Weston"}],"year":"2008","title":"A unified architecture for natural language processing: Deep neural networks with multitask learning","source":"Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML 2008. Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585."},{"authors":[{"first":"Hal","last":"Daumé III"},{"first":"Daniel","last":"Marcu"}],"year":"2005","title":"Learning as search optimization: Approximate large margin methods for structured prediction","source":"Hal Daumé III and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In ICML-2005."},{"authors":[{"first":"Koen","last":"Deschacht"},{"first":"Marie-Francine","last":"Moens"}],"year":"2009","title":"Semi-supervised semantic role labeling using the latent words language model","source":"Koen Deschacht and Marie-Francine Moens. 2009. Semi-supervised semantic role labeling using the latent words language model. In EMNLP-2009."},{"authors":[{"first":"Hagen","last":"Fürstenau"},{"first":"Mirella","last":"Lapata"}],"year":"2009","title":"Graph alignment for semi-supervised semantic role labeling","source":"Hagen Fürstenau and Mirella Lapata. 2009. Graph alignment for semi-supervised semantic role labeling. In EMNLP-2009."},{"authors":[{"first":"Jan","last":"Hajič"},{"first":"Massimiliano","last":"Ciaramita"},{"first":"Richard","last":"Johansson"},{"first":"Daisuke","last":"Kawahara"},{"first":"Maria","middle":"Antònia","last":"Martı́"},{"first":"Lluı́s","last":"Màrquez"},{"first":"Adam","last":"Meyers"},{"first":"Joakim","last":"Nivre"},{"first":"Sebastian","last":"Padó"},{"first":"Jan","last":"Štěpánek"},{"first":"Pavel","last":"Straňák"},{"first":"Mihai","last":"Surdeanu"},{"first":"Nianwen","last":"Xue"},{"first":"Yi","last":"Zhang"}],"year":"2009","title":"The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages","source":"Jan Hajič, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s Màrquez, Adam Meyers, Joakim Nivre, Sebastian Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In CoNLL-2009, Boulder, Colorado, USA."},{"authors":[{"first":"Richard","last":"Johansson"},{"first":"Pierre","last":"Nugues"}],"year":"2008","title":"Dependency-based syntactic-semantic analysis with propbank and nombank","source":"Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic-semantic analysis with propbank and nombank. In CoNLL-2008."},{"authors":[{"first":"Jun’Ichi","last":"Kazama"},{"first":"Kentaro","last":"Torisawa"}],"year":"2007","title":"A new perceptron algorithm for sequence labeling with non-local features","source":"Jun’Ichi Kazama and Kentaro Torisawa. 2007. A new perceptron algorithm for sequence labeling with non-local features. In EMNLP-CoNLL 2007."},{"authors":[{"first":"Ivan","last":"Meza-Ruiz"},{"first":"Sebastian","last":"Riedel"}],"year":"2009a","title":"Jointly identifying predicates, arguments and senses using markov logic","source":"Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly identifying predicates, arguments and senses using markov logic. In HLT/NAACL-2009."},{"authors":[{"first":"Ivan","last":"Meza-Ruiz"},{"first":"Sebastian","last":"Riedel"}],"year":"2009b","title":"Multilingual semantic role labelling with markov logic","source":"Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multilingual semantic role labelling with markov logic. In CoNLL-2009."},{"authors":[{"first":"Sebastian","last":"Riedel"},{"first":"Ivan","last":"Meza-Ruiz"}],"year":"2008","title":"Collective semantic role labelling with markov logic","source":"Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collective semantic role labelling with markov logic. In CoNLL-2008."},{"authors":[{"first":"Mihai","last":"Surdeanu"},{"first":"Richard","last":"Johansson"},{"first":"Adam","last":"Meyers"},{"first":"Lluı́s","last":"Màrquez"},{"first":"Joakim","last":"Nivre"}],"year":"2008","title":"The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies","source":"Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluı́s Màrquez, and Joakim Nivre. 2008. The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL-2008."},{"authors":[{"first":"Synthia","middle":"A.","last":"Thompson"},{"first":"Roger","last":"Levy"},{"first":"Christopher","middle":"D.","last":"Manning"}],"year":"2010","title":"A generative model for semantic role labeling","source":"Synthia A. Thompson, Roger Levy, and Christopher D. Manning. 2010. A generative model for semantic role labeling. In Proceedings of the 48th Annual Meeting of the Association of Computational Linguistics (to appear)."},{"authors":[{"first":"Kristina","last":"Toutanova"},{"first":"Aria","last":"Haghighi"},{"first":"Christopher","middle":"D.","last":"Manning"}],"year":"2008","title":"A global joint model for semantic role labeling","source":"Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2008. A global joint model for semantic role labeling. Computational Linguistics, 34(2). 102"}],"cites":[{"style":0,"text":"Surdeanu et al., 2008","origin":{"pointer":"/sections/2/paragraphs/0","offset":380,"length":21},"authors":[{"last":"Surdeanu"},{"last":"al."}],"year":"2008","references":["/references/11"]},{"style":0,"text":"Hajič et al., 2009","origin":{"pointer":"/sections/2/paragraphs/0","offset":403,"length":18},"authors":[{"last":"Hajič"},{"last":"al."}],"year":"2009","references":["/references/5"]},{"style":0,"text":"Toutanova et al. (2008)","origin":{"pointer":"/sections/2/paragraphs/1","offset":144,"length":23},"authors":[{"last":"Toutanova"},{"last":"al."}],"year":"2008","references":["/references/13"]},{"style":0,"text":"Johansson and Nugues (2008)","origin":{"pointer":"/sections/2/paragraphs/1","offset":169,"length":27},"authors":[{"last":"Johansson"},{"last":"Nugues"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Björkelund et al. (2009)","origin":{"pointer":"/sections/2/paragraphs/1","offset":202,"length":24},"authors":[{"last":"Björkelund"},{"last":"al."}],"year":"2009","references":["/references/0"]},{"style":0,"text":"Thompson et al. (2010)","origin":{"pointer":"/sections/2/paragraphs/4","offset":0,"length":22},"authors":[{"last":"Thompson"},{"last":"al."}],"year":"2010","references":["/references/12"]},{"style":0,"text":"Daumé III and Marcu, 2005","origin":{"pointer":"/sections/3/paragraphs/6","offset":273,"length":25},"authors":[{"last":"Daumé III"},{"last":"Marcu"}],"year":"2005","references":["/references/2"]},{"style":0,"text":"Kazama and Torisawa, 2007","origin":{"pointer":"/sections/3/paragraphs/6","offset":300,"length":25},"authors":[{"last":"Kazama"},{"last":"Torisawa"}],"year":"2007","references":["/references/7"]},{"style":0,"text":"Kazama and Torisawa, 2007","origin":{"pointer":"/sections/3/paragraphs/6","offset":375,"length":25},"authors":[{"last":"Kazama"},{"last":"Torisawa"}],"year":"2007","references":["/references/7"]},{"style":0,"text":"Crammer et al., 2006","origin":{"pointer":"/sections/3/paragraphs/6","offset":1061,"length":20},"authors":[{"last":"Crammer"},{"last":"al."}],"year":"2006","references":[]},{"style":0,"text":"Hajič et al., 2009","origin":{"pointer":"/sections/4/paragraphs/0","offset":43,"length":18},"authors":[{"last":"Hajič"},{"last":"al."}],"year":"2009","references":["/references/5"]},{"style":0,"text":"Toutanova et al., 2008","origin":{"pointer":"/sections/4/paragraphs/4","offset":118,"length":22},"authors":[{"last":"Toutanova"},{"last":"al."}],"year":"2008","references":["/references/13"]},{"style":0,"text":"Johansson and Nugues, 2008","origin":{"pointer":"/sections/4/paragraphs/4","offset":142,"length":26},"authors":[{"last":"Johansson"},{"last":"Nugues"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Meza-Ruiz and Riedel, 2009b","origin":{"pointer":"/sections/4/paragraphs/12","offset":259,"length":27},"authors":[{"last":"Meza-Ruiz"},{"last":"Riedel"}],"year":"2009b","references":["/references/9"]},{"style":0,"text":"Collobert and Weston, 2008","origin":{"pointer":"/sections/5/paragraphs/1","offset":156,"length":26},"authors":[{"last":"Collobert"},{"last":"Weston"}],"year":"2008","references":["/references/1"]},{"style":0,"text":"Deschacht and Moens, 2009","origin":{"pointer":"/sections/5/paragraphs/1","offset":184,"length":25},"authors":[{"last":"Deschacht"},{"last":"Moens"}],"year":"2009","references":["/references/3"]},{"style":0,"text":"Fürstenau and Lapata, 2009","origin":{"pointer":"/sections/5/paragraphs/1","offset":211,"length":26},"authors":[{"last":"Fürstenau"},{"last":"Lapata"}],"year":"2009","references":["/references/4"]}]}
