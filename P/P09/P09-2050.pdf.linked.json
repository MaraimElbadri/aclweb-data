{"sections":[{"title":"","paragraphs":["Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 197–200, Suntec, Singapore, 4 August 2009. c⃝2009 ACL and AFNLP"]},{"title":"Extracting Paraphrases of Technical Terms from Noisy Parallel Software Corpora Xiaoyin Wang","paragraphs":["1,2"]},{"title":", David Lo","paragraphs":["1"]},{"title":", Jing Jiang","paragraphs":["1"]},{"title":", Lu Zhang","paragraphs":["2"]},{"title":", Hong Mei","paragraphs":["2 1"]},{"title":"School of Information Systems, Singapore Management University, Singapore, 178902 {xywang, davidlo, jingjiang}@smu.edu.sg","paragraphs":["2"]},{"title":"Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education Beijing, 100871, China {zhanglu, meih}@sei.pku.edu.cn Abstract","paragraphs":["In this paper, we study the problem of extracting technical paraphrases from a parallel software corpus, namely, a collection of duplicate bug reports. Paraphrase acquisition is a fundamental task in the emerging area of text mining for software engineering. Existing paraphrase extraction methods are not entirely suitable here due to the noisy nature of bug reports. We propose a number of techniques to address the noisy data problem. The empirical evaluation shows that our method significantly improves an existing method by up to 58%."]},{"title":"1 Introduction","paragraphs":["Using natural language processing (NLP) techniques to mine software corpora such as code comments and bug reports to assist software engineering (SE) is an emerging and promising research direction (Wang et al., 2008; Tan et al., 2007). Paraphrase extraction is one of the fundamental problems that have not been addressed in this area. It has many applications including software ontology construction and query expansion for retriev-ing relevant technical documents.","In this paper, we study automatic paraphrase extraction from a large collection of software bug reports. Most large software projects have bug tracking systems, e.g., Bugzilla1",", to help global users to describe and report the bugs they encounter when using the software. However, since the same bug may be seen by many users, many duplicate bug reports are sent to bug tracking systems. The duplicate bug reports are manually tagged and associated to the original bug report by either the system manager or software developers. These families of duplicate bug reports form a semi-parallel","1","http://www.bugzilla.org/ Parallel bug reports with a pair of true paraphrases 1: connector extend with a straight line in full screen","mode 2: connector show straight line in presentation mode Non-parallel bug reports referring to the same bug 1: Settle language for part of text and spellchecking","part of text 2: Feature requested to improve the management of a","multi-language document Context-peculiar paraphrases (shown in italics) 1: status bar appear in the middle of the screen 2: maximizing window create phantom status bar in","middle of document Table 1: Bug Report Examples corpus and therefore a good candidate for extraction of paraphrases of technical terms. Hence, bug reports interest us because (1) they are abundant and freely available,(2) they naturally form a semi-parallel corpus, and (3) they contain many technical terms.","However, bug reports have characteristics that raise many new challenges. Different from many other parallel corpora, bug reports are noisy. We observe at least three types of noise common in bug reports. First, many bug reports have many spelling, grammatical and sentence structure errors. To address this we extend a suitable state-of-the-art technique that is robust to such corpora, i.e. (Barzilay and McKeown, 2001). Second, many duplicate bug report families contain sentences that are not truly parallel. An example is shown in Table 1 (middle). We handle this by considering lexical similarity between duplicate bug reports. Third, even if the bug reports are parallel, we find many cases of context-peculiar paraphrases, i.e., a pair of phrases that have the same meaning in a very narrow context. An example is shown in Table 1 (bottom). To address this, we introduce two notions of global context-based score and co-occurrence based score which take into account all good and bad occurrences of the phrases in a candidate paraphrase in the corpus. These scores are then used to identify and remove 197 context-peculiar paraphrases.","The contributions of our work are twofold. First, we studied the important problem of paraphrase extraction from a noisy semi-parallel software corpus, which has not been studied either in the NLP or the SE community. Second, taking into consideration the special characteristics of our noisy data, we proposed several improvements to an existing general paraphrase extraction method, resulting in a significant performance gain – up to 58% relative improvement in precision."]},{"title":"2 Related Work","paragraphs":["In the area of text mining for software engineering, paraphrases have been used in many tasks, e.g., (Wang et al., 2008; Tan et al., 2007). However, most paraphrases used are obtained manually. A recent study using synonyms from Word-Net highlights the fact that these are not effective in software engineering tasks due to domain specificity (Sridhara et al., 2008). Therefore, an automatic way to derive technical paraphrases specific to software engineering is desired.","Paraphrases can be extracted from non-parallel corpora using contextual similarity (Lin, 1998). They can also be obtained from parallel corpora if such data is available (Barzilay and McKeown, 2001; Ibrahim et al., 2003). Recently, there are also a number of studies that extract paraphrases from multilingual corpora (Bannard and Callison-Burch, 2005; Zhao et al., 2008).","The approach in (Barzilay and McKeown, 2001) does not use deep linguistic analysis and therefore is suitable to noisy corpora like ours. Due to this reason, we build our technique on top of theirs. The following provides a summary of their technique.","Two types of paraphrase patterns are defined: (1) Syntactic patterns which consist of the POS tags of the phrases. For example, the paraphrases “a VGA monitor” and “a monitor” are represented as “DT1 JJ NN2” ↔ “DT1 NN2”, where the subscripts denote common words. (2) Contextual patterns which consist of the POS tags before and after the phrases. For example, the contexts “in the middle of” and “in middle of” in Table 1 (bottom) are represented as “IN1 DT NN2 IN3” ↔ “IN1 NN2 IN3”.","During pre-processing, the parallel corpus is aligned to give a list of parallel sentence pairs. The sentences are then processed by a POS tagger and a chunker. The authors first used identical words and phrases as seeds to find and score contextual patterns. The patterns are scored based on the following formula: (n+)/n, in which, n+ refers to the number of positively labeled paraphrases satisfying the patterns and n refers to the number of all paraphrases satisfying the patterns. Only patterns with scores above a threshold are considered. More paraphrases are identified using these contextual patterns, and more patterns are then found and scored using the newly-discovered paraphrases. This co-training algorithm is employed in an iterative fashion to find more patterns and positively labeled paraphrases."]},{"title":"3 Methodology","paragraphs":["Our paraphrase extraction method consists of three components: sentence selection, global context-based scoring and co-occurrence-based scoring. We marry the three components together into a holistic solution. Selection of Parallel Sentences Our corpus consists of short bug report summaries, each containing one or two sentences only, grouped by the bugs they report. Each group corresponds to reports pertaining to a single bug and are duplicate of one another. Therefore, reports belonging to the same group can be naturally regarded as parallel sentences.","However, these sentences are only partially parallel because two users may describe the same bug in very different ways. An example is shown in Table 1 (middle). This kind of sentence pairs should not be regarded as parallel. To address this problem, we take a heuristic approach and only select sentence pairs that have strong similarities. Our similarity score is based on the number of common words, bigrams and trigrams shared between two parallel sentences. We use a threshold of 5 to filter out non-parallel sentences. Global Context-Based Scoring Our context-based paraphrase scoring method is an extension of (Barzilay and McKeown, 2001) described in Sec. 2. Parallel bug reports are usually noisy. At times, some words might be detected as paraphrases incidentally due to the noise. In (Barzilay and McKeown, 2001), a paraphrase is reported as long as there is a single good supporting pair of sentences. Although this works well for a relatively clean parallel corpus considered in their work, i.e., novels, this does not work well for bug reports. Consider the context-peculiar example in Table 1 (bottom). For a context-peculiar para-198 phrase, there can be many sentences containing the pair of phrases but very few support them to be a paraphrase. We develop a technique to off-set this noise by computing a global context-based score for two phrases being a paraphrase over all their parallel occurrences. This is defined by the following formula: Sg = 1","n Σn","i=1si, where n is the number of parallel bug reports with the two phrases occurring in parallel, and si is the score for the i’th occurrence. si is computed as follows: 1. We compute the set of patterns with affixed","pattern scores based on (Barzilay and McK-","eown, 2001). 2. For the i’th parallel occurrence of the pair of","phrases we want to score, we try to find a pat-","tern that matches the occurrence and assign","the pattern score to the pair of phrases as si.","If no such pattern exists, we set si to 0.","By taking the average of si as the global score for a pair of phrases, we do not rely much on a single si and can therefore prevent context-peculiar paraphrases to some degree. Co-occurrence-Based Scoring We also consider another global co-occurrence-based score that is commonly used for finding collocations. A general observation is that noise tends to appear in random but random things do not occur in the same way often. It is less likely for randomly paired words or paraphrases to co-occur together many times. To compute the likelihood of two phrases occurring together, we use the following commonly used co-occurrence-based score: Sc = P (w1, w2) P (w1)P (w2) . (1) The expression P (w1, w2) refers to the probability of a pair of phrases w1 and w2 appearing together. It is estimated based on the proportion of the corpus containing both w1 and w2 in parallel. Similarly, P (w1) and P (w2) each corresponds to the probability of w1 and w2 appearing respectively. We normalize the Sc score to the range of 0 to 1 by dividing it with the size of the corpus. Holistic Solution We employ the parallel sentence selection as a pre-processing step, and merge co-occurrence-based scoring with global context-based scoring. For each parallel sentence pairs, a chunker is used to get chunks from each sentence. All possible pairings of chunks are then formed. This set of chunk pairs are later fed to the method in (Barzilay and McKeown, 2001) to produce a set of patterns with affixed scores. With this we compute our global-context based scores. The co-occurrence based scores are computed following the approach described above.","Two thresholds are used and candidate paraphrases whose scores are below the respective thresholds are removed. Alternatively, one of the score is used as a filter, while the other is used to rank the candidates. The next section describes our experimental results."]},{"title":"4 Evaluation Data Set","paragraphs":["Our bug report corpus is built from OpenOffice2",". OpenOffice is a well-known open source software which has similar functionalities as Microsoft Office. We use the bug reports that are submitted before Jan 1, 2008. Also, we only use the summary part of the bug reports.","We build our corpus in the following steps. We collect a total of 13,898 duplicate bug reports from OpenOffice. Each duplicate bug report is associated to a master report—there is one master report for each unique bug. From this information, we create duplicate bug report groups where each member of a group is a duplicate of all other members in the same group. Finally, we extract duplicate bug report pairs by pairing each two members of each group. We get in total 53,363 duplicate bug report pairs.","As the first step, we employ parallel sentence selection, described in Sec. 3, to remove non-parallel duplicate bug report pairs. After this step, we find 5,935 parallel duplicate bug report pairs. Experimental Setup The baseline method we consider is the one in (Barzilay and McKeown, 2001) without sentence alignment – as the bug reports are usually of one sentence long. We call it BL. As described in Sec. 2, BL utilizes a threshold to control the number of patterns mined. These patterns are later used to select paraphrases. In the experiment, we find that running BL using their default threshold of 0.95 on the 5,935 parallel bug reports only gives us 18 paraphrases. This number is too small for practical purposes. Therefore, we reduce the threshold to get more paraphrases. For each threshold in the range of 0.45-0.95 (step size: 0.05), we extract paraphrases and compute the corresponding precision.","In our approach, we first form chunk pairs from the 5,935 pairs of parallel sentences and then use the baseline approach at a low threshold to ob-2 http://www.openoffice.org/ 199 tain patterns. Using these patterns we compute the global context-based scores Sg. We also compute the co-occurrence scores Sc. We rank and extract top-k paraphrases based on these scores. We consider 4 different methods: We can use either Sg or Sc to rank the discovered paraphrases. We call them Rk-Sg and Rk-Sc. We also consider using one of the scores for ranking and the other for filtering bad candidate paraphrases. A threshold of 0.05 is used for filtering. We call these two methods Rk-Sc+Ft-Sg and Rk-Sg+Ft-Sc. With ranked lists from these 4 methods, we can compute precision@k for the top-k paraphrases. Results The comparison among these methods is plotted in Figure 1. From the figure we can see that our holistic approach using global-context score to rank and co-occurrence score to filter (i.e., Rk-Sg+Ft-Sc) has higher precision than the baseline approach (i.e., BL) in all ks. In general, the other holistic configuration (i.e., Rk-Sc+Ft-Sg) also works well for most of the ks considered. In-terestingly, the graph shows that using only one of the scores alone (i.e., Rk-Sg and Rk-Sc) does not result in a significantly higher precision than the baseline approach. A holistic approach by merg-ing global-context score and co-occurrence score is needed to yield higher precision.","In Table 2, we show some examples of the paraphrases our algorithm extracted from the bug report corpus. As we can see, most of the paraphrases are very technical and only make sense in the software domain. It demonstrates the effectiveness of our method. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 50 100 150 200 250 300 350 400 450 precision at k k","BL Rk-Sg Rk-Sc","Rk-Sc+Ft-Sg","Rk-Sg+Ft-Sc Figure 1: Precision@k for a range of k."]},{"title":"5 Conclusion","paragraphs":["In this paper, we develop a new technique to extract paraphrases of technical terms from software bug reports. Paraphrases of technical terms have been shown to be useful for various software en-the edit-field ↔ input line field","presentation mode ↔ full screen mode","word separator ↔ a word delimiter application ↔ app","freeze ↔ crash mru file list ↔ recent file list","multiple monitor ↔ extended desktop","xl file ↔ excel file Table 2: Examples of paraphrases of technical terms mined from bug reports. gineering tasks. These paraphrases could not be obtained via general purpose thesaurus e.g., Word-Net. Interestingly, there is a wealth of text data, in particular bug reports, available for analysis in open-source software repositories. Despite their availability, a good technique is needed to extract paraphrases from these corpora as they are often noisy. We develop several approaches to address noisy data via parallel sentence selection, global-context based scoring and co-occurrence based scoring. To show the utility of our approach, we experimented with many parallel bug reports from a large software project. The preliminary experiment result is promising as it could significantly improves an existing method by up to 58%."]},{"title":"References","paragraphs":["C. Bannard and C. Callison-Burch. 2005. Paraphras-ing with bilingual parallel corpora. In ACL: Annual Meet. of Assoc. of Computational Linguistics.","R. Barzilay and K. R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In ACL: Annual Meet. of Assoc. of Computational Linguistics.","A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Int. Workshop on Paraphrasing.","D. Lin. 1998. Automatic retrieval and clustering of similar words. In ACL: Annual Meet. of Assoc. of Computational Linguistics.","G. Sridhara, E. Hill, L. Pollock, and K. Vijay-Shanker. 2008. Identifying word relations in software: A comparative study of semantic similarity tools. In ICPC: Int. Conf. on Program Comprehension.","L. Tan, D. Yuan, G. Krishna, and Y. Zhou. 2007. /*icomment: bugs or bad comments?*/. In SOSP: Symp. on Operating System Principles.","X. Wang, L. Zhang, T. Xie, J. Anvik, and J. Sun. 2008. An approach to detecting duplicate bug reports using natural language and execution information. In ICSE: Int. Conf. on Software Engineering.","S. Zhao, H. Wang, T. Liu, and S. Li. 2008. Pivot approach for extracting paraphrase patterns from bilingual corpora. In ACL: Annual Meet. of Assoc. of Computational Linguistics. 200"]}],"references":[{"authors":[{"first":"C.","last":"Bannard"},{"first":"C.","last":"Callison-Burch"}],"year":"2005","title":"Paraphras-ing with bilingual parallel corpora","source":"C. Bannard and C. Callison-Burch. 2005. Paraphras-ing with bilingual parallel corpora. In ACL: Annual Meet. of Assoc. of Computational Linguistics."},{"authors":[{"first":"R.","last":"Barzilay"},{"first":"K.","middle":"R.","last":"McKeown"}],"year":"2001","title":"Extracting paraphrases from a parallel corpus","source":"R. Barzilay and K. R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In ACL: Annual Meet. of Assoc. of Computational Linguistics."},{"authors":[{"first":"A.","last":"Ibrahim"},{"first":"B.","last":"Katz"},{"first":"J.","last":"Lin"}],"year":"2003","title":"Extracting structural paraphrases from aligned monolingual corpora","source":"A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Int. Workshop on Paraphrasing."},{"authors":[{"first":"D.","last":"Lin"}],"year":"1998","title":"Automatic retrieval and clustering of similar words","source":"D. Lin. 1998. Automatic retrieval and clustering of similar words. In ACL: Annual Meet. of Assoc. of Computational Linguistics."},{"authors":[{"first":"G.","last":"Sridhara"},{"first":"E.","last":"Hill"},{"first":"L.","last":"Pollock"},{"first":"K.","last":"Vijay-Shanker"}],"year":"2008","title":"Identifying word relations in software: A comparative study of semantic similarity tools","source":"G. Sridhara, E. Hill, L. Pollock, and K. Vijay-Shanker. 2008. Identifying word relations in software: A comparative study of semantic similarity tools. In ICPC: Int. Conf. on Program Comprehension."},{"authors":[{"first":"L.","last":"Tan"},{"first":"D.","last":"Yuan"},{"first":"G.","last":"Krishna"},{"first":"Y.","last":"Zhou"}],"year":"2007","title":"/*icomment: bugs or bad comments?*/","source":"L. Tan, D. Yuan, G. Krishna, and Y. Zhou. 2007. /*icomment: bugs or bad comments?*/. In SOSP: Symp. on Operating System Principles."},{"authors":[{"first":"X.","last":"Wang"},{"first":"L.","last":"Zhang"},{"first":"T.","last":"Xie"},{"first":"J.","last":"Anvik"},{"first":"J.","last":"Sun"}],"year":"2008","title":"An approach to detecting duplicate bug reports using natural language and execution information","source":"X. Wang, L. Zhang, T. Xie, J. Anvik, and J. Sun. 2008. An approach to detecting duplicate bug reports using natural language and execution information. In ICSE: Int. Conf. on Software Engineering."},{"authors":[{"first":"S.","last":"Zhao"},{"first":"H.","last":"Wang"},{"first":"T.","last":"Liu"},{"first":"S.","last":"Li"}],"year":"2008","title":"Pivot approach for extracting paraphrase patterns from bilingual corpora","source":"S. Zhao, H. Wang, T. Liu, and S. Li. 2008. Pivot approach for extracting paraphrase patterns from bilingual corpora. In ACL: Annual Meet. of Assoc. of Computational Linguistics. 200"}],"cites":[{"style":0,"text":"Wang et al., 2008","origin":{"pointer":"/sections/8/paragraphs/0","offset":199,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Tan et al., 2007","origin":{"pointer":"/sections/8/paragraphs/0","offset":218,"length":16},"authors":[{"last":"Tan"},{"last":"al."}],"year":"2007","references":["/references/5"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/8/paragraphs/9","offset":394,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Wang et al., 2008","origin":{"pointer":"/sections/9/paragraphs/0","offset":102,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Tan et al., 2007","origin":{"pointer":"/sections/9/paragraphs/0","offset":121,"length":16},"authors":[{"last":"Tan"},{"last":"al."}],"year":"2007","references":["/references/5"]},{"style":0,"text":"Sridhara et al., 2008","origin":{"pointer":"/sections/9/paragraphs/0","offset":344,"length":21},"authors":[{"last":"Sridhara"},{"last":"al."}],"year":"2008","references":["/references/4"]},{"style":0,"text":"Lin, 1998","origin":{"pointer":"/sections/9/paragraphs/1","offset":84,"length":9},"authors":[{"last":"Lin"}],"year":"1998","references":["/references/3"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/9/paragraphs/1","offset":171,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Ibrahim et al., 2003","origin":{"pointer":"/sections/9/paragraphs/1","offset":199,"length":20},"authors":[{"last":"Ibrahim"},{"last":"al."}],"year":"2003","references":["/references/2"]},{"style":0,"text":"Bannard and Callison-Burch, 2005","origin":{"pointer":"/sections/9/paragraphs/1","offset":319,"length":32},"authors":[{"last":"Bannard"},{"last":"Callison-Burch"}],"year":"2005","references":["/references/0"]},{"style":0,"text":"Zhao et al., 2008","origin":{"pointer":"/sections/9/paragraphs/1","offset":353,"length":17},"authors":[{"last":"Zhao"},{"last":"al."}],"year":"2008","references":["/references/7"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/9/paragraphs/2","offset":17,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/10/paragraphs/1","offset":618,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/10/paragraphs/1","offset":796,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/10/paragraphs/10","offset":1418,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]},{"style":0,"text":"Barzilay and McKeown, 2001","origin":{"pointer":"/sections/11/paragraphs/3","offset":264,"length":26},"authors":[{"last":"Barzilay"},{"last":"McKeown"}],"year":"2001","references":["/references/1"]}]}
