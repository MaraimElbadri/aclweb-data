{"sections":[{"title":"","paragraphs":["Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 342–350, Suntec, Singapore, 2-7 August 2009. c⃝2009 ACL and AFNLP"]},{"title":"Concise Integer Linear Programming Formulations for Dependency Parsing André F. T. Martins","paragraphs":["∗†"]},{"title":"Noah A. Smith","paragraphs":["∗"]},{"title":"Eric P. Xing","paragraphs":["∗ ∗"]},{"title":"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA","paragraphs":["†"]},{"title":"Instituto de Telecomunicações, Instituto Superior Técnico, Lisboa, Portugal {afm,nasmith,epxing}@cs.cmu.edu Abstract","paragraphs":["We formulate the problem of non-projective dependency parsing as a polynomial-sized integer linear program. Our formulation is able to handle non-local output features in an efficient manner; not only is it compatible with prior knowledge encoded as hard constraints, it can also learn soft constraints from data. In particular, our model is able to learn correlations among neighboring arcs (siblings and grandparents), word valency, and tendencies toward nearly-projective parses. The model parameters are learned in a max-margin framework by employing a linear programming relaxation. We evaluate the performance of our parser on data in several natural languages, achieving improvements over existing state-of-the-art methods."]},{"title":"1 Introduction","paragraphs":["Much attention has recently been devoted to integer linear programming (ILP) formulations of NLP problems, with interesting results in applications like semantic role labeling (Roth and Yih, 2005; Punyakanok et al., 2004), dependency parsing (Riedel and Clarke, 2006), word alignment for machine translation (Lacoste-Julien et al., 2006), summarization (Clarke and Lapata, 2008), and coreference resolution (Denis and Baldridge, 2007), among others. In general, the rationale for the development of ILP formulations is to incorporate non-local features or global constraints, which are often difficult to handle with traditional algorithms. ILP formulations focus more on the modeling of problems, rather than algorithm design. While solving an ILP is NP-hard in general, fast solvers are available today that make it a practical solution for many NLP problems.","This paper presents new, concise ILP formulations for projective and non-projective dependency parsing. We believe that our formulations can pave the way for efficient exploitation of global features and constraints in parsing applica-tions, leading to more powerful models. Riedel and Clarke (2006) cast dependency parsing as an ILP, but efficient formulations remain an open problem. Our formulations offer the following comparative advantages:","• The numbers of variables and constraints are polynomial in the sentence length, as opposed to requiring exponentially many constraints, eliminating the need for incremental procedures like the cutting-plane algorithm;","• LP relaxations permit fast online discriminative training of the constrained model;","• Soft constraints may be automatically learned from data. In particular, our formulations handle higher-order arc interactions (like siblings and grandparents), model word valency, and can learn to favor nearly-projective parses. We evaluate the performance of the new parsers on standard parsing tasks in seven languages. The techniques that we present are also compatible with scenarios where expert knowledge is available, for example in the form of hard or soft first-order logic constraints (Richardson and Domingos, 2006; Chang et al., 2008)."]},{"title":"2 Dependency Parsing 2.1 Preliminaries","paragraphs":["A dependency tree is a lightweight syntactic representation that attempts to capture functional relationships between words. Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al., 2007).","Let us first describe formally the set of legal dependency parse trees. Consider a sentence x = 342 ⟨w0, . . . , wn⟩, where wi denotes the word at the i-th position, and w0 = $ is a wall symbol. We form the (complete1",") directed graph D = ⟨V, A⟩, with vertices in V = {0, . . . , n} (the i-th vertex corresponding to the i-th word) and arcs in A = V 2",". Using terminology from graph theory, we say that B ⊆ A is an r-arborescence 2","of the directed graph D if ⟨V, B⟩ is a (directed) tree rooted at r. We define the set of legal dependency parse trees of x (denoted Y(x)) as the set of 0-arborescences of D, i.e., we admit each arborescence as a potential dependency tree.","Let y ∈ Y(x) be a legal dependency tree for x; if the arc a = ⟨i, j⟩ ∈ y, we refer to i as the parent of j (denoted i = π(j)) and j as a child of i. We also say that a is projective (in the sense of Kahane et al., 1998) if any vertex k in the span of a is reachable from i (in other words, if for any k satisfying min(i, j) < k < max(i, j), there is a directed path in y from i to k). A dependency tree is called projective if it only contains projective arcs. Fig. 1 illustrates this concept.3","The formulation to be introduced in §3 makes use of the notion of the incidence vector associated with a dependency tree y ∈ Y(x). This is the binary vector z ≜ ⟨za⟩a∈A with each component defined as za = I(a ∈ y) (here, I(.) denotes the indicator function). Considering simultaneously all incidence vectors of legal dependency trees and taking the convex hull, we obtain a polyhedron that we call the arborescence polytope, denoted by Z(x). Each vertex of Z(x) can be identified with a dependency tree in Y(x). The Minkowski-Weyl theorem (Rockafellar, 1970) ensures that Z(x) has a representation of the form Z(x) = {z ∈ R|A|","| Az ≤ b}, for some p-by- |A| matrix A and some vector b in Rp",". However, it is not easy to obtain a compact representation (where p grows polynomially with the number of words n). In §3, we will provide a compact representation of an outer polytope Z̄(x) ⊇ Z(x) whose integer vertices correspond to dependency trees. Hence, the problem of finding the dependency tree that maximizes some linear function of the inci-1 The general case where A ⊆ V 2","is also of interest; it","arises whenever a constraint or a lexicon forbids some arcs","from appearing in dependency tree. It may also arise as a","consequence of a first-stage pruning step where some candi-","date arcs are eliminated; this will be further discussed in §4. 2 Or “directed spanning tree with designated root r.” 3 In this paper, we consider unlabeled dependency parsing,","where only the backbone structure (i.e., the arcs without the","labels depicted in Fig. 1) is to be predicted. Figure 1: A projective dependency graph. Figure 2: Non-projective dependency graph. those that assume each dependency decision is in-dependent modulo the global structural constraint that dependency graphs must be trees. Such models are commonly referred to as edge-factored since their parameters factor relative to individual edges of the graph (Paskin, 2001; McDonald et al., 2005a). Edge-factored models have many computational benefits, most notably that inference for non-projective dependency graphs can be achieved in polynomial time (McDonald et al., 2005b). The primary problem in treating each dependency as in-dependent is that it is not a realistic assumption. Non-local information, such as arity (or valency) and neighbouring dependencies, can be crucial to obtaining high parsing accuracies (Klein and Manning, 2002; McDonald and Pereira, 2006). However, in the data-driven parsing setting this can be partially adverted by incorporating rich feature representations over the input (McDonald et al., 2005a).","The goal of this work is to further our current understanding of the computational nature of non-projective parsing algorithms for both learning and inference within the data-driven setting. We start by investigating and extending the edge-factored model of McDonald et al. (2005b). In particular, we appeal to the Matrix Tree Theorem for multi-digraphs to design polynomial-time algorithms for calculat-ing both the partition function and edge expecta-tions over all possible dependency graphs for a given sentence. To motivate these algorithms, we show that they can be used in many important learning and inference problems including min-risk decod-ing, training globally normalized log-linear models, syntactic language modeling, and unsupervised learning via the EM algorithm – none of which have previously been known to have exact non-projective implementations.","We then switch focus to models that account for non-local information, in particular arity and neighbouring parse decisions. For systems that model arity constraints we give a reduction from the Hamiltonian graph problem suggesting that the parsing problem is intractable in this case. For neighbouring parse decisions, we extend the work of McDonald and Pereira (2006) and show that modeling vertical neighbourhoods makes parsing intractable in addi-tion to modeling horizontal neighbourhoods. A consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models. 1.1 Related Work There has been extensive work on data-driven dependency parsing for both projective parsing (Eisner, 1996; Paskin, 2001; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005a) and non-projective parsing systems (Nivre and Nilsson, 2005; Hall and Nóvák, 2005; McDonald et al., 2005b). These approaches can often be classified into two broad categories. In the first category are those methods that employ approximate inference, typically through the use of linear time shift-reduce parsing algorithms (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Nivre and Nilsson, 2005). In the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (Paskin, 2001; McDonald et al., 2005a; McDonald et al., 2005b). Recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (McDonald and Pereira, 2006) and exact methods through integer linear programming (Riedel and Clarke, 2006) or branch-and-bound algorithms (Hirakawa, 2006).","For grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of Wang and Harper (2004). Theoretical studies of note include the work of Neuhaus and Böker (1997) showing that the recognition problem for a mini- $ Figure 1: A projective dependency graph. Figure 2: Non-projective dependency graph. those that assume each dependency decision is in-dependent modulo the global structural constraint that dependency graphs must be trees. Such models are commonly referred to as edge-factored since their parameters factor relative to individual edges of the graph (Paskin, 2001; McDonald et al., 2005a). Edge-factored models have many computational benefits, most notably that inference for non-projective dependency graphs can be achieved in polynomial time (McDonald et al., 2005b). The primary problem in treating each dependency as in-dependent is that it is not a realistic assumption. Non-local information, such as arity (or valency) and neighbouring dependencies, can be crucial to obtaining high parsing accuracies (Klein and Manning, 2002; McDonald and Pereira, 2006). However, in the data-driven parsing setting this can be partially adverted by incorporating rich feature representations over the input (McDonald et al., 2005a).","The goal of this work is to further our current understanding of the computational nature of non-projective parsing algorithms for both learning and inference within the data-driven setting. We start by investigating and extending the edge-factored model of McDonald et al. (2005b). In particular, we appeal to the Matrix Tree Theorem for multi-digraphs to design polynomial-time algorithms for calculat-ing both the partition function and edge expecta-tions over all possible dependency graphs for a given sentence. To motivate these algorithms, we show that they can be used in many important learning and inference problems including min-risk decod-ing, training globally normalized log-linear models, syntactic language modeling, and unsupervised learning via the EM algorithm – none of which have previously been known to have exact non-projective implementations.","We then switch focus to models that account for non-local information, in particular arity and neighbouring parse decisions. For systems that model arity constraints we give a reduction from the Hamiltonian graph problem suggesting that the parsing problem is intractable in this case. For neighbouring parse decisions, we extend the work of McDonald and Pereira (2006) and show that modeling vertical neighbourhoods makes parsing intractable in addi-tion to modeling horizontal neighbourhoods. A consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models. 1.1 Related Work There has been extensive work on data-driven dependency parsing for both projective parsing (Eisner, 1996; Paskin, 2001; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005a) and non-projective parsing systems (Nivre and Nilsson, 2005; Hall and Nóvák, 2005; McDonald et al., 2005b). These approaches can often be classified into two broad categories. In the first category are those methods that employ approximate inference, typically through the use of linear time shift-reduce parsing algorithms (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Nivre and Nilsson, 2005). In the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (Paskin, 2001; McDonald et al., 2005a; McDonald et al., 2005b). Recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (McDonald and Pereira, 2006) and exact methods through integer linear programming (Riedel and Clarke, 2006) or branch-and-bound algorithms (Hirakawa, 2006).","For grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of Wang and Harper (2004). Theoretical studies of note include the work of Neuhaus and Böker (1997) showing that the recognition problem for a mini- $ Figure 1: A projective dependency parse (top), and a non-projective dependency parse (bottom) for two English sentences; examples from McDonald and Satta (2007). dence vectors can be cast as an ILP. A similar idea was applied to word alignment by Lacoste-Julien et al. (2006), where permutations (rather than arborescences) were the combinatorial structure being requiring representation.","Letting X denote the set of possible sentences, define Y ≜ ⋃","x∈X Y(x). Given a labeled dataset L ≜ ⟨⟨x1, y1⟩, . . . , ⟨xm, ym⟩⟩ ∈ (X × Y)m",", we aim to learn a parser, i.e., a function h : X → Y that given x ∈ X outputs a legal dependency parse y ∈ Y(x). The fact that there are exponentially many candidates in Y(x) makes dependency parsing a structured classification problem. 2.2 Arc Factorization and Locality There has been much recent work on dependency parsing using graph-based, transition-based, and hybrid methods; see Nivre and McDonald (2008) for an overview. Typical graph-based methods consider linear classifiers of the form","hw(x) = argmaxy∈Y w⊤ f (x, y), (1) where f (x, y) is a vector of features and w is the corresponding weight vector. One wants hw to have small expected loss; the typical loss function is the Hamming loss, l(y′","; y) ≜ |{⟨i, j⟩ ∈ y′",": ⟨i, j⟩ /∈ y}|. Tractability is usually ensured by strong factorization assumptions, like the one underlying the arc-factored model (Eisner, 1996; McDonald et al., 2005), which forbids any feature that depends on two or more arcs. This induces a decomposition of the feature vector f (x, y) as: f (x, y) =","∑ a∈y fa(x). (2) Under this decomposition, each arc receives a score; parsing amounts to choosing the configuration that maximizes the overall score, which, as 343 shown by McDonald et al. (2005), is an instance of the maximal arborescence problem. Combinatorial algorithms (Chu and Liu, 1965; Edmonds, 1967) can solve this problem in cubic time.4","If the dependency parse trees are restricted to be projective, cubic-time algorithms are available via dynamic programming (Eisner, 1996). While in the projective case, the arc-factored assumption can be weakened in certain ways while maintain-ing polynomial parser runtime (Eisner and Satta, 1999), the same does not happen in the nonprojective case, where finding the highest-scoring tree becomes NP-hard (McDonald and Satta, 2007). Approximate algorithms have been employed to handle models that are not arc-factored (although features are still fairly local): McDonald and Pereira (2006) adopted an approximation based on O(n3",") projective parsing followed by a hillclimbing algorithm to rearrange arcs, and Smith and Eisner (2008) proposed an algorithm based on loopy belief propagation."]},{"title":"3 Dependency Parsing as an ILP","paragraphs":["Our approach will build a graph-based parser without the drawback of a restriction to local features. By formulating inference as an ILP, non-local features can be easily accommodated in our model; furthermore, by using a relaxation technique we can still make learning tractable. The impact of LP-relaxed inference in the learning problem was studied elsewhere (Martins et al., 2009).","A linear program (LP) is an optimization problem of the form minx∈Rd c⊤","x s.t. Ax ≤ b. (3) If the problem is feasible, the optimum is attained at a vertex of the polyhedron that defines the constraint space. If we add the constraint x ∈ Zd",", then the above is called an integer linear program (ILP). For some special parameter settings—e.g., when b is an integer vector and A is totally unimodular5","—all vertices of the constraining polyhedron are integer points; in these cases, the integer constraint may be suppressed and (3) is guaranteed to have integer solutions (Schrijver, 2003). Of course, this need not happen: solving a general ILP is an NP-complete problem. Despite this 4 There is also a quadratic algorithm due to Tarjan (1977). 5 A matrix is called totally unimodular if the determinants","of each square submatrix belong to {0, 1, −1}. fact, fast solvers are available today that make this a practical solution for many problems. Their performance depends on the dimensions and degree of sparsity of the constraint matrix A.","Riedel and Clarke (2006) proposed an ILP formulation for dependency parsing which refines the arc-factored model by imposing linguistically motivated “hard” constraints that forbid some arc configurations. Their formulation includes an exponential number of constraints—one for each possible cycle. Since it is intractable to throw in all constraints at once, they propose a cutting-plane algorithm, where the cycle constraints are only invoked when violated by the current solution. The resulting algorithm is still slow, and an arc-factored model is used as a surrogate during training (i.e., the hard constraints are only used at test time), which implies a discrepancy between the model that is optimized and the one that is actually going to be used.","Here, we propose ILP formulations that eliminate the need for cycle constraints; in fact, they require only a polynomial number of constraints. Not only does our model allow expert knowledge to be injected in the form of constraints, it is also capable of learning soft versions of those constraints from data; indeed, it can handle features that are not arc-factored (correlating, for example, siblings and grandparents, modeling valency, or preferring nearly projective parses). While, as pointed out by McDonald and Satta (2007), the inclusion of these features makes inference NP-hard, by relaxing the integer constraints we obtain approximate algorithms that are very efficient and competitive with state-of-the-art methods. In this paper, we focus on unlabeled dependency parsing, for clarity of exposition. If it is extended to labeled parsing (a straightforward extension), our formulation fully subsumes that of Riedel and Clarke (2006), since it allows using the same hard constraints and features while keeping the ILP polynomial in size. 3.1 The Arborescence Polytope We start by describing our constraint space. Our formulations rely on a concise polyhedral representation of the set of candidate dependency parse trees, as sketched in §2.1. This will be accomplished by drawing an analogy with a network flow problem.","Let D = ⟨V, A⟩ be the complete directed graph 344 associated with a sentence x ∈ X , as stated in §2. A subgraph y = ⟨V, B⟩ is a legal dependency tree (i.e., y ∈ Y(x)) if and only if the following conditions are met:","1. Each vertex in V \\ {0} must have exactly one incoming arc in B, 2. 0 has no incoming arcs in B, 3. B does not contain cycles. For each vertex v ∈ V , let δ−","(v) ≜ {⟨i, j⟩ ∈ A | j = v} denote its set of incoming arcs, and δ+","(v) ≜ {⟨i, j⟩ ∈ A | i = v} denote its set of outgoing arcs. The two first conditions can be easily expressed by linear constraints on the incidence vector z:","∑ a∈δ−","(j) za = 1, j ∈ V \\ {0} (4)","∑ a∈δ−","(0) za = 0 (5) Condition 3 is somewhat harder to express. Rather than adding exponentially many constraints, one for each potential cycle (like Riedel and Clarke, 2006), we equivalently replace condition 3 by","3′ . B is connected. Note that conditions 1-2-3 are equivalent to 1-2-3′",", in the sense that both define the same set Y(x). However, as we will see, the latter set of conditions is more convenient. Connectedness of graphs can be imposed via flow constraints (by requiring that, for any v ∈ V \\ {0}, there is a directed path in B connecting 0 to v). We adapt the single commodity flow formulation for the (undirected) minimum spanning tree problem, due to Magnanti and Wolsey (1994), that requires O(n2",") variables and constraints. Under this model, the root node must send one unit of flow to every other node. By making use of extra variables, φ ≜ ⟨φa⟩a∈A, to denote the flow of commodities through each arc, we are led to the following constraints in addition to Eqs. 4–5 (we denote U ≜ [0, 1], and B ≜ {0, 1} = U ∩ Z): • Root sends flow n:","∑ a∈δ+","(0) φa = n (6)","• Each node consumes one unit of flow: ∑","a∈δ− (j) φa − ∑","a∈δ+ (j) φa = 1, j ∈ V \\ {0} (7) • Flow is zero on disabled arcs: φa ≤ nza, a ∈ A (8) • Each arc indicator lies in the unit interval: za ∈ U, a ∈ A. (9) These constraints project an outer bound of the arborescence polytope, i.e.,","Z̄(x) ≜ {z ∈ R|A| | (z, φ) satisfy (4–9)} ⊇ Z(x). (10) Furthermore, the integer points of Z̄(x) are precisely the incidence vectors of dependency trees in Y(x); these are obtained by replacing Eq. 9 by za ∈ B, a ∈ A. (11) 3.2 Arc-Factored Model Given our polyhedral representation of (an outer bound of) the arborescence polytope, we can now formulate dependency parsing with an arc-factored model as an ILP. By storing the arc-local feature vectors into the columns of a matrix F(x) ≜ [fa(x)]a∈A, and defining the score vector s ≜ F(x)⊤","w (each entry is an arc score) the inference problem can be written as max y∈Y(x)","w⊤ f (x, y) = max","z∈Z(x)","w⊤ F(x)z","= max z,φ","s⊤ z s.t. A [ z φ ] ≤ b z ∈ B","(12) where A is a sparse constraint matrix (with O(|A|) non-zero elements), and b is the constraint vector; A and b encode the constraints (4–9). This is an ILP with O(|A|) variables and constraints (hence, quadratic in n); if we drop the integer constraint the problem becomes the LP relaxation. As is, this formulation is no more attractive than solving the problem with the existing combinatorial algorithms discussed in §2.2; however, we can now start adding non-local features to build a more powerful model. 3.3 Sibling and Grandparent Features To cope with higher-order features of the form fa1,...,aK (x) (i.e., features whose values depend on the simultaneous inclusion of arcs a1, . . . , aK on 345 a candidate dependency tree), we employ a linearization trick (Boros and Hammer, 2002), defining extra variables za1...aK ≜ za1 ∧ . . . ∧ zaK . This logical relation can be expressed by the following O(K) agreement constraints:6 za1...aK ≤ zai, i = 1, . . . , K za1...aK ≥","∑K i=1 zai − K + 1. (13) As shown by McDonald and Pereira (2006) and Carreras (2007), the inclusion of features that correlate sibling and grandparent arcs may be highly beneficial, even if doing so requires resort-ing to approximate algorithms.7","Define Rsibl","≜ {⟨i, j, k⟩ | ⟨i, j⟩ ∈ A, ⟨i, k⟩ ∈ A} and Rgrand","≜ {⟨i, j, k⟩ | ⟨i, j⟩ ∈ A, ⟨j, k⟩ ∈ A}. To include such features in our formulation, we need to add extra variables zsibl","≜ ⟨z","r⟩r∈Rsibl and zgrand","≜ ⟨zr⟩r∈Rgrand that indicate the presence of sibling and grandparent arcs. Observe that these indicator variables are conjunctions of arc indicator variables, i.e., zsibl","ijk = zij ∧ zik and z","grand","ijk = zij ∧ zjk.","Hence, these features can be handled in our formu-","lation by adding the following O(|A| · |V |) vari-","ables and constraints:","zsibl","ijk ≤ zij, zsibl","ijk ≤ zik, zsibl","ijk ≥ zij + zik − 1","(14)","for all triples ⟨i, j, k⟩ ∈ Rsibl , and z grand ijk ≤ zij, z grand ijk ≤ zjk, z","grand","ijk ≥ zij+zjk−1","(15)","for all triples ⟨i, j, k⟩ ∈ Rgrand",". Let R ≜ A ∪","Rsibl","∪ Rgrand","; by redefining z ≜ ⟨z","r⟩r∈R and F(x) ≜ [fr(x)]r∈R, we may express our inference problem as in Eq. 12, with O(|A| · |V |) variables and constraints.","Notice that the strategy just described to handle sibling features is not fully compatible with the features proposed by Eisner (1996) for projective parsing, as the latter correlate only consecutive siblings and are also able to place special features on the first child of a given word. The ability to handle such “ordered” features is intimately associated with Eisner’s dynamic programming parsing algorithm and with the Markovian assumptions made explicitly by his genera-tive model. We next show how similar features","6","Actually, any logical condition can be encoded with linear constraints involving binary variables; see e.g. Clarke and Lapata (2008) for an overview.","7","By sibling features we mean features that depend on pairs of sibling arcs (i.e., of the form ⟨i, j⟩ and ⟨i, k⟩); by grandparent features we mean features that depend on pairs of grandparent arcs (of the form ⟨i, j⟩ and ⟨j, k⟩). can be incorporated in our model by adding “dynamic” constraints to our ILP. Define: znext sibl ijk ≜    1 if ⟨i, j⟩ and ⟨i, k⟩ are","consecutive siblings, 0 otherwise, zfirst child ij ≜ { 1 if j is the first child of i, 0 otherwise. Suppose (without loss of generality) that i < j < k ≤ n. We could naively compose the constraints (14) with additional linear constraints that encode the logical relation znext sibl ijk = zsibl","ijk ∧ ∧ j<l<k ¬zil, but this would yield a constraint matrix with O(n4",") non-zero elements. Instead, we define auxiliary variables βjk and γij: βjk = { 1, if ∃l s.t. π(l) = π(j) < j < l < k 0, otherwise, γij = { 1, if ∃k s.t. i < k < j and ⟨i, k⟩ ∈ y 0, otherwise. (16)","Then, we have that znext sibl ijk = zsibl","ijk ∧ (¬βjk) and zfirst child ij = zij ∧ (¬γij), which can be encoded via","znext sibl","ijk ≤ zsibl","ijk zfirst child","ij ≤ zij znext sibl ijk ≤ 1 − βjk zfirst child","ij ≤ 1 − γij","znext sibl","ijk ≥ zsibl","ijk − βjk zfirst child","ij ≥ zij − γij The following “dynamic” constraints encode the logical relations for the auxiliary variables (16): βj(j+1) = 0 γi(i+1) = 0 βj(k+1) ≥ βjk γi(j+1) ≥ γij βj(k+1) ≥ ∑ i<j zsibl ijk γi(j+1) ≥ zij βj(k+1) ≤ βjk + ∑ i<j zsibl ijk γi(j+1) ≤ γij + zij Auxiliary variables and constraints are defined analogously for the case n ≥ i > j > k. This results in a sparser constraint matrix, with only O(n3",") non-zero elements. 3.4 Valency Features A crucial fact about dependency grammars is that words have preferences about the number and arrangement of arguments and modifiers they accept. Therefore, it is desirable to include features 346 that indicate, for a candidate arborescence, how many outgoing arcs depart from each vertex; denote these quantities by vi ≜","∑","a∈δ+","(i) za, for each i ∈ V . We call vi the valency of the ith vertex. We add valency indicators zval","ik ≜ I(vi = k) for i ∈ V and k = 0, . . . , n − 1. This way, we are able to penalize candidate dependency trees that assign unusual valencies to some of their vertices, by specifying a individual cost for each possible value of valency. The following O(|V |2",") constraints encode the agreement between valency indicators and the other variables: ∑n−1","k=0 kzval","ik =","∑ a∈δ+","(i) za, i ∈ V (17)","∑n−1","k=0 zval ik = 1, i ∈ V zval ik ≥ 0, i ∈ V, k ∈ {0, . . . , n − 1} 3.5 Projectivity Features For most languages, dependency parse trees tend to be nearly projective (cf. Buchholz and Marsi, 2006). We wish to make our model capable of learning to prefer “nearly” projective parses whenever that behavior is observed in the data.","The multicommodity directed flow model of Magnanti and Wolsey (1994) is a refinement of the model described in §3.1 which offers a compact and elegant way to indicate nonprojective arcs, requiring O(n3",") variables and constraints. In this model, every node k ̸= 0 defines a commodity: one unit of commodity k originates at the root node and must be delivered to node k; the vari-able φk","ij denotes the flow of commodity k in arc ⟨i, j⟩. We first replace (4–9) by (18–22):","• The root sends one unit of commodity to each node: ∑","a∈δ− (0) φk a − ∑","a∈δ+ (0) φk a = −1, k ∈ V \\ {0} (18)","• Any node consumes its own commodity and no other: ∑","a∈δ− (j) φk a − ∑","a∈δ+ (j) φk a = δk","j , j, k ∈ V \\ {0} (19)","where δk j ≜ I(j = k) is the Kronecker delta. • Disabled arcs do not carry any flow: φk a ≤ za, a ∈ A, k ∈ V (20)","• There are exactly n enabled arcs: ∑","a∈A za = n (21) • All variables lie in the unit interval:","za ∈ U, φk a ∈ U, a ∈ A, k ∈ V (22)","We next define auxiliary variables ψjk that indicate if there is a path from j to k. Since each vertex except the root has only one incoming arc, the following linear equalities are enough to describe these new variables: ψjk =","∑","a∈δ−","(j) φk","a, j, k ∈ V \\ {0} ψ0k = 1, k ∈ V \\ {0}. (23)","Now, define indicators znp ≜ ⟨znp","a ⟩a∈A, where znp a ≜ I(a ∈ y and a is nonprojective). From the definition of projective arcs in §2.1, we have that z","np","a = 1 if and only if the arc is active (za = 1) and there is some vertex k in the span of a = ⟨i, j⟩ such that ψik = 0. We are led to the following O(|A| · |V |) constraints for ⟨i, j⟩ ∈ A: z np ij ≤ zij z np ij ≥ zij − ψik, min(i, j) ≤ k ≤ max(i, j) z np ij ≤ −","∑max(i,j)−1 k=min(i,j)+1 ψik + |j − i| − 1 There are other ways to introduce nonprojectiv-ity indicators and alternative definitions of “non-projective arc.” For example, by using dynamic constraints of the same kind as those in §3.3, we can indicate arcs that “cross” other arcs with O(n3",") variables and constraints, and a cubic number of non-zero elements in the constraint matrix (omitted for space). 3.6 Projective Parsing It would be straightforward to adapt the constraints in §3.5 to allow only projective parse trees: simply force z","np","a = 0 for any a ∈ A. But there are more efficient ways of accomplish this. While it is difficult to impose projectivity constraints or cycle constraints individually, there is a simpler way of imposing both. Consider 3 (or 3′",") from §3.1. Proposition 1 Replace condition 3 (or 3′",") with 3′′ . If ⟨i, j⟩ ∈ B, then, for any k = 1, . . . , n such that k ̸= j, the parent of k must satisfy (defining i′","≜ min(i, j) and j′","≜ max(i, j)):   ","i′","≤ π(k) ≤ j′",", if i′","< k < j′",",","π(k) < i′","∨ π(k) > j′",", if k < i′","or k > j′","or k = i. 347 Then, Y(x) will be redefined as the set of projective dependency parse trees. We omit the proof for space. Conditions 1, 2, and 3′′ can be encoded with O(n2",") constraints."]},{"title":"4 Experiments","paragraphs":["We report experiments on seven languages, six (Danish, Dutch, Portuguese, Slovene, Swedish and Turkish) from the CoNLL-X shared task (Buchholz and Marsi, 2006), and one (English) from the CoNLL-2008 shared task (Surdeanu et al., 2008).8","All experiments are evaluated using the unlabeled attachment score (UAS), using the default settings.9","We used the same arc-factored features as McDonald et al. (2005) (included in the MSTParser toolkit10","); for the higher-order models described in §3.3–3.5, we employed simple higher order features that look at the word, part-of-speech tag, and (if available) morphological information of the words being correlated through the indicator variables. For scalability (and noting that some of the models require O(|V | · |A|) constraints and variables, which, when A = V 2",", grows cubically with the number of words), we first prune the base graph by running a simple algorithm that ranks the k-best candidate parents for each word in the sentence (we set k = 10); this reduces the number of candidate arcs to |A| = kn.11","This strategy is similar to the one employed by Carreras et al. (2008) to prune the search space of the actual parser. The ranker is a local model trained using a max-margin criterion; it is arc-factored and not subject to any structural constraints, so it is very fast.","The actual parser was trained via the online structured passive-aggressive algorithm of Crammer et al. (2006); it differs from the 1-best MIRA algorithm of McDonald et al. (2005) by solving a sequence of loss-augmented inference problems.12","The number of iterations was set to 10.","The results are summarized in Table 1; for the sake of comparison, we reproduced three strong","8","We used the provided train/test splits except for English, for which we tested on the development partition. For training, sentences longer than 80 words were discarded. For test-ing, all sentences were kept (the longest one has length 118).","9","http://nextens.uvt.nl/∼","conll/software.html","10","http://sourceforge.net/projects/mstparser","11","Note that, unlike reranking approaches, there are still exponentially many candidate parse trees after pruning. The oracle constrained to pick parents from these lists achieves > 98% in every case.","12","The loss-augmented inference problem can also be expressed as an LP for Hamming loss functions that factor over arcs; we refer to Martins et al. (2009) for further details. baselines, all of them state-of-the-art parsers based on non-arc-factored models: the second order model of McDonald and Pereira (2006), the hybrid model of Nivre and McDonald (2008), which combines a (labeled) transition-based and a graph-based parser, and a refinement of the latter, due to Martins et al. (2008), which attempts to approximate non-local features. 13","We did not reproduce the model of Riedel and Clarke (2006) since the latter is tailored for labeled dependency parsing; however, experiments reported in that paper for Dutch (and extended to other languages in the CoNLL-X task) suggest that their model performs worse than our three baselines.","By looking at the middle four columns, we can see that adding non-arc-factored features makes the models more accurate, for all languages. With the exception of Portuguese, the best results are achieved with the full set of features. We can also observe that, for some languages, the valency features do not seem to help. Merely modeling the number of dependents of a word may not be as valuable as knowing what kinds of dependents they are (for example, distinguishing among arguments and adjuncts).","Comparing with the baselines, we observe that our full model outperforms that of McDonald and Pereira (2006), and is in line with the most accurate dependency parsers (Nivre and McDonald, 2008; Martins et al., 2008), obtained by combining transition-based and graph-based parsers. 14 Notice that our model, compared with these hybrid parsers, has the advantage of not requiring an ensemble configuration (eliminating, for example, the need to tune two parsers). Unlike the ensembles, it directly handles non-local output features by optimizing a single global objective. Perhaps more importantly, it makes it possible to exploit expert knowledge through the form of hard global constraints. Although not pursued here, the same kind of constraints employed by Riedel and Clarke (2006) can straightforwardly fit into our model, after extending it to perform labeled dependency parsing. We believe that a careful design of fea-","13","Unlike our model, the hybrid models used here as baselines make use of the dependency labels at training time; in-deed, the transition-based parser is trained to predict a labeled dependency parse tree, and the graph-based parser use these predicted labels as input features. Our model ignores this information at training time; therefore, this comparison is slightly unfair to us.","14","See also Zhang and Clark (2008) for a different approach that combines transition-based and graph-based methods. 348 [MP06] [NM08]","[MDSX08]","ARC-F ACTORED +SIBL/GRANDP.","+VALENCY","+PROJ. (FULL)","FULL, RELAXED DANISH 90.60 91.30 91.54 89.80 91.06 90.98 91.18 91.04 (-0.14) DUTCH 84.11 84.19 84.79 83.55 84.65 84.93 85.57 85.41 (-0.16) PORTUGUESE 91.40 91.81 92.11 90.66 92.11 92.01 91.42 91.44 (+0.02) SLOVENE 83.67 85.09 85.13 83.93 85.13 85.45 85.61 85.41 (-0.20) SWEDISH 89.05 90.54 90.50 89.09 90.50 90.34 90.60 90.52 (-0.08) TURKISH 75.30 75.68 76.36 75.16 76.20 76.08 76.34 76.32 (-0.02) ENGLISH 90.85 – – 90.15 91.13 91.12 91.16 91.14 (-0.02) Table 1: Results for nonprojective dependency parsing (unlabeled attachment scores). The three baselines are the second order model of McDonald and Pereira (2006) and the hybrid models of Nivre and McDonald (2008) and Martins et al. (2008). The four middle columns show the performance of our model using exact (ILP) inference at test time, for increasing sets of features (see §3.2–§3.5). The rightmost column shows the results obtained with the full set of features using relaxed LP inference followed by projection onto the feasible set. Differences are with respect to exact inference for the same set of features. Bold indicates the best result for a language. As for overall performance, both the exact and relaxed full model outperform the arc-factored model and the second order model of McDonald and Pereira (2006) with statistical significance (p < 0.01) according to Dan Bikel’s randomized method (http://www.cis.upenn.edu/∼","dbikel/software.html). tures and constraints can lead to further improvements on accuracy.","We now turn to a different issue: scalability. In previous work (Martins et al., 2009), we showed that training the model via LP-relaxed inference (as we do here) makes it learn to avoid fractional solutions; as a consequence, ILP solvers will converge faster to the optimum (on average). Yet, it is known from worst case complexity the-ory that solving a general ILP is NP-hard; hence, these solvers may not scale well with the sentence length. Merely considering the LP-relaxed version of the problem at test time is unsatisfactory, as it may lead to a fractional solution (i.e., a solution whose components indexed by arcs, z̃ = ⟨za⟩a∈A, are not all integer), which does not correspond to a valid dependency tree. We propose the following approximate algorithm to obtain an actual parse: first, solve the LP relaxation (which can be done in polynomial time with interior-point methods); then, if the solution is fractional, project it onto the feasible set Y(x). Fortunately, the Euclidean projection can be computed in a straightforward way by finding a maximal arborescence in the directed graph whose weights are defined by z̃ (we omit the proof for space); as we saw in §2.2, the Chu-Liu-Edmonds algorithm can do this in polynomial time. The overall parsing runtime becomes polynomial with respect to the length of the sentence.","The last column of Table 1 compares the accuracy of this approximate method with the exact one. We observe that there is not a substantial drop in accuracy; on the other hand, we observed a considerable speed-up with respect to exact inference, particularly for long sentences. The average runtime (across all languages) is 0.632 seconds per sentence, which is in line with existing higher-order parsers and is much faster than the runtimes reported by Riedel and Clarke (2006)."]},{"title":"5 Conclusions","paragraphs":["We presented new dependency parsers based on concise ILP formulations. We have shown how non-local output features can be incorporated, while keeping only a polynomial number of constraints. These features can act as soft constraints whose penalty values are automatically learned from data; in addition, our model is also compatible with expert knowledge in the form of hard constraints. Learning through a max-margin framework is made effective by the means of a LP-relaxation. Experimental results on seven languages show that our rich-featured parsers outperform arc-factored and approximate higher-order parsers, and are in line with stacked parsers, hav-ing with respect to the latter the advantage of not requiring an ensemble configuration."]},{"title":"Acknowledgments","paragraphs":["The authors thank the reviewers for their comments. Martins was supported by a grant from FCT/ICTI through the CMU-Portugal Program, and also by Priberam Informática. Smith was supported by NSF IIS-0836431 and an IBM Faculty Award. Xing was supported by NSF DBI-0546594, DBI-0640543, IIS-0713379, and an Alfred Sloan Foundation Fellowship in Computer Science. 349"]},{"title":"References","paragraphs":["E. Boros and P.L. Hammer. 2002. Pseudo-Boolean optimization. Discrete Applied Mathematics, 123(1– 3):155–225.","S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL.","X. Carreras, M. Collins, and T. Koo. 2008. TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proc. of CoNLL.","X. Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proc. of CoNLL.","M. Chang, L. Ratinov, and D. Roth. 2008. Constraints as prior knowledge. In ICML Workshop on Prior Knowledge for Text and Language Processing.","Y. J. Chu and T. H. Liu. 1965. On the shortest arborescence of a directed graph. Science Sinica, 14:1396– 1400.","J. Clarke and M. Lapata. 2008. Global inference for sentence compression an integer linear programming approach. JAIR, 31:399–429.","K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585.","A. Culotta and J. Sorensen. 2004. Dependency tree kernels for relation extraction. In Proc. of ACL.","P. Denis and J. Baldridge. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. In Proc. of HLT-NAACL.","Y. Ding and M. Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammar. In Proc. of ACL.","J. Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards, 71B:233–240.","J. Eisner and G. Satta. 1999. Efficient parsing for bilexical context-free grammars and head automaton grammars. In Proc. of ACL.","J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of COL-ING.","S. Kahane, A. Nasr, and O. Rambow. 1998. Pseudoprojectivity: a polynomially parsable non-projective dependency grammar. In Proc. of COLING-ACL.","S. Lacoste-Julien, B. Taskar, D. Klein, and M. I. Jordan. 2006. Word alignment via quadratic assignment. In Proc. of HLT-NAACL.","T. L. Magnanti and L. A. Wolsey. 1994. Optimal Trees. Technical Report 290-94, Massachusetts In-stitute of Technology, Operations Research Center.","A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing. 2008. Stacking dependency parsers. In Proc. of EMNLP.","A. F. T. Martins, N. A. Smith, and E. P. Xing. 2009. Polyhedral outer approximations with application to natural language parsing. In Proc. of ICML.","R. T. McDonald and F. C. N. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL.","R. McDonald and G. Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In Proc. of IWPT.","R. T. McDonald, F. Pereira, K. Ribarov, and J. Hajič. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. of HLT-EMNLP.","J. Nivre and R. McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proc. of ACL-HLT.","V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2004. Semantic role labeling via integer linear programming inference. In Proc. of COLING.","M. Richardson and P. Domingos. 2006. Markov logic networks. Machine Learning, 62(1):107–136.","S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proc. of EMNLP.","R. T. Rockafellar. 1970. Convex Analysis. Princeton University Press.","D. Roth and W. T. Yih. 2005. Integer linear programming inference for conditional random fields. In ICML.","A. Schrijver. 2003. Combinatorial Optimization: Polyhedra and Efficiency, volume 24 of Algorithms and Combinatorics. Springer.","D. A. Smith and J. Eisner. 2008. Dependency parsing by belief propagation. In Proc. of EMNLP.","M. Surdeanu, R. Johansson, A. Meyers, L. Màrquez, and J. Nivre. 2008. The conll-2008 shared task on joint parsing of syntactic and semantic dependencies. Proc. of CoNLL.","R. E. Tarjan. 1977. Finding optimum branchings. Networks, 7(1):25–36.","M. Wang, N. A. Smith, and T. Mitamura. 2007. What is the Jeopardy model? A quasi-synchronous grammar for QA. In Proceedings of EMNLP-CoNLL.","Y. Zhang and S. Clark. 2008. A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search. In Proc. of EMNLP. 350"]}],"references":[{"authors":[{"first":"E.","last":"Boros"},{"first":"P.","middle":"L.","last":"Hammer"}],"year":"2002","title":"Pseudo-Boolean optimization","source":"E. Boros and P.L. Hammer. 2002. Pseudo-Boolean optimization. Discrete Applied Mathematics, 123(1– 3):155–225."},{"authors":[{"first":"S.","last":"Buchholz"},{"first":"E.","last":"Marsi"}],"year":"2006","title":"CoNLL-X shared task on multilingual dependency parsing","source":"S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL."},{"authors":[{"first":"X.","last":"Carreras"},{"first":"M.","last":"Collins"},{"first":"T.","last":"Koo"}],"year":"2008","title":"TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing","source":"X. Carreras, M. Collins, and T. Koo. 2008. TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proc. of CoNLL."},{"authors":[{"first":"X.","last":"Carreras"}],"year":"2007","title":"Experiments with a higher-order projective dependency parser","source":"X. Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proc. of CoNLL."},{"authors":[{"first":"M.","last":"Chang"},{"first":"L.","last":"Ratinov"},{"first":"D.","last":"Roth"}],"year":"2008","title":"Constraints as prior knowledge","source":"M. Chang, L. Ratinov, and D. Roth. 2008. Constraints as prior knowledge. In ICML Workshop on Prior Knowledge for Text and Language Processing."},{"authors":[{"first":"Y.","middle":"J.","last":"Chu"},{"first":"T.","middle":"H.","last":"Liu"}],"year":"1965","title":"On the shortest arborescence of a directed graph","source":"Y. J. Chu and T. H. Liu. 1965. On the shortest arborescence of a directed graph. Science Sinica, 14:1396– 1400."},{"authors":[{"first":"J.","last":"Clarke"},{"first":"M.","last":"Lapata"}],"year":"2008","title":"Global inference for sentence compression an integer linear programming approach","source":"J. Clarke and M. Lapata. 2008. Global inference for sentence compression an integer linear programming approach. JAIR, 31:399–429."},{"authors":[{"first":"K.","last":"Crammer"},{"first":"O.","last":"Dekel"},{"first":"J.","last":"Keshet"},{"first":"S.","last":"Shalev-Shwartz"},{"first":"Y.","last":"Singer"}],"year":"2006","title":"Online passive-aggressive algorithms","source":"K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585."},{"authors":[{"first":"A.","last":"Culotta"},{"first":"J.","last":"Sorensen"}],"year":"2004","title":"Dependency tree kernels for relation extraction","source":"A. Culotta and J. Sorensen. 2004. Dependency tree kernels for relation extraction. In Proc. of ACL."},{"authors":[{"first":"P.","last":"Denis"},{"first":"J.","last":"Baldridge"}],"year":"2007","title":"Joint determination of anaphoricity and coreference resolution using integer programming","source":"P. Denis and J. Baldridge. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. In Proc. of HLT-NAACL."},{"authors":[{"first":"Y.","last":"Ding"},{"first":"M.","last":"Palmer"}],"year":"2005","title":"Machine translation using probabilistic synchronous dependency insertion grammar","source":"Y. Ding and M. Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammar. In Proc. of ACL."},{"authors":[{"first":"J.","last":"Edmonds"}],"year":"1967","title":"Optimum branchings","source":"J. Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards, 71B:233–240."},{"authors":[{"first":"J.","last":"Eisner"},{"first":"G.","last":"Satta"}],"year":"1999","title":"Efficient parsing for bilexical context-free grammars and head automaton grammars","source":"J. Eisner and G. Satta. 1999. Efficient parsing for bilexical context-free grammars and head automaton grammars. In Proc. of ACL."},{"authors":[{"first":"J.","last":"Eisner"}],"year":"1996","title":"Three new probabilistic models for dependency parsing: An exploration","source":"J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of COL-ING."},{"authors":[{"first":"S.","last":"Kahane"},{"first":"A.","last":"Nasr"},{"first":"O.","last":"Rambow"}],"year":"1998","title":"Pseudoprojectivity: a polynomially parsable non-projective dependency grammar","source":"S. Kahane, A. Nasr, and O. Rambow. 1998. Pseudoprojectivity: a polynomially parsable non-projective dependency grammar. In Proc. of COLING-ACL."},{"authors":[{"first":"S.","last":"Lacoste-Julien"},{"first":"B.","last":"Taskar"},{"first":"D.","last":"Klein"},{"first":"M.","middle":"I.","last":"Jordan"}],"year":"2006","title":"Word alignment via quadratic assignment","source":"S. Lacoste-Julien, B. Taskar, D. Klein, and M. I. Jordan. 2006. Word alignment via quadratic assignment. In Proc. of HLT-NAACL."},{"authors":[{"first":"T.","middle":"L.","last":"Magnanti"},{"first":"L.","middle":"A.","last":"Wolsey"}],"year":"1994","title":"Optimal Trees","source":"T. L. Magnanti and L. A. Wolsey. 1994. Optimal Trees. Technical Report 290-94, Massachusetts In-stitute of Technology, Operations Research Center."},{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"D.","last":"Das"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2008","title":"Stacking dependency parsers","source":"A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing. 2008. Stacking dependency parsers. In Proc. of EMNLP."},{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2009","title":"Polyhedral outer approximations with application to natural language parsing","source":"A. F. T. Martins, N. A. Smith, and E. P. Xing. 2009. Polyhedral outer approximations with application to natural language parsing. In Proc. of ICML."},{"authors":[{"first":"R.","middle":"T.","last":"McDonald"},{"first":"F.","middle":"C. N.","last":"Pereira"}],"year":"2006","title":"Online learning of approximate dependency parsing algorithms","source":"R. T. McDonald and F. C. N. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL."},{"authors":[{"first":"R.","last":"McDonald"},{"first":"G.","last":"Satta"}],"year":"2007","title":"On the complexity of non-projective data-driven dependency parsing","source":"R. McDonald and G. Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In Proc. of IWPT."},{"authors":[{"first":"R.","middle":"T.","last":"McDonald"},{"first":"F.","last":"Pereira"},{"first":"K.","last":"Ribarov"},{"first":"J.","last":"Hajič"}],"year":"2005","title":"Non-projective dependency parsing using spanning tree algorithms","source":"R. T. McDonald, F. Pereira, K. Ribarov, and J. Hajič. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. of HLT-EMNLP."},{"authors":[{"first":"J.","last":"Nivre"},{"first":"R.","last":"McDonald"}],"year":"2008","title":"Integrating graph-based and transition-based dependency parsers","source":"J. Nivre and R. McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proc. of ACL-HLT."},{"authors":[{"first":"V.","last":"Punyakanok"},{"first":"D.","last":"Roth"},{"first":"W.","last":"Yih"},{"first":"D.","last":"Zimak"}],"year":"2004","title":"Semantic role labeling via integer linear programming inference","source":"V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2004. Semantic role labeling via integer linear programming inference. In Proc. of COLING."},{"authors":[{"first":"M.","last":"Richardson"},{"first":"P.","last":"Domingos"}],"year":"2006","title":"Markov logic networks","source":"M. Richardson and P. Domingos. 2006. Markov logic networks. Machine Learning, 62(1):107–136."},{"authors":[{"first":"S.","last":"Riedel"},{"first":"J.","last":"Clarke"}],"year":"2006","title":"Incremental integer linear programming for non-projective dependency parsing","source":"S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proc. of EMNLP."},{"authors":[{"first":"R.","middle":"T.","last":"Rockafellar"}],"year":"1970","title":"Convex Analysis","source":"R. T. Rockafellar. 1970. Convex Analysis. Princeton University Press."},{"authors":[{"first":"D.","last":"Roth"},{"first":"W.","middle":"T.","last":"Yih"}],"year":"2005","title":"Integer linear programming inference for conditional random fields","source":"D. Roth and W. T. Yih. 2005. Integer linear programming inference for conditional random fields. In ICML."},{"authors":[{"first":"A.","last":"Schrijver"}],"year":"2003","title":"Combinatorial Optimization: Polyhedra and Efficiency, volume 24 of Algorithms and Combinatorics","source":"A. Schrijver. 2003. Combinatorial Optimization: Polyhedra and Efficiency, volume 24 of Algorithms and Combinatorics. Springer."},{"authors":[{"first":"D.","middle":"A.","last":"Smith"},{"first":"J.","last":"Eisner"}],"year":"2008","title":"Dependency parsing by belief propagation","source":"D. A. Smith and J. Eisner. 2008. Dependency parsing by belief propagation. In Proc. of EMNLP."},{"authors":[{"first":"M.","last":"Surdeanu"},{"first":"R.","last":"Johansson"},{"first":"A.","last":"Meyers"},{"first":"L.","last":"Màrquez"},{"first":"J.","last":"Nivre"}],"year":"2008","title":"The conll-2008 shared task on joint parsing of syntactic and semantic dependencies","source":"M. Surdeanu, R. Johansson, A. Meyers, L. Màrquez, and J. Nivre. 2008. The conll-2008 shared task on joint parsing of syntactic and semantic dependencies. Proc. of CoNLL."},{"authors":[{"first":"R.","middle":"E.","last":"Tarjan"}],"year":"1977","title":"Finding optimum branchings","source":"R. E. Tarjan. 1977. Finding optimum branchings. Networks, 7(1):25–36."},{"authors":[{"first":"M.","last":"Wang"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"T.","last":"Mitamura"}],"year":"2007","title":"What is the Jeopardy model? A quasi-synchronous grammar for QA","source":"M. Wang, N. A. Smith, and T. Mitamura. 2007. What is the Jeopardy model? A quasi-synchronous grammar for QA. In Proceedings of EMNLP-CoNLL."},{"authors":[{"first":"Y.","last":"Zhang"},{"first":"S.","last":"Clark"}],"year":"2008","title":"A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search","source":"Y. Zhang and S. Clark. 2008. A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search. In Proc. of EMNLP. 350"}],"cites":[{"style":0,"text":"Roth and Yih, 2005","origin":{"pointer":"/sections/6/paragraphs/0","offset":177,"length":18},"authors":[{"last":"Roth"},{"last":"Yih"}],"year":"2005","references":["/references/27"]},{"style":0,"text":"Punyakanok et al., 2004","origin":{"pointer":"/sections/6/paragraphs/0","offset":197,"length":23},"authors":[{"last":"Punyakanok"},{"last":"al."}],"year":"2004","references":["/references/23"]},{"style":0,"text":"Riedel and Clarke, 2006","origin":{"pointer":"/sections/6/paragraphs/0","offset":243,"length":23},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Lacoste-Julien et al., 2006","origin":{"pointer":"/sections/6/paragraphs/0","offset":309,"length":27},"authors":[{"last":"Lacoste-Julien"},{"last":"al."}],"year":"2006","references":["/references/15"]},{"style":0,"text":"Clarke and Lapata, 2008","origin":{"pointer":"/sections/6/paragraphs/0","offset":354,"length":23},"authors":[{"last":"Clarke"},{"last":"Lapata"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Denis and Baldridge, 2007","origin":{"pointer":"/sections/6/paragraphs/0","offset":408,"length":25},"authors":[{"last":"Denis"},{"last":"Baldridge"}],"year":"2007","references":["/references/9"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/6/paragraphs/1","offset":275,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Richardson and Domingos, 2006","origin":{"pointer":"/sections/6/paragraphs/4","offset":498,"length":29},"authors":[{"last":"Richardson"},{"last":"Domingos"}],"year":"2006","references":["/references/24"]},{"style":0,"text":"Chang et al., 2008","origin":{"pointer":"/sections/6/paragraphs/4","offset":529,"length":18},"authors":[{"last":"Chang"},{"last":"al."}],"year":"2008","references":["/references/4"]},{"style":0,"text":"Ding and Palmer, 2005","origin":{"pointer":"/sections/7/paragraphs/0","offset":262,"length":21},"authors":[{"last":"Ding"},{"last":"Palmer"}],"year":"2005","references":["/references/10"]},{"style":0,"text":"Culotta and Sorensen, 2004","origin":{"pointer":"/sections/7/paragraphs/0","offset":309,"length":26},"authors":[{"last":"Culotta"},{"last":"Sorensen"}],"year":"2004","references":["/references/8"]},{"style":0,"text":"Wang et al., 2007","origin":{"pointer":"/sections/7/paragraphs/0","offset":361,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2007","references":["/references/32"]},{"style":0,"text":"Kahane et al., 1998","origin":{"pointer":"/sections/7/paragraphs/5","offset":199,"length":19},"authors":[{"last":"Kahane"},{"last":"al."}],"year":"1998","references":["/references/14"]},{"style":0,"text":"Rockafellar, 1970","origin":{"pointer":"/sections/7/paragraphs/6","offset":540,"length":17},"authors":[{"last":"Rockafellar"}],"year":"1970","references":["/references/26"]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/15","offset":395,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/15","offset":409,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/15","offset":590,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"Klein and Manning, 2002","origin":{"pointer":"/sections/7/paragraphs/15","offset":855,"length":23},"authors":[{"last":"Klein"},{"last":"Manning"}],"year":"2002","references":[]},{"style":0,"text":"McDonald and Pereira, 2006","origin":{"pointer":"/sections/7/paragraphs/15","offset":880,"length":26},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/15","offset":1046,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al. (2005b)","origin":{"pointer":"/sections/7/paragraphs/16","offset":258,"length":23},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/7/paragraphs/17","offset":342,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Eisner, 1996","origin":{"pointer":"/sections/7/paragraphs/17","offset":795,"length":12},"authors":[{"last":"Eisner"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/17","offset":809,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"Yamada and Matsumoto, 2003","origin":{"pointer":"/sections/7/paragraphs/17","offset":823,"length":26},"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","references":[]},{"style":0,"text":"Nivre and Scholz, 2004","origin":{"pointer":"/sections/7/paragraphs/17","offset":851,"length":22},"authors":[{"last":"Nivre"},{"last":"Scholz"}],"year":"2004","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/17","offset":875,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"Nivre and Nilsson, 2005","origin":{"pointer":"/sections/7/paragraphs/17","offset":935,"length":23},"authors":[{"last":"Nivre"},{"last":"Nilsson"}],"year":"2005","references":[]},{"style":0,"text":"Hall and Nóvák, 2005","origin":{"pointer":"/sections/7/paragraphs/17","offset":960,"length":20},"authors":[{"last":"Hall"},{"last":"Nóvák"}],"year":"2005","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/17","offset":982,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"Yamada and Matsumoto, 2003","origin":{"pointer":"/sections/7/paragraphs/17","offset":1224,"length":26},"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","references":[]},{"style":0,"text":"Nivre and Scholz, 2004","origin":{"pointer":"/sections/7/paragraphs/17","offset":1252,"length":22},"authors":[{"last":"Nivre"},{"last":"Scholz"}],"year":"2004","references":[]},{"style":0,"text":"Nivre and Nilsson, 2005","origin":{"pointer":"/sections/7/paragraphs/17","offset":1276,"length":23},"authors":[{"last":"Nivre"},{"last":"Nilsson"}],"year":"2005","references":[]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/17","offset":1472,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/17","offset":1486,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/17","offset":1510,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"McDonald and Pereira, 2006","origin":{"pointer":"/sections/7/paragraphs/17","offset":1676,"length":26},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Riedel and Clarke, 2006","origin":{"pointer":"/sections/7/paragraphs/17","offset":1758,"length":23},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Hirakawa, 2006","origin":{"pointer":"/sections/7/paragraphs/17","offset":1815,"length":14},"authors":[{"last":"Hirakawa"}],"year":"2006","references":[]},{"style":0,"text":"Wang and Harper (2004)","origin":{"pointer":"/sections/7/paragraphs/18","offset":149,"length":22},"authors":[{"last":"Wang"},{"last":"Harper"}],"year":"2004","references":[]},{"style":0,"text":"Neuhaus and Böker (1997)","origin":{"pointer":"/sections/7/paragraphs/18","offset":221,"length":24},"authors":[{"last":"Neuhaus"},{"last":"Böker"}],"year":"1997","references":[]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/18","offset":645,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/18","offset":659,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/18","offset":840,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"Klein and Manning, 2002","origin":{"pointer":"/sections/7/paragraphs/18","offset":1105,"length":23},"authors":[{"last":"Klein"},{"last":"Manning"}],"year":"2002","references":[]},{"style":0,"text":"McDonald and Pereira, 2006","origin":{"pointer":"/sections/7/paragraphs/18","offset":1130,"length":26},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/18","offset":1296,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al. (2005b)","origin":{"pointer":"/sections/7/paragraphs/19","offset":258,"length":23},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/7/paragraphs/20","offset":342,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Eisner, 1996","origin":{"pointer":"/sections/7/paragraphs/20","offset":795,"length":12},"authors":[{"last":"Eisner"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/20","offset":809,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"Yamada and Matsumoto, 2003","origin":{"pointer":"/sections/7/paragraphs/20","offset":823,"length":26},"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","references":[]},{"style":0,"text":"Nivre and Scholz, 2004","origin":{"pointer":"/sections/7/paragraphs/20","offset":851,"length":22},"authors":[{"last":"Nivre"},{"last":"Scholz"}],"year":"2004","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/20","offset":875,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"Nivre and Nilsson, 2005","origin":{"pointer":"/sections/7/paragraphs/20","offset":935,"length":23},"authors":[{"last":"Nivre"},{"last":"Nilsson"}],"year":"2005","references":[]},{"style":0,"text":"Hall and Nóvák, 2005","origin":{"pointer":"/sections/7/paragraphs/20","offset":960,"length":20},"authors":[{"last":"Hall"},{"last":"Nóvák"}],"year":"2005","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/20","offset":982,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"Yamada and Matsumoto, 2003","origin":{"pointer":"/sections/7/paragraphs/20","offset":1224,"length":26},"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","references":[]},{"style":0,"text":"Nivre and Scholz, 2004","origin":{"pointer":"/sections/7/paragraphs/20","offset":1252,"length":22},"authors":[{"last":"Nivre"},{"last":"Scholz"}],"year":"2004","references":[]},{"style":0,"text":"Nivre and Nilsson, 2005","origin":{"pointer":"/sections/7/paragraphs/20","offset":1276,"length":23},"authors":[{"last":"Nivre"},{"last":"Nilsson"}],"year":"2005","references":[]},{"style":0,"text":"Paskin, 2001","origin":{"pointer":"/sections/7/paragraphs/20","offset":1472,"length":12},"authors":[{"last":"Paskin"}],"year":"2001","references":[]},{"style":0,"text":"McDonald et al., 2005a","origin":{"pointer":"/sections/7/paragraphs/20","offset":1486,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005a","references":[]},{"style":0,"text":"McDonald et al., 2005b","origin":{"pointer":"/sections/7/paragraphs/20","offset":1510,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005b","references":[]},{"style":0,"text":"McDonald and Pereira, 2006","origin":{"pointer":"/sections/7/paragraphs/20","offset":1676,"length":26},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Riedel and Clarke, 2006","origin":{"pointer":"/sections/7/paragraphs/20","offset":1758,"length":23},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Hirakawa, 2006","origin":{"pointer":"/sections/7/paragraphs/20","offset":1815,"length":14},"authors":[{"last":"Hirakawa"}],"year":"2006","references":[]},{"style":0,"text":"Wang and Harper (2004)","origin":{"pointer":"/sections/7/paragraphs/21","offset":149,"length":22},"authors":[{"last":"Wang"},{"last":"Harper"}],"year":"2004","references":[]},{"style":0,"text":"Neuhaus and Böker (1997)","origin":{"pointer":"/sections/7/paragraphs/21","offset":221,"length":24},"authors":[{"last":"Neuhaus"},{"last":"Böker"}],"year":"1997","references":[]},{"style":0,"text":"McDonald and Satta (2007)","origin":{"pointer":"/sections/7/paragraphs/21","offset":432,"length":25},"authors":[{"last":"McDonald"},{"last":"Satta"}],"year":"2007","references":["/references/20"]},{"style":0,"text":"Lacoste-Julien et al. (2006)","origin":{"pointer":"/sections/7/paragraphs/21","offset":544,"length":28},"authors":[{"last":"Lacoste-Julien"},{"last":"al."}],"year":"2006","references":["/references/15"]},{"style":0,"text":"Nivre and McDonald (2008)","origin":{"pointer":"/sections/7/paragraphs/24","offset":389,"length":25},"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","references":["/references/22"]},{"style":0,"text":"Eisner, 1996","origin":{"pointer":"/sections/7/paragraphs/27","offset":134,"length":12},"authors":[{"last":"Eisner"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"McDonald et al., 2005","origin":{"pointer":"/sections/7/paragraphs/27","offset":148,"length":21},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"McDonald et al. (2005)","origin":{"pointer":"/sections/7/paragraphs/28","offset":173,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"Chu and Liu, 1965","origin":{"pointer":"/sections/7/paragraphs/28","offset":275,"length":17},"authors":[{"last":"Chu"},{"last":"Liu"}],"year":"1965","references":["/references/5"]},{"style":0,"text":"Edmonds, 1967","origin":{"pointer":"/sections/7/paragraphs/28","offset":294,"length":13},"authors":[{"last":"Edmonds"}],"year":"1967","references":["/references/11"]},{"style":0,"text":"Eisner, 1996","origin":{"pointer":"/sections/7/paragraphs/29","offset":124,"length":12},"authors":[{"last":"Eisner"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"Eisner and Satta, 1999","origin":{"pointer":"/sections/7/paragraphs/29","offset":275,"length":22},"authors":[{"last":"Eisner"},{"last":"Satta"}],"year":"1999","references":["/references/12"]},{"style":0,"text":"McDonald and Satta, 2007","origin":{"pointer":"/sections/7/paragraphs/29","offset":408,"length":24},"authors":[{"last":"McDonald"},{"last":"Satta"}],"year":"2007","references":["/references/20"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/7/paragraphs/29","offset":564,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Smith and Eisner (2008)","origin":{"pointer":"/sections/7/paragraphs/30","offset":81,"length":23},"authors":[{"last":"Smith"},{"last":"Eisner"}],"year":"2008","references":["/references/29"]},{"style":0,"text":"Martins et al., 2009","origin":{"pointer":"/sections/8/paragraphs/0","offset":363,"length":20},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2009","references":["/references/18"]},{"style":0,"text":"Schrijver, 2003","origin":{"pointer":"/sections/8/paragraphs/4","offset":171,"length":15},"authors":[{"last":"Schrijver"}],"year":"2003","references":["/references/28"]},{"style":0,"text":"Tarjan (1977)","origin":{"pointer":"/sections/8/paragraphs/4","offset":329,"length":13},"authors":[{"last":"Tarjan"}],"year":"1977","references":["/references/31"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/8/paragraphs/6","offset":0,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"McDonald and Satta (2007)","origin":{"pointer":"/sections/8/paragraphs/7","offset":506,"length":25},"authors":[{"last":"McDonald"},{"last":"Satta"}],"year":"2007","references":["/references/20"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/8/paragraphs/7","offset":921,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Riedel and Clarke, 2006","origin":{"pointer":"/sections/8/paragraphs/15","offset":144,"length":23},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Magnanti and Wolsey (1994)","origin":{"pointer":"/sections/8/paragraphs/17","offset":382,"length":26},"authors":[{"last":"Magnanti"},{"last":"Wolsey"}],"year":"1994","references":["/references/16"]},{"style":0,"text":"Boros and Hammer, 2002","origin":{"pointer":"/sections/8/paragraphs/31","offset":772,"length":22},"authors":[{"last":"Boros"},{"last":"Hammer"}],"year":"2002","references":["/references/0"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/8/paragraphs/32","offset":37,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Carreras (2007)","origin":{"pointer":"/sections/8/paragraphs/32","offset":69,"length":15},"authors":[{"last":"Carreras"}],"year":"2007","references":["/references/3"]},{"style":0,"text":"Eisner (1996)","origin":{"pointer":"/sections/8/paragraphs/60","offset":121,"length":13},"authors":[{"last":"Eisner"}],"year":"1996","references":["/references/13"]},{"style":0,"text":"Clarke and Lapata (2008)","origin":{"pointer":"/sections/8/paragraphs/62","offset":108,"length":24},"authors":[{"last":"Clarke"},{"last":"Lapata"}],"year":"2008","references":["/references/6"]},{"style":0,"text":"Buchholz and Marsi, 2006","origin":{"pointer":"/sections/8/paragraphs/90","offset":169,"length":24},"authors":[{"last":"Buchholz"},{"last":"Marsi"}],"year":"2006","references":["/references/1"]},{"style":0,"text":"Magnanti and Wolsey (1994)","origin":{"pointer":"/sections/8/paragraphs/91","offset":42,"length":26},"authors":[{"last":"Magnanti"},{"last":"Wolsey"}],"year":"1994","references":["/references/16"]},{"style":0,"text":"Buchholz and Marsi, 2006","origin":{"pointer":"/sections/9/paragraphs/0","offset":134,"length":24},"authors":[{"last":"Buchholz"},{"last":"Marsi"}],"year":"2006","references":["/references/1"]},{"style":0,"text":"Surdeanu et al., 2008","origin":{"pointer":"/sections/9/paragraphs/0","offset":212,"length":21},"authors":[{"last":"Surdeanu"},{"last":"al."}],"year":"2008","references":["/references/30"]},{"style":0,"text":"McDonald et al. (2005)","origin":{"pointer":"/sections/9/paragraphs/2","offset":42,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"Carreras et al. (2008)","origin":{"pointer":"/sections/9/paragraphs/5","offset":48,"length":22},"authors":[{"last":"Carreras"},{"last":"al."}],"year":"2008","references":["/references/2"]},{"style":0,"text":"Crammer et al. (2006)","origin":{"pointer":"/sections/9/paragraphs/6","offset":88,"length":21},"authors":[{"last":"Crammer"},{"last":"al."}],"year":"2006","references":["/references/7"]},{"style":0,"text":"McDonald et al. (2005)","origin":{"pointer":"/sections/9/paragraphs/6","offset":156,"length":22},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"Martins et al. (2009)","origin":{"pointer":"/sections/9/paragraphs/19","offset":130,"length":21},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2009","references":["/references/18"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/9/paragraphs/19","offset":281,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Nivre and McDonald (2008)","origin":{"pointer":"/sections/9/paragraphs/19","offset":330,"length":25},"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","references":["/references/22"]},{"style":0,"text":"Martins et al. (2008)","origin":{"pointer":"/sections/9/paragraphs/19","offset":466,"length":21},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","references":["/references/17"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/9/paragraphs/20","offset":34,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/9/paragraphs/22","offset":81,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Nivre and McDonald, 2008","origin":{"pointer":"/sections/9/paragraphs/22","offset":168,"length":24},"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","references":["/references/22"]},{"style":0,"text":"Martins et al., 2008","origin":{"pointer":"/sections/9/paragraphs/22","offset":194,"length":20},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","references":["/references/17"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/9/paragraphs/22","offset":759,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]},{"style":0,"text":"Zhang and Clark (2008)","origin":{"pointer":"/sections/9/paragraphs/26","offset":9,"length":22},"authors":[{"last":"Zhang"},{"last":"Clark"}],"year":"2008","references":["/references/33"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/9/paragraphs/31","offset":589,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Nivre and McDonald (2008)","origin":{"pointer":"/sections/9/paragraphs/31","offset":642,"length":25},"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","references":["/references/22"]},{"style":0,"text":"Martins et al. (2008)","origin":{"pointer":"/sections/9/paragraphs/31","offset":672,"length":21},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","references":["/references/17"]},{"style":0,"text":"McDonald and Pereira (2006)","origin":{"pointer":"/sections/9/paragraphs/31","offset":1250,"length":27},"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Martins et al., 2009","origin":{"pointer":"/sections/9/paragraphs/33","offset":65,"length":20},"authors":[{"last":"Martins"},{"last":"al."}],"year":"2009","references":["/references/18"]},{"style":0,"text":"Riedel and Clarke (2006)","origin":{"pointer":"/sections/9/paragraphs/34","offset":453,"length":24},"authors":[{"last":"Riedel"},{"last":"Clarke"}],"year":"2006","references":["/references/25"]}]}
