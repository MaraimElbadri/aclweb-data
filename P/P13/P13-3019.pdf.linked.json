{"sections":[{"title":"","paragraphs":["Proceedings of the ACL Student Research Workshop, pages 130–135, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"A New Syntactic Metric for Evaluation of Machine Translation  Melania Duma Department of Computer Science University of Hamburg Vogt-Kölln-Straße 30 22527 Hamburg duma@informatik.uni -hamburg.de Cristina Vertan Faculty for Language, Literature and Media University of Hamburg Von Melle Park 6 20146 Hamburg cristina.vertan@uni -hamburg.de Wolfgang Menzel Department of Computer Science University of Hamburg Vogt-Kölln-Straße 30 22527 Hamburg menzel@informatik.uni -hamburg.de   Abstract","paragraphs":["Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level."]},{"title":"1 Introduction","paragraphs":["Research in automatic machine translation (MT) evaluation has the goal of developing a set of computer-based methods that measure accurately the correctness of the output generated by a MT system. However, this task is a difficult one mainly because there is no unique reference output that can be used in the comparison with the candidate translation. One sentence can have several correct translations. Thus, it is difficult to decide if the deviation from an existing reference translation is a matter of style (the use of synonymous words, different syntax etc.) or a real translation error.","Most of the automatic evaluation metrics developed so far are focused on the idea of lexical matching between the tokens of one or more reference translations and the tokens of a candidate translation. However, structural similarity between a reference translation and a candidate one cannot be captured by lexical features. Therefore, research in MT evaluation experiences a gradual shift of focus from lexical metrics to structural ones, whether they are syntactic or semantic or a combination of both.","This paper introduces a new syntactic automatic MT evaluation method. At this stage of research the new metric is evaluating translations from any source language into German. Given that a set of constraint-based grammar rules are available for that language, extensions to other target languages are anytime possible. The chosen tool for providing syntactic information for German is the Weighted Constraints Dependency Grammar (WCDG) parser (Menzel and Schröder, 1998), which is preferred over other parsers because of its robustness to ungrammatical input, as it is typical for MT output. The rest of this paper is organized as follows. In Section 2 the state of the art in MT evaluation is presented, while in Section 3 the new syntactic metric is described. The experimental setup and results are presented in Section 4. The last section deals with the conclusions and future work."]},{"title":"2 State of the art","paragraphs":["Automatic evaluation of MT systems relies on the existence of at least one reference1","created by a human annotator. Using an automatic method of evaluation a score is computed, based on the similarity between the output of the MT system and the reference. This similarity can be computed at different levels: lexical, syntactic or semantic. At the lexical level, the metrics developed so far can be divided into two major categories: n-gram based and edit distance based.  1 We will use the term reference for the reference translation and the term translation for the candidate translation. 130 Among the n-gram based metrics, one of the most popular methods of evaluation is BLEU (Papineni et al., 2001). It provides a score that is computed as the summed number of n-grams shared by the references and the output, divided by the total number of n-grams. Lexical metrics that use the edit distance are constructed using the Levenshtein distance applied at the word level. Among these metrics, WER (Niessen et al., 2000) is the one which is used more frequently; it calculates the minimal number of insertion, substitutions and deletions needed to transform the candidate translation into a reference.","Metrics based on lexical matching suffer from not being able to consider the variation encountered in natural language. Thus, they reward a low score to an otherwise fluent and syntactically correct candidate translation, if it does not share a certain number of words with the set of references. Because of this, major disagreements between the scores assigned by BLEU and human judgments have been reported in Koehn and Monz (2006) and Callison-Burch et al. (2006). Another disadvantage is that many of them cannot be applied at the segment level, which is often needed in order to better assess the quality of MT output and to determine which improvements should be made to the MT system. Because of these disadvantages there is an increasing need for other approaches to MT evaluation that go beyond the lexical level of the phrases compared.","In Liu and Gildea (2005), three syntactic evaluation metrics are presented. The first of these metrics, the Subtree Metric (SMT), is based on determining the number of subtrees that can be found in both the candidate translation and the reference phrase structure trees. The second metric, which is a kernel-based subtree metric, is defined as the maximum of the cosine measure between the MT output and the set of references. The third metric proposed computes the number of matching n-grams between the headword chains of the reference and the candidate translation dependency trees obtained using the parser described in (Collins, 1999).","The idea of syntactic similarity is further exploited in Owczarzak et al. (2007) which uses a Lexical Functional Grammar (LFG) parser. The similarity between the translation and the reference is computed using the precision and the recall of the dependencies that illustrate the pair of sentences. Furthermore, paraphrases are used in order to improve the correlation with human judgments. Another set of syntactic metrics has been introduced in Gimenez (2008); some of them are based on analyzing different types of linguistic information (i.e. part-of-speech or lemma)."]},{"title":"3 A new syntactic automatic metric","paragraphs":["In this section we introduce the new syntactic metric which is based on constraint dependency parsing. In the first subsection, the WCDG parser is presented, together with the advantages of using this parser over the other ones available, while the second subsection provides a detailed description of the new metric.","3.1 Weighted Constraint Dependency Grammar Parser Our research was performed using a dependency parser. We decided on this type of parser because, as opposed to constituent parsers, it offers the possibility of better representing nonprojective structures. Moreover, it has been shown in Kuebler and Prokic (2006) that, at least in the case of German, the results achieved by a dependency parser are more accurate than the ones obtained when parsing using constituent parsers, and this is because dependency parsers can handle better long distance relations and coordination.","The goal of constraint dependency grammars (CDG) is to create dependency structures that represent a given phrase (Schröder et al., 2000) on parallel levels of analysis. A relation between two words in a sentence is represented using an edge, which connects the regent and the dependent. Edges are annotated using labels in order to distinguish between different types of relations. A constraint is made up of a logical formula that describes properties of the tree. One property, for example, that is always enforced is that no word can have more than one regent on any level at a time. During the analysis, each of the constraints is applied to every edge or every pair of edges belonging to the constructed dependency parse tree. The main advantage of using constraint dependency grammars over dependency grammars based on generative rules is that they can deal better with free word order languages (Foth, 2004). Weighted Constraint Dependency Grammar (WCDG) (Menzel and Schröder, 1998) assigns different weights to the constraints of the grammar. Every constraint in WCDG is assigned a score which is a number between 0.0 and 1.0, 131 while the general score of a parse is calculated as the product of all the scores of all the instances of constraints that have not been satisfied. Rules that have a score of 0 are called hard rules, meaning that they cannot be ignored, which is the case of the one regent only rule mentioned earlier. The advantage of using graded constraints, as opposed to crisp ones, stems from the fact that weights allow the parser to tolerate constraint violations, which, in turn, makes the parser robust against ungrammaticality. The parser was evaluated using different types of texts, and the results show that it has an accuracy between 80% and 90% in computing correct dependency attachments depending on the type of text (Foth et al., 2004a).","The benefit of using WCDG over other parsers is that it provides further information on a parse, like the general score of the parse and the constraints that are violated by the final result. This information can be further explored in order to perform an error analysis. Moreover, because of the fact that the candidate translations are sometimes not well-formed, parsing them represents a challenge. However, WCDG will always provide a final result, in the form of a dependency structure, even though it might have a low score due to the violated constraints. 3.2 Description of the metric In order to define a new syntactic metric for MT evaluation, we have incorporated the WCDG parser in the process of evaluation. Because the output of the WCDG parser is a dependency tree, we have looked into techniques of measuring how similar two trees are. Our aim was to determine whether a tree similarity metric applied on the two dependency parse trees would prove to be an efficient way of capturing the similarity between the reference and the translation. Let us consider this example, in which the reference sentence is “Die schwarze Katze springt schnell auf den roten Stuhl.”(engl. The black cat jumps quickly on the red chair) and the candidate translation is“Auf den roten Stuhl schnell springt die schwarze Katze”(engl. On the red chair quickly jumps the red cat). Even though the word order of the two segments is quite different, and the translation has an incorrect syntax, they roughly have the same meaning. We present in Figure 1 the dependency parse trees obtained using WCDG for the sentences considered. We can observe that the general structure of the translation is similar to that of the reference, the only difference being the reverse order between the left subtree and the right subtree. The tree similarity measure that we chose to use was the All Common Embedded Subtrees (ACET) (Lin et al., 2008) similarity. Given a tree T, an embedded subtree is obtained by removing one or more nodes, except for the root, from the tree T. The idea behind ACET is that, the more substructures two trees share, the more similar they are. Therefore, ACET is defined as the number of common embedded subtrees shared between two trees. The results reported in Lin et al. (2008) show that ACET outperforms tree edit distance (Zhang and Shasha, 1989) in terms of efficiency.   Figure 1. Example of dependency parse trees for reference and candidate translations  In our experiments, we have applied the ACET algorithm, and computed the number of common embedded subtrees between the dependency parse trees of the hypothesis and the reference. Because of the additional information provided by the parsing, pre-processing of the output of the WCDG parser was necessary in order to transform the dependency tree into a general tree. We first removed the labels assigned to every edge, but maintained the nodes and the left to right order between them.","In the following, we will refer to the new proposed metric using CESM (Common Embedded Subtree Metric). CESM was computed using the precision, the recall and the F-measure of the common embedded subtrees of the reference and the translation:         132      where treeref and treehyp represent the preprocessed dependency trees of the reference and the hypothesis translations."]},{"title":"4 Experimental setup and evaluation","paragraphs":["In order to determine how accurate CESM is in capturing the similarity between references and translations, we evaluated it at the system level and at the segment level. The evaluation was conducted using data provided by the NAACL 2012 WMT workshop (Callison-Burch et al., 2012). The test data for the workshop consisted of 99 translated news articles in English, German, French, Spanish and Czech.","At the system level, the initial German test set provided at the workshop was filtered according to the length of segments. This was done in order to limit the time requirements of WCDG. As a result, 500 segments with a length between 50 and 80 characters were extracted from the German reference file. In the next step, we arbitrarily selected the outputs of 7 of the 15 systems that were submitted for evaluation in the English to German translation task: DFKI (Vilar, 2012), JHU (Ganitkevitch et al., 2012), KIT (Niehues et al., 2012), UK (Zeman, 2012) and three anonymized system outputs referred to as OnlineA, OnlineB, OnlineC.","After this initial step of filtering the data, the 7 systems were evaluated by calculating the CESM score for every pair of reference and translation segments corresponding to a system. The average scores obtained are depicted in Table 1. Evaluation of the metric at the system level was performed by measuring the correlation of the CESM metric with human judgments using Spearman's rank correlation coefficient ρ:","   ","","","where n represents the number of MT systems considered during evaluation, and di2","represents the difference between the ranks, assigned to a system, by the metric and the human judgments. The minimum value of ρ is -1, when there is no correlation between the two rankings, while the maximum value is 1, when the two rankings correlate perfectly (Callison-Burch et al., 2012). In order to compute the ρ score, the scores attributed to every system by CESM, were converted into ranks. From the different ranking strategies that were presented by the WMT12 workshop, the standard ranking order was chosen. The ρ rank correlation coefficient was calculated as being ρ = 0.92, which shows there is a strong correlation between the results of CESM and the human judgments. In order to better assess the quality of CESM, the test set was also evaluated using NIST (Doddington, 2002), which managed to obtain the same rank correlation coefficient of ρ = 0.92.","","No. System name CESM score","NIST","score 1 DFKI 0.069 4.7709 2 JHU 0.073 4.9904 3 KIT 0.090 5.1358 4 OnlineA 0.093 5.3039 5 OnlineB 0.091 5.3039 6 OnlineC 0.085 4.8022 7 UK 0.075 4.6579 Table 1. System level evaluation results  The first step in evaluating at the segment level was filtering the initial test set provided by the WMT12 workshop. For this purpose, 2500 reference and translation segments were selected with a length between 50 and 80 characters. The Kendall tau rank correlation coefficient was calculated in order to measure the correlation with human judgments, where Kendall tau (Callison-Burch et al., 2012) is defined as:"," ","    In order to compute the value of Kendall tau, we determined the number of concordant pairs and the number of discordant pairs of judgments. Similarly to the guideline followed during the WMT12 workshop (Callison-Burch et al., 2012), we penalized ties given by CESM and ignored ties assigned by the human judgments. The obtained result was a correlation of 0.058. As a term of comparison, the highest correlation for segment level reported in Callinson-Burch et al. (2012) was 0.19 obtained by TerrorCat (Fishel et al., 2012) and the lowest was BlockErrCats (Popovic, 2012) with 0.040. However, these results were obtained by evaluating on the entire test set. The rather low correlation result we obtained can be partially explained by the fact that only one judgment of a pair of reference and translation was taken into account. It will be 133 interesting to see how the averaging of the ranks of a translation influences the correlation coefficient."]},{"title":"5 Conclusions and future work","paragraphs":["In this paper, a new evaluation metric for MT was introduced, which is based on the comparison of dependency parse trees. The dependency trees were obtained using the WCDG German parser. The reason why we chose this parser was that, due to its architecture, it is able to handle ungrammatical and ambiguous input data. The experiments conducted so far show that using the data made available at the NAACL 2012 WMT workshop, CESM correlates well with the human judgments at the system level. One of the future experiments that we intend to perform is to assess metric quality on the entire evaluation set. Moreover, we plan to compare CESM with other tree-based MT metrics. Furthermore, the WMT12 workshop offers different ranking possibilities, like the ones presented in Bojar et al (2011) and in Lopez (2012). It will be determined how much are the segment level evaluation results influenced by these ranking orders.","One limitation of the proposed metric is that, at the moment it is restricted to translations from any source language to German as a target language. Because of this reason, we plan to extend the metric to other languages and see how well it performs in different settings. In further experiments we also intend to test CESM using statistical based dependency parsers, like the Malt Parser (Nivre et al., 2007) and the MST parser (McDonald et al., 2006), in order to decide whether the choice of parser influences the performance of the metric.","Another approach that we will explore for improving CESM is to compare dependency parse trees using the base form and the part-of-speech of the tokens, instead of the exact lexical match. We will try this approach in order to avoid penalizing lexical variation.","The accuracy of CESM can be further increased by the use of paraphrases, which can be obtained by using a German thesaurus or a lexical resource like GermaNet (Hamp and Feldweg, 1997). Furthermore, a technique like the one described in Owczarzak (2008) can be implemented for generating domain specific paraphrases. The results reported show that the use of this kind of paraphrases in order to produce new references has increased the BLEU score, therefore this is an approach that will be further investigated."," Acknowledgments  This work was funded by the University of Hamburg Doctoral Fellowships in accordance with the Hamburg Act for the Promotion of Young Researchers and Artists (HmbNFG), and the EAMT Project “Using Syntactic and Semantic Information in the Evaluation of Corpus-based Machine Translation”."]},{"title":"Reference","paragraphs":["O. Bojar, M. Ercegovčević, M Popel and O. Zaidan. 2011. A Grain of Salt for the WMT Manual Evaluation. Proceedings of the Sixth Workshop on Statistical Machine Translation.","C. Callison-Burch, M. Osborne and P. Koehn. 2006. Re-evaluating the Role of Bleu in Machine Translation Research. Proceedings of EACL-2006.","C. Callison-Burch, P. Koehn, C. Monz, M. Post, R. Soricut and L. Specia. 2012. Findings of the 2012 Workshop on Statistical Machine Translation. Proceedings of WMT12.","M. J. Collins. 1999. Head-driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.","G. Doddington. 2002. Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics. Proceedings of the 2nd International Conference on Human Language Technology.","K. Foth. 2004. Writing weighted constraints for large de-pendency grammars. Recent Advances in De-pendency Grammar, Workshop COLING 2004.","K. Foth, M. Daum and W. Menzel. 2004a. A broadcoverage parser for German based on defeasible constraints. KONVENS 2004, Beiträge zur 7, Konferenz zur Verarbeitung natürlicher Sprache, Wien.","K. Foth, M. Daum and W. Menzel. 2004b. Interactive grammar development with WCDG. Proc. of the 42nd Annual Meeting of the Association for Com-putational Linguistics.","K. Foth, T. By and W. Menzel. 2006. Guiding a con-straint dependency parser with supertags. Proceedings of the 21st Int. Conf. on Computational Linguistics. 134","M. Fishel, R. Sennrich, M. Popovic and O. Bojar. 2012. TerrorCat: a translation error categorization-based MT quality metric. Proceedings of the Seventh Workshop on Statistical Machine Translation.","J. Ganitkevitch, Y. Cao, J. Weese, M. Post and C. Callison-Burch. 2012. Joshua 4.0: Packing, PRO, and paraphrases. Proceedings of the Seventh Workshop on Statistical Machine Translation.","J. Gimenez. 2008. Empirical Machine Translation and its Evaluation. Ph. D. thesis.","B. Hamp and H. Feldweg. 1997. GermaNet - a Lexical-Semantic Net for German. Proc. of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications.","P. Koehn and C. Monz. 2006. Manual and Automatic Evaluation of Machine Translation between European Languages. NAACL 2006 Workshop on Statistical Machine Translation.","P. Koehn. 2010. Statistical Machine Translation. Cambridge University Press.","S. Kübler and J. Prokic. 2006. Why is German Dependency Parsing more Reliable than Constituent Parsing?. Proceedings of the Fifth International Work-shop on Treebanks and Linguistic Theories.","Z. Lin, H. Wang, S. McClean and C. Liu. 2008. All Common Embedded Subtrees for Measuring Tree Similarity. International Symposium on Computational Intelligence and Design.","D. Liu and D. Gildea. 2005. Syntactic Features for Evaluation of Machine Translation. ACL 2005 Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization.","A. Lopez. 2012. Putting human assessments of machine translation systems in order. Proceedings of the Seventh Workshop on Statistical Machine Translation.","R. McDonald, K. Lerman and F. Pereira. 2006. Multilingual Dependency Parsing with a Two-Stage Discriminative Parser. Tenth Conference on Computational Natural Language Learning.","W. Menzel and I. Schröder. 1998. Decision Procedures for Dependency Parsing Using Graded Constraints. Workshop On Processing Of Dependency-Based Grammars.","J. Niehues, Y. Zhang, M. Mediani, T. Herrmann, E. Cho and A. Waibel. 2012. The karlsruhe institute of technology translation systems for the WMT 2012. Proceedings of the Seventh Workshop on Statistical Machine Translation.","S. Niessen, F. J. Och, G. Leusch and H. Ney. 2000. An Evaluation Tool for Machine Translation: Fast Evaluation for MT Research. Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC).","J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kübler, S. Marinov and E. Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering.","K. Owczarzak, J. van Genabith and A. Way. 2007. Dependency-based automatic evaluation for machine translation. Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation.","K. Owczarzak. 2008. A Novel Dependency-Based Evaluation Metric for Machine Translation, Ph.D. thesis.","K. Papineni, S. Roukos, T. Ward and W.-J. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. RC22176 (Technical Report), IBM T.J. Watson Research Center.","M. Popovic. 2012. Class error rates for evaluation of machine translation output. Proceedings of the Seventh Workshop on Statistical Machine Translation.","I. Schröder, W. Menzel, K. Foth and M. Schulz. 2000. Modeling dependency grammar with restricted constraints. Traitement Automatique des Langues.","I. Schröder, H. Pop, W. Menzel and K. Foth. 2001. Learning grammar weights using genetic algorithms. Proceedings Euroconference Recent Advances in Natural Language Processing.","I. Schröder. 2002. Natural Language Parsing with Graded Constraints. Ph.D. thesis, Dept. of Computer Science, University of Hamburg.","D. Vilar. 2012. DFKI’s SMT system for WMT 2012. Proceedings of the Seventh Workshop on Statistical Machine Translation.","D. Zeman. 2012. Data issues of the multilingual translation matrix. Proceedings of the Seventh Workshop on Statistical Machine Translation.","K. Zhang and D. Shasha. 1989. Simple fast algorithms for the editing distance between trees and related problems. SIAM Journal on Computing.  135"]}],"references":[{"authors":[{"first":"O.","last":"Bojar"},{"first":"M.","last":"Ercegovčević"},{"first":"M","last":"Popel"},{"first":"O.","last":"Zaidan"}],"year":"2011","title":"A Grain of Salt for the WMT Manual Evaluation","source":"O. Bojar, M. Ercegovčević, M Popel and O. Zaidan. 2011. A Grain of Salt for the WMT Manual Evaluation. Proceedings of the Sixth Workshop on Statistical Machine Translation."},{"authors":[{"first":"C.","last":"Callison-Burch"},{"first":"M.","last":"Osborne"},{"first":"P.","last":"Koehn"}],"year":"2006","title":"Re-evaluating the Role of Bleu in Machine Translation Research","source":"C. Callison-Burch, M. Osborne and P. Koehn. 2006. Re-evaluating the Role of Bleu in Machine Translation Research. Proceedings of EACL-2006."},{"authors":[{"first":"C.","last":"Callison-Burch"},{"first":"P.","last":"Koehn"},{"first":"C.","last":"Monz"},{"first":"M.","last":"Post"},{"first":"R.","last":"Soricut"},{"first":"L.","last":"Specia"}],"year":"2012","title":"Findings of the 2012 Workshop on Statistical Machine Translation","source":"C. Callison-Burch, P. Koehn, C. Monz, M. Post, R. Soricut and L. Specia. 2012. Findings of the 2012 Workshop on Statistical Machine Translation. Proceedings of WMT12."},{"authors":[{"first":"M.","middle":"J.","last":"Collins"}],"year":"1999","title":"Head-driven Statistical Models for Natural Language Parsing","source":"M. J. Collins. 1999. Head-driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania."},{"authors":[{"first":"G.","last":"Doddington"}],"year":"2002","title":"Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics","source":"G. Doddington. 2002. Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics. Proceedings of the 2nd International Conference on Human Language Technology."},{"authors":[{"first":"K.","last":"Foth"}],"year":"2004","title":"Writing weighted constraints for large de-pendency grammars","source":"K. Foth. 2004. Writing weighted constraints for large de-pendency grammars. Recent Advances in De-pendency Grammar, Workshop COLING 2004."},{"authors":[{"first":"K.","last":"Foth"},{"first":"M.","last":"Daum"},{"first":"W.","last":"Menzel"}],"year":"2004a","title":"A broadcoverage parser for German based on defeasible constraints","source":"K. Foth, M. Daum and W. Menzel. 2004a. A broadcoverage parser for German based on defeasible constraints. KONVENS 2004, Beiträge zur 7, Konferenz zur Verarbeitung natürlicher Sprache, Wien."},{"authors":[{"first":"K.","last":"Foth"},{"first":"M.","last":"Daum"},{"first":"W.","last":"Menzel"}],"year":"2004b","title":"Interactive grammar development with WCDG","source":"K. Foth, M. Daum and W. Menzel. 2004b. Interactive grammar development with WCDG. Proc. of the 42nd Annual Meeting of the Association for Com-putational Linguistics."},{"authors":[{"first":"K.","last":"Foth"},{"first":"T.","last":"By"},{"first":"W.","last":"Menzel"}],"year":"2006","title":"Guiding a con-straint dependency parser with supertags","source":"K. Foth, T. By and W. Menzel. 2006. Guiding a con-straint dependency parser with supertags. Proceedings of the 21st Int. Conf. on Computational Linguistics. 134"},{"authors":[{"first":"M.","last":"Fishel"},{"first":"R.","last":"Sennrich"},{"first":"M.","last":"Popovic"},{"first":"O.","last":"Bojar"}],"year":"2012","title":"TerrorCat: a translation error categorization-based MT quality metric","source":"M. Fishel, R. Sennrich, M. Popovic and O. Bojar. 2012. TerrorCat: a translation error categorization-based MT quality metric. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"J.","last":"Ganitkevitch"},{"first":"Y.","last":"Cao"},{"first":"J.","last":"Weese"},{"first":"M.","last":"Post"},{"first":"C.","last":"Callison-Burch"}],"year":"2012","title":"Joshua 4","source":"J. Ganitkevitch, Y. Cao, J. Weese, M. Post and C. Callison-Burch. 2012. Joshua 4.0: Packing, PRO, and paraphrases. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"J.","last":"Gimenez"}],"year":"2008","title":"Empirical Machine Translation and its Evaluation","source":"J. Gimenez. 2008. Empirical Machine Translation and its Evaluation. Ph. D. thesis."},{"authors":[{"first":"B.","last":"Hamp"},{"first":"H.","last":"Feldweg"}],"year":"1997","title":"GermaNet - a Lexical-Semantic Net for German","source":"B. Hamp and H. Feldweg. 1997. GermaNet - a Lexical-Semantic Net for German. Proc. of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications."},{"authors":[{"first":"P.","last":"Koehn"},{"first":"C.","last":"Monz"}],"year":"2006","title":"Manual and Automatic Evaluation of Machine Translation between European Languages","source":"P. Koehn and C. Monz. 2006. Manual and Automatic Evaluation of Machine Translation between European Languages. NAACL 2006 Workshop on Statistical Machine Translation."},{"authors":[{"first":"P.","last":"Koehn"}],"year":"2010","title":"Statistical Machine Translation","source":"P. Koehn. 2010. Statistical Machine Translation. Cambridge University Press."},{"authors":[{"first":"S.","last":"Kübler"},{"first":"J.","last":"Prokic"}],"year":"2006","title":"Why is German Dependency Parsing more Reliable than Constituent Parsing?","source":"S. Kübler and J. Prokic. 2006. Why is German Dependency Parsing more Reliable than Constituent Parsing?. Proceedings of the Fifth International Work-shop on Treebanks and Linguistic Theories."},{"authors":[{"first":"Z.","last":"Lin"},{"first":"H.","last":"Wang"},{"first":"S.","last":"McClean"},{"first":"C.","last":"Liu"}],"year":"2008","title":"All Common Embedded Subtrees for Measuring Tree Similarity","source":"Z. Lin, H. Wang, S. McClean and C. Liu. 2008. All Common Embedded Subtrees for Measuring Tree Similarity. International Symposium on Computational Intelligence and Design."},{"authors":[{"first":"D.","last":"Liu"},{"first":"D.","last":"Gildea"}],"year":"2005","title":"Syntactic Features for Evaluation of Machine Translation","source":"D. Liu and D. Gildea. 2005. Syntactic Features for Evaluation of Machine Translation. ACL 2005 Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization."},{"authors":[{"first":"A.","last":"Lopez"}],"year":"2012","title":"Putting human assessments of machine translation systems in order","source":"A. Lopez. 2012. Putting human assessments of machine translation systems in order. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Lerman"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Multilingual Dependency Parsing with a Two-Stage Discriminative Parser","source":"R. McDonald, K. Lerman and F. Pereira. 2006. Multilingual Dependency Parsing with a Two-Stage Discriminative Parser. Tenth Conference on Computational Natural Language Learning."},{"authors":[{"first":"W.","last":"Menzel"},{"first":"I.","last":"Schröder"}],"year":"1998","title":"Decision Procedures for Dependency Parsing Using Graded Constraints","source":"W. Menzel and I. Schröder. 1998. Decision Procedures for Dependency Parsing Using Graded Constraints. Workshop On Processing Of Dependency-Based Grammars."},{"authors":[{"first":"J.","last":"Niehues"},{"first":"Y.","last":"Zhang"},{"first":"M.","last":"Mediani"},{"first":"T.","last":"Herrmann"},{"first":"E.","last":"Cho"},{"first":"A.","last":"Waibel"}],"year":"2012","title":"The karlsruhe institute of technology translation systems for the WMT 2012","source":"J. Niehues, Y. Zhang, M. Mediani, T. Herrmann, E. Cho and A. Waibel. 2012. The karlsruhe institute of technology translation systems for the WMT 2012. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"S.","last":"Niessen"},{"first":"F.","middle":"J.","last":"Och"},{"first":"G.","last":"Leusch"},{"first":"H.","last":"Ney"}],"year":"2000","title":"An Evaluation Tool for Machine Translation: Fast Evaluation for MT Research","source":"S. Niessen, F. J. Och, G. Leusch and H. Ney. 2000. An Evaluation Tool for Machine Translation: Fast Evaluation for MT Research. Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC)."},{"authors":[{"first":"J.","last":"Nivre"},{"first":"J.","last":"Hall"},{"first":"J.","last":"Nilsson"},{"first":"A.","last":"Chanev"},{"first":"G.","last":"Eryigit"},{"first":"S.","last":"Kübler"},{"first":"S.","last":"Marinov"},{"first":"E.","last":"Marsi"}],"year":"2007","title":"MaltParser: A language-independent system for data-driven dependency parsing","source":"J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kübler, S. Marinov and E. Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering."},{"authors":[{"first":"K.","last":"Owczarzak"},{"first":"J.","last":"van Genabith"},{"first":"A.","last":"Way"}],"year":"2007","title":"Dependency-based automatic evaluation for machine translation","source":"K. Owczarzak, J. van Genabith and A. Way. 2007. Dependency-based automatic evaluation for machine translation. Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation."},{"authors":[{"first":"K.","last":"Owczarzak"}],"year":"2008","title":"A Novel Dependency-Based Evaluation Metric for Machine Translation, Ph","source":"K. Owczarzak. 2008. A Novel Dependency-Based Evaluation Metric for Machine Translation, Ph.D. thesis."},{"authors":[{"first":"K.","last":"Papineni"},{"first":"S.","last":"Roukos"},{"first":"T.","last":"Ward"},{"first":"W.","middle":"-J.","last":"Zhu"}],"year":"2001","title":"Bleu: a method for automatic evaluation of machine translation","source":"K. Papineni, S. Roukos, T. Ward and W.-J. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. RC22176 (Technical Report), IBM T.J. Watson Research Center."},{"authors":[{"first":"M.","last":"Popovic"}],"year":"2012","title":"Class error rates for evaluation of machine translation output","source":"M. Popovic. 2012. Class error rates for evaluation of machine translation output. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"I.","last":"Schröder"},{"first":"W.","last":"Menzel"},{"first":"K.","last":"Foth"},{"first":"M.","last":"Schulz"}],"year":"2000","title":"Modeling dependency grammar with restricted constraints","source":"I. Schröder, W. Menzel, K. Foth and M. Schulz. 2000. Modeling dependency grammar with restricted constraints. Traitement Automatique des Langues."},{"authors":[{"first":"I.","last":"Schröder"},{"first":"H.","last":"Pop"},{"first":"W.","last":"Menzel"},{"first":"K.","last":"Foth"}],"year":"2001","title":"Learning grammar weights using genetic algorithms","source":"I. Schröder, H. Pop, W. Menzel and K. Foth. 2001. Learning grammar weights using genetic algorithms. Proceedings Euroconference Recent Advances in Natural Language Processing."},{"authors":[{"first":"I.","last":"Schröder"}],"year":"2002","title":"Natural Language Parsing with Graded Constraints","source":"I. Schröder. 2002. Natural Language Parsing with Graded Constraints. Ph.D. thesis, Dept. of Computer Science, University of Hamburg."},{"authors":[{"first":"D.","last":"Vilar"}],"year":"2012","title":"DFKI’s SMT system for WMT 2012","source":"D. Vilar. 2012. DFKI’s SMT system for WMT 2012. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"D.","last":"Zeman"}],"year":"2012","title":"Data issues of the multilingual translation matrix","source":"D. Zeman. 2012. Data issues of the multilingual translation matrix. Proceedings of the Seventh Workshop on Statistical Machine Translation."},{"authors":[{"first":"K.","last":"Zhang"},{"first":"D.","last":"Shasha"}],"year":"1989","title":"Simple fast algorithms for the editing distance between trees and related problems","source":"K. Zhang and D. Shasha. 1989. Simple fast algorithms for the editing distance between trees and related problems. SIAM Journal on Computing.  135"}],"cites":[{"style":0,"text":"Menzel and Schröder, 1998","origin":{"pointer":"/sections/2/paragraphs/2","offset":444,"length":25},"authors":[{"last":"Menzel"},{"last":"Schröder"}],"year":"1998","references":["/references/20"]},{"style":0,"text":"Papineni et al., 2001","origin":{"pointer":"/sections/3/paragraphs/1","offset":597,"length":21},"authors":[{"last":"Papineni"},{"last":"al."}],"year":"2001","references":["/references/26"]},{"style":0,"text":"Niessen et al., 2000","origin":{"pointer":"/sections/3/paragraphs/1","offset":914,"length":20},"authors":[{"last":"Niessen"},{"last":"al."}],"year":"2000","references":["/references/22"]},{"style":0,"text":"Koehn and Monz (2006)","origin":{"pointer":"/sections/3/paragraphs/2","offset":412,"length":21},"authors":[{"last":"Koehn"},{"last":"Monz"}],"year":"2006","references":["/references/13"]},{"style":0,"text":"Callison-Burch et al. (2006)","origin":{"pointer":"/sections/3/paragraphs/2","offset":438,"length":28},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2006","references":["/references/1"]},{"style":0,"text":"Liu and Gildea (2005)","origin":{"pointer":"/sections/3/paragraphs/3","offset":3,"length":21},"authors":[{"last":"Liu"},{"last":"Gildea"}],"year":"2005","references":["/references/17"]},{"style":0,"text":"Collins, 1999","origin":{"pointer":"/sections/3/paragraphs/3","offset":625,"length":13},"authors":[{"last":"Collins"}],"year":"1999","references":["/references/3"]},{"style":0,"text":"Owczarzak et al. (2007)","origin":{"pointer":"/sections/3/paragraphs/4","offset":57,"length":23},"authors":[{"last":"Owczarzak"},{"last":"al."}],"year":"2007","references":["/references/24"]},{"style":0,"text":"Gimenez (2008)","origin":{"pointer":"/sections/3/paragraphs/4","offset":446,"length":14},"authors":[{"last":"Gimenez"}],"year":"2008","references":["/references/11"]},{"style":0,"text":"Kuebler and Prokic (2006)","origin":{"pointer":"/sections/4/paragraphs/1","offset":288,"length":25},"authors":[{"last":"Kuebler"},{"last":"Prokic"}],"year":"2006","references":[]},{"style":0,"text":"Schröder et al., 2000","origin":{"pointer":"/sections/4/paragraphs/2","offset":115,"length":21},"authors":[{"last":"Schröder"},{"last":"al."}],"year":"2000","references":["/references/28"]},{"style":0,"text":"Foth, 2004","origin":{"pointer":"/sections/4/paragraphs/2","offset":904,"length":10},"authors":[{"last":"Foth"}],"year":"2004","references":["/references/5"]},{"style":0,"text":"Menzel and Schröder, 1998","origin":{"pointer":"/sections/4/paragraphs/2","offset":964,"length":25},"authors":[{"last":"Menzel"},{"last":"Schröder"}],"year":"1998","references":["/references/20"]},{"style":0,"text":"Foth et al., 2004a","origin":{"pointer":"/sections/4/paragraphs/2","offset":1859,"length":18},"authors":[{"last":"Foth"},{"last":"al."}],"year":"2004a","references":["/references/6"]},{"style":0,"text":"Lin et al., 2008","origin":{"pointer":"/sections/4/paragraphs/3","offset":1904,"length":16},"authors":[{"last":"Lin"},{"last":"al."}],"year":"2008","references":["/references/16"]},{"style":0,"text":"Lin et al. (2008)","origin":{"pointer":"/sections/4/paragraphs/3","offset":2267,"length":17},"authors":[{"last":"Lin"},{"last":"al."}],"year":"2008","references":["/references/16"]},{"style":0,"text":"Zhang and Shasha, 1989","origin":{"pointer":"/sections/4/paragraphs/3","offset":2332,"length":22},"authors":[{"last":"Zhang"},{"last":"Shasha"}],"year":"1989","references":["/references/33"]},{"style":0,"text":"Callison-Burch et al., 2012","origin":{"pointer":"/sections/5/paragraphs/0","offset":251,"length":27},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2012","references":["/references/2"]},{"style":0,"text":"Vilar, 2012","origin":{"pointer":"/sections/5/paragraphs/1","offset":464,"length":11},"authors":[{"last":"Vilar"}],"year":"2012","references":["/references/31"]},{"style":0,"text":"Ganitkevitch et al., 2012","origin":{"pointer":"/sections/5/paragraphs/1","offset":483,"length":25},"authors":[{"last":"Ganitkevitch"},{"last":"al."}],"year":"2012","references":["/references/10"]},{"style":0,"text":"Niehues et al., 2012","origin":{"pointer":"/sections/5/paragraphs/1","offset":516,"length":20},"authors":[{"last":"Niehues"},{"last":"al."}],"year":"2012","references":["/references/21"]},{"style":0,"text":"Zeman, 2012","origin":{"pointer":"/sections/5/paragraphs/1","offset":543,"length":11},"authors":[{"last":"Zeman"}],"year":"2012","references":["/references/32"]},{"style":0,"text":"Callison-Burch et al., 2012","origin":{"pointer":"/sections/5/paragraphs/7","offset":264,"length":27},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2012","references":["/references/2"]},{"style":0,"text":"Doddington, 2002","origin":{"pointer":"/sections/5/paragraphs/7","offset":776,"length":16},"authors":[{"last":"Doddington"}],"year":"2002","references":["/references/4"]},{"style":0,"text":"Callison-Burch et al., 2012","origin":{"pointer":"/sections/5/paragraphs/11","offset":563,"length":27},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2012","references":["/references/2"]},{"style":0,"text":"Callison-Burch et al., 2012","origin":{"pointer":"/sections/5/paragraphs/13","offset":207,"length":27},"authors":[{"last":"Callison-Burch"},{"last":"al."}],"year":"2012","references":["/references/2"]},{"style":0,"text":"Callinson-Burch et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/13","offset":446,"length":29},"authors":[{"last":"Callinson-Burch"},{"last":"al."}],"year":"2012","references":[]},{"style":0,"text":"Fishel et al., 2012","origin":{"pointer":"/sections/5/paragraphs/13","offset":508,"length":19},"authors":[{"last":"Fishel"},{"last":"al."}],"year":"2012","references":["/references/9"]},{"style":0,"text":"Popovic, 2012","origin":{"pointer":"/sections/5/paragraphs/13","offset":562,"length":13},"authors":[{"last":"Popovic"}],"year":"2012","references":["/references/27"]},{"style":0,"text":"Lopez (2012)","origin":{"pointer":"/sections/6/paragraphs/0","offset":798,"length":12},"authors":[{"last":"Lopez"}],"year":"2012","references":["/references/18"]},{"style":0,"text":"Nivre et al., 2007","origin":{"pointer":"/sections/6/paragraphs/1","offset":392,"length":18},"authors":[{"last":"Nivre"},{"last":"al."}],"year":"2007","references":["/references/23"]},{"style":0,"text":"McDonald et al., 2006","origin":{"pointer":"/sections/6/paragraphs/1","offset":432,"length":21},"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2006","references":["/references/19"]},{"style":0,"text":"Hamp and Feldweg, 1997","origin":{"pointer":"/sections/6/paragraphs/3","offset":160,"length":22},"authors":[{"last":"Hamp"},{"last":"Feldweg"}],"year":"1997","references":["/references/12"]},{"style":0,"text":"Owczarzak (2008)","origin":{"pointer":"/sections/6/paragraphs/3","offset":236,"length":16},"authors":[{"last":"Owczarzak"}],"year":"2008","references":["/references/25"]}]}
