{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 429–433, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Question Classification Transfer Anne-Laure Ligozat LIMSI-CNRS / BP133, 91403 Orsay cedex, France ENSIIE / 1, square de la résistance, Evry, France firstname.lastname@limsi.fr Abstract","paragraphs":["Question answering systems have been developed for many languages, but most resources were created for English, which can be a problem when developing a system in another language such as French. In particular, for question classification, no labeled question corpus is available for French, so this paper studies the possibility to use existing English corpora and transfer a classification by translating the question and their labels. By translating the training corpus, we obtain results close to a monolingual setting."]},{"title":"1 Introduction","paragraphs":["In question answering (QA), as in most Natural Language Processing domains, English is the best resourced language, in terms of corpora, lexicons, or systems. Many methods are based on supervised machine learning which is made possible by the great amount of resources for this language.","While developing a question answering system for French, we were thus limited by the lack of resources for this language. Some were created, for example for answer validation (Grappy et al., 2011). Yet, for question classification, although question corpora in French exist, only a small part of them is annotated with question classes, and such an annotation is costly. We thus wondered if it was possible to use existing English corpora, in this case the data used in (Li and Roth, 2002), to create a classification module for French.","Transfering knowledge from one language to another is usually done by exploiting parallel corpora; yet in this case, few such corpora exists (CLEF QA datasets could be used, but question classes are not very precise). We thus investigated the possibility of using machine translation to create a parallel corpus, as has been done for spoken language understanding (Jabaian et al., 2011) for example. The idea is that using machine translation would enable us to have a large training corpus, either by using the English one and translating the test corpus, or by translating the training corpus. One of the questions posed was whether the quality of present machine translation systems would enable to learn the classification properly.","This paper presents a question classification transfer method, which results are close to those of a monolingual system. The contributions of the paper are the following:","• comparison of train-on-target and test-on-source strategies for question classification;","• creation of an effective question classification system for French, with minimal annotation effort.","This paper is organized as follows: The problem of Question Classification is defined in section 2. The proposed methods are presented in section 3, and the experiments in section 4. Section 5 details the related works in Question Answering. Finally, Section 6 concludes with a summary and a few directions for future work."]},{"title":"2 Problem definition","paragraphs":["A Question Answering (QA) system aims at returning a precise answer to a natural language question: if asked ”How large is the Lincoln Memorial?”, a QA system should return the answer ”164 acres” as well as a justifying snippet. Most systems include a question classification step which determines the expected answer type, for example area in the previous case. This type can then be used to extract the correct answer in documents.","Detecting the answer type is usually considered as a multiclass classification problem, with each answer type representing a class. (Zhang and 429","English training corpus","English training corpus English test corpus (translation) French test corpus French test corpus French training corpus (translation) Question classification for English Question classification for French learn predict translation learn predict translation Figure 1: Methods for transfering question classification Lee, 2003) showed that a training corpus of several thousands of questions was required to obtain around 90% correct classification, which makes it a costly process to adapt a system to another language than English. In this paper, we wish to learn such a system for French, without having to manually annotate thousands of questions."]},{"title":"3 Transfering question classification","paragraphs":["The two methods tested for transfering the classification, following (Jabaian et al., 2011), are presented in Figure 1:","• The first one (on the left), called test-on-source, consists in learning a classification model in English, and to translate the test corpus from French to English, in order to apply the English model on the translated test corpus.","• The second one (on the right), called train-on-target, consists in translating the training corpus from English to French. We obtain an labeled French corpus, on which it is possible to learn a classification model.","In the first case, classification is learned on well written questions; yet, as the test corpus is translated, translation errors may disturb the classifier. In the second case, the classification model will be learned on less well written questions, but the corpus may be large enough to compensate for the loss in quality. Figure 2: Some of the question categories proposed by (Li and Roth, 2002)"]},{"title":"4 Experiments 4.1 Question classes","paragraphs":["We used the question taxonomy proposed by (Li and Roth, 2002), which enabled us to compare our results to those obtained by (Zhang and Lee, 2003) on English. This taxonomy contains two levels: the first one contains 50 fine grained categories, the second one contains 6 coarse grained categories. Figure 2 presents a few of these categories. 4.2 Corpora For English, we used the data from (Li and Roth, 2002), which was assembled from USC, UIUC and TREC collections, and has been manually labeled according to their taxonomy. The training set contains 5,500 labeled questions, and the test-ing set contains 500 questions.","For French, we gathered questions from several evaluation campaigns: QA@CLEF 2005, 2006, 2007, EQueR and Quæro 2008, 2009 and 2010. After elimination of duplicated questions, we obtained a corpus of 1,421 questions, which were divided into a training set of 728 questions, and a test set of 693 questions 1",". Some of these questions were already labeled, and we manually annotated the rest of them.","Translation was performed by Google Translate online interface, which had satisfactory performance on interrogative forms, which are not well handled by all machine translation systems 2",". 1 This distribution is due to further constraints on the sys-","tem. 2 We tested other translation systems, but Google Trans-","late gave the best results. 430","Train en en fr fr","(trans.)","Test en en fr fr (trans.)","Method test-on- source","train-","on-","target 50 .798 .677 .794 .769 classes 6 .90 .735 .828 .84 classes Table 1: Question classification precision for both levels of the hierarchy (features = word n-grams, classifier = libsvm) 4.3 Classification parameters The classifier used was LibSVM (Chang and Lin, 2011) with default parameters, which offers one-vs-one multiclass classification, and which (Zhang and Lee, 2003) showed to be most effective for this task.","We only considered surface features, and extracted bag-of-ngrams (with n = 1..2). 4.4 Results and discussion Table 1 shows the results obtained with the basic configuration, for both transfer methods.","Results are given in precision, i.e. the propor-tion of correctly classified questions among the test questions 3",".","Using word n-grams, monolingual English classification obtains .798 correct classification for the fine grained classes, and .90 for the coarse grained classes, results which are very close to those obtained by (Zhang and Lee, 2003).","On French, we obtain lower results: .769 for fine grained classes, and .84 for coarse grained classes, probably mostly due to the smallest size of the training corpus: (Zhang and Lee, 2003) had a precision of .65 for the fine grained classification with a 1,000 questions training corpus.","When translating test questions from French to English, classification precision decreases, as was expected from (Cumbreras et al., 2006). Yet, when translating the training corpus from English to French and learning the classification model","3","We measured the significance of precision differences (Student t test, p=.05), for each level of the hierarchy between each test, and, unless indicated otherwise, comparable results are significantly different in each condition. Train en fr fr","(trans.) Test en fr fr Method train-","on-","target 50 .822 .798 .807 classes 6 classes .92 .841 .872 Table 2: Question classification precision for both levels of the hierarchy (features = word n-grams with abbreviations, classifier = libsvm) on this translated corpus, precision is close to the French monolingual one for coarse grained classes and a little higher than monolingual for fine grained classification (and close to the English monolingual one): this method gives precisions of .794 for fine grained classes and .828 for coarse grained classes.","One possible explanation is that the condition when test questions are translated is very sensitive to translation errors: if one of the test questions is not correcly translated, the classifier will have a hard time categorizing it. If the training corpus is translated, translation errors can be counterbalanced by correct translations. In the following results, we do not consider the ”en to en (trans)” method since it systematically gives lower results.","As results were lower than our existing rule-based method, we added parts-of-speech as features in order to try to improve them, as well as semantic classes: the classes are lists of words related to a particular category; for example ”president” usually means that a person is expected as an answer. Table 2 shows the classification performance with this additional information.","Classification is slightly improved, but only for coarse grained classes (the difference is not significant for fine grained classes).","When analyzing the results, we noted that most confusion errors were due to the type of features given as inputs: for example, to correctly classify the question ”What is BPH?” as a question expecting an expression corresponding to an abbreviation (ABBR:exp class in the hierarchy), it is necessary to know that ”BPH” is an abbrevia-tion. We thus added a specific feature to detect if a question word is an abbreviation, simply by test-431 Train en fr fr","(trans.) Test en fr fr 50 .804 .837 .828 classes 6 classes .904 .869 .900 Table 3: Question classification precision for both levels of the hierarchy (features = word n-grams with abbreviations, classifier = libsvm) ing if it contains only upper case letters, and normalizing them. Table 3 gives the results with this additional feature (we only kept the method with translation of the training corpus since results were much higher).","Precision is improved for both levels of the hierarchy: for fine grained classes, results increase from .794 to .837, and for coarse grained classes, from .828 to .869. Remaining classification errors are much more disparate."]},{"title":"5 Related work","paragraphs":["Most question answering systems include question classification, which is generally based on supervised learning. (Li and Roth, 2002) trained the SNoW hierarchical classifier for question classification, with a 50 classes fine grained hierarchy, and a coarse grained one of 6 classes. The features used are words, parts-of-speech, chunks, named entities, chunk heads and words related to a class. They obtain 98.8% correct classification of the coarse grained classes, and 95% on the fine grained one. This hierarchy was widely used by other QA systems.","(Zhang and Lee, 2003) studied the classification performance according to the classifier and training dataser size, as well as the contribution of question parse trees. Their results are 87% correct classification on coarse grained classes and 80% on fine grained classes with vectorial attributes, and 90% correct classification on coarse grained classes and 80% on fine grained classes with structured input and tree kerneks.","These question classifications were used for English only. Adapting the methods to other languages requires to annotated large corpora of questions.","In order to classify questions in different languages, (Solorio et al., 2004) proposed an in-ternet based approach to determine the expected type. By combining this information with question words, they obtain 84% correct classification for English, 84% for Spanish and 89% for Italian, with a cross validation on a 450 question corpus for 7 question classes. One of the limitations raised by the authors is the lack of large labeled corpora for all languages.","A possibility to overcome this lack of resources is to use existing English resources. (Cumbreras et al., 2006) developed a QA system for Spanish, based on an English QA system, by translating the questions from Spanish to English. They obtain a 65% precision for Spanish question classification, while English classification are correctly classified with an 80% precision. This method thus leads to an important drop in performance.","Crosslingual QA systems, in which the question is in a different language than the documents, also usually rely on English systems, and translate answers for example (Bos and Nissim, 2006; Bowden et al., 2008)."]},{"title":"6 Conclusion","paragraphs":["This paper presents a comparison between two transfer modes to adapt question classification from English to French. Results show that translating the training corpus gives better results than translating the test corpus.","Part-of-speech information only was used, but since (Zhang and Lee, 2003) showed that best results are obtained with parse trees and tree kernels, it could be interesting to test this additional information; yet, parsing translated questions may prove unreliable.","Finally, as interrogative forms occur rarely is corpora, their translation is usually of a slightly lower quality. A possible future direction for this work could be to use a specific model of translation for questions in order to learn question classification on higher quality translations."]},{"title":"References","paragraphs":["J. Bos and M. Nissim. 2006. Cross-lingual question answering by answer translation. In Working Notes of the Cross Language Evaluation Forum.","M. Bowden, M. Olteanu, P. Suriyentrakorn, T. dŚilva, and D. Moldovan. 2008. Multilingual question answering through intermediate translation: Lccś poweranswer at qa@clef 2007. Advances in Mul-432 tilingual and Multimodal Information Retrieval, 5152:273–283.","Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-SVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27.","M. Á.G. Cumbreras, L. López, and F.M. Santiago. 2006. Bruja: Question classification for spanish. using machine translation and an english classifier. In Proceedings of the Workshop on Multilingual Question Answering, pages 39–44. Association for Computational Linguistics.","Arnaud Grappy, Brigitte Grau, Mathieu-Henri Falco, Anne-Laure Ligozat, Isabelle Robba, and Anne Vilnat. 2011. Selecting answers to questions from web documents by a robust validation process. In IEEE/WIC/ACM International Conference on Web Intelligence.","Bassam Jabaian, Laurent Besacier, and Fabrice Lefèvre. 2011. Combination of stochastic understanding and machine translation systems for language portability of dialogue systems. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pages 5612– 5615. IEEE.","X. Li and D. Roth. 2002. Learning question classifiers. In Proceedings of the 19th international conference on Computational linguistics-Volume 1, pages 1–7. Association for Computational Linguistics.","T. Solorio, M. Pérez-Coutino, et al. 2004. A language independent method for question classification. In Proceedings of the 20th international conference on Computational Linguistics, pages 1374–1380. Association for Computational Linguistics.","D. Zhang and W.S. Lee. 2003. Question classification using support vector machines. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 26–32. ACM. 433"]}],"references":[{"authors":[{"first":"J.","last":"Bos"},{"first":"M.","last":"Nissim"}],"year":"2006","title":"Cross-lingual question answering by answer translation","source":"J. Bos and M. Nissim. 2006. Cross-lingual question answering by answer translation. In Working Notes of the Cross Language Evaluation Forum."},{"authors":[{"first":"M.","last":"Bowden"},{"first":"M.","last":"Olteanu"},{"first":"P.","last":"Suriyentrakorn"},{"first":"T.","last":"dŚilva"},{"first":"D.","last":"Moldovan"}],"year":"2008","title":"Multilingual question answering through intermediate translation: Lccś poweranswer at qa@clef 2007","source":"M. Bowden, M. Olteanu, P. Suriyentrakorn, T. dŚilva, and D. Moldovan. 2008. Multilingual question answering through intermediate translation: Lccś poweranswer at qa@clef 2007. Advances in Mul-432 tilingual and Multimodal Information Retrieval, 5152:273–283."},{"authors":[{"first":"Chih-Chung","last":"Chang"},{"first":"Chih-Jen","last":"Lin"}],"year":"2011","title":"LIB-SVM: A library for support vector machines","source":"Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-SVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27."},{"authors":[{"first":"M.","middle":"Á.G.","last":"Cumbreras"},{"first":"L.","last":"López"},{"first":"F.","middle":"M.","last":"Santiago"}],"year":"2006","title":"Bruja: Question classification for spanish","source":"M. Á.G. Cumbreras, L. López, and F.M. Santiago. 2006. Bruja: Question classification for spanish. using machine translation and an english classifier. In Proceedings of the Workshop on Multilingual Question Answering, pages 39–44. Association for Computational Linguistics."},{"authors":[{"first":"Arnaud","last":"Grappy"},{"first":"Brigitte","last":"Grau"},{"first":"Mathieu-Henri","last":"Falco"},{"first":"Anne-Laure","last":"Ligozat"},{"first":"Isabelle","last":"Robba"},{"first":"Anne","last":"Vilnat"}],"year":"2011","title":"Selecting answers to questions from web documents by a robust validation process","source":"Arnaud Grappy, Brigitte Grau, Mathieu-Henri Falco, Anne-Laure Ligozat, Isabelle Robba, and Anne Vilnat. 2011. Selecting answers to questions from web documents by a robust validation process. In IEEE/WIC/ACM International Conference on Web Intelligence."},{"authors":[{"first":"Bassam","last":"Jabaian"},{"first":"Laurent","last":"Besacier"},{"first":"Fabrice","last":"Lefèvre"}],"year":"2011","title":"Combination of stochastic understanding and machine translation systems for language portability of dialogue systems","source":"Bassam Jabaian, Laurent Besacier, and Fabrice Lefèvre. 2011. Combination of stochastic understanding and machine translation systems for language portability of dialogue systems. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pages 5612– 5615. IEEE."},{"authors":[{"first":"X.","last":"Li"},{"first":"D.","last":"Roth"}],"year":"2002","title":"Learning question classifiers","source":"X. Li and D. Roth. 2002. Learning question classifiers. In Proceedings of the 19th international conference on Computational linguistics-Volume 1, pages 1–7. Association for Computational Linguistics."},{"authors":[{"first":"T.","last":"Solorio"},{"first":"M.","last":"Pérez-Coutino"},{"last":"al"}],"year":"2004","title":"A language independent method for question classification","source":"T. Solorio, M. Pérez-Coutino, et al. 2004. A language independent method for question classification. In Proceedings of the 20th international conference on Computational Linguistics, pages 1374–1380. Association for Computational Linguistics."},{"authors":[{"first":"D.","last":"Zhang"},{"first":"W.","middle":"S.","last":"Lee"}],"year":"2003","title":"Question classification using support vector machines","source":"D. Zhang and W.S. Lee. 2003. Question classification using support vector machines. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 26–32. ACM. 433"}],"cites":[{"style":0,"text":"Grappy et al., 2011","origin":{"pointer":"/sections/2/paragraphs/1","offset":176,"length":19},"authors":[{"last":"Grappy"},{"last":"al."}],"year":"2011","references":["/references/4"]},{"style":0,"text":"Li and Roth, 2002","origin":{"pointer":"/sections/2/paragraphs/1","offset":471,"length":17},"authors":[{"last":"Li"},{"last":"Roth"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Jabaian et al., 2011","origin":{"pointer":"/sections/2/paragraphs/2","offset":365,"length":20},"authors":[{"last":"Jabaian"},{"last":"al."}],"year":"2011","references":["/references/5"]},{"style":0,"text":"Lee, 2003","origin":{"pointer":"/sections/3/paragraphs/3","offset":314,"length":9},"authors":[{"last":"Lee"}],"year":"2003","references":[]},{"style":0,"text":"Jabaian et al., 2011","origin":{"pointer":"/sections/4/paragraphs/0","offset":70,"length":20},"authors":[{"last":"Jabaian"},{"last":"al."}],"year":"2011","references":["/references/5"]},{"style":0,"text":"Li and Roth, 2002","origin":{"pointer":"/sections/4/paragraphs/3","offset":380,"length":17},"authors":[{"last":"Li"},{"last":"Roth"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Li and Roth, 2002","origin":{"pointer":"/sections/5/paragraphs/0","offset":43,"length":17},"authors":[{"last":"Li"},{"last":"Roth"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/5/paragraphs/0","offset":125,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Li and Roth, 2002","origin":{"pointer":"/sections/5/paragraphs/0","offset":390,"length":17},"authors":[{"last":"Li"},{"last":"Roth"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Chang and Lin, 2011","origin":{"pointer":"/sections/5/paragraphs/13","offset":251,"length":19},"authors":[{"last":"Chang"},{"last":"Lin"}],"year":"2011","references":["/references/2"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/5/paragraphs/13","offset":359,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/5/paragraphs/17","offset":212,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/5/paragraphs/18","offset":169,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Cumbreras et al., 2006","origin":{"pointer":"/sections/5/paragraphs/19","offset":114,"length":22},"authors":[{"last":"Cumbreras"},{"last":"al."}],"year":"2006","references":["/references/3"]},{"style":0,"text":"Li and Roth, 2002","origin":{"pointer":"/sections/6/paragraphs/0","offset":115,"length":17},"authors":[{"last":"Li"},{"last":"Roth"}],"year":"2002","references":["/references/6"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/6/paragraphs/1","offset":1,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]},{"style":0,"text":"Solorio et al., 2004","origin":{"pointer":"/sections/6/paragraphs/3","offset":56,"length":20},"authors":[{"last":"Solorio"},{"last":"al."}],"year":"2004","references":["/references/7"]},{"style":0,"text":"Cumbreras et al., 2006","origin":{"pointer":"/sections/6/paragraphs/4","offset":88,"length":22},"authors":[{"last":"Cumbreras"},{"last":"al."}],"year":"2006","references":["/references/3"]},{"style":0,"text":"Bos and Nissim, 2006","origin":{"pointer":"/sections/6/paragraphs/5","offset":167,"length":20},"authors":[{"last":"Bos"},{"last":"Nissim"}],"year":"2006","references":["/references/0"]},{"style":0,"text":"Bowden et al., 2008","origin":{"pointer":"/sections/6/paragraphs/5","offset":189,"length":19},"authors":[{"last":"Bowden"},{"last":"al."}],"year":"2008","references":["/references/1"]},{"style":0,"text":"Zhang and Lee, 2003","origin":{"pointer":"/sections/7/paragraphs/1","offset":53,"length":19},"authors":[{"last":"Zhang"},{"last":"Lee"}],"year":"2003","references":["/references/8"]}]}
