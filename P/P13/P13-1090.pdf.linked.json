{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 914–923, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Semi-Supervised Semantic Tagging of Conversational Understanding using Markov Topic Regression Asli Celikyilmaz Microsoft Mountain View, CA, USA asli@ieee.org Dilek Hakkani-Tur, Gokhan Tur Microsoft Research Mountain View, CA, USA dilek@ieee.org gokhan.tur@ieee.org Ruhi Sarikaya Microsoft Redmond, WA, USA rusarika@microsoft.com Abstract","paragraphs":["Finding concepts in natural language utterances is a challenging task, especially given the scarcity of labeled data for learning semantic ambiguity. Furthermore, data mismatch issues, which arise when the expected test (target) data does not exactly match the training data, aggravate this scarcity problem. To deal with these issues, we describe an efficient semi-supervised learning (SSL) approach which has two components: (i) Markov Topic Regression is a new probabilistic model to cluster words into semantic tags (concepts). It can efficiently handle semantic ambiguity by extending standard topic models with two new features. First, it encodes word n-gram features from labeled source and unlabeled target data. Second, by going beyond a bag-of-words approach, it takes into account the inherent sequential nature of utterances to learn semantic classes based on context. (ii) Retrospective Learner is a new learning technique that adapts to the unlabeled target data. Our new SSL approach improves semantic tagging performance by 3% absolute over the baseline models, and also compares favorably on semi-supervised syntactic tagging."]},{"title":"1 Introduction","paragraphs":["Semantic tagging is used in natural language understanding (NLU) to recognize words of semantic importance in an utterance, such as entities. Typically, a semantic tagging model require large amount of domain specific data to achieve good performance (Tur and DeMori, 2011). This requires a tedious and time intensive data collection and labeling process. In the absence of large labeled training data, the tagging model can behave poorly on test data (target domain). This is usually caused by data mismatch issues and lack of coverage that arise when the target data does not match the training data.","To deal with these issues, we present a new semi-supervised learning (SSL) approach, which mainly has two components. It initially starts with training supervised Conditional Random Fields (CRF) (Lafferty et al., 2001) on the source training data which has been semantically tagged. Using the trained model, it decodes unlabeled dataset from the target domain. With the data mismatch issues in mind, to correct errors that the supervised model make on the target data, the SSL model leverages the additional information by way of a new clustering method. Our first contribution is a new probabilistic topic model, Markov Topic Regression (MTR), which uses rich features to capture the degree of association between words and semantic tags. First, it encodes the n-gram context features from the labeled source data and the unlabeled target data as prior information to learn semantic classes based on context. Thus, each latent semantic class corresponds to one of the semantic tags found in labeled data. MTR is not invariant to reshuffling of words due to its Markovian property; hence, word-topic assignments are also affected by the topics of the surrounding words. Because of these properties, MTR is less sensitive to the errors caused by the semantic ambiguities. Our SSL uses MTR to smooth the semantic tag posteriors on the unlabeled target data (decoded using the CRF model) and later obtains the best tag sequences. Using the labeled source and automati-914 cally labeled target data, it re-trains a new CRF-model.","Although our iterative SSL learning model can deal with the training and test data mismatch, it neglects the performance effects caused by adapting the source domain to the target domain. In fact, most SSL methods used for adaptation, e.g., (Zhu, 2005), (Daumé-III, 2010), (Subramanya et al., 2010), etc., do not emphasize this issue. With this in mind, we introduce a new iterative training algorithm, Retrospective Learning, as our second contribution. While retrospective learning iteratively trains CRF models with the automatically annotated target data (explained above), it keeps track of the errors of the previous iterations so as to carry the properties of both the source and target domains.","In short, through a series of experiments we show how MTR clustering provides additional information to SSL on the target domain utterances, and greatly impacts semantic tagging performance. Specifically, we analyze MTR’s performance on two different types of semantic tags: named-entities and descriptive tags as shown in Table 1. Our experiments show that it is much harder to detect descriptive tags compared to named-entities.","Our SSL approach uses probabilistic clustering method tailored for tagging natural language utterances. To the best of our knowledge, our work is the first to explore the unlabeled data to iteratively adapt the semantic tagging models for target domains, preserving information from the previous iterations. With the hope of spurring related work in domains such as entity detection, syntactic tagging, etc., we extend the earlier work on SSL part-of-speech (POS) tagging and show in the experiments that our approach is not only useful for semantic tagging but also syntactic tagging.","The remainder of this paper is divided as follows: §2 gives background on SSL and semantic clustering methods, §3 describes our new clustering approach, §4 presents the new iterative learning, §5 presents our experimental results and §6 concludes our paper."]},{"title":"2 Related Work and Motivation (I) Semi-Supervised Tagging.","paragraphs":["Supervised methods for semantic tagging in NLU require a large number of in-domain human-labeled utterances and gazetteers (movie, actor names, etc.), increas- • Are there any [comedies] with [Ryan Gosling]? • How about [oscar winning] movies by [James Cameron]? • Find [Woody Allen] movies similar to [Manhattan]. [Named Entities] director: James Cameron, Woody Allen,... actor: Ryan Gosling, Woody Allen,... title: Manhattan, Midnight in Paris,... [Descriptive Tags] restriction: similar, suitable, free,rate,... description: oscar winning, new release, gardening,... genre: spooky, comedies, feel good, romance,... Table 1: Samples of semantically tagged utterances from movie domain, named-entities and descriptive tags. ing the need for significant manual labor (Tur and DeMori, 2011). Recent work on similar tasks overcome these challenges using SSL methods as follows:","• (Wang et al., 2009; Li et al., 2009; Li, 2010; Liu et al., 2011) investigate web query tagging using semi-supervised sequence models. They extract semantic lexicons from unlabeled web queries, to use as features. Our work differs from these, in that, rather than just detecting named-entities, our utterances include descriptive tags (see Table 1).","• Typically the source domain has different distribution than the target domain, due to topic shifts in time, newly introduced features (e.g., until recently online articles did not include facebook ”like” feature.), etc. Adapting the source domain using unlabeled data is the key to achieving good performance across domains. Recent adaptation methods for SSL use: expectation minimization (Daumé-III, 2010) graph-based learning (Chapelle et al., 2006; Zhu, 2005), etc. In (Subramanya et al., 2010) an efficient iterative SSL method is described for syntactic tagging, using graph-based learning to smooth POS tag posteriors. However, (Reisinger and Mooney, 2011) argues that vector space models, such as graph-learning, may fail to capture the richness of word meaning, as similarity is not a globally consistent metric. Rather than graph-learning, we present a new SSL using a probabilistic model, MTR, to cluster words based on co-occurrence statistics.","• Most iterative SSL methods, do not keep track of the errors made, nor consider the divergence from the original model. (Lavoie et al., 2011) argues that iterative learning models should mitigate new errors made by the model at each iteration by 915 keeping the history of the prior predictions. This ensures that a penalty is paid for diverging from the previous model’s predictions, which will be traded off against the benefit of reducing classification loss. We present a retrospective SSL for CRF, in that, the iterative learner keeps track of the errors of the previous iterations so as to carry the properties of both the source and target domains.","(II) Semantic Clustering. A common property of several context-based word clustering techniques, e.g., Brown clustering (Brown et al., 1992), Clustering by Committee (Pantel, 2003), etc., is that they mainly cluster based on local context such as nearby words. Standard topic models, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), use a bag-of-words approach, which disregards word order and clusters words together that appear in a similar global context. Such models have been effective in discovering lexicons in many NLP tasks, e.g., named-entity recognition (Guo et al., 2009), word-sense disambiguation (Boyd-Graber et al., 2007; Li et al., 2010), syntactic/semantic parsing (Griffiths et al., 2005; Singh et al., 2010), speaker identification (Nyugen et al., 2012), etc. Recent topic models consider word sequence information in documents (Griffiths et al., 2005; Moon et al., 2010). The Hidden Topic Markov Model (HTMM) by (Gruber et al., 2005), for instance, models sentences in documents as Markov chains, assuming all words in a sentence have the same topic. While MTR has a similar Markovian property, we encode features on words to allow each word in an utterance to sample from any of the given semantic tags, as in ”what are [scary]genre movies by [Hitchcock]director?”.","In LDA, common words tend to dominate all topics causing related words to end up in different topics. In (Petterson et al., 2010), the vector-based features of words are used as prior information in LDA so that the words that are synonyms end up in same topic. Thus, we build a semantically rich topic model, MTR, using word context features as side information. Using a smoothing prior for each word-topic pair (instead of a constant β smoother), MTR assures that the words are distributed over topics based on how similar they are. (e.g., ”scary” and ”spooky”, which have similar context features, go into the same semantic tag, ”genre”). Thus, to best of our knowledge, MTR is the first topic model to incorporate word features while considering the sequence of words."]},{"title":"3 Markov Topic Regression - MTR 3.1 Model and Abstractions","paragraphs":["LDA assumes that the latent topics of documents are sampled independently from one of K topics. MTR breaks down this independence assumption by allowing Markov relations between the hidden tags to capture the relations between consecutive words (as sketched in Figure 1 and Algorithm 1).","(I) Semantic Tags (si): Each word wi of a given utterance with Nj words, uj={wi}","Nj","i=1∈U , j=1,..|U |, from a set of utterances U , is associated with a latent semantic tag (state) variable si∈S, where S is the set of semantic tags. We assume a fixed K topics corresponding to semantic tags of labeled data. In a similar way to HTMM (Gruber et al., 2005) described for documents, MTR samples each si from a Markov chain that is specific to its utterance uj. Each state si generates a word, wi, based on the word-state co-occurrences. MTR allows for sampling of consecutive words from different tag clusters. The initial probabilities of the latent states are sampled from a Dirichlet distribution over state variables, θj, with α hyper-parameter for each uj.","(II) Tag Transition Indicator (ψv): Given utterance uj, the decision to sample a wi from a new topic is determined by an indicator variable, cj,i, that is sampled from a Binomial(ψv=wi) distribution with a Beta conjugate prior. (There are v binomials for each vocabulary term.) cj,i=1 suggests that a new state be sampled from K possible tags for the word wi in uj, and cj,i=0 suggests that the state si of wi should be the same as the previous word’s latent state si−1. The first position of the sequence is sampled from a new state, hence cj,i=1=1.","(III) Tag Transition Base Measure (η): Prior probability of a word given a tag should increase the chances of sampling words from the correct semantic tag. MTR constrains the generation of a tag si given the previous tag si−1 and the current wi based on cj,i by using a vocabulary specific Beta prior, ψv∼Beta(ηv) 1",", on each word in vocabulary wv=1,..V . We inject the prior information on semantic tags to define values of the base measure ηv using external knowledge from two sources: (a) Entity Priors (ηS): Prior probability on named-entities and descriptive tags denoted as 1 For each beta distribution we use symmetric","Beta(ηv)=Beta(α=ηv,β=ηv). 916","latent semantic tag distribution over semantic tags s1"]},{"title":"...","paragraphs":["w1"]},{"title":"...","paragraphs":["!j \" c2 c3 # $kv %kv xv &k s2 s3 w2 w3 wn ' V K |U| V indicator for sampling semantic tags vocabulary features","as prior information","semantic tag","dependent","smoothing coefficient semantic tag indicator parameter prior on per-word state transitions $k ! Dir(%kv|x;&k) !k = exp(f(x;&k)) semantic tag distribution over tags smoother for tag-word pair cNj sNj Figure 1: The graph representation of the Markov Topic Regression (MTR). To demonstrate hidden state Markov Chain, the generation of each word is explicitly shown (inside of the plate). ηS=p(si|si−1,wi=v,wi−1). We use web sources (wiki pages on movies and urls such as imdb.com) and labeled training data to extract entity lists that correspond to the semantic tags of our domains. We keep the frequency of each n-gram to convert into (empirical) prior probability distribution. (b) Language Model Prior (ηW ): Probabilities on word transitions denoted as ηW =p(wi=v|wi−1). We built a language model using SRILM (Stolcke, 2002) on the domain specific sources such as top wiki pages and blogs on online movie reviews, etc., to obtain the probabilities of domain-specific n-grams, up to 3-grams. The observed priors, ηS and ηW , are used for calculating the base measure η for each vocabulary wv as: η si|si−1 v = { η si|si−1,wi=v S , if η si|si−1,wi=v S exists, η wi=v,wi−1 W , otherwise","(1) In Eq.(1), we assume that the prior on the semantic tags, ηS, is more indicative of the decision for sampling a wi from a new tag compared to language model posteriors on word sequences, ηW . Here we represent the base-measure (hyper-parameter) of the semantic tag indicator variable, which is not to be confused with a probability measure 2","We update the indicator parameter via mean criteria, ψv=wi=","∑K i,j=1η si|sj v=wi/(K2","). If no prior on","2","The base-measure used in Eq.(1) does not relate to a back-off model in LM sense. Here, instead of using a constant value for the hyper-parameters, we use probability scores that we obtain from LM. Algorithm 1 Markov Topic Regression 1: for each semantic tag topic sk, k ← 1, ..., K do 2: − draw a topic mixture φk ∼ Dir(βk|λk, x), 3: − let βk=exp(f(x;λk)); x={xv}V","l","v=1, βk∈ RV","l 4: for each word wv in vocabulary v ← 1, ..., V do 5: − draw a tag indicator mixture ψv ∼ Beta(η), 6: for each utterance j ← 1, ..., |U| do 7: −draw transition distribution θs","j ∼ Dir(α) 8: over states si and set cj1=1. 9: −for words wi in uj, i ← 1, ..., Nj do 10: ⋄ if i >1, toss a coin cj,i ∼ Binomial(ψw","i). 11: ⋄ If cj,i=1, draw si∼Multi(θ s i,s","i−1 j )† 12: otherwise si=si−1. 13: ⋄ Sample wi∼Multi(φs","i). † Markov assumption over utterance words is used (See Eq.(4)). a specific word exists, a default value is used for base measure, ηv=0.01.","(IV) Topic-Word Distribution Priors (βk): Different from (Mimno et al., 2008), which uses asymmetric hyper-parameters on document-topic distributions, in MTR, we learn the asymmetric hyper-parameters of the semantic tag-word distributions. We use blocked Gibbs sampling, in which the topic assignments sk and hyper-parameters {βk}K","k=1 are alternately sampled at each Gibbs sampling lag period g given all other variables. We impose the prior knowledge on naturally related words, such that if two words ”funny” and ”hilarious” indicate the same given ”genre” class, then their latent tag distributions should also be similar. We enforce this on smoothing parameter βk,v, e.g., βk,′","funny′∼βk,′","hilarious′ for a given tag k as follows:","At each g lag period of the Gibbs sampling, K log-linear models with parameters, λ(g)","k ∈RM",", is trained to predict β (g) kv ∈βk, for each wv of a tag sk: β","(g)","k = exp(f (xl","; λ(g)","k )) (2) where the log-linear function f is: n (g) kv = f (xl","v; λ (g) k ) = ∑ m λ(g) k,mxl","v,m (3) Here x∈RV ×M","is the input matrix x, wherein rows xv∈RM","represents M -dimensional scalar vector of explanatory features on vocabulary words. We use the word-tag posterior probabilities obtained from a CRF sequence model trained on labeled utterances as features. The x={xl",",xu","} has labeled (l) and unlabeled (u) parts. The labeled part contains Vl size vocabulary of which we know the semantic tags, xl","={(xl","1,s1),...,(xl","Vl,sVl)}. At the start of the Gibbs sampling, we designate the 917 K latent topics to the K semantic tags of our labeled data. Therefore, we assign labeled words to their designated topics. This way we use observed scalar counts of each labeled word v associated with its semantic tag k, n (g) kv , as the output label of its input vector, xl","v; an indication of likelihood of words getting sampled from the corresponding semantic label sk. Since the impact of the asymmetric prior is equivalent to adding pseudo-counts to the sufficient statistics of the semantic tag to which the word belongs, we predict the pseudo-counts β (g) kv using the scalar counts of the labeled data, n (g) kv , based on the log-linear model","in Eq. (2). At g=0, we use β (0) kv =28",", if x","v∈Xl ; otherwise β (0) kv =2−2",", commonly used values for large","and small β. Note that larger β-values indicate","correlation between the word and the topic. 3.2 Collapsed Sampler The goal of MTR is to infer the degree of relationship between a word v and each semantic tag k, φkv. To perform inference we need two components:","• a sampler which can draw from conditional PMTR(sji=k|sji−1, s\\ji, α, ψi, βji), when cj,i=1, where sji and sji−1 are the semantic tags of the current wi=v of vocabulary v and previous word wi−1 in utterance uj, and s\\ji are the semantic tag topics of all words except for wi; and,","• an estimation procedure for (βkv, λk) (see §3.1). We integrate out the multinomial and binomial parameters of the model: utterance-tag distributions θj, binomial state transition indicator distribution per each word ψv, and φk for tag-word distributions. We use collapsed Gibbs sampling to reduce random components and model the posterior distribution by obtaining samples (sji, cj,i) drawn from this distribution. Under the Markov assumption, for each word wi=v in a given utterance uj, if cj,i=1, we sample a new tag si=k given the remaining tags and hyper-parameters βk, α, and η si|si−1 wi=v . Using the following parameters; n","(si)","ji ,","which is the number of words assigned to a seman-","tic class si=k excluding case i, and n","(si−1)","si is the","number of transitions from class si−1 to si, where","indicator I(si−1, si)=1 if slot si=si−1, the update equation is formulated as follows: p(sji = k|w, s−ji, α, η si|si−1 wi , βk) ∝ n (si) ji + βkwi n (k) (.) +","∑ v βkv ∗ (n (si−1) si + α)∗ (n (si) si+1 + I(si−1, si) + I(si+1, si) + α) n (si) (.) + I(si−1, k) + Kα (4)"]},{"title":"4 Semi-Supervised Semantic Labeling 4.1 Semi Supervised Learning (SSL) with CRF","paragraphs":["In (Subramanya et al., 2010), a new SSL method is described for adapting syntactic POS tagging of sentences in newswire articles along with search queries to a target domain of natural language (NL) questions. They decode unlabeled queries from target domain (t) using a CRF model trained on the POS-labeled newswire data (source domain (o)). The unlabeled POS tag posteriors are then smoothed using a graph-based learning algorithm. On graph, the similarities are defined over sequences by constructing the graph over types, word 3-grams, where types capture the local context of words. Since CRF tagger only uses local features of the input to score tag pairs, they try to capture all the context with the graph with additional context features on types. Later, using viterbi decoding, they select the 1-best POS tag sequence, s∗","j for each utterance uj. Graph-based SSL defines a new CRF objective function:","Λ(t)","n+1 =argmin","Λ∈RK","{ − ∑ j=1:l","log p(sj|uj; Λ(t) n ) + μ∥Λ(t)","n ∥2 } − { τ","∑l+u","j=l log pn(s∗","j |uj; Λ(t)","n )} (5) The first bracket in Eq.(5) is the loss on the labeled data and L2 regularization on parameters, Λ(t) n , from nth iteration, same as standard CRF. The last term is the loss on unlabeled data from target domain with a hyper-parameter τ . They use a small value for τ to enable the new model to be as close as possible to the initial model trained on source data. 4.2 Retrospective Semi-Supervised CRF We describe a Retrospective SSL (R-SSL) training with CRF (Algorithm 2), using MTR as a 918 smoothing model, instead of a graph-based model, as follows:","I. DECODING and SMOOTHING. The posterior probability of a tag sji=k given a word wji in unlabeled utterance uj from target domain (t) p̂n(j, i)=p̂n(sji=k|wji; Λ(t)","n ), is decoded using the n-th iteration CRF model. MTR uses the decoded probabilities as semantic tag prior features on vocabulary items. We generate a word-tag matrix of posteriors, x∈(0, 1)V ×K",", where K is the number of semantic tags and V is the vocabulary size from n-th iteration. Each row is a K dimensional vector of tag posterior probabilities xv={xv1,. . . xvK } on the vocabulary term, wv. The labeled rows xl","of the vocabulary matrix, x={xl",",xu","}, contain only {0,1} values, indicating the word’s observed semantic tags in the labeled data. Since a labeled term wv can have different tags (e.g., ”clint eastwood” may be tagged as actor-name and directorname in the training data),","∑K","k xvk≥1 holds. The x is used as the input matrix of the kth log-linear model (corresponding to kth semantic tag (topic)) to infer the β hyper-parameter of MTR in Eq. (2). MTR generates smoothed conditional probabilities φkv for each vocabulary term v given semantic tag k.","II. INTERPOLATION. For each word wji=v in unlabeled utterance uj, we interpolate tag marginals from CRF and MTR for each semantic tag sji = k:","q̂n(sji|wij; Λ(t) n ) = π CRF posterior { }} { p̂n(sji|wij; Λ(t)","n ) +(1 − π) MTR {}}{ φkv (6) III. VITERBI. Using viterbi decoding over","the tag marginals, q̂n(sji|wij; Λ(t)","n ), and transition","probabilities obtained from the CRF model of n-th","iteration, we get p̂n(s∗","j |uj; Λ(t)","n ), the 1-best decode s∗ j of each unlabeled utterance uj∈U u","n .","IV. RETROSPECTIVE SSL (R-SSL). After we decode the unlabeled data, we re-train a new CRF model at each iteration. Each iteration makes predictions on the semantic tags of unlabeled data with varying posterior probabilities. Motivated by (Lavoie et al., 2011), we want the loss function to have a dependency on the prior model predictions. Thus, R-SSL encodes the history of the prior pre-","Algorithm 2 Retrospective Semi-Supervised CRF Input: Labeled U l",", and unlabeled U u","data. Process: Λ (o) n =crf-train(Ul) at n=0, n=n+1 †",".","While not converged","p̂=posterior-decode(U u","n ,Λ(o)","n )","φ=smooth-posteriors(p̂) using MTR,","q̂=interpolate-posteriors(p̂,φ),","U u","n =viterbi-decode(q̂)","Λ(t)","n+1=crf-retrospective(U l",", U u","n ,. . . ,U u","1 ,Λ(t)","n ) † (n):iteration, (t):target, (o):source domains. dictions, as follows: Λ","(t)","n+1 =argmin","Λ∈RK","{ − ∑ j=1:l","log p(sj|uj; Λ(t) n ) + μ∥Λ (t) n ∥2 } { − ∑ j=1:(l+u)","max{0, p̂∗∗ n } } (7) where, p̂∗∗","n =1 − log hn(uj)p̂n(s∗","j |uj; Λ(t)","n ). The first two terms are same as standard CRF. The last term ensures that the predictions of the current model have the same sign as the predictions of the previous models (using labeled and unlabeled data), denoted by a maximum margin hinge weight, hn(uj)= 1","n−1","∑n−1","1 p̂n(s∗","j |uj; Λ(t)","n ). It should also be noted that with MTR, the R-SSL learns the word-tag relations by using features that describe the words in context, eliminating the need for additional type representation of graph-based model. MTR provides a separate probability distribution θj over tags for each utterance j, implicitly allowing for the same word v in separate utterances to differ in tag posteriors φkv."]},{"title":"5 Experiments 5.1 Datasets and Tagsets 5.1.1 Semantic Tagging Datasets","paragraphs":["We focus here on audiovisual media in the movie domain. The user is expected to interact by voice with a system than can perform a variety of tasks such as browsing, searching, querying information, etc. To build initial NLU models for such a dialog system, we used crowd-sourcing to collect and annotate utterances, which we consider our source domain. Given movie domain-specific tasks, we asked the crowd about how they would 919 interact with the media system as if they were talk-ing to a person.","Our data from target domain is internally collected from real-use scenarios of our spoken dialog system. The transcribed text forms of these utterances are obtained from speech recognition engine. Although the crowd-sourced data is similar to target domain, in terms of pre-defined user in-tentions, the target domain contains more descriptive vocabulary, which is almost twice as large as the source domain. This causes data-mismatch issues and hence provides a perfect test-bed for a domain adaptation task. In total, our corpus has a 40K semantically tagged utterances from each source and target domains. There are around 15 named-entity and 10 descriptive tags. We separated 5K utterances to test the performance of the semantic tagging models. The most frequent entities are: movie-director (’James Cameron’), movie-title (’Die Hard’), etc.; whereas top descriptive tags are: genre (’feel good’), description (’black and white’, ’pg 13’), review-rate (’epic’, ’not for me’), theater-location (’near me’,’city center’), etc.","Unlabeled utterances similar to the movie domain are pulled from a month old web query logs and extracted over 2 million search queries from well-known sites, e.g., IMDB, Netflix, etc. We filtered queries that are similar to our target set that start with wh-phrases (’what’, ’who’, etc.) as well as imperatives ’show’, ’list’, etc. In addition, we extracted web n-grams and entity lists (see §3) from movie related web sites, and online blogs and reviews. We collected around 300K movie review and blog entries on the entities observed in our data. We extract prior distributions for entities and n-grams to calculate entity list η and word-tag β priors (see §3.1). 5.1.2 Syntactic Tagging Datasets We use the Wall Street Journal (WSJ) section of the Penn Treebank as our labeled source data. Following previous research, we train on sections 00-18, comprised of 38,219 POS-tagged sentences. To evaluate the domain adaptation (DA) approach and to compare with results reported by (Subramanya et al., 2010), we use the first and second half of QuestionBank (Judge et al., 2006) as our development and test sets (target). The QuestionBank contains 4000 POS-tagged questions, how-ever it is difficult to tag with WSJ-trained tag-gers because the word order is different than WSJ and contains a test-set vocabulary that is twice as large as the one in the development set. As for unlabeled data we crawled the web and collected around 100,000 questions that are similar in style and length to the ones in QuestionBank, e.g. ”wh” questions. There are 36 different tag sets in the Penn dataset which includes tag labels for verbs, nouns, adjectives, adverbs, modal, determiners, prepositions, etc. More information about the Penn Tree-bank tag set can be found here (Marcus et al., 1993). 5.2 Models We evaluated several baseline models on two tasks: 5.2.1 Semantic Clustering Since MTR provides a mixture of properties adapted from earlier models, we present performance benchmarks on tag clustering using: (i) LDA; (ii) Hidden Markov Topic Model HMTM (Gruber et al., 2005); and, (iii) w-LDA (Petterson et al., 2010) that uses word features as priors in LDA. When a uniform β hyper-parameter is used with no external information on the state transitions in MTR, it reduces to a HMTM model. Similarly, if no Markov properties are used (bag-of-words), MTR reduces to w-LDA. Each topic model uses Gibbs sampling for inference and parameter learning. We sample models for 1000 iterations, with a 500-iteration burn-in and a sampling lag of 10. For testing we iterated the Gibbs sampler using the trained model for 10 iterations on the testing data. 5.2.2 SSL for Semantic/Syntactic Tagging We evaluated three different baselines against our SSL models: ⋆ CRF: a standard supervised sequence tagging. ⋆ Self-CRF: a wrapper method for SSL using self-training. First a supervised learning algorithm is used to build a CRF model based on the labeled data. A CRF model is used to decode the unlabeled data to generate more labeled examples for re-training. ⋆ SSL-Graph: A SSL model presented in (Subramanya et al., 2010) that uses graph-based learning as posterior tag smoother for CRF model using Eq.(5).","In addition to the three baseline, we evaluated three variations of our SSL method: ⋆ SSL-MTR: Our first version of SSL uses MTR to 920 LDA w-LDA HMTM MTR 0.6 0.7 0.8 0.9 82% 77% 84% 82%","79%78%","74% • Descriptive Tags ♦ Named-Entities ■ All Tags F-Measure Figure 2: F-measure for semantic clustering performance. Performance differences for three different baseline models and our MTR approach by different semantic tags. smooth the semantic tag posteriors of a unlabeled data decoded by the CRF model using Eq.(5). ⋆ R-SSL-Graph: Our second version uses graph-learning to smooth the tag posteriors and re-train a new CRF model using retrospective SSL in Eq.(7). ⋆ R-SSL-MTR: Our full model uses MTR as a Bayesian smoothing model, and retrospective SSL in Eq.(7) for iterative CRF training.","For all the CRF models, we use lexical features consisting of unigrams in a five-word window around the current word. To include contextual information, we add binary features for all possible tags. We inject dictionary constraints to all CRF models, such as features indicating label prior information. For each model we use several named entity features, e.g., movie-title, actor-name, etc., non-named entity (descriptive) features, e.g., movie-description, movie-genre, and domain independent dictionaries, e.g, time, location, etc. For graph-based learning, we implemented the algorithm presented in (Subramanya et al., 2010) and used the same hyper-parameters and features. For the rest of the hyper-parameters, we used: α=0.01 for MTR, π=0.5 for interpolation mixing. These parameters were chosen based on the performance of the development set. All CRF objective functions were optimized using Stochas-tic Gradient Descent. 5.3 Results and Discussions","5.3.1 Experiment 1: Clustering Semantic Tags. Here, we want to demonstrate the performance of MTR model for capturing relationships between words and semantic tags against baseline topic models: LDA, HMTM, w-LDA. We take the semantically labeled utterances from the movie target domain and use the first half for training and the rest for performance testing. We use all the collected unlabeled web queries from the movie domain. For fair comparison, each benchmark topic model is provided with prior information on word-semantic tag distributions based on the labeled training data, hence, each K latent topic is assigned to one of K semantic tags at the beginning of Gibbs sampling.","We evaluate the performance separately on descriptive tags, named-entities, and all tags together. The performance of the four topic models are reported in Figure 2. LDA shows the worst performance, even though some supervision is provided by way of labeled semantic tags. Although w-LDA improves semantic clustering performance over LDA, the fact that it does not have Markov properties makes it fall short behind MTR. As for the effect of word features in MTR, we see a 3% absolute performance gain over the second best performing HMTM baseline on named-entity tags, a 1% absolute gain on descriptive tags and a 2% absolute overall gain. As expected, we see a drop in F-measure on all models on descriptive tags.","5.3.2 Experiment 2: Domain Adaptation Task. We compare the performance of our SSL model to that of state-of-the-art models on semantic and syntactic tagging. Each SSL model is built using labeled training data from the source domain and unlabeled training data from target domain. In Table 2 we show the results on Movie and QuestionBank target test datasets. The results of SSL-Graph on QuestionBank is taken from (Subramanya et al., 2010). The self-training model, Self-CRF adds 3% improvement over supervised CRF models on movie domain, but does not improve syntactic tagging. Because it is always inherently biased towards the source domain, self-training tends to reinforce the knowledge that the supervised model already has. SSL-Graph works much better for both syntactic and semantic tagging compared to CRF and Self-CRF models. Our Bayesian MTR efficiently extracts information from the unlabeled data for the target domain. Combined with retrospective training, R-SSL-MTR demonstrates no-ticeable improvements, ∼2% on descriptive tags, and 1% absolute gains in overall semantic tag-921 ging performance over SSL-Graph. On syntactic tagging, the two retrospective learning models is comparable, close to 1% improvement over the SSL-Graph and SSL-MTR.","Movie Domain QBank Model Desc. NE All POS CRF 75.05 75.84 75.84 83.80 Self-CRF 78.96 79.53 79.19 84.00 SSL-Graph 80.27 81.35 81.23 86.80 SSL-MTR 79.87 79.31 79.19 86.30 R-SSL-Graph 80.58 81.95 81.52 87.12 R-SSL-MTR 82.76 82.27 82.24 87.34 Table 2: Domain Adaptation performance in F-measure on Semantic Tagging on Movie Target domain and POS tagging on QBank:QuestionBank. Best performing models are bolded.","5.3.3 Experiment 3: Analysis of Semantic Disambiguation. Here we focus on the accuracy of our models in tagging semantically ambiguous words. We investigate words that have more than one observed semantic tag in training data, such as ”are there any [war]genre movies available.”, ”remove all movies about [war]description.”). Our corpus contained 30,000 unique vocabulary, 55% of which are contained in one or more semantic categories. Only 6.5% of those are tagged as multiple categories (polysemous), which are the sources of semantic ambiguity. Table-3 shows the precision of two best models for most confused words.","We compare our two best SSL models with different smoothing regularizes: R-SSL-MTR (MTR) and R-SSL-Graph (GRAPH). We use precision and recall criterion on semantically confused words.","In Table 3 we show two most frequent descriptive tags; genre and description, and commonly misclassified words by the two models. Results indicate that the R-SSL-MTR, performs better than the R-SSL-Graph, in activating the correct meaning of a word. The results indicate that incorporating context information with MTR is an effective option for identifying semantic ambiguity."]},{"title":"6 Conclusions","paragraphs":["We have presented a novel semi supervised learning approach using a probabilistic clustering","genre description Vocab. GRAPH MTR GRAPH MTR war 50% 100% 75% 88% popular 90% 89% 80% 100% kids 78% 86% − 100% crime 49% 80% 86% 67% zombie 67% 89% 67% 86% Table 3: Classification performance in F-measure for semantically ambiguous words on the most frequently confused descriptive tags in the movie domain. method to semantically tag spoken language utterances. Our results show that encoding priors on words and context information contributes significantly to the performance of semantic clustering. We have also described an efficient iterative learning model that can handle data inconsistencies that leads to performance increases in semantic and syntactic tagging.","As a future work, we will investigate using ses-sion data, namely the entire dialog between the human and the computer. Rather than using single turn utterances, we hope to utilize the context information, e.g., information from previous turns for improving the performance of the semantic tagging of the current turns."]},{"title":"References","paragraphs":["D. Blei, A. Ng, and M. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research.","J. Boyd-Graber, D. Blei, and X. Zhu. 2007. A topic model for word sense disambiguation. Proc. EMNLP.","P.F. Brown, V.J.D. Pietra, P.V. deSouza, and J.C. Lai. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479.","O. Chapelle, B. Schlkopf, and Alexander Zien. 2006. Semi-supervised learning. MIT Press.","H. Daumé-III. 2010. Frustratingly easy semi-supervised domain adaptation. Proc. Workshop on Domain Adaptation for Natural Language Process-ing at ACL.","T.L Griffiths, M. Steyvers, D.M. Blei, and J.M. Tenenbaum. 2005. Integrating topics and syntax. Proc. of NIPS.","A. Gruber, M. Rosen-Zvi, and Y. Weiss. 2005. Hidden topic markov models. Proc. of ICML.","H. Guo, H. Zhu, Z. Guo, X. Zhang, X. Wu, and Z. Su. 2009. Domain adaptation with latent semantic association for named entity recognition. Proc. NAACL. 922","J. Judge, A. Cahill, and J.Van Genabith. 2006. Question-bank: Creating corpus of parse-annotated questions. Proc. Int. Conf. Computational Linguistics and ACL.","A. Lavoie, M.E. Otey, N. Ratliff, and D. Sculley. 2011. History dependent domain adaptation. Proc. NIPS Workshop on Domain Adaptation.","X. Li, Y.-Y. Wang, and A. Acero. 2009. Extracting structured information from user queries with semi-supervised conditional random fields. Proc. of SI-GIR.","L. Li, B. Roth, and C. Sporleder. 2010. Topic models for word sense disambiguation and token-based idiom detection. Proc. ACL.","X. Li. 2010. Understanding semantic structure of noun phrase queries. Proc. ACL.","J Liu, X. Li, A. Acero, and Ye-Yi Wang. 2011. Lexicon modeling for query understanding. Proc. of ICASSP.","M. P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 27:1–30.","D. Mimno, W. Li, and A. McCallum. 2008. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. Proc. UAI.","T. Moon, K. Erk, and J. Baldridge. 2010. Crouch-ing dirichlet, hidden markov model: Unsupervised pos tagging with context local tag generation. Proc. ACL.","V.-A. Nyugen, J. Boyd-Graber, and P. Resnik. 2012. Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations. Proc. ACL.","P. Pantel. 2003. Clustering by committee. Ph.D. The-sis, University of Alberta, Edmonton, Alta., Canada.","J. Petterson, A. Smola, T. Caetano, W. Buntine, and S. Narayanamurthy. 2010. Word features for latent dirichlet allocation. In Proc. NIPS.","J. Reisinger and R. Mooney. 2011. Cross-cutting models of lexical semantics. In Proc. of EMNLP.","S. Singh, D. Hillard, and C. Leggetter. 2010. Minimally-supervised extraction of entities from text advertisements. Proc. NAACL-HLT.","A. Stolcke. 2002. An extensible language modeling toolkit. Proc. Interspeech.","A. Subramanya, S. Petrov, and F. Pereira. 2010. Efficient graph-based semi-supervised learning of structured tagging models. In Proc. EMNLP.","G. Tur and R. DeMori. 2011. Spoken language understanding: Systems for extracting semantic information from speech. Wiley Press.","Y.-Y. Wang, R. Hoffman, X. Li, and J. Syzmanski. 2009. Semi-supervised learning of semantic classes for query understanding from the web and for the web. In The 18th ACM Conference on Information and Knowledge Management.","X. Zhu. 2005. Semi-supervised learning literature survey. Technical Report 1530, University of Wisconsin-Madison. 923"]}],"references":[{"authors":[{"first":"D.","last":"Blei"},{"first":"A.","last":"Ng"},{"first":"M.","last":"Jordan"}],"year":"2003","title":"Latent dirichlet allocation","source":"D. Blei, A. Ng, and M. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research."},{"authors":[{"first":"J.","last":"Boyd-Graber"},{"first":"D.","last":"Blei"},{"first":"X.","last":"Zhu"}],"year":"2007","title":"A topic model for word sense disambiguation","source":"J. Boyd-Graber, D. Blei, and X. Zhu. 2007. A topic model for word sense disambiguation. Proc. EMNLP."},{"authors":[{"first":"P.","middle":"F.","last":"Brown"},{"first":"V.","middle":"J. D.","last":"Pietra"},{"first":"P.","middle":"V.","last":"deSouza"},{"first":"J.","middle":"C.","last":"Lai"}],"year":"1992","title":"Class-based n-gram models of natural language","source":"P.F. Brown, V.J.D. Pietra, P.V. deSouza, and J.C. Lai. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479."},{"authors":[{"first":"O.","last":"Chapelle"},{"first":"B.","last":"Schlkopf"},{"first":"Alexander","last":"Zien"}],"year":"2006","title":"Semi-supervised learning","source":"O. Chapelle, B. Schlkopf, and Alexander Zien. 2006. Semi-supervised learning. MIT Press."},{"authors":[{"first":"H.","last":"Daumé-III"}],"year":"2010","title":"Frustratingly easy semi-supervised domain adaptation","source":"H. Daumé-III. 2010. Frustratingly easy semi-supervised domain adaptation. Proc. Workshop on Domain Adaptation for Natural Language Process-ing at ACL."},{"authors":[{"first":"T.","middle":"L","last":"Griffiths"},{"first":"M.","last":"Steyvers"},{"first":"D.","middle":"M.","last":"Blei"},{"first":"J.","middle":"M.","last":"Tenenbaum"}],"year":"2005","title":"Integrating topics and syntax","source":"T.L Griffiths, M. Steyvers, D.M. Blei, and J.M. Tenenbaum. 2005. Integrating topics and syntax. Proc. of NIPS."},{"authors":[{"first":"A.","last":"Gruber"},{"first":"M.","last":"Rosen-Zvi"},{"first":"Y.","last":"Weiss"}],"year":"2005","title":"Hidden topic markov models","source":"A. Gruber, M. Rosen-Zvi, and Y. Weiss. 2005. Hidden topic markov models. Proc. of ICML."},{"authors":[{"first":"H.","last":"Guo"},{"first":"H.","last":"Zhu"},{"first":"Z.","last":"Guo"},{"first":"X.","last":"Zhang"},{"first":"X.","last":"Wu"},{"first":"Z.","last":"Su"}],"year":"2009","title":"Domain adaptation with latent semantic association for named entity recognition","source":"H. Guo, H. Zhu, Z. Guo, X. Zhang, X. Wu, and Z. Su. 2009. Domain adaptation with latent semantic association for named entity recognition. Proc. NAACL. 922"},{"authors":[{"first":"J.","last":"Judge"},{"first":"A.","last":"Cahill"},{"first":"J.","last":"Van Genabith"}],"year":"2006","title":"Question-bank: Creating corpus of parse-annotated questions","source":"J. Judge, A. Cahill, and J.Van Genabith. 2006. Question-bank: Creating corpus of parse-annotated questions. Proc. Int. Conf. Computational Linguistics and ACL."},{"authors":[{"first":"A.","last":"Lavoie"},{"first":"M.","middle":"E.","last":"Otey"},{"first":"N.","last":"Ratliff"},{"first":"D.","last":"Sculley"}],"year":"2011","title":"History dependent domain adaptation","source":"A. Lavoie, M.E. Otey, N. Ratliff, and D. Sculley. 2011. History dependent domain adaptation. Proc. NIPS Workshop on Domain Adaptation."},{"authors":[{"first":"X.","last":"Li"},{"first":"Y.","middle":"-Y.","last":"Wang"},{"first":"A.","last":"Acero"}],"year":"2009","title":"Extracting structured information from user queries with semi-supervised conditional random fields","source":"X. Li, Y.-Y. Wang, and A. Acero. 2009. Extracting structured information from user queries with semi-supervised conditional random fields. Proc. of SI-GIR."},{"authors":[{"first":"L.","last":"Li"},{"first":"B.","last":"Roth"},{"first":"C.","last":"Sporleder"}],"year":"2010","title":"Topic models for word sense disambiguation and token-based idiom detection","source":"L. Li, B. Roth, and C. Sporleder. 2010. Topic models for word sense disambiguation and token-based idiom detection. Proc. ACL."},{"authors":[{"first":"X.","last":"Li"}],"year":"2010","title":"Understanding semantic structure of noun phrase queries","source":"X. Li. 2010. Understanding semantic structure of noun phrase queries. Proc. ACL."},{"authors":[{"first":"J","last":"Liu"},{"first":"X.","last":"Li"},{"first":"A.","last":"Acero"},{"first":"Ye-Yi","last":"Wang"}],"year":"2011","title":"Lexicon modeling for query understanding","source":"J Liu, X. Li, A. Acero, and Ye-Yi Wang. 2011. Lexicon modeling for query understanding. Proc. of ICASSP."},{"authors":[{"first":"M.","middle":"P.","last":"Marcus"},{"first":"B.","last":"Santorini"},{"first":"M.","middle":"A.","last":"Marcinkiewicz"}],"year":"1993","title":"Building a large annotated corpus of english: The penn treebank","source":"M. P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 27:1–30."},{"authors":[{"first":"D.","last":"Mimno"},{"first":"W.","last":"Li"},{"first":"A.","last":"McCallum"}],"year":"2008","title":"Topic models conditioned on arbitrary features with dirichlet-multinomial regression","source":"D. Mimno, W. Li, and A. McCallum. 2008. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. Proc. UAI."},{"authors":[{"first":"T.","last":"Moon"},{"first":"K.","last":"Erk"},{"first":"J.","last":"Baldridge"}],"year":"2010","title":"Crouch-ing dirichlet, hidden markov model: Unsupervised pos tagging with context local tag generation","source":"T. Moon, K. Erk, and J. Baldridge. 2010. Crouch-ing dirichlet, hidden markov model: Unsupervised pos tagging with context local tag generation. Proc. ACL."},{"authors":[{"first":"V.","middle":"-A.","last":"Nyugen"},{"first":"J.","last":"Boyd-Graber"},{"first":"P.","last":"Resnik"}],"year":"2012","title":"Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations","source":"V.-A. Nyugen, J. Boyd-Graber, and P. Resnik. 2012. Sits: A hierarchical nonparametric model using speaker identity for topic segmentation in multiparty conversations. Proc. ACL."},{"authors":[{"first":"P.","last":"Pantel"}],"year":"2003","title":"Clustering by committee","source":"P. Pantel. 2003. Clustering by committee. Ph.D. The-sis, University of Alberta, Edmonton, Alta., Canada."},{"authors":[{"first":"J.","last":"Petterson"},{"first":"A.","last":"Smola"},{"first":"T.","last":"Caetano"},{"first":"W.","last":"Buntine"},{"first":"S.","last":"Narayanamurthy"}],"year":"2010","title":"Word features for latent dirichlet allocation","source":"J. Petterson, A. Smola, T. Caetano, W. Buntine, and S. Narayanamurthy. 2010. Word features for latent dirichlet allocation. In Proc. NIPS."},{"authors":[{"first":"J.","last":"Reisinger"},{"first":"R.","last":"Mooney"}],"year":"2011","title":"Cross-cutting models of lexical semantics","source":"J. Reisinger and R. Mooney. 2011. Cross-cutting models of lexical semantics. In Proc. of EMNLP."},{"authors":[{"first":"S.","last":"Singh"},{"first":"D.","last":"Hillard"},{"first":"C.","last":"Leggetter"}],"year":"2010","title":"Minimally-supervised extraction of entities from text advertisements","source":"S. Singh, D. Hillard, and C. Leggetter. 2010. Minimally-supervised extraction of entities from text advertisements. Proc. NAACL-HLT."},{"authors":[{"first":"A.","last":"Stolcke"}],"year":"2002","title":"An extensible language modeling toolkit","source":"A. Stolcke. 2002. An extensible language modeling toolkit. Proc. Interspeech."},{"authors":[{"first":"A.","last":"Subramanya"},{"first":"S.","last":"Petrov"},{"first":"F.","last":"Pereira"}],"year":"2010","title":"Efficient graph-based semi-supervised learning of structured tagging models","source":"A. Subramanya, S. Petrov, and F. Pereira. 2010. Efficient graph-based semi-supervised learning of structured tagging models. In Proc. EMNLP."},{"authors":[{"first":"G.","last":"Tur"},{"first":"R.","last":"DeMori"}],"year":"2011","title":"Spoken language understanding: Systems for extracting semantic information from speech","source":"G. Tur and R. DeMori. 2011. Spoken language understanding: Systems for extracting semantic information from speech. Wiley Press."},{"authors":[{"first":"Y.","middle":"-Y.","last":"Wang"},{"first":"R.","last":"Hoffman"},{"first":"X.","last":"Li"},{"first":"J.","last":"Syzmanski"}],"year":"2009","title":"Semi-supervised learning of semantic classes for query understanding from the web and for the web","source":"Y.-Y. Wang, R. Hoffman, X. Li, and J. Syzmanski. 2009. Semi-supervised learning of semantic classes for query understanding from the web and for the web. In The 18th ACM Conference on Information and Knowledge Management."},{"authors":[{"first":"X.","last":"Zhu"}],"year":"2005","title":"Semi-supervised learning literature survey","source":"X. Zhu. 2005. Semi-supervised learning literature survey. Technical Report 1530, University of Wisconsin-Madison. 923"}],"cites":[{"style":0,"text":"Tur and DeMori, 2011","origin":{"pointer":"/sections/2/paragraphs/0","offset":252,"length":20},"authors":[{"last":"Tur"},{"last":"DeMori"}],"year":"2011","references":["/references/24"]},{"style":0,"text":"Lafferty et al., 2001","origin":{"pointer":"/sections/2/paragraphs/1","offset":196,"length":21},"authors":[{"last":"Lafferty"},{"last":"al."}],"year":"2001","references":[]},{"style":0,"text":"Zhu, 2005","origin":{"pointer":"/sections/2/paragraphs/2","offset":242,"length":9},"authors":[{"last":"Zhu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Daumé-III, 2010","origin":{"pointer":"/sections/2/paragraphs/2","offset":255,"length":15},"authors":[{"last":"Daumé-III"}],"year":"2010","references":["/references/4"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/2/paragraphs/2","offset":274,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Tur and DeMori, 2011","origin":{"pointer":"/sections/3/paragraphs/0","offset":768,"length":20},"authors":[{"last":"Tur"},{"last":"DeMori"}],"year":"2011","references":["/references/24"]},{"style":0,"text":"Wang et al., 2009","origin":{"pointer":"/sections/3/paragraphs/1","offset":3,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2009","references":["/references/25"]},{"style":0,"text":"Li et al., 2009","origin":{"pointer":"/sections/3/paragraphs/1","offset":22,"length":15},"authors":[{"last":"Li"},{"last":"al."}],"year":"2009","references":["/references/10"]},{"style":0,"text":"Li, 2010","origin":{"pointer":"/sections/3/paragraphs/1","offset":39,"length":8},"authors":[{"last":"Li"}],"year":"2010","references":["/references/12"]},{"style":0,"text":"Liu et al., 2011","origin":{"pointer":"/sections/3/paragraphs/1","offset":49,"length":16},"authors":[{"last":"Liu"},{"last":"al."}],"year":"2011","references":["/references/13"]},{"style":0,"text":"Daumé-III, 2010","origin":{"pointer":"/sections/3/paragraphs/2","offset":392,"length":15},"authors":[{"last":"Daumé-III"}],"year":"2010","references":["/references/4"]},{"style":0,"text":"Chapelle et al., 2006","origin":{"pointer":"/sections/3/paragraphs/2","offset":431,"length":21},"authors":[{"last":"Chapelle"},{"last":"al."}],"year":"2006","references":["/references/3"]},{"style":0,"text":"Zhu, 2005","origin":{"pointer":"/sections/3/paragraphs/2","offset":454,"length":9},"authors":[{"last":"Zhu"}],"year":"2005","references":["/references/26"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/3/paragraphs/2","offset":475,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Reisinger and Mooney, 2011","origin":{"pointer":"/sections/3/paragraphs/2","offset":637,"length":26},"authors":[{"last":"Reisinger"},{"last":"Mooney"}],"year":"2011","references":["/references/20"]},{"style":0,"text":"Lavoie et al., 2011","origin":{"pointer":"/sections/3/paragraphs/3","offset":122,"length":19},"authors":[{"last":"Lavoie"},{"last":"al."}],"year":"2011","references":["/references/9"]},{"style":0,"text":"Brown et al., 1992","origin":{"pointer":"/sections/3/paragraphs/4","offset":121,"length":18},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1992","references":["/references/2"]},{"style":0,"text":"Pantel, 2003","origin":{"pointer":"/sections/3/paragraphs/4","offset":167,"length":12},"authors":[{"last":"Pantel"}],"year":"2003","references":["/references/18"]},{"style":0,"text":"Blei et al., 2003","origin":{"pointer":"/sections/3/paragraphs/4","offset":327,"length":17},"authors":[{"last":"Blei"},{"last":"al."}],"year":"2003","references":["/references/0"]},{"style":0,"text":"Guo et al., 2009","origin":{"pointer":"/sections/3/paragraphs/4","offset":580,"length":16},"authors":[{"last":"Guo"},{"last":"al."}],"year":"2009","references":["/references/7"]},{"style":0,"text":"Boyd-Graber et al., 2007","origin":{"pointer":"/sections/3/paragraphs/4","offset":626,"length":24},"authors":[{"last":"Boyd-Graber"},{"last":"al."}],"year":"2007","references":["/references/1"]},{"style":0,"text":"Li et al., 2010","origin":{"pointer":"/sections/3/paragraphs/4","offset":652,"length":15},"authors":[{"last":"Li"},{"last":"al."}],"year":"2010","references":["/references/11"]},{"style":0,"text":"Griffiths et al., 2005","origin":{"pointer":"/sections/3/paragraphs/4","offset":698,"length":22},"authors":[{"last":"Griffiths"},{"last":"al."}],"year":"2005","references":["/references/5"]},{"style":0,"text":"Singh et al., 2010","origin":{"pointer":"/sections/3/paragraphs/4","offset":722,"length":18},"authors":[{"last":"Singh"},{"last":"al."}],"year":"2010","references":["/references/21"]},{"style":0,"text":"Nyugen et al., 2012","origin":{"pointer":"/sections/3/paragraphs/4","offset":767,"length":19},"authors":[{"last":"Nyugen"},{"last":"al."}],"year":"2012","references":["/references/17"]},{"style":0,"text":"Griffiths et al., 2005","origin":{"pointer":"/sections/3/paragraphs/4","offset":863,"length":22},"authors":[{"last":"Griffiths"},{"last":"al."}],"year":"2005","references":["/references/5"]},{"style":0,"text":"Moon et al., 2010","origin":{"pointer":"/sections/3/paragraphs/4","offset":887,"length":17},"authors":[{"last":"Moon"},{"last":"al."}],"year":"2010","references":["/references/16"]},{"style":0,"text":"Gruber et al., 2005","origin":{"pointer":"/sections/3/paragraphs/4","offset":948,"length":19},"authors":[{"last":"Gruber"},{"last":"al."}],"year":"2005","references":["/references/6"]},{"style":0,"text":"Petterson et al., 2010","origin":{"pointer":"/sections/3/paragraphs/5","offset":106,"length":22},"authors":[{"last":"Petterson"},{"last":"al."}],"year":"2010","references":["/references/19"]},{"style":0,"text":"Gruber et al., 2005","origin":{"pointer":"/sections/4/paragraphs/3","offset":251,"length":19},"authors":[{"last":"Gruber"},{"last":"al."}],"year":"2005","references":["/references/6"]},{"style":0,"text":"Stolcke, 2002","origin":{"pointer":"/sections/6/paragraphs/4","offset":812,"length":13},"authors":[{"last":"Stolcke"}],"year":"2002","references":["/references/22"]},{"style":0,"text":"Mimno et al., 2008","origin":{"pointer":"/sections/6/paragraphs/18","offset":58,"length":18},"authors":[{"last":"Mimno"},{"last":"al."}],"year":"2008","references":["/references/15"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/7/paragraphs/0","offset":4,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Lavoie et al., 2011","origin":{"pointer":"/sections/7/paragraphs/30","offset":238,"length":19},"authors":[{"last":"Lavoie"},{"last":"al."}],"year":"2011","references":["/references/9"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/8/paragraphs/2","offset":982,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Judge et al., 2006","origin":{"pointer":"/sections/8/paragraphs/2","offset":1058,"length":18},"authors":[{"last":"Judge"},{"last":"al."}],"year":"2006","references":["/references/8"]},{"style":0,"text":"Marcus et al., 1993","origin":{"pointer":"/sections/8/paragraphs/2","offset":1762,"length":19},"authors":[{"last":"Marcus"},{"last":"al."}],"year":"1993","references":["/references/14"]},{"style":0,"text":"Gruber et al., 2005","origin":{"pointer":"/sections/8/paragraphs/2","offset":2049,"length":19},"authors":[{"last":"Gruber"},{"last":"al."}],"year":"2005","references":["/references/6"]},{"style":0,"text":"Petterson et al., 2010","origin":{"pointer":"/sections/8/paragraphs/2","offset":2089,"length":22},"authors":[{"last":"Petterson"},{"last":"al."}],"year":"2010","references":["/references/19"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/8/paragraphs/2","offset":3083,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/8/paragraphs/6","offset":605,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]},{"style":0,"text":"Subramanya et al., 2010","origin":{"pointer":"/sections/8/paragraphs/9","offset":416,"length":23},"authors":[{"last":"Subramanya"},{"last":"al."}],"year":"2010","references":["/references/23"]}]}
