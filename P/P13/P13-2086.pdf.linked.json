{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 484–488, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"A Novel Text Classifier Based on Quantum Computation   Ding Liu, Xiaofang Yang, Minghu Jiang Laboratory of Computational Linguistics, School of Humanities, Tsinghua University, Beijing , China Dingliu_thu@126.com xfyang.thu@gmail.com jiang.mh@mail.tsinghua.edu.cn   Abstract","paragraphs":["In this article, we propose a novel classifier based on quantum computation theory. Different from existing methods, we consider the classification as an evolutionary process of a physical system and build the classifier by using the basic quantum mechanics equation. The performance of the experiments on two datasets indicates feasibility and potentiality of the quantum classifier."]},{"title":"1 Introduction","paragraphs":["Taking modern natural science into account, the quantum mechanics theory (QM) is one of the most famous and profound theory which brings a world-shaking revolution for physics. Since QM was born, it has been considered as a significant part of theoretic physics and has shown its power in explaining experimental results. Furthermore, some scientists believe that QM is the final principle of physics even the whole natural science. Thus, more and more researchers have expanded the study of QM in other fields of science, and it has affected almost every aspect of natural science and technology deeply, such as quantum computation.","The principle of quantum computation has also affected a lot of scientific researches in computer science, specifically in computational modeling, cryptography theory as well as information theory. Some researchers have employed the principle and technology of quantum computation to improve the studies on Machine Learning (ML) (Aїmeur et al., 2006; Aїmeur et al., 2007; Chen et al., 2008; Gambs, 2008; Horn and Gottlieb, 2001; Nasios and Bors, 2007), a field which studies theories and constructions of systems that can learn from data, among which classification is a typical task. Thus, we attempted to  build a computational model based on quantum computation theory to handle classification tasks in order to prove the feasibility of applying the QM model to machine learning.","In this article, we present a method that considers the classifier as a physical system amenable to QM and treat the entire process of classification as the evolutionary process of a closed quantum system. According to QM, the evolution of quantum system can be described by a unitary operator. Therefore, the primary problem of building a quantum classifier (QC) is to find the correct or optimal unitary operator. We applied classical optimization algorithms to deal with the problem, and the experimental results have confirmed our theory.","The outline of this paper is as follows. First, the basic principle and structure of QC is introduced in section 2. Then, two different experiments are described in section 3. Finally, section 4 concludes with a discussion."]},{"title":"2 Basic principle of quantum classifier","paragraphs":["As we mentioned in the introduction, the major principle of quantum classifier (QC) is to consider the classifier as a physical system and the whole process of classification as the evolutionary process of a closed quantum system. Thus, the evolution of the quantum system can be described by a unitary operator (unitary matrix), and the remaining job is to find the correct or optimal unitary operator. 2.1 Architecture of quantum classifier The architecture and the whole procedure of data processing of QC are illustrated in Figure 1. As is shown, the key aspect of QC is the optimization part where we employ the optimization algorithm to find an optimal unitary operator",". 484"," Figure 1. Architecture of quantum classifier  The detailed information about each phase of the process will be explained thoroughly in the following sections. 2.2 Encode input state and target state In quantum mechanics theory, the state of a physical system can be described as a superposi-tion of the so called eigenstates which are orthogonal. Any state, including the eigenstate, can be represented by a complex number vector. We use Dirac’s braket notation to formalize the data as equation 1:","|⟩ = |⟩  (1)  where |⟩ denotes a state and ∈ C is a complex number with = ⟨|⟩ being the projec-tion of |⟩ on the eigenstate |⟩. According to quantum theory, denotes the probability amplitude. Furthermore, the probability of |⟩ collapsing on |⟩ is P() =","||","∑ ||",".","Based on the hypothesis that QC can be considered as a quantum system, the input data should be transformed to an available format in quantum theory — the complex number vector. According to Euler’s formula, a complex number z can be denoted as =","with r≥ , ∈ R. Equation 1, thus, can be written as:  |⟩ =","|⟩  (2)"," where and denote the module and the phase of the complex coefficient respectively.   For different applications, we employ different approaches to determine the value of and . Specifically, in our experiment, we assigned the term frequency, a feature frequently used in text classification to , and treated the phase as a constant, since we found the phase makes little contribution to the classification.","For each data sample , we calculate the corresponding input complex number vector by equation 3, which is illustrated in detail in Figure 2.","","|⟩ = ∙ |   (3)   Figure 2. Process of calculating the input state  Each eigenstate | denotes the corresponding , resulting in m eigenstates for all the samples. As is mentioned above, the evolutionary process of a closed physical system can be described by a unitary operator, depicted by a matrix as in equation 4:  |","⟩ = |⟩ (4)  where |","⟩ and |⟩ denote the final state and the initial state respectively. The approach to determine the unitary operator will be discussed in 485 section 2.3. We encode the target state in the similar way. Like the Vector Space Model(VSM), we use a label matrix to represent each class as in Figure 3. ","","Figure 3. Label matrix","","For each input sample , we generate","the corresponding target complex number vector","according to equation 5:","|⟩ = ∙ |   (5)  where each eigenstate | represents the corresponding , resulting in w eigenstates for all the labels. Totally, we need + eigenstates, including features and labels.","","2.3 Finding the Hamiltonian matrix and the Unitary operator As is mentioned in the first section, finding a unitary operator to describe the evolutionary process is the vital step in building a QC. As a basic quantum mechanics theory, a unitary operator can be represented by a unitary matrix with the property","=",", and a unitary operator can also be written as equation 6:","= ħ (6)  where H is the Hamiltonian matrix and ħ is the reduced Planck constant. Moreover, the Hamiltonian H is a Hermitian matrix with the property ","= (",")∗","= . The remaining job, therefore, is to find an optimal Hamiltonian matrix.","Since H is a Hermitian matrix, we only need to determine ( + )","free real parameters, provided that the dimension of H is (m+w). Thus, the problem of determining H can be regarded as a classical optimization problem, which can be resolved by various optimization algorithms (Chen and Kudlek, 2001). An error function is defined as equation 7:"," () =","","∑",""," (,)∈ (7) where T is a set of training pairs with , , denoting the target, input, and output state respectively, and is determined by as equation 8: ","|⟩ = ħ |⟩ (8)","","In the optimization phase, we employed several optimization algorithm, including BFGS, Generic Algorithm, and a multi-objective optimization algorithm SQP (sequential quadratic programming) to optimize the error function. In our experiment, the SQP method performed best out-performed the others. "]},{"title":"3 Experiment","paragraphs":["We tested the performance of QC on two different datasets. In section 3.1, the Reuters-21578 dataset was used to train a binary QC. We compared the performance of QC with several classical classification methods, including Support Vector Machine (SVM) and K-nearest neighbor (KNN). In section 3.2, we evaluated the performance on multi-class classification using an oral conversation datasets and analyzed the results. 3.1 Reuters-21578 The Reuters dataset we tested contains 3,964 texts belonging to “earnings” category and 8,938 texts belonging to “others” categories. In this classification task, we selected the features by calculating the","score of each term from the “earnings” category (Manning and Schütze, 2002).","For the convenience of counting, we adopted 3,900 “earnings” documents and 8,900 “others” documents and divided them into two groups: the training pool and the testing sets. Since we focused on the performance of QC trained by small-scale training sets in our experiment, we each selected 1,000 samples from the “earnings” and the “others” category as our training pool and took the rest of the samples (2,900 “earnings” and 7,900 “others” documents) as our testing sets. We randomly selected training samples from the training pool ten times to train QC, SVM, and KNN classifier respectively and then verified the three trained classifiers on the testing sets, the results of which are illustrated in Figure 4. We noted that the QC performed better than both KNN and SVM on small-scale training sets, when the number of training samples is less than 50. 486 ","Figure 4. Classification accuracy for Reuters-21578 datasets ","Generally speaking, the QC trained by a large training set may not always has an ideal performance. Whereas some single training sample pair led to a favorable result when we used only one sample from each category to train the QC. Actually, some single samples could lead to an accuracy of more than 90%, while some others may produce an accuracy lower than 30%. Therefore, the most significant factor for QC is the quality of the training samples rather than the quantity. 3.2 Oral conversation datasets Besides the binary QC, we also built a multi-class version and tested its performance on an oral conversation dataset which was collected by the Laboratory of Computational Linguistics of Tsinghua university. The dataset consisted of 1,000 texts and were categorized into 5 classes, each containing 200 texts. We still took the term frequency as the feature, the dimension of which exceeded 1,000. We, therefore, utilized the primary component analysis (PCA) to reduce the high dimension of the features in order to decrease the computational complexity. In this experiment, we chose the top 10 primary components of the outcome of PCA, which contained nearly 60% information of the original data. Again, we focused on the performance of QC trained by small-scale training sets. We selected 100 samples from each class to construct the training pool and took the rest of the data as the testing sets. Same to the experiment in section 3.1, we randomly selected the training samples from the training pool ten times to train QC, SVM, and KNN classifier respectively and veri fied the models on the testing sets, the results of which are shown in Figure 5.  ","Figure 5. Classification accuracy for oral conversation datasets "]},{"title":"4 Discussion","paragraphs":["We present here our model of text classification and compare it with SVM and KNN on two datasets. We find that it is feasible to build a supervised learning model based on quantum mechanics theory. Previous studies focus on combining quantum method with existing classification models such as neural network (Chen et al., 2008) and kernel function (Nasios and Bors, 2007) aim-ing to improve existing models to work faster and more efficiently. Our work, however, focuses on developing a novel method which explores the relationship between machine learning model with physical world, in order to investigate these models by physical rule which describe our universe. Moreover, the QC performs well in text classification compared with SVM and KNN and outperforms them on small-scale training sets. Additionally, the time complexity of QC depends on the optimization algorithm and the amounts of features we adopt. Generally speaking, simulat-ing quantum computing on classical computer always requires more computation resources, and we believe that quantum computer will tackle the difficulty in the forthcoming future. Actually, Google and NASA have launched a quantum computing AI lab this year, and we regard the project as an exciting beginning.","Future studies include: We hope to find a more suitable optimization algorithm for QC and a more reasonable physical explanation towards the “quantum nature” of the QC. We hope our attempt will shed some light upon the application of quantum theory into the field of machine learning.    487 Acknowledgments  This work was supported by the National Natural Science Foundation in China (61171114), State Key Lab of Pattern Recognition open foundation, CAS. Tsinghua University Self-determination Research Project (20111081023 & 20111081010) and Human & liberal arts development founda-tion (2010WKHQ009) "]},{"title":"References","paragraphs":["Esma Aїmeur, Gilles Brassard, and Sébastien Gambs. 2006. Machine Learning in a Quantum World. Canadian AI 2006","Esma Aїmeur, Gilles Brassard and Sébastien Gambs. 2007. Quantum Clustering Algorithms. Proceedings of the 24 th International Conference on Machine Learning","Joseph C.H. Chen and Manfred Kudlek. 2001. Duality of Syntex and Semantics – From the View Point of Brain as a Quantum Computer. Proceedings of Recent Advances in NLP","Joseph C.H. Chen. 2001. Quantum Computation and Natural Language Processing. University of Hamburg, Germany. Ph.D. thesis","Joseph C.H. Chen. 2001. A Quantum Mechanical Approach to Cognition and Representation. Consciousness and its Place in Nature,Toward a Science of Consciousness.","Cheng-Hung Chen, Cheng-Jian Lin and Chin-Teng Lin. 2008. An efficient quantum neuro-fuzzy classifier based on fuzzy entropy and compensatory operation. Soft Comput, 12:567–583.","Fumiyo Fukumoto and Yoshimi Suzuki. 2002. Manipulating Large Corpora for Text Classification. Proceedings of the Conference on Empirical Methods in Natural Language Processing","Sébastien Gambs. 2008. Quantum classification, arXiv:0809.0444","Lov K. Grover. 1997. Quantum Mechanics Helps in Searching for a Needle in a Haystack. Physical Re view Letters, 79,325–328","David Horn and Assaf Gottlieb. 2001. The Method of Quantum Clustering. Proceedings of Advances in Neural Information Processing Systems .","Christopher D. Manning and Hinrich Schütze. 2002. Foundations of Statistical Natural Language Processing. MIT Press. Cambridge, Massachusetts,USA.","Nikolaos Nasios and Adrian G. Bors. 2007. Kernel-based classification using quantum mechanics. Pattern Recognition, 40:875–889","Hartmut Neven and Vasil S. Denchev. 2009. Training a Large Scale Classifier with the Quantum Adiabatic Algorithm. arXiv:0912.0779v1","Michael A. Nielsen and Isasc L. Chuang. 2000. Quantum Computation and Quantum Information, Cambridge University Press, Cambridge, UK.","Masahide Sasaki and and Alberto Carlini. 2002. Quantum learning and universal quantum matching machine. Physical Review, A 66, 022303","Dan Ventura. 2002. Pattern classification using a quantum system. Proceedings of the Joint Conference on Information Sciences.  488"]}],"references":[{"authors":[{"first":"Esma","last":"Aїmeur"},{"first":"Gilles","last":"Brassard"},{"first":"Sébastien","last":"Gambs"}],"year":"2006","title":"Machine Learning in a Quantum World","source":"Esma Aїmeur, Gilles Brassard, and Sébastien Gambs. 2006. Machine Learning in a Quantum World. Canadian AI 2006"},{"authors":[{"first":"Esma","last":"Aїmeur"},{"first":"Gilles","last":"Brassard"},{"first":"Sébastien","last":"Gambs"}],"year":"2007","title":"Quantum Clustering Algorithms","source":"Esma Aїmeur, Gilles Brassard and Sébastien Gambs. 2007. Quantum Clustering Algorithms. Proceedings of the 24 th International Conference on Machine Learning"},{"authors":[{"first":"Joseph","middle":"C. H.","last":"Chen"},{"first":"Manfred","last":"Kudlek"}],"year":"2001","title":"Duality of Syntex and Semantics – From the View Point of Brain as a Quantum Computer","source":"Joseph C.H. Chen and Manfred Kudlek. 2001. Duality of Syntex and Semantics – From the View Point of Brain as a Quantum Computer. Proceedings of Recent Advances in NLP"},{"authors":[{"first":"Joseph","middle":"C. H.","last":"Chen"}],"year":"2001","title":"Quantum Computation and Natural Language Processing","source":"Joseph C.H. Chen. 2001. Quantum Computation and Natural Language Processing. University of Hamburg, Germany. Ph.D. thesis"},{"authors":[{"first":"Joseph","middle":"C. H.","last":"Chen"}],"year":"2001","title":"A Quantum Mechanical Approach to Cognition and Representation","source":"Joseph C.H. Chen. 2001. A Quantum Mechanical Approach to Cognition and Representation. Consciousness and its Place in Nature,Toward a Science of Consciousness."},{"authors":[{"first":"Cheng-Hung","last":"Chen"},{"first":"Cheng-Jian","last":"Lin"},{"first":"Chin-Teng","last":"Lin"}],"year":"2008","title":"An efficient quantum neuro-fuzzy classifier based on fuzzy entropy and compensatory operation","source":"Cheng-Hung Chen, Cheng-Jian Lin and Chin-Teng Lin. 2008. An efficient quantum neuro-fuzzy classifier based on fuzzy entropy and compensatory operation. Soft Comput, 12:567–583."},{"authors":[{"first":"Fumiyo","last":"Fukumoto"},{"first":"Yoshimi","last":"Suzuki"}],"year":"2002","title":"Manipulating Large Corpora for Text Classification","source":"Fumiyo Fukumoto and Yoshimi Suzuki. 2002. Manipulating Large Corpora for Text Classification. Proceedings of the Conference on Empirical Methods in Natural Language Processing"},{"authors":[{"first":"Sébastien","last":"Gambs"}],"year":"2008","title":"Quantum classification, arXiv:0809","source":"Sébastien Gambs. 2008. Quantum classification, arXiv:0809.0444"},{"authors":[{"first":"Lov","middle":"K.","last":"Grover"}],"year":"1997","title":"Quantum Mechanics Helps in Searching for a Needle in a Haystack","source":"Lov K. Grover. 1997. Quantum Mechanics Helps in Searching for a Needle in a Haystack. Physical Re view Letters, 79,325–328"},{"authors":[{"first":"David","last":"Horn"},{"first":"Assaf","last":"Gottlieb"}],"year":"2001","title":"The Method of Quantum Clustering","source":"David Horn and Assaf Gottlieb. 2001. The Method of Quantum Clustering. Proceedings of Advances in Neural Information Processing Systems ."},{"authors":[{"first":"Christopher","middle":"D.","last":"Manning"},{"first":"Hinrich","last":"Schütze"}],"year":"2002","title":"Foundations of Statistical Natural Language Processing","source":"Christopher D. Manning and Hinrich Schütze. 2002. Foundations of Statistical Natural Language Processing. MIT Press. Cambridge, Massachusetts,USA."},{"authors":[{"first":"Nikolaos","last":"Nasios"},{"first":"Adrian","middle":"G.","last":"Bors"}],"year":"2007","title":"Kernel-based classification using quantum mechanics","source":"Nikolaos Nasios and Adrian G. Bors. 2007. Kernel-based classification using quantum mechanics. Pattern Recognition, 40:875–889"},{"authors":[{"first":"Hartmut","last":"Neven"},{"first":"Vasil","middle":"S.","last":"Denchev"}],"year":"2009","title":"Training a Large Scale Classifier with the Quantum Adiabatic Algorithm","source":"Hartmut Neven and Vasil S. Denchev. 2009. Training a Large Scale Classifier with the Quantum Adiabatic Algorithm. arXiv:0912.0779v1"},{"authors":[{"first":"Michael","middle":"A.","last":"Nielsen"},{"first":"Isasc","middle":"L.","last":"Chuang"}],"year":"2000","title":"Quantum Computation and Quantum Information, Cambridge University Press, Cambridge, UK","source":"Michael A. Nielsen and Isasc L. Chuang. 2000. Quantum Computation and Quantum Information, Cambridge University Press, Cambridge, UK."},{"authors":[{"first":"Masahide","last":"Sasaki"},{"first":"Alberto","last":"Carlini"}],"year":"2002","title":"Quantum learning and universal quantum matching machine","source":"Masahide Sasaki and and Alberto Carlini. 2002. Quantum learning and universal quantum matching machine. Physical Review, A 66, 022303"},{"authors":[{"first":"Dan","last":"Ventura"}],"year":"2002","title":"Pattern classification using a quantum system","source":"Dan Ventura. 2002. Pattern classification using a quantum system. Proceedings of the Joint Conference on Information Sciences.  488"}],"cites":[{"style":0,"text":"Aїmeur et al., 2006","origin":{"pointer":"/sections/2/paragraphs/1","offset":330,"length":19},"authors":[{"last":"Aїmeur"},{"last":"al."}],"year":"2006","references":["/references/0"]},{"style":0,"text":"Aїmeur et al., 2007","origin":{"pointer":"/sections/2/paragraphs/1","offset":351,"length":19},"authors":[{"last":"Aїmeur"},{"last":"al."}],"year":"2007","references":["/references/1"]},{"style":0,"text":"Chen et al., 2008","origin":{"pointer":"/sections/2/paragraphs/1","offset":372,"length":17},"authors":[{"last":"Chen"},{"last":"al."}],"year":"2008","references":["/references/5"]},{"style":0,"text":"Gambs, 2008","origin":{"pointer":"/sections/2/paragraphs/1","offset":391,"length":11},"authors":[{"last":"Gambs"}],"year":"2008","references":["/references/7"]},{"style":0,"text":"Horn and Gottlieb, 2001","origin":{"pointer":"/sections/2/paragraphs/1","offset":404,"length":23},"authors":[{"last":"Horn"},{"last":"Gottlieb"}],"year":"2001","references":["/references/9"]},{"style":0,"text":"Nasios and Bors, 2007","origin":{"pointer":"/sections/2/paragraphs/1","offset":429,"length":21},"authors":[{"last":"Nasios"},{"last":"Bors"}],"year":"2007","references":["/references/11"]},{"style":0,"text":"Chen and Kudlek, 2001","origin":{"pointer":"/sections/3/paragraphs/32","offset":211,"length":21},"authors":[{"last":"Chen"},{"last":"Kudlek"}],"year":"2001","references":["/references/2"]},{"style":0,"text":"Manning and Schütze, 2002","origin":{"pointer":"/sections/4/paragraphs/1","offset":49,"length":25},"authors":[{"last":"Manning"},{"last":"Schütze"}],"year":"2002","references":["/references/10"]},{"style":0,"text":"Chen et al., 2008","origin":{"pointer":"/sections/5/paragraphs/0","offset":309,"length":17},"authors":[{"last":"Chen"},{"last":"al."}],"year":"2008","references":["/references/5"]},{"style":0,"text":"Nasios and Bors, 2007","origin":{"pointer":"/sections/5/paragraphs/0","offset":349,"length":21},"authors":[{"last":"Nasios"},{"last":"Bors"}],"year":"2007","references":["/references/11"]}]}
