{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 323–327, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Task Alternation in Parallel Sentence Retrieval for Twitter Translation Felix Hieber and Laura Jehl and Stefan Riezler Department of Computational Linguistics Heidelberg University 69120 Heidelberg, Germany {jehl,hieber,riezler}@cl.uni-heidelberg.de Abstract","paragraphs":["We present an approach to mine comparable data for parallel sentences using translation-based cross-lingual information retrieval (CLIR). By iteratively alternating between the tasks of retrieval and translation, an initial general-domain model is allowed to adapt to in-domain data. Adaptation is done by training the translation system on a few thousand sentences retrieved in the step before. Our setup is time- and memory-efficient and of similar quality as CLIR-based adaptation on millions of parallel sentences."]},{"title":"1 Introduction","paragraphs":["Statistical Machine Translation (SMT) crucially relies on large amounts of bilingual data (Brown et al., 1993). Unfortunately sentence-parallel bilingual data are not always available. Various approaches have been presented to remedy this problem by mining parallel sentences from comparable data, for example by using cross-lingual information retrieval (CLIR) techniques to retrieve a target language sentence for a source language sentence treated as a query. Most such approaches try to overcome the noise inherent in automatically extracted parallel data by sheer size. However, find-ing good quality parallel data from noisy resources like Twitter requires sophisticated retrieval methods. Running these methods on millions of queries and documents can take weeks.","Our method aims to achieve improvements similar to large-scale parallel sentence extraction approaches, while requiring only a fraction of the extracted data and considerably less computing resources. Our key idea is to extend a straightforward application of translation-based CLIR to an iterative method: Instead of attempting to retrieve in one step as many parallel sentences as possible, we allow the retrieval model to gradually adapt to new data by using an SMT model trained on the freshly retrieved sentence pairs in the translation-based retrieval step. We alternate between the tasks of translation-based retrieval of target sentences, and the task of SMT, by re-training the SMT model on the data that were retrieved in the previous step. This task alternation is done iteratively until the number of newly added pairs stabilizes at a relatively small value.","In our experiments on Arabic-English Twitter translation, we achieved improvements of over 1 BLEU point over a strong baseline that uses in-domain data for language modeling and parameter tuning. Compared to a CLIR-approach which extracts more than 3 million parallel sentences from a noisy comparable corpus, our system produces similar results in terms of BLEU using only about 40 thousand sentences for training in each of a few iterations, thus being much more time- and resource-efficient."]},{"title":"2 Related Work","paragraphs":["In the terminology of semi-supervised learning (Abney, 2008), our method resembles self-training and co-training by training a learning method on its own predictions. It is different in the aspect of task alternation: The SMT model trained on retrieved sentence pairs is not used for generating training data, but for scoring noisy parallel data in a translation-based retrieval setup. Our method also incorporates aspects of transductive learning in that candidate sentences used as queries are filtered for out-of-vocabulary (OOV) words and similarity to sentences in the development set in or-der to maximize the impact of translation-based retrieval.","Our work most closely resembles approaches that make use of variants of SMT to mine comparable corpora for parallel sentences. Recent work uses word-based translation (Munteanu and 323 Marcu, 2005; Munteanu and Marcu, 2006), full-sentence translation (Abdul-Rauf and Schwenk, 2009; Uszkoreit et al., 2010), or a sophisticated interpolation of word-based and contextual translation of full sentences (Snover et al., 2008; Jehl et al., 2012; Ture and Lin, 2012) to project source language sentences into the target language for retrieval. The novel aspect of task alternation in-troduced in this paper can be applied to all approaches incorporating SMT for sentence retrieval from comparable data.","For our baseline system we use in-domain language models (Bertoldi and Federico, 2009) and meta-parameter tuning on in-domain development sets (Koehn and Schroeder, 2007)."]},{"title":"3 CLIR for Parallel Sentence Retrieval 3.1 Context-Sensitive Translation for CLIR","paragraphs":["Our CLIR model extends the translation-based retrieval model of Xu et al. (2001). While translation options in this approach are given by a lexical translation table, we also select translation options estimated from the decoder’s n-best list for translating a particular query. The central idea is to let the language model choose fluent, context-aware translations for each query term during decoding.","For mapping source language query terms to target language query terms, we follow Ture et al. (2012a; 2012). Given a source language query Q with query terms qj, we project it into the target language by representing each source token qj by its probabilistically weighted translations. The score of target document D, given source language query Q, is computed by calculating the Okapi BM25 rank (Robertson et al., 1998) over projected term frequency and document frequency weights as follows: score(D|Q) = |Q| ∑ j=1 bm25(tf(qj, D), df(qj)) tf(q, D) = |Tq| ∑ i=1 tf(ti, D)P (ti|q) df(q) = |Tq| ∑ i=1 df(ti)P (ti|q) where Tq = {t|P (t|q) > L} is the set of translation options for query term q with probability greater than L. Following Ture et al. (2012a; 2012) we impose a cumulative threshold C, so that only the most probable options are added until C is reached.","Like Ture et al. (2012a; 2012) we achieved best retrieval performance when translation probabilities are calculated as an interpolation between (context-free) lexical translation probabilities Plex estimated on symmetrized word alignments, and (context-aware) translation probabilities Pnbest estimated on the n-best list of an SMT decoder: P (t|q) = λPnbest(t|q) + (1 − λ)Plex(t|q) (1) Pnbest(t|q) is the decoder’s confidence to translate q into t within the context of query Q. Let ak(t, q) be a function indicating an alignment of target term t to source term q in the k-th derivation of query Q. Then we can estimate Pnbest(t|q) as follows: Pnbest(t|q) = ∑n k=1 ak(t, q)D(k, Q) ∑n k=1 ak(·, q)D(k, Q) (2) D(k, Q) is the model score of the k-th derivation in the n-best list for query Q.","In our work, we use hierarchical phrase-based translation (Chiang, 2007), as implemented in the cdec framework (Dyer et al., 2010). This allows us to extract word alignments between source and target text for Q from the SCFG rules used in the derivation. The concept of self-translation is covered by the decoder’s ability to use pass-through rules if words or phrases cannot be translated. 3.2 Task Alternation in CLIR The key idea of our approach is to iteratively alternate between the tasks of retrieval and translation for efficient mining of parallel sentences. We allow the initial general-domain CLIR model to adapt to in-domain data over multiple iterations. Since our set of in-domain queries was small (see 4.2), we trained an adapted SMT model on the concatenation of general-domain sentences and in-domain sentences retrieved in the step be-fore, rather than working with separate models.","Algorithm 1 shows the iterative task alternation procedure. In terms of semi-supervised learning, we can view algorithm 1 as non-persistent as we do not keep labels/pairs from previous iterations. We have tried different variations of label persistency but did not find any improvements. A similar effect of preventing the SMT model to “for-get” general-domain knowledge across iterations is achieved by mixing models from current and previous iterations. This is accomplished in two ways: First, by linearly interpolating the translation option weights P (t|q) from the current and 324 Algorithm 1 Task Alternation Require: source language Tweets Qsrc, target language Tweets Dtrg, general-domain parallel sentences Sgen, general-domain","SMT model Mgen, interpolation parameter θ","procedure TASK-ALTERNATION(Qsrc, Dtrg, Sgen, Mgen, θ)","t ← 1","while true do Sin ← ∅ ▷ Start with empty parallel in-domain sentences if t == 1 then","M(t)","clir ← Mgen ▷ Start with general-domain SMT model for CLIR","else","M(t) clir ← θM(t−1)","smt + (1 − θ)M(t)","smt ▷ Use mixture of previous and current SMT model for CLIR end if Sin ← CLIR(Qsrc, Dtrg, M(t)","clir) ▷ Retrieve top 1 target language Tweets for each source language query M(t+1)","smt ← TRAIN(Sgen + Sin) ▷ Train SMT model on general-domain and retrieved in-domain data t ← t + 1","end while","end procedure BLEU (test) # of in-domain sents Standard DA 14.05 - Full-scale CLIR 14.97 3,198,913 Task alternation 15.31 ∼40k Table 1: Standard Domain Adaptation with in-domain LM and tuning; Full-scale CLIR yielding over 3M in-domain parallel sentences; Task alternation (θ = 0.1, iteration 7) using ∼40k parallel sentences per iteration. previous model with interpolation parameter θ. Second, by always using Plex(t|q) weights estimated from word alignments on Sgen.","We experimented with different ways of using the ranked retrieval results for each query and found that taking just the highest ranked document yielded the best results. This returns one pair of parallel Twitter messages per query, which are then used as additional training data for the SMT model in each iteration."]},{"title":"4 Experiments 4.1 Data","paragraphs":["We trained the general domain model Mgen on data from the NIST evaluation campaign, includ-ing UN reports, newswire, broadcast news and blogs. Since we were interested in relative improvements rather than absolute performance, we sampled 1 million parallel sentences Sgen from the originally over 5.8 million parallel sentences.","We used a large corpus of Twitter messages, originally created by Jehl et al. (2012), as comparable in-domain data. Language identification was carried out with an off-the-shelf tool (Lui and Baldwin, 2012). We kept only Tweets classified as Arabic or English with over 95% confidence. After removing duplicates, we obtained 5.5 million Arabic Tweets and 3.7 million English Tweets (Dtrg). Jehl et al. (2012) also supply a set of 1,022 Arabic Tweets with 3 English translations each for evaluation purposes, which was created by crowdsourcing translation on Amazon Mechanical Turk. We randomly split the parallel sentences into 511 sentences for development and 511 sentences for testing. All URLs and user names in Tweets were replaced by common placeholders. Hashtags were kept, since they might be helpful in the retrieval step. Since the evaluation data do not contain any hashtags, URLs or user names, we apply a postprocessing step after decoding in which we remove those tokens. 4.2 Transductive Setup Our method can be considered transductive in two ways. First, all Twitter data were collected by keyword-based crawling. Therefore, we can expect a topical similarity between development, test and training data. Second, since our setup aims for speed, we created a small set of queries Qsrc, consisting of the source side of the evaluation data and similar Tweets. Similarity was defined by two criteria: First, we ranked all Arabic Tweets with respect to their term overlap with the development and test Tweets. Smoothed per-sentence BLEU (Lin and Och, 2004) was used as a similarity metric. OOV-coverage served as a second criterion to remedy the problem of unknown words in Twitter translation. We first created a general list of all OOVs in the evaluation data under Mgen (3,069 out of 7,641 types). For each of the top 100 BLEU-ranked Tweets, we counted OOV-coverage with respect to the corresponding source Tweet and the general OOV list. We only kept Tweets 325","0 1 2 3 4 5 6 7 8 iteration 14.05 14.97 15.31 16.00 BLEU (test) (a) θ =0.0 θ =0.1 θ =0.5 θ =0.9","1 2 3 4 5 6 7 8 iteration 0 10000 20000 30000 40000 50000 60000 70000 # new pairs (b) θ =0.0 θ =0.1 θ =0.5 θ =0.9 Figure 1: Learning curves for varying θ parameters. (a) BLEU scores and (b) number of new pairs added per iteration. containing at least one OOV term from the corresponding source Tweet and two OOV terms from the general list, resulting in 65,643 Arabic queries covering 86% of all OOVs. Our query set Qsrc performed better (14.76 BLEU) after one iteration than a similar-sized set of random queries (13.39). 4.3 Experimental Results We simulated the full-scale retrieval approach by Jehl et al. (2012) with the CLIR model described in section 3. It took 14 days to run 5.5M Arabic queries on 3.7M English documents. In contrast, our iterative approach completed a single iteration in less than 24 hours.1","In the absence of a Twitter data set for retrieval, we selected the parameters λ = 0.6 (eq.1), L = 0.005 and C = 0.95 in a mate-finding task on Wikipedia data. The n-best list size for Pnbest(t|q) was 1000. All SMT models included a 5-gram language model built from the English side of the NIST data plus the English side of the Twitter corpus Dtrg. Word alignments were created using GIZA++ (Och and Ney, 2003). Rule extraction and parameter tuning (MERT) was carried out with cdec, using standard features. We ran MERT 5 times per iteration, carrying over the weights which achieved median performance on the development set to the next iteration.","Table 1 reports median BLEU scores on test of our standard adaptation baseline, the full-scale retrieval approach and the best result from our task alternation systems. Approximate randomization tests (Noreen, 1989; Riezler and Maxwell, 2005) showed that improvements of full-scale retrieval and task alternation over the baseline were statis-1 Retrieval was done in 4 batches on a Hadoop cluster us-","ing 190 mappers at once. tically significant. Differences between full-scale retrieval and task alternation were not significant.2","Figure 1 illustrates the impact of θ, which controls the importance of the previous model compared to the current one, on median BLEU (a) and change of Sin (b) over iterations. For all θ, few iterations suffice to reach or surpass full-scale retrieval performance. Yet, no run achieved good performance after one iteration, showing that the transductive setup must be combined with task alternation to be effective. While we see fluctuations in BLEU for all θ-values, θ = 0.1 achieves high scores faster and more consistently, pointing to-wards selecting a bolder updating strategy. This is also supported by plot (b), which indicates that choosing θ = 0.1 leads to faster stabilization in the pairs added per iteration (Sin). We used this stabilization as a stopping criterion."]},{"title":"5 Conclusion","paragraphs":["We presented a method that makes translation-based CLIR feasible for mining parallel sentences from large amounts of comparable data. The key of our approach is a translation-based high-quality retrieval model which gradually adapts to the target domain by iteratively re-training the underly-ing SMT model on a few thousand parallel sentences retrieved in the step before. The number of new pairs added per iteration stabilizes to a few thousand after 7 iterations, yielding an SMT model that improves 0.35 BLEU points over a model trained on millions of retrieved pairs.","2","Note that our full-scale results are not directly comparable to those of Jehl et al. (2012) since our setup uses less than one fifth of the NIST data, a different decoder, a new CLIR approach, and a different development and test split. 326"]},{"title":"References","paragraphs":["Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the use of comparable corpora to improve SMT performance. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL’09), Athens, Greece.","Steven Abney. 2008. Semisupervised Learning for Computational Linguistics. Chapman and Hall.","Nicola Bertoldi and Marcello Federico. 2009. Domain adaptation for statistical machine translation with monolingual resources. In Proceedings of the 4th EACL Workshop on Statistical Machine Translation (WMT’09), Athens, Greece.","Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2).","David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2).","Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of the ACL 2010 System Demonstrations (ACL’10), Uppsala, Sweden.","Laura Jehl, Felix Hieber, and Stefan Riezler. 2012. Twitter translation using translation-based cross-lingual retrieval. In Proceedings of the Seventh Workshop on Statistical Machine Translation (WMT’12), Montreal, Quebec, Canada.","Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, Prague, Czech Republic.","Chin-Yew Lin and Franz Josef Och. 2004. Orange: a method for evaluating automatic evaluation metrics for machine translation. In Proceedings the 20th International Conference on Computational Linguistics (COLING’04).","Marco Lui and Timothy Baldwin. 2012. langid.py: An off-the-shelf language identification tool. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Demo Session (ACL’12), Jeju, Republic of Korea.","Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving machine translation performance by exploit-ing non-parallel corpora. Computational Linguistics, 31(4).","Dragos Stefan Munteanu and Daniel Marcu. 2006. Extracting parallel sub-sentential fragments from non-parallel corpora. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics (COLING-ACL’06), Sydney, Australia.","Eric W. Noreen. 1989. Computer Intensive Methods for Testing Hypotheses. An Introduction. Wiley, New York.","Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1).","Stefan Riezler and John Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing for MT. In Proceedings of the ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization, Ann Arbor, MI.","Stephen E. Robertson, Steve Walker, and Micheline Hancock-Beaulieu. 1998. Okapi at TREC-7. In Proceedings of the Seventh Text REtrieval Conference (TREC-7), Gaithersburg, MD.","Matthew Snover, Bonnie Dorr, and Richard Schwartz. 2008. Language and translation model adaptation using comparable corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08), Honolulu, Hawaii.","Ferhan Ture and Jimmy Lin. 2012. Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT’12), Montreal, Canada.","Ferhan Ture, Jimmy Lin, and Douglas W. Oard. 2012. Combining statistical translation techniques for cross-language information retrieval. In Proceedings of the International Conference on Computational Linguistics (COLING’12), Mumbai, India.","Ferhan Ture, Jimmy Lin, and Douglas W. Oard. 2012a. Looking inside the box: Context-sensitive translation for cross-language information retrieval. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’12), Portland, OR.","Jakob Uszkoreit, Jay M. Ponte, Ashok C. Popat, and Moshe Dubiner. 2010. Large scale parallel document mining for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING’10), Beijing, China.","Jinxi Xu, Ralph Weischedel, and Chanh Nguyen. 2001. Evaluating a probabilistic model for cross-lingual information retrieval. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’01), New York, NY. 327"]}],"references":[{"authors":[{"first":"Sadaf","last":"Abdul-Rauf"},{"first":"Holger","last":"Schwenk"}],"year":"2009","title":"On the use of comparable corpora to improve SMT performance","source":"Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the use of comparable corpora to improve SMT performance. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL’09), Athens, Greece."},{"authors":[{"first":"Steven","last":"Abney"}],"year":"2008","title":"Semisupervised Learning for Computational Linguistics","source":"Steven Abney. 2008. Semisupervised Learning for Computational Linguistics. Chapman and Hall."},{"authors":[{"first":"Nicola","last":"Bertoldi"},{"first":"Marcello","last":"Federico"}],"year":"2009","title":"Domain adaptation for statistical machine translation with monolingual resources","source":"Nicola Bertoldi and Marcello Federico. 2009. Domain adaptation for statistical machine translation with monolingual resources. In Proceedings of the 4th EACL Workshop on Statistical Machine Translation (WMT’09), Athens, Greece."},{"authors":[{"first":"Peter","middle":"F.","last":"Brown"},{"first":"Stephen","middle":"A. Della","last":"Pietra"},{"first":"Vincent","middle":"J. Della","last":"Pietra"},{"first":"Robert","middle":"L.","last":"Mercer"}],"year":"1993","title":"The mathematics of statistical machine translation: Parameter estimation","source":"Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2)."},{"authors":[{"first":"David","last":"Chiang"}],"year":"2007","title":"Hierarchical phrase-based translation","source":"David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2)."},{"authors":[{"first":"Chris","last":"Dyer"},{"first":"Adam","last":"Lopez"},{"first":"Juri","last":"Ganitkevitch"},{"first":"Jonathan","last":"Weese"},{"first":"Ferhan","last":"Ture"},{"first":"Phil","last":"Blunsom"},{"first":"Hendra","last":"Setiawan"},{"first":"Vladimir","last":"Eidelman"},{"first":"Philip","last":"Resnik"}],"year":"2010","title":"cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models","source":"Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of the ACL 2010 System Demonstrations (ACL’10), Uppsala, Sweden."},{"authors":[{"first":"Laura","last":"Jehl"},{"first":"Felix","last":"Hieber"},{"first":"Stefan","last":"Riezler"}],"year":"2012","title":"Twitter translation using translation-based cross-lingual retrieval","source":"Laura Jehl, Felix Hieber, and Stefan Riezler. 2012. Twitter translation using translation-based cross-lingual retrieval. In Proceedings of the Seventh Workshop on Statistical Machine Translation (WMT’12), Montreal, Quebec, Canada."},{"authors":[{"first":"Philipp","last":"Koehn"},{"first":"Josh","last":"Schroeder"}],"year":"2007","title":"Experiments in domain adaptation for statistical machine translation","source":"Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, Prague, Czech Republic."},{"authors":[{"first":"Chin-Yew","last":"Lin"},{"first":"Franz","middle":"Josef","last":"Och"}],"year":"2004","title":"Orange: a method for evaluating automatic evaluation metrics for machine translation","source":"Chin-Yew Lin and Franz Josef Och. 2004. Orange: a method for evaluating automatic evaluation metrics for machine translation. In Proceedings the 20th International Conference on Computational Linguistics (COLING’04)."},{"authors":[{"first":"Marco","last":"Lui"},{"first":"Timothy","last":"Baldwin"}],"year":"2012","title":"langid","source":"Marco Lui and Timothy Baldwin. 2012. langid.py: An off-the-shelf language identification tool. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Demo Session (ACL’12), Jeju, Republic of Korea."},{"authors":[{"first":"Dragos","middle":"Stefan","last":"Munteanu"},{"first":"Daniel","last":"Marcu"}],"year":"2005","title":"Improving machine translation performance by exploit-ing non-parallel corpora","source":"Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving machine translation performance by exploit-ing non-parallel corpora. Computational Linguistics, 31(4)."},{"authors":[{"first":"Dragos","middle":"Stefan","last":"Munteanu"},{"first":"Daniel","last":"Marcu"}],"year":"2006","title":"Extracting parallel sub-sentential fragments from non-parallel corpora","source":"Dragos Stefan Munteanu and Daniel Marcu. 2006. Extracting parallel sub-sentential fragments from non-parallel corpora. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics (COLING-ACL’06), Sydney, Australia."},{"authors":[{"first":"Eric","middle":"W.","last":"Noreen"}],"year":"1989","title":"Computer Intensive Methods for Testing Hypotheses","source":"Eric W. Noreen. 1989. Computer Intensive Methods for Testing Hypotheses. An Introduction. Wiley, New York."},{"authors":[{"first":"Franz","middle":"Josef","last":"Och"},{"first":"Hermann","last":"Ney"}],"year":"2003","title":"A systematic comparison of various statistical alignment models","source":"Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1)."},{"authors":[{"first":"Stefan","last":"Riezler"},{"first":"John","last":"Maxwell"}],"year":"2005","title":"On some pitfalls in automatic evaluation and significance testing for MT","source":"Stefan Riezler and John Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing for MT. In Proceedings of the ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization, Ann Arbor, MI."},{"authors":[{"first":"Stephen","middle":"E.","last":"Robertson"},{"first":"Steve","last":"Walker"},{"first":"Micheline","last":"Hancock-Beaulieu"}],"year":"1998","title":"Okapi at TREC-7","source":"Stephen E. Robertson, Steve Walker, and Micheline Hancock-Beaulieu. 1998. Okapi at TREC-7. In Proceedings of the Seventh Text REtrieval Conference (TREC-7), Gaithersburg, MD."},{"authors":[{"first":"Matthew","last":"Snover"},{"first":"Bonnie","last":"Dorr"},{"first":"Richard","last":"Schwartz"}],"year":"2008","title":"Language and translation model adaptation using comparable corpora","source":"Matthew Snover, Bonnie Dorr, and Richard Schwartz. 2008. Language and translation model adaptation using comparable corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08), Honolulu, Hawaii."},{"authors":[{"first":"Ferhan","last":"Ture"},{"first":"Jimmy","last":"Lin"}],"year":"2012","title":"Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling","source":"Ferhan Ture and Jimmy Lin. 2012. Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT’12), Montreal, Canada."},{"authors":[{"first":"Ferhan","last":"Ture"},{"first":"Jimmy","last":"Lin"},{"first":"Douglas","middle":"W.","last":"Oard"}],"year":"2012","title":"Combining statistical translation techniques for cross-language information retrieval","source":"Ferhan Ture, Jimmy Lin, and Douglas W. Oard. 2012. Combining statistical translation techniques for cross-language information retrieval. In Proceedings of the International Conference on Computational Linguistics (COLING’12), Mumbai, India."},{"authors":[{"first":"Ferhan","last":"Ture"},{"first":"Jimmy","last":"Lin"},{"first":"Douglas","middle":"W.","last":"Oard"}],"year":"2012a","title":"Looking inside the box: Context-sensitive translation for cross-language information retrieval","source":"Ferhan Ture, Jimmy Lin, and Douglas W. Oard. 2012a. Looking inside the box: Context-sensitive translation for cross-language information retrieval. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’12), Portland, OR."},{"authors":[{"first":"Jakob","last":"Uszkoreit"},{"first":"Jay","middle":"M.","last":"Ponte"},{"first":"Ashok","middle":"C.","last":"Popat"},{"first":"Moshe","last":"Dubiner"}],"year":"2010","title":"Large scale parallel document mining for machine translation","source":"Jakob Uszkoreit, Jay M. Ponte, Ashok C. Popat, and Moshe Dubiner. 2010. Large scale parallel document mining for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING’10), Beijing, China."},{"authors":[{"first":"Jinxi","last":"Xu"},{"first":"Ralph","last":"Weischedel"},{"first":"Chanh","last":"Nguyen"}],"year":"2001","title":"Evaluating a probabilistic model for cross-lingual information retrieval","source":"Jinxi Xu, Ralph Weischedel, and Chanh Nguyen. 2001. Evaluating a probabilistic model for cross-lingual information retrieval. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’01), New York, NY. 327"}],"cites":[{"style":0,"text":"Brown et al., 1993","origin":{"pointer":"/sections/2/paragraphs/0","offset":91,"length":18},"authors":[{"last":"Brown"},{"last":"al."}],"year":"1993","references":["/references/3"]},{"style":0,"text":"Abney, 2008","origin":{"pointer":"/sections/3/paragraphs/0","offset":48,"length":11},"authors":[{"last":"Abney"}],"year":"2008","references":["/references/1"]},{"style":0,"text":"Marcu, 2005","origin":{"pointer":"/sections/3/paragraphs/1","offset":185,"length":11},"authors":[{"last":"Marcu"}],"year":"2005","references":[]},{"style":0,"text":"Munteanu and Marcu, 2006","origin":{"pointer":"/sections/3/paragraphs/1","offset":198,"length":24},"authors":[{"last":"Munteanu"},{"last":"Marcu"}],"year":"2006","references":["/references/11"]},{"style":0,"text":"Abdul-Rauf and Schwenk, 2009","origin":{"pointer":"/sections/3/paragraphs/1","offset":252,"length":28},"authors":[{"last":"Abdul-Rauf"},{"last":"Schwenk"}],"year":"2009","references":["/references/0"]},{"style":0,"text":"Uszkoreit et al., 2010","origin":{"pointer":"/sections/3/paragraphs/1","offset":282,"length":22},"authors":[{"last":"Uszkoreit"},{"last":"al."}],"year":"2010","references":["/references/20"]},{"style":0,"text":"Snover et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":400,"length":19},"authors":[{"last":"Snover"},{"last":"al."}],"year":"2008","references":["/references/16"]},{"style":0,"text":"Jehl et al., 2012","origin":{"pointer":"/sections/3/paragraphs/1","offset":421,"length":17},"authors":[{"last":"Jehl"},{"last":"al."}],"year":"2012","references":["/references/6"]},{"style":0,"text":"Ture and Lin, 2012","origin":{"pointer":"/sections/3/paragraphs/1","offset":440,"length":18},"authors":[{"last":"Ture"},{"last":"Lin"}],"year":"2012","references":["/references/17"]},{"style":0,"text":"Bertoldi and Federico, 2009","origin":{"pointer":"/sections/3/paragraphs/2","offset":58,"length":27},"authors":[{"last":"Bertoldi"},{"last":"Federico"}],"year":"2009","references":["/references/2"]},{"style":0,"text":"Koehn and Schroeder, 2007","origin":{"pointer":"/sections/3/paragraphs/2","offset":144,"length":25},"authors":[{"last":"Koehn"},{"last":"Schroeder"}],"year":"2007","references":["/references/7"]},{"style":0,"text":"Xu et al. (2001)","origin":{"pointer":"/sections/4/paragraphs/0","offset":64,"length":16},"authors":[{"last":"Xu"},{"last":"al."}],"year":"2001","references":["/references/21"]},{"style":0,"text":"Robertson et al., 1998","origin":{"pointer":"/sections/4/paragraphs/1","offset":397,"length":22},"authors":[{"last":"Robertson"},{"last":"al."}],"year":"1998","references":["/references/15"]},{"style":0,"text":"Chiang, 2007","origin":{"pointer":"/sections/4/paragraphs/3","offset":59,"length":12},"authors":[{"last":"Chiang"}],"year":"2007","references":["/references/4"]},{"style":0,"text":"Dyer et al., 2010","origin":{"pointer":"/sections/4/paragraphs/3","offset":112,"length":17},"authors":[{"last":"Dyer"},{"last":"al."}],"year":"2010","references":["/references/5"]},{"style":0,"text":"Jehl et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/1","offset":66,"length":18},"authors":[{"last":"Jehl"},{"last":"al."}],"year":"2012","references":["/references/6"]},{"style":0,"text":"Lui and Baldwin, 2012","origin":{"pointer":"/sections/5/paragraphs/1","offset":184,"length":21},"authors":[{"last":"Lui"},{"last":"Baldwin"}],"year":"2012","references":["/references/9"]},{"style":0,"text":"Jehl et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/1","offset":390,"length":18},"authors":[{"last":"Jehl"},{"last":"al."}],"year":"2012","references":["/references/6"]},{"style":0,"text":"Lin and Och, 2004","origin":{"pointer":"/sections/5/paragraphs/1","offset":1550,"length":17},"authors":[{"last":"Lin"},{"last":"Och"}],"year":"2004","references":["/references/8"]},{"style":0,"text":"Jehl et al. (2012)","origin":{"pointer":"/sections/5/paragraphs/3","offset":598,"length":18},"authors":[{"last":"Jehl"},{"last":"al."}],"year":"2012","references":["/references/6"]},{"style":0,"text":"Och and Ney, 2003","origin":{"pointer":"/sections/5/paragraphs/4","offset":393,"length":17},"authors":[{"last":"Och"},{"last":"Ney"}],"year":"2003","references":["/references/13"]},{"style":0,"text":"Noreen, 1989","origin":{"pointer":"/sections/5/paragraphs/5","offset":202,"length":12},"authors":[{"last":"Noreen"}],"year":"1989","references":["/references/12"]},{"style":0,"text":"Riezler and Maxwell, 2005","origin":{"pointer":"/sections/5/paragraphs/5","offset":216,"length":25},"authors":[{"last":"Riezler"},{"last":"Maxwell"}],"year":"2005","references":["/references/14"]},{"style":0,"text":"Jehl et al. (2012)","origin":{"pointer":"/sections/6/paragraphs/2","offset":73,"length":18},"authors":[{"last":"Jehl"},{"last":"al."}],"year":"2012","references":["/references/6"]}]}
