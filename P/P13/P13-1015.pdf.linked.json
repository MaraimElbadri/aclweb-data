{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 145–154, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Generic binarization for parsing and translation Matthias B üchse Technische Universität Dresden","paragraphs":["matthias.buechse@tu-dresden.de"]},{"title":"Alexander Koller University of Potsdam","paragraphs":["koller@ling.uni-potsdam.de"]},{"title":"Heiko Vogler Technische Universität Dresden","paragraphs":["heiko.vogler@tu-dresden.de"]},{"title":"Abstract","paragraphs":["Binarization of grammars is crucial for improving the complexity and performance of parsing and translation. We present a versatile binarization algorithm that can be tailored to a number of grammar formalisms by simply varying a formal parameter. We apply our algorithm to binarizing tree-to-string transducers used in syntax-based machine translation."]},{"title":"1 Introduction","paragraphs":["Binarization amounts to transforming a given grammar into an equivalent grammar of rank 2, i.e., with at most two nonterminals on any right-hand side. The ability to binarize grammars is crucial for efficient parsing, because for many grammar formalisms the parsing complexity depends exponentially on the rank of the grammar. It is also critically important for tractable statistical machine translation (SMT). Syntax-based SMT systems (Chiang, 2007; Graehl et al., 2008) typically use some type of synchronous grammar describing a binary translation relation between strings and/or trees, such as synchronous context-free grammars (SCFGs) (Lewis and Stearns, 1966; Chiang, 2007), synchronous tree-substitution grammars (Eisner, 2003), synchronous tree-adjoining grammars (Nesson et al., 2006; DeNeefe and Knight, 2009), and tree-to-string transducers (Yamada and Knight, 2001; Graehl et al., 2008). These grammars typically have a large number of rules, many of which have rank greater than two.","The classical approach to binarization, as known from the Chomsky normal form transformation for context-free grammars (CFGs), proceeds rule by rule. It replaces each rule of rank greater than 2 by an equivalent collection of rules of rank 2. All CFGs can be binarized in this way, which is why their recognition problem is cubic. In the case of linear context-free rewriting systems (LCFRSs, (Weir, 1988)) the rule-by-rule technique also applies to every grammar, as long as an increased fanout it permitted (Rambow and Satta, 1999).","There are also grammar formalisms for which the rule-by-rule technique is not complete. In the case of SCFGs, not every grammar has an equivalent representation of rank 2 in the first place (Aho and Ullman, 1969). Even when such a representation exists, it is not always possible to compute it rule by rule. Nevertheless, the rule-by-rule binarization algorithm of Huang et al. (2009) is very useful in practice.","In this paper, we offer a generic approach for transferring the rule-by-rule binarization technique to new grammar formalisms. At the core of our approach is a binarization algorithm that can be adapted to a new formalism by changing a parameter at runtime. Thus it only needs to be implemented once, and can then be reused for a variety of formalisms. More specifically, our algorithm requires the user to (i) encode the grammar formalism as a subclass of interpreted regular tree grammars (IRTGs, (Koller and Kuhlmann, 2011)) and (ii) supply a collection of b-rules, which represent equivalence of grammars syntactically. Our algorithm then replaces, in a given grammar, each rule of rank greater than 2 by an equivalent collection of rules of rank 2, if such a collection is licensed by the b-rules. We define completeness of b-rules in a way that ensures that if any equivalent collection of rules of rank 2 exists, the algorithm finds one. As a consequence, the algorithm binarizes every grammar that can be binarized rule by rule. Step (i) is possible for all the grammar formalisms mentioned above. We show Step (ii) for SCFGs and tree-to-string transducers.","We will use SCFGs as our running example throughout the paper. We will also apply the algo-145 rithm to tree-to-string transducers (Graehl et al., 2008; Galley et al., 2004), which describe relations between strings in one language and parse trees of another, which means that existing methods for binarizing SCFGs and LCFRSs cannot be directly applied to these systems. To our knowledge, our binarization algorithm is the first to binarize such transducers. We illustrate the effectiveness of our system by binarizing a large tree-to-string transducer for English-German SMT. Plan of the paper. We start by defining IRTGs in Section 2. In Section 3, we define the general outline of our approach to rule-by-rule binarization for IRTGs, and then extend this to an efficient binarization algorithm based on b-rules in Section 4. In Section 5 we show how to use the algorithm to perform rule-by-rule binarization of SCFGs and tree-to-string transducers, and relate the results to existing work."]},{"title":"2 Interpreted regular tree grammars","paragraphs":["Grammar formalisms employed in parsing and SMT, such as those mentioned in the introduc-tion, differ in the the derived objects—e.g., strings, trees, and graphs—and the operations involved in the derivation—e.g., concatenation, substitution, and adjoining. Interpreted regular tree grammars (IRTGs) permit a uniform treatment of many of these formalisms. To this end, IRTGs combine two ideas, which we explain here. Algebras IRTGs represent the objects and operations symbolically using terms; the object in question is obtained by interpreting each symbol in the term as a function. As an example, Table 1 shows terms for a string and a tree, together with the denoted object. In the string case, we describe complex strings as concatenation (con2",") of elementary symbols (e.g., a, b); in the tree case, we alternate the construction of a sequence of trees (con2",") with the construction of a single tree by placing a symbol (e.g., α, β, σ) on top of a (possibly empty) sequence of trees. Whenever a term contains variables, it does not denote an object, but rather a function. In the parlance of universal-algebra theory, we are employing initial-algebra semantics (Goguen et al., 1977).","An alphabet is a nonempty finite set. Through-out this paper, let X = {x1, x2, . . . } be a set, whose elements we call variables. We let Xk denote the set {x1, . . . , xk} for every k ≥ 0. Let Σ be an alphabet and V ⊆ X. We write TΣ(V ) for the set of all terms over Σ with variables V , i.e., the smallest set T such that (i) V ⊆ T and (ii) for every σ ∈ Σ, k ≥ 0, and t1, . . . , tk ∈ T , we have σ(t1, . . . , tk) ∈ T . Alternatively, we view TΣ(V ) as the set of all (rooted, labeled, ordered, unranked) trees over Σ and V , and draw them as usual. By TΣ we abbreviate TΣ(∅). The set CΣ(V ) of contexts over Σ and V is the set of all trees over Σ and V in which each variable in V occurs exactly once.","A signature is an alphabet Σ where each symbol is equipped with an arity. We write Σ|k for the subset of all k-ary symbols of Σ, and σ|k to denote σ ∈ Σ|k. We denote the signature by Σ as well. A signature is binary if the arities do not exceed 2. Whenever we use TΣ(V ) with a signature Σ, we assume that the trees are ranked, i.e., each node labeled by σ ∈ Σ|k has exactly k children.","Let ∆ be a signature. A ∆-algebra A consists of a nonempty set A called the domain and, for each symbol f ∈ ∆ with rank k, a total function f A",": Ak","→ A, the operation associated with f . We can evaluate any term t in T∆(Xk) in A, to obtain a k-ary operation tA","over the domain. In particular, terms in T∆ evaluate to elements of A. For instance, in the string algebra shown in Table 1, the term con2","(a, b) evaluates to ab, and the term con2","(con2","(x","2, a), x1) evaluates to a binary operation f such that, e.g., f (b, c) = cab. Bimorphisms IRTGs separate the finite control (state behavior) of a derivation from its derived object (in its term representation; generational behavior); the former is captured by a regular tree language, while the latter is obtained by applying a tree homomorphism. This idea goes back to the tree bimorphisms of Arnold and Dauchet (1976).","Let Σ be a signature. A regular tree grammar (RTG) G over Σ is a triple (Q, q0, R) where Q is a finite set (of states), q0 ∈ Q, and R is a finite set of rules of the form q → α(q1, . . . , qk), where q ∈ Q, α ∈ Σ|k and q, q1, . . . , qk ∈ Q. We call α the terminal symbol and k the rank of the rule. Rules of rank greater than two are called suprabinary. For every q ∈ Q we define thelanguage Lq","(G) derived from q as the set {α(t1, . . . , tk) | q → α(q1, . . . , qk) ∈ R, tj ∈ Lqj","(G)}. If q = q","0, we drop the superscript and write L(G) for the tree language of G. In the literature, there is a definition of RTG which also permits more than one terminal symbol per rule, 146 strings over Γ trees over Γ","example term and denoted object con2 a b ↦→ ab σ con2 α con0 β con0 ↦→ σ α β","domain Γ∗ T ∗ Γ (set of sequences of trees)","signature ∆ {a|0 | a ∈ Γ} ∪ {γ|1 | γ ∈ Γ} ∪","{conk","|k | 0 ≤ k ≤ K, k ̸= 1} {conk","|k | 0 ≤ k ≤ K, k ̸= 1}","operations a : () ↦→ a γ : x1 ↦→ γ(x1) conk",": (x","1, . . . , xk) ↦→ x1 · · · xk conk : (x 1, . . . , xk) ↦→ x1 · · · xk Table 1: Algebras for strings and trees, given an alphabet Γ and a maximum arity K ∈ N. or none. This does not increase the generative capacity (Brainerd, 1969).","A (linear, nondeleting) tree homomorphism is a mapping h : TΣ(X) → T∆(X) that satisfies the following condition: there is a mapping g : Σ → T∆(X) such that (i) g(σ) ∈ C∆(Xk) for every σ ∈ Σ|k, (ii) h(σ(t1, . . . , tk)) is the tree obtained from g(σ) by replacing the occurrence of xj by h(tj), and (iii) h(xj) = xj. This extends the usual definition of linear and nondeleting homomorphisms (Gécseg and Steinby, 1997) to trees with variables. We abuse notation and write h(σ) for g(σ) for every σ ∈ Σ.","Let n ≥ 1 and ∆1, . . . , ∆n be signatures. A (generalized) bimorphism over (∆1, . . . , ∆n) is a tuple B = (G, h1, . . . , hn) where G is an RTG over some signature Σ and hi is a tree homomorphism from TΣ(X) into T∆i(X). The language L(B) induced by B is the tree relation {(h1(t), . . . , hn(t)) | t ∈ L(G)}.","An IRTG is a bimorphism whose derived trees are viewed as terms over algebras; see Fig. 1. Formally, an IRTG G over (∆1, . . . , ∆n) is a tuple (B, A1, . . . , An) such that B is a bimorphism over (∆1, . . . , ∆n) and Ai is a ∆i-algebra. The language L(G) induced by G is the relation {(tA1","1 , . . . , tAn","n ) | (t1, . . . , tn) ∈ L(B)}. We call the trees in L(G) derivation trees and the terms in L(B) semantic terms. We say that two IRTGs G and G′","are equivalent if L(G) = L(G′","). IRTGs were first defined in (Koller and Kuhlmann, 2011).","For example, Fig. 2 is an IRTG that encodes a synchronous context-free grammar (SCFG). It contains a bimorphism B = (G, h1, h2) consist-ing of an RTG G with four rules and homomor-L(G) T∆1 · · · T∆n A1 · · · An h1 hn","(.)A1 (.)An ⊆ TΣ bimorphism B = (G, h1, h2) IRTG G = (B, A1, A2)","derivation trees semantic terms derived objects Figure 1: IRTG, bimorphism overview.","A → α(B, C, D) B → α1, C → α2, D → α3 con3 x1 x2 x3 h1 ←− α h2 ↦−→ con4 x3 a x1 x2 b h1 ←− α1 h2 ↦−→ b c h1 ←− α2 h2 ↦−→ c d h1 ←− α3 h2 ↦−→ d Figure 2: An IRTG encoding an SCFG. phisms h1 and h2 which map derivation trees to trees over the signature of the string algebra in Table 1. By evaluating these trees in the algebra, the symbols con3","and con4","are interpreted as concatenation, and we see that the first rule encodes the SCFG rule A → ⟨BCD, DaBC⟩. Figure 3 shows a derivation tree with its two homomorphic images, which evaluate to the strings bcd and dabc.","IRTGs can be tailored to the expressive capacity of specific grammar formalisms by selecting suit-able algebras. The string algebra in Table 1 yields context-free languages, more complex string al-147 con3 b c d h1 ←− α α1 α2 α3 h2 ↦−→ con4 d a b c Figure 3: Derivation tree and semantic terms.","A → α′","(A′",", D)","A′","→ α′′","(B, C) con2 x1 x2 h′ 1 ←− α′ h′","2","↦−→ con2 con2 x2 a x1 con2 x1 x2 h′ 1 ←− α′′ h′","2","↦−→ con2 x1 x2 Figure 4: Binary rules corresponding to the α-rule in Fig. 2. gebras yield tree-adjoining languages (Koller and Kuhlmann, 2012), and algebras over other do-mains can yield languages of trees, graphs, or other objects. Furthermore, IRTGs with n = 1 describe languages that are subsets of the algebra’s domain, n = 2 yields synchronous languages or tree transductions, and so on."]},{"title":"3 IRTG binarization","paragraphs":["We will now show how to apply the rule-by-rule binarization technique to IRTGs. We start in this section by defining the binarization of a rule in an IRTG, and characterizing it in terms of binarization terms and variable trees. We derive the actual binarization algorithm from this in Section 4.","For the remainder of this paper, let G = (B, A1, . . . , An) be an IRTG over (∆1, . . . , ∆n) with B = (G, h1, . . . , hn). 3.1 An introductory example We start with an example to give an intuition of our approach. Consider the first rule in Fig. 2, which has rank three. This rule derives (in one step) the fragment α(x1, x2, x3) of the derivation tree in Fig. 3, which is mapped to the semantic terms h1(α) and h2(α) shown in Fig. 2. Now consider the rules in Fig. 4. These rules can be used to derive (in two steps) the derivation tree fragment ξ in Fig. 5e. Note that the terms h′","1(ξ) and h1(α) are equivalent in that they denote the same function over the string algebra, and so are the terms h′ 2(ξ) and h2(α). Thus, replacing the α-rule by the rules in Fig. 4 does not change the language of the IRTG. However, since the new rules are binary, (a)","con3 x1 x2 x3","con4 x3 a x1 x2 (b) con2","x1 con2 x2 x3 con2 con2 x1 x2","x3t1 : con2 con2 x3 a con2 x1 x2 t2 : con2 con2","x3 con2 a x1 x2 (c) (d) con2 x1 x2","x1 con2 x1 x2 x1 x2 con2 con2 x2 a x1","x1 con2 x1 x2 x1 x2 (e) h1 ←− α h2","↦−→ {x1, x2, x3} {x1} {x2, x3} {x2} {x3} {x1, x2, x3} {x1, x2} {x1} {x2} {x3} τ : {x1, x2, x3} {x1, x3} {x1} {x3} {x2} con2 con2 x1 x2 x3 t1 : h′ 1 ←− α′ α′′ x1 x2 x3 ξ : h′ 2 ↦−→ con2 con2 x3 a con2 x1 x2 t2 : Figure 5: Outline of the binarization algorithm. parsing and translation will be cheaper.","Now we want to construct the binary rules systematically. In the example, we proceed as follows (cf. Fig. 5). For each of the terms h1(α) and h2(α) (Fig. 5a), we consider all terms that satisfy two properties (Fig. 5b): (i) they are equivalent to h1(α) and h2(α), respectively, and (ii) at each node at most two subtrees contain variables. As Fig. 5 suggests, there may be many different terms of this kind. For each of these terms, we analyze the bracketing of variables, obtaining what we call a variable tree (Fig. 5c). Now we pick terms t1 and t2 corresponding to h1(α) and h2(α), respectively, such that (iii) they have the same variable tree, say τ . We construct a tree ξ from τ by a simple relabeling, and we read off the tree homomorphisms h′","1 and h′","2 from a decomposition we perform on t1 and t2, respectively; see Fig. 5, dotted arrows, and compare the boxes in Fig. 5d with the homomorphisms in Fig. 4. Now the rules in Fig. 4 are easily extracted from ξ.","These rules are equivalent to r because of (i); they are binary because ξ is binary, which in turn holds because of (ii); finally, the decompositions of t1 and t2 are compatible with ξ because of (iii). We call terms t1 and t2 binarization terms if they satisfy (i)–(iii). We will see below that we can con-148 struct binary rules equivalent to r from any given sequence of binarization terms t1, t2, and that binarization terms exist whenever equivalent binary rules exist. The majority of this paper revolves around the question of finding binarization terms.","Rule-by-rule binarization of IRTGs follows the intuition laid out in this example closely: it means processing each suprabinary rule, attempting to replace it with an equivalent collection of binary rules. 3.2 Binarization terms","We will now make this intuition precise. To this","end, we assume that r = q → α(q1, . . . , qk) is a","suprabinary rule of G. As we have seen, binariz-","ing r boils down to constructing: • a tree ξ over some binary signature Σ′","and • tree homomorphisms h′","1, . . . , h′","n of type","h′","i : TΣ′(X) → T∆i(X), such that h′","i(ξ) and hi(α) are equivalent, i.e., they denote the same function over Ai. We call such a tuple (ξ, h′","1, . . . , h′","n) a binarization of the rule r. Note that a binarization of r need not exist. The problem of rule-by-rule binarization consists in computing a binarization of each suprabinary rule of a grammar. If such a binarization does not exist, the problem does not have a solution.","In order to define variable trees, we assume a mapping seq that maps each finite set U of pairwise disjoint variable sets to a sequence over U which contains each element exactly once. Let t ∈ C∆(Xk). The variable set of t is the set of all variables that occur in t. The set S(t) of subtree variables of t consists of the nonempty variable sets of all subtrees of t. We represent S(t) as a tree v(t), which we call variable tree as follows. Any two elements of S(t) are either comparable (with respect to the subset relation) or disjoint. We extend this ordering to a tree structure by ordering disjoint elements via seq. We let v(L) = {v(t) | t ∈ L} for every L ⊆ C∆(Xk).","In the example of Fig. 5, t1 and t2 have the same set of subtree variables; it is {{x1}, {x2}, {x3}, {x1, x2}, {x1, x2, x3}}. If we assume that seq orders sets of variables according to the least variable index, we arrive at the variable tree in the center of Fig. 5.","Now let t1 ∈ T∆1(Xk), . . . , tn ∈ T∆n(Xk). We call the tuple t1, . . . , tn binarization terms of r if the following properties hold: (i) hi(α) and ti are equivalent; (ii) at each node the tree ti contains at most two subtrees with variables; and (iii) the terms t1, . . . , tn have the same variable tree.","Assume for now that we have found binarization terms t1, . . . , tn. We show how to construct a binarization (ξ, h′","1, . . . , h′","n) of r with ti = h′","i(ξ).","First, we construct ξ. Since t1, . . . , tn are binarization terms, they have the same variable tree, say, τ . We obtain ξ from τ by replacing every label of the form {xj} with xj, and every other label with a fresh symbol. Because of condition (ii) in in the definition of binarization terms,ξ is binary.","In order to construct h′","i(σ) for each symbol σ in ξ, we transform ti into a tree t′","i with labels from C∆i(X) and the same structure as ξ. Then we read off h′","i(σ) from the node of t′","i that corresponds to the σ-labeled node of ξ. The transformation proceeds as illustrated in Fig. 6: first, we apply the maximal decomposition operation ⇝d; it replaces every label f ∈ ∆i|k by the tree f (x1, . . . , xk), represented as a box. After that, we keep applying the merge operation ⇝m as often as possible; it merges two boxes that are in a parent-child relation, given that one of them has at most one child. Thus the number of variables in any box can only decrease. Finally, the reorder operation ⇝o orders the children of each box according to the seq of their variable sets. These operations do not change the variable tree; one can use this to show that t′","i has the same structure as ξ. Thus, if we can find binarization terms, we can construct a binarization of r. Conversely, for any given binarization (ξ, h′","1, . . . , h′","n) the seman-","tic terms h′","1(ξ), . . . , h′","n(ξ) are binarization terms.","This proves the following lemma. Lemma 1 There is a binarization of r if and only if there are binarization terms of r. 3.3 Finding binarization terms It remains to show how we can find binarization terms of r, if there are any.","Let bi : T∆i(Xk) → P(T∆i(Xk)) the mapping with bi(t) = {t′","∈ T∆i(Xk) | t and t′","are equivalent, and at each node t′","has at most two children with variables}. Figure 5b shows some elements of b1(h1(α)) and b2(h2(α)) for our example. Terms t1, . . . , tn are binarization terms precisely when ti ∈ bi(hi(α)) and t1, . . . , tn have the same variable tree. Thus we can characterize binarization terms as follows. Lemma 2 There are binarization terms if and only if ⋂ i v(bi(hi(α))) ̸= ∅. 149 con2 con2 x3 a con2 x1 x2 ⇝d con2 x1 x2 con2 x1 x2 x3 a con2 x1 x2 x1 x2 ⇝m con2 x1 x2 con2 x1 a x3 con2 x1 x2 x1 x2 ⇝m con2 con2 x1 a x2 x3 con2 x1 x2 x1 x2 ⇝o con2 con2 x2 a x1 con2 x1 x2 x1 x2 x3","Figure 6: Transforming t2 into t′ 2.","This result suggests the following procedure for obtaining binarization terms. First, determine whether the intersection in Lemma 2 is empty. If it is, then there is no binarization of r. Otherwise, select a variable tree τ from this set. We know that there are trees t1, . . . , tn such that ti ∈ bi(hi(α)) and v(ti) = τ . We can therefore select arbitrary concrete trees ti ∈ bi(hi(α)) ∩ v−1","(τ ). The terms t1, . . . , tn are then binarization terms."]},{"title":"4 Effective IRTG binarization","paragraphs":["In this section we develop our binarization algorithm. Its key task is finding binarization terms t1, . . . , tn. This task involves deciding term equivalence, as ti must be equivalent to hi(α). In general, equivalence is undecidable, so the task cannot be solved. We avoid deciding equivalence by requiring the user to specify an explicit approximation of bi, which we call a b-rule. This parameter gives rise to a restricted version of the rule-by-rule binarization problem, which is efficiently computable while remaining practically relevant.","Let ∆ be a signature. A binarization rule (b-rule) over ∆ is a mapping b : ∆ → P(T∆(X)) where for every f ∈ ∆|k we have that b(f ) ⊆ C∆(Xk), at each node of a tree in b(f ) only two children contain variables, and b(f ) is a regular tree language. We extend b to T∆(X) by setting b(xj) = {xj} and b(f (t1, . . . , tk)) = {t[xj/t′","j |","1 ≤ j ≤ k] | t ∈ b(f ), t′ j ∈ b(tj)}, where [xj/t′","j] denotes substitution of xj by t′","j. Given an algebra A over ∆, a b-rule b over ∆ is called a b-rule over A if, for every t ∈ T∆(Xk) and t′","∈ b(t), t′","and t are equivalent in A. Such a b-rule encodes equivalence in A, and it does so in an explicit and compact way: because b(f ) is a regular tree language, a b-rule can be specified by a finite collection of RTGs, one for each symbol f ∈ ∆. We will look at examples (for the string and tree algebras shown earlier) in Section 5.","From now on, we assume that b1, . . . , bn are b-rules over A1, . . . , An, respectively. A binarization (ξ, h′","1, . . . , h′","n) of r is a binarization of r with respect to b1, . . . , bn if h′","i(ξ) ∈ bi(hi(α)). Likewise, binarization terms t1, . . . , tn are binarization terms with respect to b1, . . . , bn if ti ∈ bi(hi(α)). Lemmas 1 and 2 carry over to the restricted notions. The problem of rule-by-rule binarization with respect to b1, . . . , bn consists in computing a binarization with respect to b1, . . . , bn for each suprabinary rule.","By definition, every solution to this restricted problem is also a solution to the general problem. The converse need not be true. However, we can guarantee that the restricted problem has at least one solution whenever the general problem has one, by requiring v(bi(hi(α)) = v(b(hi(α)). Then the intersection in Lemma 2 is empty in the restricted case if and only if it is empty in the general case. We call the b-rules b1, . . . , b1 complete on G if the equation holds for every α ∈ Σ.","Now we show how to effectively compute binarization terms with respect to b1, . . . , bn, along the lines of Section 3.3. More specifically, we construct an RTG for each of the sets (i) bi(hi(α)), (ii) b′","i = v(bi(hi(α))), (iii) ⋂","i b′","i, and (iv) b′′","i = bi(hi(α))∩v−1","(τ ) (given τ ). Then we can select τ from (iii) and ti from (iv) using a standard algorithm, such as the Viterbi algorithm or Knuth’s algorithm (Knuth, 1977; Nederhof, 2003; Huang and Chiang, 2005). The effectiveness of our procedure stems from the fact that we only manipulate RTGs and never enumerate languages.","The construction for (i) is recursive, following the definition of bi. The base case is a language {xj}, for which the RTG is easy. For the recursive case, we use the fact that regular tree languages are closed under substitution (Gécseg and Steinby, 1997, Prop. 7.3). Thus we obtain an RTG Gi with L(Gi) = bi(hi(α)).","For (ii) and (iv), we need the following auxiliary 150 construction. Let Gi = (P, p0, R). We define the mapping vari : P → P(Xk) such that for every p ∈ P , every t ∈ Lp","(G","i) contains exactly the variables in vari(p). We construct it as follows. We initialize vari(p) to “unknown” for every p. For every rule p → xj, we set vari(p) = {xj}. For every rule p → σ(p1, . . . , pk) such that vari(pj) is known, we set vari(p) = ⋃","j vari(pj). This is iter-","ated; it can be shown that vari(p) is never assigned","two different values for the same p. Finally, we set","all remaining unknown entries to ∅. For (ii), we construct an RTG G′","i with L(G′","i) =","b′","i as follows. We let G′","i = ({⟨vari(p)⟩ | p ∈","P }, vari(p0), R′",") where R′","consists of the rules ⟨{xj}⟩ → {xj} if p → xi ∈ R , ⟨vari(p)⟩ → vari(p)(⟨U1⟩, . . . , ⟨Ul⟩⟩) if p → σ(p1, . . . , pk) ∈ R, V = {vari(pj) | 1 ≤ j ≤ k} \\ {∅}, |V | ≥ 2, seq(V ) = (U1, . . . , Ul) . For (iii), we use the standard product construc-","tion (Gécseg and Steinby, 1997, Prop. 7.1). For (iv), we construct an RTG G′′","i such that","L(G′′","i ) = b′′ i as follows. We let G′′","i = (P, p0, R′′","),","where R′′ consists of the rules p → σ(p1, . . . , pk) if p → σ(p1, . . . , pk) ∈ R, V = {vari(pj) | 1 ≤ j ≤ k} \\ {∅}, if |V | ≥ 2, then (vari(p), seq(V )) is a fork in τ . By a fork (u, u1 · · · uk) in τ , we mean that there is a node labeled u with k children labeled u1 up to uk.","At this point we have all the ingredients for our binarization algorithm, shown in Algorithm 1. It operates directly on a bimorphism, because all the relevant information about the algebras is captured by the b-rules. The following theorem documents the behavior of the algorithm. In short, it solves the problem of rule-by-rule binarization with respect to b-rules b1, . . . , bn. Theorem 3 Let G = (B, A1, . . . , An) be an IRTG, and let b1, . . . , bn be b-rules over A1, . . . , An, respectively.","Algorithm 1 terminates. Let B′","be the bimorphism computed by Algorithm 1 on B and b1, . . . , bn. Then G′","= (B′",", A","1, . . . , An) is","equivalent to G, and G′ is of rank 2 if and only Input: bimorphism B = (G, h1, . . . , hn),","b-rules b1, . . . , bn over ∆1, . . . , ∆n Output: bimorphism B′ 1: B′","← (G|≤2, h1, . . . , hn) 2: for rule r : q → α(q1, . . . , qk) of G|>2 do 3: for i = 1, . . . , n do 4: compute RTG Gi for bi(hi(α)) 5: compute RTG G′","i for v(bi(hi(α))) 6: compute RTG Gv for ⋂","i L(G′ i) 7: if L(Gv) = ∅ then 8: add r to B′ 9: else 10: select t′","∈ L(G","v)","11: for i = 1, . . . , n do","12: compute RTG G′′","i for","13: b′′","i = bi(hi(α)) ∩ v−1","(t′",")","14: select ti ∈ L(G′′","i ) 15: construct binarization for t1, . . . , tn 16: add appropriate rules to B′ Algorithm 1: Complete binarization algorithm, where G|≤2 and G|>2 is G restricted to binary and suprabinary rules, respectively. if every suprabinary rule of G has a binarization with respect to b1, . . . , bn.","The runtime of Algorithm 1 is dominated by the intersection construction in line 6, which is O(m1 · . . . · mn) per rule, where mi is the size of G′","i. The quantity mi is linear in the size of the terms on the right-hand side of hi, and in the number of rules in the b-rule bi."]},{"title":"5 Applications","paragraphs":["Algorithm 1 implements rule-by-rule binarization with respect to given b-rules. If a rule of the given IRTG does not have a binarization with respect to these b-rules, it is simply carried over to the new grammar, which then has a rank higher than 2. The number of remaining suprabinary rules depends on the b-rules (except for rules that have no binarization at all). The user can thus engineer the b-rules according to their current needs, trading off completeness, runtime, and engineering effort.","By contrast, earlier binarization algorithms for formalisms such as SCFG and LCFRS simply at-tempt to find an equivalent grammar of rank 2; there is no analogue of our b-rules. The problem these algorithms solve corresponds to the general rule-by-rule binarization problem from Section 3. 151 NP NP DT the x1:NNP POS ’s x2:JJ x3:NN −→ das x2 x3 der x1 Figure 7: A rule of a tree-to-string transducer. We show that under certain conditions, our algorithm can be used to solve this problem as well. In the following two subsections, we illustrate this for SCFGs and tree-to-string transducers, respectively. In the final subsection, we discuss how to extend this approach to other grammar formalisms as well. 5.1 Synchronous context-free grammars We have used SCFGs as the running example in this paper. SCFGs are IRTGs with two interpretations into the string algebra of Table 1, as illustrated by the example in Fig. 2. In order to make our algorithm ready to use, it remains to specify a b-rule for the string algeba.","We use the following b-rule for both b1 and b2. Each symbol a ∈ ∆i|0 is mapped to the language {a}. Each symbol conk",", k ≥ 2, is mapped to the language induced by the following RTG with states of the form [j, j′","] (where 0 ≤ j < j′","≤ k) and final state[0, k]:","[j − 1, j] → xj (1 ≤ j ≤ k)","[j, j′","] → con2","([j, j′′","], [j′′",", j′","])","(0 ≤ j < j′′","< j′","≤ k) This language expresses all possible ways in which conk","can be written in terms of con2",".","Our definition of rule-by-rule binarization with respect to b1 and b2 coincides with that of Huang et al. (2009): any rule can be binarized by both algorithms or neither. For instance, for the SCFG rule A → ⟨BCDE, CEBD⟩, the sets v(b1(h1(α))) and v(b2(h2(α))) are disjoint, thus no binarization exists. Two strings of length N can be parsed with a binary IRTG that represents an SCFG in time O(N 6","). 5.2 Tree-to-string transducers Some approaches to SMT go beyond string-to-string translation models such as SCFG by exploit-ing known syntactic structures in the source or target language. This perspective on translation naturally leads to the use of tree-to-string transducers NP → α(NNP, JJ, NN) NP con3 NP con3 DT the con0","x1 POS ’s con0 x2 x3 h1 ←− α h2 ↦−→ con5 das x2 x3 der x1 Figure 8: An IRTG rule encoding the rule in Fig. 7. (Yamada and Knight, 2001; Galley et al., 2004; Huang et al., 2006; Graehl et al., 2008). Figure 7 shows an example of a tree-to-string rule. It might be used to translate “the Commission’s strategic plan” into “das langfristige Programm der Kommission”.","Our algorithm can binarize tree-to-string transducers; to our knowledge, it is the first algorithm to do so. We model the tree-to-string transducer as an IRTG G = ((G, h1, h2), A1, A2), where A2 is the string algebra, but this time A1 is the tree algebra shown in Table 1. This algebra has operations conk","to concatenate sequences of trees and unary γ that maps any sequence (t1, . . . , tl) of trees to the tree γ(t1, . . . , tl), viewed as a sequence of length 1. Note that we exclude the operation con1","because it is the identity and thus unnecessary. Thus the rule in Fig. 7 translates to the IRTG rule shown in Fig. 8. For the string algebra, we reuse the b-rule from Section 5.1; we call it b2 here. For the tree algebra, we use the following b-rule b1. It maps con0","to {con0","} and each unary symbol γ to {γ(x","1)}. Each symbol conk",", k ≥ 2, is treated as in the string case. Using these b-rules, we can binarize the rule in Fig. 8 and obtain the rules in Fig. 9. Parsing of a binary IRTG that represents a tree-to-string transducer is O(N 3","· M ) for a string of length N and a tree with M nodes.","We have implemented our binarization algorithm and the b-rules for the string and the tree algebra. In order to test our implementation, we extracted a tree-to-string transducer from about a million parallel sentences of English-German Europarl data, using the GHKM rule extractor (Galley, 2010). Then we binarized the transducer. The results are shown in Fig. 10. Of the 2.15 million rules in the extracted transducer, 460,000 were suprabinary, and 67 % of these could be binarized. Binarization took 4.4 minutes on a single core of an Intel Core i5 2520M processor. 152","NP → α′","(NNP, A′",")","A′","→ α′′","(JJ, NN) NP con2 NP con2 DT the con0 con2","x1 POS","’s con0 x2 h′ 1 ←− α′ h′","2","↦−→ con2 con2 das x2 con2 der x1 con2 x1 x2 h′ 1 ←− α′′ h′","2","↦−→ con2 x1 x2 Figure 9: Binarization of the rule in Fig. 8. 1 1.2 1.4 1.6 1.8 2 2.2 2.4 ext bin # rules (millions) rank 0123456-78-10 Figure 10: Rules of a transducer extracted from Europarl (ext) vs. its binarization (bin). 5.3 General approach Our binarization algorithm can be used to solve the general rule-by-rule binarization problem for a specific grammar formalism, provided that one can find appropriate b-rules. More precisely, we need to devise a class C of IRTGs over the same sequence A1, . . . , An of algebras that encodes the grammar formalism, together with b-rules b1, . . . , bn over A1, . . . , An that are complete on every grammar in C, as defined in Section 4.","We have already seen the b-rules for SCFGs and tree-to-string transducers in the preceding subsections; now we have a closer look at the class C for SCFGs. We used the class of all IRTGs with two string algebras and in which hi(α) contains at most one occurrence of a symbol conk","for every α ∈ Σ. On such a grammar the b-rules are complete. Note that this would not be the case if we allowed several occurrences of conk",", as in con2","(con2","(x","1, x2), x3). This term is equivalent","to itself and to con2","(x1, con2","(x 2, x3)), but the b-rules only cover the former. Thus they miss one variable tree. For the term con3","(x","1, x2, x3), how-ever, the b-rules cover both variable trees.","Generally speaking, given C and b-rules b1, . . . , bn that are complete on every IRTG in C, Algorithm 1 solves the general rule-by-rule binarization problem on C. We can adapt Theorem 3 by requiring that G must be in C, and replacing each of the two occurrences of “binarization with respect to b1, . . . , bn” by simply “binarization”. If C is such that every grammar from a given grammar formalism can be encoded as an IRTG in C, this solves the general rule-by-rule binarization problem of that grammar formalism."]},{"title":"6 Conclusion","paragraphs":["We have presented an algorithm for binarizing IRTGs rule by rule, with respect to b-rules that the user specifies for each algebra. This improves the complexity of parsing and translation with any monolingual or synchronous grammar that can be represented as an IRTG. A novel algorithm for binarizing tree-to-string transducers falls out as a special case.","In this paper, we have taken the perspective that the binarized IRTG uses the same algebras as the original IRTG. Our algorithm extends to grammars of arbitrary fanout (such as synchronous tree-adjoining grammar (Koller and Kuhlmann, 2012)), but unlike LCFRS-based approaches to binarization, it will not increase the fanout to ensure binarizability. In the future, we will explore IRTG binarization with fanout increase. This could be done by binarizing into an IRTG with a more complicated algebra (e.g., of string tuples). We might compute binarizations that are optimal with respect to some measure (e.g., fanout (Gomez-Rodriguez et al., 2009) or parsing complexity (Gildea, 2010)) by keeping track of this measure in the b-rule and taking intersections of weighted tree automata."]},{"title":"Acknowledgments","paragraphs":["We thank the anonymous referees for their insightful remarks, and Sarah Hemmen for implementing an early version of the algorithm. Matthias Büchse was financially supported by DFG VO 1011/6-1. 153"]},{"title":"References","paragraphs":["Alfred V. Aho and Jeffrey D. Ullman. 1969. Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3:37–56.","André Arnold and Max Dauchet. 1976. Bitransduction de forêts. In Proc. 3rd Int. Coll. Automata, Languages and Programming, pages 74–86. Edinburgh University Press.","Walter S. Brainerd. 1969. Tree generating regular systems. Information and Control, 14(2):217–231.","David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.","Steve DeNeefe and Kevin Knight. 2009. Synchronous tree-adjoining machine translation. In Proceedings of EMNLP, pages 727–736.","Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In Proceedings of the 41st ACL, pages 205–208.","Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings of HLT/NAACL, pages 273–280.","Michael Galley. 2010. GHKM rule extractor. http: //www-nlp.stanford.edu/m̃galley/ software/stanford-ghkm-latest.tar. gz, retrieved on March 28, 2012.","Ferenc Gécseg and Magnus Steinby. 1997. Tree languages. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3, chapter 1, pages 1–68. Springer-Verlag.","Daniel Gildea. 2010. Optimal parsing strategies for linear context-free rewriting systems. In Proceedings of NAACL HLT.","Joseph A. Goguen, Jim W. Thatcher, Eric G. Wagner, and Jesse B. Wright. 1977. Initial algebra semantics and continuous algebras. Journal of the ACM, 24:68–95.","Carlos Gomez-Rodriguez, Marco Kuhlmann, Giorgio Satta, and David Weir. 2009. Optimal reduction of rule length in linear context-free rewriting systems. In Proceedings of NAACL HLT.","Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3):391–427.","Liang Huang and David Chiang. 2005. Better k-best parsing. In Proceedings of the 9th IWPT, pages 53– 64.","Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proceedings of the 7th AMTA, pages 66–73.","Liang Huang, Hao Zhang, Daniel Gildea, and Kevin Knight. 2009. Binarization of synchronous context-free grammars. Computational Linguistics, 35(4):559–595.","Donald E. Knuth. 1977. A generalization of Dijkstra’s algorithm. Information Processing Letters, 6(1):1– 5.","Alexander Koller and Marco Kuhlmann. 2011. A generalized view on parsing and translation. In Proceedings of the 12th IWPT, pages 2–13.","Alexander Koller and Marco Kuhlmann. 2012. Decomposing TAG algorithms using simple algebraizations. In Proceedings of the 11th TAG+ Workshop, pages 135–143.","Philip M. Lewis and Richard E. Stearns. 1966. Syntax directed transduction. Foundations of Computer Science, IEEE Annual Symposium on, 0:21–35.","Mark-Jan Nederhof. 2003. Weighted deductive parsing and Knuth’s algorithm. Computational Linguistics, 29(1):135–143.","Rebecca Nesson, Stuart M. Shieber, and Alexander Rush. 2006. Induction of probabilistic synchronous tree-insertion grammars for machine translation. In Proceedings of the 7th AMTA.","Owen Rambow and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223(1–2):87– 120.","David J. Weir. 1988. Characterizing Mildly Context-Sensitive Grammar Formalisms. Ph.D. thesis, University of Pennsylvania.","Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings of the 39th ACL, pages 523–530. 154"]}],"references":[{"authors":[{"first":"Alfred V","middle":".","last":"Aho"},{"first":"Jeffrey","middle":"D.","last":"Ullman"}],"year":"1969","title":"Syntax directed translations and the pushdown assembler","source":"Alfred V. Aho and Jeffrey D. Ullman. 1969. Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3:37–56."},{"authors":[{"first":"André","last":"Arnold"},{"first":"Max","last":"Dauchet"}],"year":"1976","title":"Bitransduction de forêts","source":"André Arnold and Max Dauchet. 1976. Bitransduction de forêts. In Proc. 3rd Int. Coll. Automata, Languages and Programming, pages 74–86. Edinburgh University Press."},{"authors":[{"first":"Walter","middle":"S.","last":"Brainerd"}],"year":"1969","title":"Tree generating regular systems","source":"Walter S. Brainerd. 1969. Tree generating regular systems. Information and Control, 14(2):217–231."},{"authors":[{"first":"David","last":"Chiang"}],"year":"2007","title":"Hierarchical phrase-based translation","source":"David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228."},{"authors":[{"first":"Steve","last":"DeNeefe"},{"first":"Kevin","last":"Knight"}],"year":"2009","title":"Synchronous tree-adjoining machine translation","source":"Steve DeNeefe and Kevin Knight. 2009. Synchronous tree-adjoining machine translation. In Proceedings of EMNLP, pages 727–736."},{"authors":[{"first":"Jason","last":"Eisner"}],"year":"2003","title":"Learning non-isomorphic tree mappings for machine translation","source":"Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In Proceedings of the 41st ACL, pages 205–208."},{"authors":[{"first":"Michel","last":"Galley"},{"first":"Mark","last":"Hopkins"},{"first":"Kevin","last":"Knight"},{"first":"Daniel","last":"Marcu"}],"year":"2004","title":"What’s in a translation rule? In Proceedings of HLT/NAACL, pages 273–280","source":"Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings of HLT/NAACL, pages 273–280."},{"authors":[{"first":"Michael","last":"Galley"}],"year":"2010","title":"GHKM rule extractor","source":"Michael Galley. 2010. GHKM rule extractor. http: //www-nlp.stanford.edu/m̃galley/ software/stanford-ghkm-latest.tar. gz, retrieved on March 28, 2012."},{"authors":[{"first":"Ferenc","last":"Gécseg"},{"first":"Magnus","last":"Steinby"}],"year":"1997","title":"Tree languages","source":"Ferenc Gécseg and Magnus Steinby. 1997. Tree languages. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3, chapter 1, pages 1–68. Springer-Verlag."},{"authors":[{"first":"Daniel","last":"Gildea"}],"year":"2010","title":"Optimal parsing strategies for linear context-free rewriting systems","source":"Daniel Gildea. 2010. Optimal parsing strategies for linear context-free rewriting systems. In Proceedings of NAACL HLT."},{"authors":[{"first":"Joseph","middle":"A.","last":"Goguen"},{"first":"Jim","middle":"W.","last":"Thatcher"},{"first":"Eric","middle":"G.","last":"Wagner"},{"first":"Jesse","middle":"B.","last":"Wright"}],"year":"1977","title":"Initial algebra semantics and continuous algebras","source":"Joseph A. Goguen, Jim W. Thatcher, Eric G. Wagner, and Jesse B. Wright. 1977. Initial algebra semantics and continuous algebras. Journal of the ACM, 24:68–95."},{"authors":[{"first":"Carlos","last":"Gomez-Rodriguez"},{"first":"Marco","last":"Kuhlmann"},{"first":"Giorgio","last":"Satta"},{"first":"David","last":"Weir"}],"year":"2009","title":"Optimal reduction of rule length in linear context-free rewriting systems","source":"Carlos Gomez-Rodriguez, Marco Kuhlmann, Giorgio Satta, and David Weir. 2009. Optimal reduction of rule length in linear context-free rewriting systems. In Proceedings of NAACL HLT."},{"authors":[{"first":"Jonathan","last":"Graehl"},{"first":"Kevin","last":"Knight"},{"first":"Jonathan","last":"May"}],"year":"2008","title":"Training tree transducers","source":"Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3):391–427."},{"authors":[{"first":"Liang","last":"Huang"},{"first":"David","last":"Chiang"}],"year":"2005","title":"Better k-best parsing","source":"Liang Huang and David Chiang. 2005. Better k-best parsing. In Proceedings of the 9th IWPT, pages 53– 64."},{"authors":[{"first":"Liang","last":"Huang"},{"first":"Kevin","last":"Knight"},{"first":"Aravind","last":"Joshi"}],"year":"2006","title":"Statistical syntax-directed translation with extended domain of locality","source":"Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proceedings of the 7th AMTA, pages 66–73."},{"authors":[{"first":"Liang","last":"Huang"},{"first":"Hao","last":"Zhang"},{"first":"Daniel","last":"Gildea"},{"first":"Kevin","last":"Knight"}],"year":"2009","title":"Binarization of synchronous context-free grammars","source":"Liang Huang, Hao Zhang, Daniel Gildea, and Kevin Knight. 2009. Binarization of synchronous context-free grammars. Computational Linguistics, 35(4):559–595."},{"authors":[{"first":"Donald","middle":"E.","last":"Knuth"}],"year":"1977","title":"A generalization of Dijkstra’s algorithm","source":"Donald E. Knuth. 1977. A generalization of Dijkstra’s algorithm. Information Processing Letters, 6(1):1– 5."},{"authors":[{"first":"Alexander","last":"Koller"},{"first":"Marco","last":"Kuhlmann"}],"year":"2011","title":"A generalized view on parsing and translation","source":"Alexander Koller and Marco Kuhlmann. 2011. A generalized view on parsing and translation. In Proceedings of the 12th IWPT, pages 2–13."},{"authors":[{"first":"Alexander","last":"Koller"},{"first":"Marco","last":"Kuhlmann"}],"year":"2012","title":"Decomposing TAG algorithms using simple algebraizations","source":"Alexander Koller and Marco Kuhlmann. 2012. Decomposing TAG algorithms using simple algebraizations. In Proceedings of the 11th TAG+ Workshop, pages 135–143."},{"authors":[{"first":"Philip","middle":"M.","last":"Lewis"},{"first":"Richard","middle":"E.","last":"Stearns"}],"year":"1966","title":"Syntax directed transduction","source":"Philip M. Lewis and Richard E. Stearns. 1966. Syntax directed transduction. Foundations of Computer Science, IEEE Annual Symposium on, 0:21–35."},{"authors":[{"first":"Mark-Jan","last":"Nederhof"}],"year":"2003","title":"Weighted deductive parsing and Knuth’s algorithm","source":"Mark-Jan Nederhof. 2003. Weighted deductive parsing and Knuth’s algorithm. Computational Linguistics, 29(1):135–143."},{"authors":[{"first":"Rebecca","last":"Nesson"},{"first":"Stuart","middle":"M.","last":"Shieber"},{"first":"Alexander","last":"Rush"}],"year":"2006","title":"Induction of probabilistic synchronous tree-insertion grammars for machine translation","source":"Rebecca Nesson, Stuart M. Shieber, and Alexander Rush. 2006. Induction of probabilistic synchronous tree-insertion grammars for machine translation. In Proceedings of the 7th AMTA."},{"authors":[{"first":"Owen","last":"Rambow"},{"first":"Giorgio","last":"Satta"}],"year":"1999","title":"Independent parallelism in finite copying parallel rewriting systems","source":"Owen Rambow and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223(1–2):87– 120."},{"authors":[{"first":"David","middle":"J.","last":"Weir"}],"year":"1988","title":"Characterizing Mildly Context-Sensitive Grammar Formalisms","source":"David J. Weir. 1988. Characterizing Mildly Context-Sensitive Grammar Formalisms. Ph.D. thesis, University of Pennsylvania."},{"authors":[{"first":"Kenji","last":"Yamada"},{"first":"Kevin","last":"Knight"}],"year":"2001","title":"A syntax-based statistical translation model","source":"Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings of the 39th ACL, pages 523–530. 154"}],"cites":[{"style":0,"text":"Chiang, 2007","origin":{"pointer":"/sections/5/paragraphs/0","offset":438,"length":12},"authors":[{"last":"Chiang"}],"year":"2007","references":["/references/3"]},{"style":0,"text":"Graehl et al., 2008","origin":{"pointer":"/sections/5/paragraphs/0","offset":452,"length":19},"authors":[{"last":"Graehl"},{"last":"al."}],"year":"2008","references":["/references/12"]},{"style":0,"text":"Lewis and Stearns, 1966","origin":{"pointer":"/sections/5/paragraphs/0","offset":642,"length":23},"authors":[{"last":"Lewis"},{"last":"Stearns"}],"year":"1966","references":["/references/19"]},{"style":0,"text":"Chiang, 2007","origin":{"pointer":"/sections/5/paragraphs/0","offset":667,"length":12},"authors":[{"last":"Chiang"}],"year":"2007","references":["/references/3"]},{"style":0,"text":"Eisner, 2003","origin":{"pointer":"/sections/5/paragraphs/0","offset":722,"length":12},"authors":[{"last":"Eisner"}],"year":"2003","references":["/references/5"]},{"style":0,"text":"Nesson et al., 2006","origin":{"pointer":"/sections/5/paragraphs/0","offset":774,"length":19},"authors":[{"last":"Nesson"},{"last":"al."}],"year":"2006","references":["/references/21"]},{"style":0,"text":"DeNeefe and Knight, 2009","origin":{"pointer":"/sections/5/paragraphs/0","offset":795,"length":24},"authors":[{"last":"DeNeefe"},{"last":"Knight"}],"year":"2009","references":["/references/4"]},{"style":0,"text":"Yamada and Knight, 2001","origin":{"pointer":"/sections/5/paragraphs/0","offset":854,"length":23},"authors":[{"last":"Yamada"},{"last":"Knight"}],"year":"2001","references":["/references/24"]},{"style":0,"text":"Graehl et al., 2008","origin":{"pointer":"/sections/5/paragraphs/0","offset":879,"length":19},"authors":[{"last":"Graehl"},{"last":"al."}],"year":"2008","references":["/references/12"]},{"style":0,"text":"Weir, 1988","origin":{"pointer":"/sections/5/paragraphs/1","offset":394,"length":10},"authors":[{"last":"Weir"}],"year":"1988","references":["/references/23"]},{"style":0,"text":"Rambow and Satta, 1999","origin":{"pointer":"/sections/5/paragraphs/1","offset":510,"length":22},"authors":[{"last":"Rambow"},{"last":"Satta"}],"year":"1999","references":["/references/22"]},{"style":0,"text":"Aho and Ullman, 1969","origin":{"pointer":"/sections/5/paragraphs/2","offset":191,"length":20},"authors":[{"last":"Aho"},{"last":"Ullman"}],"year":"1969","references":["/references/0"]},{"style":0,"text":"Huang et al. (2009)","origin":{"pointer":"/sections/5/paragraphs/2","offset":365,"length":19},"authors":[{"last":"Huang"},{"last":"al."}],"year":"2009","references":["/references/15"]},{"style":0,"text":"Koller and Kuhlmann, 2011","origin":{"pointer":"/sections/5/paragraphs/3","offset":500,"length":25},"authors":[{"last":"Koller"},{"last":"Kuhlmann"}],"year":"2011","references":["/references/17"]},{"style":0,"text":"Graehl et al., 2008","origin":{"pointer":"/sections/5/paragraphs/4","offset":132,"length":19},"authors":[{"last":"Graehl"},{"last":"al."}],"year":"2008","references":["/references/12"]},{"style":0,"text":"Galley et al., 2004","origin":{"pointer":"/sections/5/paragraphs/4","offset":153,"length":19},"authors":[{"last":"Galley"},{"last":"al."}],"year":"2004","references":["/references/6"]},{"style":0,"text":"Goguen et al., 1977","origin":{"pointer":"/sections/6/paragraphs/2","offset":303,"length":19},"authors":[{"last":"Goguen"},{"last":"al."}],"year":"1977","references":["/references/10"]},{"style":0,"text":"Arnold and Dauchet (1976)","origin":{"pointer":"/sections/6/paragraphs/12","offset":394,"length":25},"authors":[{"last":"Arnold"},{"last":"Dauchet"}],"year":"1976","references":["/references/1"]},{"style":0,"text":"Brainerd, 1969","origin":{"pointer":"/sections/6/paragraphs/25","offset":215,"length":14},"authors":[{"last":"Brainerd"}],"year":"1969","references":["/references/2"]},{"style":0,"text":"Gécseg and Steinby, 1997","origin":{"pointer":"/sections/6/paragraphs/26","offset":391,"length":24},"authors":[{"last":"Gécseg"},{"last":"Steinby"}],"year":"1997","references":["/references/8"]},{"style":0,"text":"Koller and Kuhlmann, 2011","origin":{"pointer":"/sections/6/paragraphs/32","offset":32,"length":25},"authors":[{"last":"Koller"},{"last":"Kuhlmann"}],"year":"2011","references":["/references/17"]},{"style":0,"text":"Koller and Kuhlmann, 2012","origin":{"pointer":"/sections/6/paragraphs/49","offset":116,"length":25},"authors":[{"last":"Koller"},{"last":"Kuhlmann"}],"year":"2012","references":["/references/18"]},{"style":0,"text":"Knuth, 1977","origin":{"pointer":"/sections/8/paragraphs/18","offset":146,"length":11},"authors":[{"last":"Knuth"}],"year":"1977","references":["/references/16"]},{"style":0,"text":"Nederhof, 2003","origin":{"pointer":"/sections/8/paragraphs/18","offset":159,"length":14},"authors":[{"last":"Nederhof"}],"year":"2003","references":["/references/20"]},{"style":0,"text":"Huang and Chiang, 2005","origin":{"pointer":"/sections/8/paragraphs/18","offset":175,"length":22},"authors":[{"last":"Huang"},{"last":"Chiang"}],"year":"2005","references":["/references/13"]},{"style":0,"text":"Gécseg and Steinby, 1997","origin":{"pointer":"/sections/8/paragraphs/19","offset":231,"length":24},"authors":[{"last":"Gécseg"},{"last":"Steinby"}],"year":"1997","references":["/references/8"]},{"style":0,"text":"Gécseg and Steinby, 1997","origin":{"pointer":"/sections/8/paragraphs/35","offset":6,"length":24},"authors":[{"last":"Gécseg"},{"last":"Steinby"}],"year":"1997","references":["/references/8"]},{"style":0,"text":"Huang et al. (2009)","origin":{"pointer":"/sections/9/paragraphs/18","offset":93,"length":19},"authors":[{"last":"Huang"},{"last":"al."}],"year":"2009","references":["/references/15"]},{"style":0,"text":"Yamada and Knight, 2001","origin":{"pointer":"/sections/9/paragraphs/20","offset":111,"length":23},"authors":[{"last":"Yamada"},{"last":"Knight"}],"year":"2001","references":["/references/24"]},{"style":0,"text":"Galley et al., 2004","origin":{"pointer":"/sections/9/paragraphs/20","offset":136,"length":19},"authors":[{"last":"Galley"},{"last":"al."}],"year":"2004","references":["/references/6"]},{"style":0,"text":"Huang et al., 2006","origin":{"pointer":"/sections/9/paragraphs/20","offset":157,"length":18},"authors":[{"last":"Huang"},{"last":"al."}],"year":"2006","references":["/references/14"]},{"style":0,"text":"Graehl et al., 2008","origin":{"pointer":"/sections/9/paragraphs/20","offset":177,"length":19},"authors":[{"last":"Graehl"},{"last":"al."}],"year":"2008","references":["/references/12"]},{"style":0,"text":"Galley, 2010","origin":{"pointer":"/sections/9/paragraphs/29","offset":282,"length":12},"authors":[{"last":"Galley"}],"year":"2010","references":["/references/7"]},{"style":0,"text":"Koller and Kuhlmann, 2012","origin":{"pointer":"/sections/10/paragraphs/1","offset":213,"length":25},"authors":[{"last":"Koller"},{"last":"Kuhlmann"}],"year":"2012","references":["/references/18"]},{"style":0,"text":"Gomez-Rodriguez et al., 2009","origin":{"pointer":"/sections/10/paragraphs/1","offset":618,"length":28},"authors":[{"last":"Gomez-Rodriguez"},{"last":"al."}],"year":"2009","references":["/references/11"]},{"style":0,"text":"Gildea, 2010","origin":{"pointer":"/sections/10/paragraphs/1","offset":671,"length":12},"authors":[{"last":"Gildea"}],"year":"2010","references":["/references/9"]}]}
