{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–113, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms Elijah Mayfield, David Adamson, and Carolyn Penstein Rosé Language Technologies Institute Carnegie Mellon University 5000 Forbes Ave, Pittsburgh, PA 15213 {emayfiel, dadamson, cprose}@cs.cmu.edu Abstract","paragraphs":["Automated annotation of social behavior in conversation is necessary for large-scale analysis of real-world conversational data. Important behavioral categories, though, are often sparse and often appear only in specific subsections of a conversation. This makes supervised machine learning difficult, through a combination of noisy features and unbalanced class distributions. We propose within-instance content selection, using cue features to selectively suppress sections of text and bias-ing the remaining representation towards minority classes. We show the effective-ness of this technique in automated annotation of empowerment language in online support group chatrooms. Our technique is significantly more accurate than multiple baselines, especially when prioritizing high precision."]},{"title":"1 Introduction","paragraphs":["Quantitative social science research has experienced a recent expansion, out of controlled settings and into natural environments. With this influx of interest comes new methodology, and the inevitable question arises of how to move towards testable hypotheses, using these uncontrolled sources of data as scientific lenses into the real world.","The study of conversational transcripts is a key domain in this new frontier. There are certain social and behavioral phenomena in conversation that cannot be easily identified through questionnaire data, self-reported surveys, or easily extracted user metadata. Examples of these social phenomena in conversation include overt displays of power (Prabhakaran et al., 2012) or indicators of rapport and relationship building (Wang et al., 2012). Manually annotating these social phenomena cannot scale to large data, so researchers turn to automated annotation of transcripts (Rosé et al., 2008). While machine learning is highly effective for annotation tasks with relatively balanced labels, such as sentiment analysis (Pang and Lee, 2004), more complex social functions are often rarer. This leads to unbalanced class label distributions and a much more difficult machine learning task. Moreover, features indicative of rare social annotations tend to be drowned out in favor of features biased towards the majority class. The net effect is that classification algorithms tend to bias towards the majority class, giving low accuracy for rare class detection.","Automated annotation of social phenomena also brings opportunities for real-world applications. For example, real-time annotation of conversation can power adaptive intervention in collaborative learning settings (Rummel et al., 2008; Adamson and Rosé, 2012). However, with the considerable power of automation comes great responsibility. It is critical to avoid intervening in the case of erroneous annotations, as providing unnecessary or inappropriate support in such a setting has been shown to be harmful to group performance and social cohesion (Dillenbourg, 2002; Stahl, 2012).","We propose adaptations to existing machine learning algorithms which improve recognition of rare annotations in conversational text data. Our primary contribution comes in the form of within-instance content selection. We develop a novel algorithm based on textual cues, suppressing information which is likely to be irrelevant to an instance’s class label. This allows features which predict minority classes to gain prominence, help-ing to sidestep the frequency of common features pointing to a majority class label.","Additionally, we propose modifications to existing algorithms. First, we identify a new application of logistic model trees to text data. Next, 104 we define a modification of confidence-based ensemble voting which encourages minority class labeling. Using these techniques, we demonstrate a significant improvement in classifier performance when recognizing the language of empowerment in support group chatrooms, a critical application area for researchers studying conversational interactions in healthcare (Uden-Kraan et al., 2009).","The remainder of this paper is structured as follows. We introduce the domain of empowerment in support contexts, along with previous studies on the challenges that these annotations (and similar others) bring to machine learning. We introduce our new technique for improving the ability to automate this annotation, along with other optimizations to the machine learning workflow which are tailored to this skewed class balance. We present experimental results showing that our method is effective, and provide a detailed analysis of the behavior of our model and the features it uses most. We conclude with a discussion of particularly use-ful applications of this work."]},{"title":"2 Background","paragraphs":["We ground this paper’s discussion of machine learning with a real problem, turning to the annotation of empowerment language in chat1",". The concept of empowerment, while a prolific area of research, lacks a broad definition across professionals, but broadly relates to “the power to act efficaciously to bring about desired results” (Boehm and Staples, 2002) and “experiencing personal growth as a result of developing skills and abilities along with a more positive self-definition” (Staples, 1990). Participants in online support groups feel increased empowerment (Uden-Kraan et al., 2009; Barak et al., 2008). Quantitative studies have shown the effect of empowerment through statistical methods such as structural equation modeling (Vauth et al., 2007), as have qualitative methods such as deductive transcript analysis (Owen et al., 2008) and interview studies (Wahlin et al., 2006).","The transition between these styles of research has been gradual. Pioneering work has demonstrated the ability to distinguish empowerment language in written texts, including prompted writ-ing samples (Pennebaker and Seagal, 1999), nar-1","Definitions of empowerment are closely related to the notion of self-efficacy (Bandura, 1997). For simplicity, we use the former term exclusively in this paper.","Table 1: Empowerment label distribution in our","corpus. Annotation Label # % Self-Empowerment NA 1522 79.3","POS 202 10.5","NEG 196 10.2 Other-Empowerment NA 1560 81.3","POS 217 11.3","NEG 143 7.4 ratives in online forums (Hoybye et al., 2005), and some preliminary analysis of synchronous discussion (Ogura et al., 2008; Mayfield et al., 2012b). These transitional works have used limited analysis methodology; in the absence of sophisticated natural language processing, their conclusions often rely on coarse measures, such as word counts and proportions of annotations in a text.","Users, of course, do not express empowerment in every thread in which they participate, which leads to a challenge for machine learning. Threads often focus on a single user’s experiences, in which most participants in a chat are merely commentators, if they participate at all, matching previous research on shifts in speaker salience over time (Hassan et al., 2008). This leads to many user threads which are annotated as not applicable (N/A). We move to our proposed approach with these skewed distributions in mind."]},{"title":"3 Data","paragraphs":["Our data consists of a set of chatroom conversation transcripts from the Cancer Support Community2",". Each 90-minute conversation took place in the context of a weekly meeting in a real-time chat, with up to 6 participants in addition to a professional therapist facilitating the discussion. In total, 2,206 conversations were collected from 2007-2011. This data offers potentially rich insight into coping and social support; however, annotating such a dataset by hand would be prohibitively expensive, even when it is already transcribed.","Twenty-one of these conversations have been annotated, as originally described and analyzed in (Mayfield et al., 2012b)3",". This data was disentangled into threads based on common themes or topics, as in prior work (Elsner and Charniak,","2","www.cancersupportcommunity.org","3","All annotations were found to be adequately reliable between humans, with thread disentanglement f = 0.75 and empowerment annotation κ > 0.7. 105 Figure 1: An example mapping from a single thread’s chat lines (left) to the per-user, per-thread instances used for classification in this paper (right), with example annotations for self-empowerment indicated. 2010; Adams and Martel, 2010). A novel per-user, per-thread annotation was then employed for empowerment annotation, following a coding manual based on definitions like those in Section 2. Each user was assigned a label of positive or negative empowerment if they exhibited such emotions, or was left blank if they did not do so within the context of that thread. This annotation was performed both for their self-empowerment as well as their attitude towards others’ situations (other-empowerment). An example of this annotation for self-empowerment is presented in Figure 1 and the distribution of labels is given in Table 1.","Most previous annotation tasks attempt to annotate on a per-utterance basis, such as dialogue act tagging (Popescu-Belis, 2008), or on arbitrary spans of text, such as in the MPQA subjectivity corpus (Wiebe et al., 2005). However, for our task, a per-user, per-thread annotation is more appropriate, because empowerment is often indicated best through narrative (Hoybye et al., 2005). Human annotators are instructed to take this context into account when annotating (Mayfield et al., 2012b). It would therefore be nonsensical to annotate individual lines as “embodying” empowerment. Similar arguments have been made for sentiment, especially as the field moves towards aspect-oriented sentiment (Breck et al., 2007). Assigning labels based on thread boundaries allows for context to be meaningfully taken into account, without cross-ing topic boundaries.","However, this granularity comes with a price: the distribution of class values in these instances is highly skewed. In our data, the vast majority of users’ threads are marked as not applicable to empowerment. Perhaps more inconveniently, while taking context into account is important for reliable annotation, it leads to extraneous information in many cases. Many threads can have multiple lines of contributions that are topically related to an expression of empowerment (and thus belong in the same thread), but which do not indicate any empowerment themselves. This exacerbates the likelihood of instances being classified as N/A.","We choose to take advantage of these attributes of threads. We know from research in discourse analysis that many sections of conversations are formulaic and rote, like introductions and greetings (Schegloff, 1968). We additionally know that polarity often shifts in dialogue through the use of discourse connectives such as conjunctions and transitional phrases. These issues have been addressed in work in the language technologies community, most notably through the Penn Discourse Treebank (Prasad et al., 2008); however, their applications to noisier synchronous conversation has beenrare in computational linguistics.","With these linguistic insights in mind, we examine how we can make best use of them for machine learning performance. While techniques for predicting rare events (Weiss and Hirsh, 1998) and compensating for class imbalance (Frank and 106 Bouckaert, 2006), these approaches generally focus on statistical properties of large class sets without taking the nature of their datasets into account. In the next section, we propose a new algorithm which takes advantage specifically of the linguistic phenomena in the conversation-based data that we study for empowerment detection. As such, our algorithm is highly suited to this data and task, with the necessary tradeoff in uncertain generality to new domains with unrelated data."]},{"title":"4 Cue Discovery for Content Selection","paragraphs":["Our algorithm performs content selection by learning a set of cue features. Each of these features indicates some linguistic function within the discourse which should downplay the importance of features either before or after that discourse marker. Our algorithm allows us to evaluate the impact of rules against a baseline, and to iteratively judge each rule atop the changes made by previous rules.","This algorithm fits into existing language technologies research which has attempted to partition documents into sections which are more or less relevant for classification. Many researchers have attempted to make use of cue phrases (Hirschberg and Litman, 1993), especially for segmentation both in prose (Hearst, 1997) and conversation (Galley et al., 2003). The approach of content selection, meanwhile, has been explored for sentiment analysis (Pang and Lee, 2004), where individual sentences may be less subjective and therefore less relevant to the sentiment classification task. It is also similar conceptually to content selection algorithms that have been used for text summarization (Teufel and Moens, 2002) and text generation (Sauper and Barzilay, 2009), both of which rely on finding highly-relevant passages within source texts.","Our work is distinct from these approaches. While we have coarse-grained annotations of empowerment, there is no direct annotation of what makes a good cue for content selection. With our cues, we hope to take advantage of shallow discourse structure in conversation, such as contrastive markers, making use of implicit structure in the conversational domain. 4.1 Notation Before describing extensions to the baseline logistic regression model, we define notation. Our data is arranged hierarchically. We assume that we have a collection of d training documents Tr = {D1 . . . Dd}, each of which contains many training instances (in our task, an instance consists of all lines of chat from one user in one thread). Our total set of n instances I thus consists of instances {I1, I2, . . . In}. Each document contains lines of chat L and each instance Ii is comprised of some subset of those lines, Li ⊆ L.","Our feature space X = {x1, x2, . . . xm} consists of m unigram features representing the observed vocabulary used in our corpus. Each instance is associated with a feature vector x̄ containing values for each x ∈ X, and each feature x that is present in the i-th instance maintains a “memory” of the lines in which it appeared in that instance, Lix, where Lix ⊆ Li. Our potential out-put labels consist of Y = {N A, N EG, P OS}, though this generalizes to any nominal classification task. Each instance I is associated with exactly one y ∈ Y for self-empowerment and one for other-empowerment; these two labels do not interact and our tasks are treated as independent in this paper4",". We define classifiers as functions f (x̄ → y ∈ Y); in practice, we use logistic regression via LibLINEAR (Fan et al., 2008).","We define a content selection rule as a pairing r = ⟨c, t⟩ between a cue feature c ∈ X and a selection function t ∈ T . We created a list of possible selection functions, given a cue c, maximizing for generality while being expressive. These are illustrated in Figure 2 and described below:","• Ignore Local Future (A): Ignore all features from the two lines after each occurrence of c.","• Ignore All Future (B): Ignore all features occurring after the first occurrence ofc.","• Ignore Local History (C): Ignore all features in the two lines preceding each occurrence of c.","• Ignore All History (D): Ignore all features occurring only before the last occurrence of c.","We define an ensemble memberE = ⟨R, fR⟩ - the ordered list of learned content selection rules R = [r1, r2, . . . ] and a classifierfC trained on instances transformed by those rules. Our final out-","4","Future work may examine the interaction of jointly annotating multiple sparse social phenomena. 107 Figure 2: Effects of content selection rules, based on a cue feature (ovals) observed at lines m and n. put of a trained model is a set of ensemble members {E1, . . . , Ek}. 4.2 Algorithm Our ensemble learning follows the paradigm of cross-validated committees (Parmanto et al., 1996), where k ensemble members are trained by subdividing our training data into k subfolds. For each ensemble classifier, cue rulesR are generated on k − 1 subfolds (Trk) and evaluated on the remaining subfold (Tek). In practice, with 21 training documents, 7-fold cross-validation, and k = 3 ensemble members, each generation set consists of 12 documents’ instances, while each evaluation set contains instances from 6 documents.","Our full algorithm is presented in Algorithm 1, and is broken into component parts for clarity. Algorithm 2 begins by measuring the baseline classifier’s ability to recognize minority-class labels. After training on Trk, we measure the average probability assigned to the correct label of instances in Tek, but only for instances whose correct labels are minority classes (remember, because both Trk and Tek are drawn from the over-all Tr, we have access to true class labels). We choose this subset of only minority instances, as we are not interested in optimizing to the majority class.","We next enumerate all rules that we wish to judge. To keep this problem tractable, we ignore features which do not occur in at least 5% of training instances. For the remaining features, we create a candidate rule for each possible pairing of features and selection functions. For each of these candidates, we test its utility by selecting content as if it were an actual rule, then building a new classifier (trained on the generation set) using instances that have been altered in that way. In the evaluation set, we measure the difference in probability of minority class labels being assigned correctly between the baseline and this altered space. This measure of an individual rule’s impact is described in Algorithm 3.","Once we have evaluated every possible rule once, we select the top-ranked rule and apply it to the feature set. We then iteratively progress through our now-ranked list of candidates, each time treating the newly filtered dataset as our new baseline. We search only top can-didates for efficiency, following the fixed-width search methodology for feature selection in very high-dimensionality feature spaces (Gütlein et al., 2009). Each ensemble classifier is finally retrained on all training data, after applying the correspond-ing content selection rules to that data."]},{"title":"5 Prediction","paragraphs":["Our prediction algorithm begins with a standard implementation of cross-validated committees (Parmanto et al., 1996), whose results are aggregated with a confidence voting method in-tended to favor rare labels (Erp et al., 2002). Cross-validated committees are an ensemble technique used to subsample training data to produce multiple hypotheses for classification. Each classifier produced by our cue-based transformation is trained on a subset of our training data. Each makes predictions on all test set instances, producing a distribution of confidence across possible labels. These values serve as inputs to a voting method to produce a final label for each instance.","Compared to other ensemble methods, cross-validated committees as described above are a good fit for our task, because of its unique unit of analysis. As thread-level analysis is the set of individual participants’ turns in a conversation, we risk overfitting if we sample from the same conversations for the training and testing sets. In contrast to standard bagging, hard sampling boundaries never train and test on instances drawn from the same conversation.","To aggregate the votes from members of this ensemble into a final prediction, we employ a variant on Selfridge’s Pandemonium (Selfridge, 1958). If a minority label is selected as the highest-confidence value in any classifier in our ensemble, it is selected. The majority label, by contrast, is only selected if it is the most likely prediction by all classifiers in our ensemble. Thus consensus is required to elect the majority class, and the strongest minority candidate is elected otherwise. 108","In : generation set Trk, evaluation set Tek","Out: ensemble committee {E1 . . . Ek}","for i = 1 to k do Rfinal ← [ ]; Xfreq ← {x ∈ X | f req(x) ∈ Trk > 5%}; R ← Xfreq × T ; R∗","← R; repeat","Pbase ← EvaluateClassifier(Trk, Tek);","EvaluateRules(Pbase, Trk, Tek, R∗",");","Trk, Tek ← ApplyRule(R∗","[0]);","R ← R − R∗","[0];","∆ ← score(R∗","[0]);","Rfinal ← Rfinal + R∗","[0];","R∗","← R[0 . . . 50]; until ∆ < threshold; Trfinal ← Trk ∪ Tek; foreach r ∈ Rfinal do","Trfinal ← ApplyRule(Trfinal, r); end Train f (x̄ → y) on Trfinal;","end Algorithm 1: LearnSelectionCues()","This approach is designed to bias the prediction of our machine learning algorithms in favor of minority classes in a coherent manner. If there is a plausible model that has been trained which recognizes the possibility of a rare label, it is used; the prediction only reverts to the majority class when no plausible minority label could be chosen. As validation of this technique, we compare our “minority pandemonium” approach against both typical pandemonium and standard sum-rule confidence voting (Erp et al., 2002). 5.1 Logistic Model Stumps One characteristic of highly skewed data is that, while minority labels may be expressed in a number of different surface forms, there are many obvious cases in which they do not apply. These cases can actually be harmful to classification of borderline cases. Features that could be given high weight in marginal cases may be undervalued in “low-hanging fruit” easy cases. To remove those obvious instances, a very simple screening heuristic is often enough to eliminate frequent phenotypes of instances where the rare annotation is not present. Prior work has sometimes screened training data through obvious heuristic rules, espe-In : generation set Trk, evaluation set Tek Out: minority class probability average Pbase Train f (x̄ → y) on Trk; Temin","k ← {Instance I ∈ Tek | yI ̸= “N A”} ; Pbase ← 0 ; foreach Instance I ∈ Temin","k do","Pbase ← Pbase + P (f (x̄I ) = yI ) end Pbase = Pbase/size(Temin","k )","Algorithm 2: EvaluateClassifier()","In : Trk, Tek, rules R, base probability Pbase","Out: R sorted on each rule’s improvement score","foreach Rule r ∈ R do Tr′","k, Te′","k ← ApplyRule(Trk, Tek, r); Palter ← EvaluateClassifier(Tr′","k, Te′","k);","score(r) ← Palter − Pbase;","end","Sort R on score(r) from high to low;","Algorithm 3: EvaluateRules() cially in speech recognition; for instance, training speech recognition for words followed by a pause separately from words followed by another word (Franco et al., 2010), or training separate models based on gender (Jiang et al., 1999).","We achieve this instance screening by learning logistic model tree stumps (Landwehr et al., 2005), which allow us to quickly partition data if there is a particularly easy heuristic that can be learned to eliminate a large number of majority-class labels. One challenge of this approach is our underlying unigram feature space - tree-based algorithms are generally poor classifiers for the high-dimensionality, low-information features in a lexical feature space (Han et al., 2001). To compensate, we employ a smaller, denser set of binary features for tree stump screening: instance length thresholds and LIWC category membership.","First, we define a set of features that split based on the number of lines an instance contains, from 1 to 10 (only a tiny fraction of instances are more than 10 lines long). For example, a feature split-ting on instances with lines ≤ 2 would be true for one- and two-line instances, and false for all others. Second, we define a feature for each category in the Linguistic Inquiry and Word Count dictionary (Tausczik and Pennebaker, 2010) - these broad classes of words allow for more balanced 109 Figure 3: Precision/recall curves for algorithms. After 50% recall all models converge and there are no significant differences in performance. splits than would unigrams alone. Each category’s feature is true if any word in that category was used at least once in that instance.","We exhaustively sweep this feature space, and report the most successful stump rules for each annotation task. In our other experiments, we report results with and without the best rule for this preprocessing step; we also measure its impact alone."]},{"title":"6 Experimental Results","paragraphs":["All experiments were performed using LightSIDE (Mayfield and Rosé, 2013). We use a binary unigram feature space, and we perform 7-fold crossvalidation. Instances from the same chat transcript never occur in both train and testing folds. Furthermore, we assume that threads have been disentangled already, and our experiments use gold standard thread structure. While this is not a trivial assumption, prior work has shown thread disentanglement to be manageable (Mayfield et al., 2012a); we consider it an acceptable simplify-ing assumption for our experiments. We compare our methods against baselines including a majority baseline, a baseline logistic regression classifier with L2 regularized features, and two common ensemble methods, AdaBoost (Freund and Schapire, 1996) and bagging (Breiman, 1996) with logistic regression base classifiers5",".","Table 2 presents the best-performing result from each classification method. For self-empowerment recognition, all methods that we introduce are significant improvements in κ, the","5","These methods usually use weak, unstable base classifiers; however, in our experiments, those performed poorly. Table 2: Performance for baselines, common ensemble algorithms, and proposed methods. Statistically significant improvements over baseline are marked (p < .01, †; p < .05, *; p < 0.1, +).","Self Other Method % κ % κ Majority 79.3 .000 81.3 .000 LR Baseline 81.0 .367 81.0 .270 LR + Boosting 78.1 .325 78.5 .275 LR + Bagging 81.2 .352 81.9 .265 LR + Committee 81.0 .367 81.0 .270 Learned Stumps 81.8* .385† 81.7 .293+ Content Selection 80.9 .389† 80.7 .282 Stumps+Selection 81.3 .406† 79.4 .254 Table 3: Performance of content-selection wrapped learners, for minority voting and two baseline voting methods.","Self Other Method % κ % κ Pandemonium 80.3 .283 81.4 .239 Averaged 80.6 .304 81.6 .251 Minority Voting 80.9† .389† 80.7 .282 measurement of agreement over chance, compared to all baselines. While accuracy remains stable, this is due to predictions shifting away from the majority class and towards minority classes. Our combined model using both logistic model tree stumps and content selection is significantly better than either alone (p < .01). To compare the minority pandemonium voting method against baselines of simple pandemonium and summed confidence voting, Table 3 presents the results of content selection wrappers with each voting method. Minority voting is more effective compared to standard confidence voting, improving κ while modestly reducing accuracy; this is typical of a shift towards minority class predictions."]},{"title":"7 Discussion","paragraphs":["These results show promise for our techniques, which are able to distinguish features of rare labels, previously awash in a sea of irrelevance. Figure 3 shows the impact of our rules as we tune to different levels of recall, with a large boost in precision when recall is not important; our model converges with the baseline for high-recall, low-precision tuning. This suggests that our method is particularly suitable for tasks where confident la-110","Table 4: Cue rules commonly selected by the algo-","rithm. Average improvement over the LR baseline","is also shown. Self-Empowerment Cue Transformation ∆% and,but Ignore Local Future +5.0 have Ignore All History +4.3","! Ignore All History +4.2 me,my Ignore All History +3.4 Other-Empowerment Cue Transformation ∆% and,but Ignore Local Future +5.5 you Ignore Local History +5.2","’s Ignore Local History +4.1 that Ignore Local History +3.9 beling of a few instances is more important than labeling as many instances as possible. This is common when tasks have a high cost or carry high risk (for instance, providing real-time conversational supports with an agent, where inappropriate intervention could be disruptive). Other low-recall applications include exploration large corpora for exemplar instances, where the most confident predictions for a given label should be presented first for analyst use. In the rest of this section, we examine notable within-instance and per-instance rules selected by our methods. These rules are summarized in Tables 4 and 5.","For both self- and other-empowerment, we find pronoun rules that match the task (first-person and second-person pronouns for self-Empowerment and other-Empowerment respectively). In both tasks, we find cue rules that suppress the context preceding personal pronouns. These, as well as the possessive suffix ’s, echo the per-instance effect of the Self and You splits, anticipating that what follows such a personal reference is likely to bear an evaluation of empowerment. Exclamation marks may indicate strong emotion - we find many instances where what precedes a line with an exclamation is more objective, and what follows in-cludes an assessment. Conjunctions but and and are selected as cue rules suppressing the two lines that follow the occurrence - suggesting, as suspected, that connective discourse markers play a role in indicating empowerment (Fraser, 1999).","The best-performing stump splits for the Self-Empowerment annotation are Line Length ≤ 1 and the LIWC word-categories Article, Swear, and Table 5: Best decision rules for logistic model stumps. Significant improvement (p < 0.05) indicated with *. Self-Empowerment Split Rule κ ∆κ % ∆% Split ≤ 1 * 0.385 +.018 81.8 +0.8 LIWC-Article 0.379 +.012 81.6 +0.6 LIWC-Swear * 0.376 +.009 81.4 +0.4 LIWC-Self * 0.376 +.009 81.5 +0.5 Other-Empowerment Split Rule κ ∆κ % ∆% LIWC-You 0.293 +.023 81.7 +0.7 LIWC-Eating * 0.283 +.013 81.6 +0.6 LIWC-Negate * 0.282 +.012 82.3 +1.3 LIWC-Present 0.281 +.011 81.6 +0.6 Self. The split on line length corresponds to the observation that longer instances provide greater opportunity for personal narrative self-assessment to occur (95% of single-line instances are labeled NA). The Article category may serve as a proxy for content length - article-less instances in our corpus include one-line social greetings and exchanges of contact information. Swear words may be a cue for awareness of self-empowerment - a recent study of women coping with illness reported that swearing in the presence of others, but not alone, was related to potentially harmful outcomes (Robbins et al., 2011). Among other- oriented split rules, Eating stands out as non-obvious, although medical literature has suggested a link between dietary behavior and empowerment attitudes in a study of women with cancer (Pinto et al., 2002)."]},{"title":"8 Conclusion","paragraphs":["We have demonstrated an algorithm for improving automated classification accuracy on highly skewed tasks for conversational data. This algorithm, particularly its focus on content selection, is rooted in the structural format of our data, which can generalize to many tasks involving conversational data. Our experiments show that this model significantly improves machine learning performance. Our algorithm is taking advantage of structural facets of discourse markers, lending basic sociolinguistic validity to its behavior. Though we have treated each of these rarely-occurring labels as independent thus far, in practice we know that this is not the case. Joint prediction of labels through structured modeling is an obvious next 111 step for improving classification accuracy.","This is an important step towards large-scale analysis of the impact of support groups on patients and caregivers. Our method can be used to confidently highlight occurrences of rare labels in large data sets. This has real-world implications for professional intervention in social conversational domains, especially in scenarios where such an intervention is likely to be associated with a high cost or high risk. With the construction of more accurate classifiers, we open the possibility of automating annotation on large conversational datasets, enabling new directions for researchers with domain expertise."]},{"title":"Acknowledgments","paragraphs":["The research reported here was supported by Na-tional Science Foundation grant IIS-0968485."]},{"title":"References","paragraphs":["Paige Adams and Craig Martel. 2010. Conversational thread extraction and topic detection in text-based chat. In Semantic Computing.","David Adamson and Carolyn Penstein Rosé. 2012. Coordinating multi-dimensional support in collaborative conversational agents. In Proceedings of In-telligent Tutoring Systems.","Albert Bandura. 1997. Self-Efficacy: The Exercise of Control.","Azy Barak, Meyran Boniel-Nissim, and John Suler. 2008. Fostering empowerment in online support groups. Computers in Human Behavior.","A Boehm and L H Staples. 2002. The functions of the social worker in empowering: The voices of consumers and professionals. Social Work.","Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In Proceedings of IJCAI.","Leo Breiman. 1996. Bagging predictors. Machine Learning.","Pierre Dillenbourg. 2002. Over-scripting cscl: The risks of blending collaborative learning with instruc-tional design. Three worlds of CSCL. Can we support CSCL?","Micha Elsner and Eugene Charniak. 2010. Disentangling chat. Computational Linguistics.","Merijn Van Erp, Louis Vuurpijl, and Lambert Schomaker. 2002. An overview and comparison of voting methods for pattern recognition. In Frontiers in Handwriting Recognition. IEEE.","Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification.","Horacio Franco, Harry Bratt, Romain Rossier, Venkata Rao Gadde, Elizabeth Shriberg, Victor Abrash, and Kristin Precoda. 2010. Eduspeak: A speech recognition and pronunciation scoring toolkit for computer-aided language learning applications. Language Testing.","Eibe Frank and Remco R Bouckaert. 2006. Naive bayes for text classification with unbalanced classes. Knowledge Discovery in Databases.","Bruce Fraser. 1999. What are discourse markers? Journal of pragmatics, 31(7):931–952.","Yoav Freund and Robert E Schapire. 1996. Experiments with a new boosting algorithm. In Proceedings of ICML.","Michel Galley, Kathleen McKeown, Eric Fosler-Lussier, and Hongyan Jing. 2003. Discourse segmentation of multi-party conversation. In Proceedings of ACL.","Martin Gütlein, Eibe Frank, Mark Hall, and Andreas Karwath. 2009. Large-scale attribute selection using wrappers. In Proceedings of IEEE CIDM.","Eui-Hong Han, George Karypis, and Vipin Kumar. 2001. Text categorization using weight adjusted k-nearest neighbor classification. Lecture Notes in Computer Science: Advances in Knowledge Discovery and Data Mining.","Ahmed Hassan, Anthony Fader, Michael H Crespin, Kevin M Quinn, Burt L Monroe, Michael Colaresi, and Dragomir R Radev. 2008. Tracking the dynamic evolution of participant salience in a discussion. In Proceedings of Coling.","Marti A Hearst. 1997. Texttiling: Segmenting text into multi-paragraph subtopic passages. Computational Linguistics.","Julia Hirschberg and Diane Litman. 1993. Empirical studies on the disambiguation of cue phrases. Computational Linguistics.","Mette Terp Hoybye, Christoffer Johansen, and Tine Tjornhoj-Thomsen. 2005. Online interaction effects of storytelling in an internet breast cancer support group. Psycho-oncology.","Hui Jiang, Keikichi Hirose, and Qiang Huo. 1999. Robust speech recognition based on a bayesian prediction approach. In IEEE Transactions on Speech and Audio Processing.","Niels Landwehr, Mark Hall, and Eibe Frank. 2005. Logistic model trees. Machine Learning.","Elijah Mayfield and Carolyn Penstein Rosé. 2013. Lightside: Open source machine learning for text. In Handbook of Automated Essay Evaluation: Current Applications and New Directions. 112","Elijah Mayfield, David Adamson, and Carolyn Penstein Rosé. 2012a. Hierarchical conversation structure prediction in multi-party chat. In Proceedings of SIGDIAL Meeting on Discourse and Dialogue.","Elijah Mayfield, Miaomiao Wen, Mitch Golant, and Carolyn Penstein Rosé. 2012b. Discovering habits of effective online support group chatrooms. In ACM Conference on Supporting Group Work.","Kanayo Ogura, Takashi Kusumi, and Asako Miura. 2008. Analysis of community development using chat logs: A virtual support group of cancer patients. In Proceedings of the IEEE Symposium on Universal Communication.","Jason E. Owen, Erin O’Carroll Bantum, and Mitch Golant. 2008. Benefits and challenges experienced by professional facilitators of online support groups for cancer survivors. In Psycho-Oncology.","Bo Pang and Lillian Lee. 2004. A sentimental educa-tion: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Association for Computational Linguistics.","Bambang Parmanto, Paul Munro, and Howard R Doyle. 1996. Improving committee diagnosis with resampling techniques. In Proceedings of NIPS.","James W Pennebaker and J D Seagal. 1999. Forming a story: The health benefits of narrative. Journal of Clinical Psychology.","Bernardine M Pinto, Nancy C Maruyama, Matthew M Clark, Dean G Cruess, Elyse Park, and Mary Roberts. 2002. Motivation to modify lifestyle risk behaviors in women treated for breast cancer. In Mayo Clinic Proceedings.","Andrei Popescu-Belis. 2008. Dimensionality of dialogue act tagsets: An empirical analysis of large corpora. In Language Resources and Evaluation.","Vinodkumar Prabhakaran, Owen Rambow, and Mona Diab. 2012. Predicting overt display of power in written dialogs. In Proceedings of NAACL.","Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. In Proceedings of LREC.","Megan L Robbins, Elizabeth S Focella, Shelley Kasle, Ana Marı́a López, Karen L Weihs, and Matthias R Mehl. 2011. Naturalistically observed swearing, emotional support, and depressive symptoms in women coping with illness. Health Psychology, 30:789.","Carolyn Penstein Rosé, Yi-Chia Wang, Yue Cui, Jaime Arguello, Karsten Stegmann, Armin Weinberger, and Frank Fischer. 2008. Analyzing collaborative learning processes automatically: Exploit-ing the advances of computational linguistics in computer-supported collaborative learning. In International Journal of Computer Supported Collabora-tive Learning.","Nikol Rummel, Armin Weinberger, Christof Wecker, Frank Fischer, Anne Meier, Eleni Voyiatzaki, George Kahrimanis, Hans Spada, Nikolaos Avouris, and Erin Walker. 2008. New challenges in cscl: Towards adaptive script support. In Proceedings of ICLS.","Christina Sauper and Regina Barzilay. 2009. Automatically generating wikipedia articles: A structure-aware approach. In Proceedings of ACL.","Emanuel A Schegloff. 1968. Sequencing in conversational openings. American Anthropologist.","Oliver G Selfridge. 1958. Pandemonium: a paradigm for learning. In Proceedings of Symposium on Mechanisation of Thought Processes, Na-tional Physical Laboratory.","Gerry Stahl. 2012. Interaction analysis of a biology chat. Productive multivocality.","Lee H Staples. 1990. Powerful ideas about empowerment. Administration in Social Work.","Yla R Tausczik and James W Pennebaker. 2010. The psychological meaning of words: Liwc and computerized text analysis methods. Journal of Language and Social Psychology.","Simone Teufel and Marc Moens. 2002. Summariz-ing scientic articles: Experiments with relevance and rhetorical status. Computational Linguistics.","C F Van Uden-Kraan, C H C Drossaert, E Taal, E R Seydel, and M A F J Van de Laar. 2009. Participation in online patient support groups endorses patients empowerment. Patient Education and Counseling.","R Vauth, B Kleim, M Wirtz, and P W Corrigan. 2007. Self-efficacy and empowerment as outcomes of selfstigmatizing and coping in schizophrenia. Psychiatry Research.","Ingrid Wahlin, Anna-Christina Ek, and Ewa Idvali. 2006. Patient empowerment in intensive carean interview study. Intensive and Critical Care Nursing.","William Yang Wang, Samantha Finkelstein, Amy Ogan, Alan Black, and Justine Cassell. 2012. “love ya, jerkface:” using sparse log-linear models to build positive (and impolite) relationships with teens. In Proceedings of SIGDIAL.","Gary M Weiss and Haym Hirsh. 1998. Learning to predict rare events in event sequences. In Proceedings of KDD.","Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation. 113"]}],"references":[{"authors":[{"first":"Paige","last":"Adams"},{"first":"Craig","last":"Martel"}],"year":"2010","title":"Conversational thread extraction and topic detection in text-based chat","source":"Paige Adams and Craig Martel. 2010. Conversational thread extraction and topic detection in text-based chat. In Semantic Computing."},{"authors":[{"first":"David","last":"Adamson"},{"first":"Carolyn","middle":"Penstein","last":"Rosé"}],"year":"2012","title":"Coordinating multi-dimensional support in collaborative conversational agents","source":"David Adamson and Carolyn Penstein Rosé. 2012. Coordinating multi-dimensional support in collaborative conversational agents. In Proceedings of In-telligent Tutoring Systems."},{"authors":[{"first":"Albert","last":"Bandura"}],"year":"1997","title":"Self-Efficacy: The Exercise of Control","source":"Albert Bandura. 1997. Self-Efficacy: The Exercise of Control."},{"authors":[{"first":"Azy","last":"Barak"},{"first":"Meyran","last":"Boniel-Nissim"},{"first":"John","last":"Suler"}],"year":"2008","title":"Fostering empowerment in online support groups","source":"Azy Barak, Meyran Boniel-Nissim, and John Suler. 2008. Fostering empowerment in online support groups. Computers in Human Behavior."},{"authors":[{"first":"A","last":"Boehm"},{"first":"L","middle":"H","last":"Staples"}],"year":"2002","title":"The functions of the social worker in empowering: The voices of consumers and professionals","source":"A Boehm and L H Staples. 2002. The functions of the social worker in empowering: The voices of consumers and professionals. Social Work."},{"authors":[{"first":"Eric","last":"Breck"},{"first":"Yejin","last":"Choi"},{"first":"Claire","last":"Cardie"}],"year":"2007","title":"Identifying expressions of opinion in context","source":"Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In Proceedings of IJCAI."},{"authors":[{"first":"Leo","last":"Breiman"}],"year":"1996","title":"Bagging predictors","source":"Leo Breiman. 1996. Bagging predictors. Machine Learning."},{"authors":[{"first":"Pierre","last":"Dillenbourg"}],"year":"2002","title":"Over-scripting cscl: The risks of blending collaborative learning with instruc-tional design","source":"Pierre Dillenbourg. 2002. Over-scripting cscl: The risks of blending collaborative learning with instruc-tional design. Three worlds of CSCL. Can we support CSCL?"},{"authors":[{"first":"Micha","last":"Elsner"},{"first":"Eugene","last":"Charniak"}],"year":"2010","title":"Disentangling chat","source":"Micha Elsner and Eugene Charniak. 2010. Disentangling chat. Computational Linguistics."},{"authors":[{"first":"Merijn","last":"Van Erp"},{"first":"Louis","last":"Vuurpijl"},{"first":"Lambert","last":"Schomaker"}],"year":"2002","title":"An overview and comparison of voting methods for pattern recognition","source":"Merijn Van Erp, Louis Vuurpijl, and Lambert Schomaker. 2002. An overview and comparison of voting methods for pattern recognition. In Frontiers in Handwriting Recognition. IEEE."},{"authors":[{"first":"Rong-En","last":"Fan"},{"first":"Kai-Wei","last":"Chang"},{"first":"Cho-Jui","last":"Hsieh"},{"first":"Xiang-Rui","last":"Wang"},{"first":"Chih-Jen","last":"Lin"}],"year":"2008","title":"LIBLINEAR: A library for large linear classification","source":"Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification."},{"authors":[{"first":"Horacio","last":"Franco"},{"first":"Harry","last":"Bratt"},{"first":"Romain","last":"Rossier"},{"first":"Venkata","middle":"Rao","last":"Gadde"},{"first":"Elizabeth","last":"Shriberg"},{"first":"Victor","last":"Abrash"},{"first":"Kristin","last":"Precoda"}],"year":"2010","title":"Eduspeak: A speech recognition and pronunciation scoring toolkit for computer-aided language learning applications","source":"Horacio Franco, Harry Bratt, Romain Rossier, Venkata Rao Gadde, Elizabeth Shriberg, Victor Abrash, and Kristin Precoda. 2010. Eduspeak: A speech recognition and pronunciation scoring toolkit for computer-aided language learning applications. Language Testing."},{"authors":[{"first":"Eibe","last":"Frank"},{"first":"Remco","middle":"R","last":"Bouckaert"}],"year":"2006","title":"Naive bayes for text classification with unbalanced classes","source":"Eibe Frank and Remco R Bouckaert. 2006. Naive bayes for text classification with unbalanced classes. Knowledge Discovery in Databases."},{"authors":[{"first":"Bruce","last":"Fraser"}],"year":"1999","title":"What are discourse markers? Journal of pragmatics, 31(7):931–952","source":"Bruce Fraser. 1999. What are discourse markers? Journal of pragmatics, 31(7):931–952."},{"authors":[{"first":"Yoav","last":"Freund"},{"first":"Robert","middle":"E","last":"Schapire"}],"year":"1996","title":"Experiments with a new boosting algorithm","source":"Yoav Freund and Robert E Schapire. 1996. Experiments with a new boosting algorithm. In Proceedings of ICML."},{"authors":[{"first":"Michel","last":"Galley"},{"first":"Kathleen","last":"McKeown"},{"first":"Eric","last":"Fosler-Lussier"},{"first":"Hongyan","last":"Jing"}],"year":"2003","title":"Discourse segmentation of multi-party conversation","source":"Michel Galley, Kathleen McKeown, Eric Fosler-Lussier, and Hongyan Jing. 2003. Discourse segmentation of multi-party conversation. In Proceedings of ACL."},{"authors":[{"first":"Martin","last":"Gütlein"},{"first":"Eibe","last":"Frank"},{"first":"Mark","last":"Hall"},{"first":"Andreas","last":"Karwath"}],"year":"2009","title":"Large-scale attribute selection using wrappers","source":"Martin Gütlein, Eibe Frank, Mark Hall, and Andreas Karwath. 2009. Large-scale attribute selection using wrappers. In Proceedings of IEEE CIDM."},{"authors":[{"first":"Eui-Hong","last":"Han"},{"first":"George","last":"Karypis"},{"first":"Vipin","last":"Kumar"}],"year":"2001","title":"Text categorization using weight adjusted k-nearest neighbor classification","source":"Eui-Hong Han, George Karypis, and Vipin Kumar. 2001. Text categorization using weight adjusted k-nearest neighbor classification. Lecture Notes in Computer Science: Advances in Knowledge Discovery and Data Mining."},{"authors":[{"first":"Ahmed","last":"Hassan"},{"first":"Anthony","last":"Fader"},{"first":"Michael","middle":"H","last":"Crespin"},{"first":"Kevin","middle":"M","last":"Quinn"},{"first":"Burt","middle":"L","last":"Monroe"},{"first":"Michael","last":"Colaresi"},{"first":"Dragomir","middle":"R","last":"Radev"}],"year":"2008","title":"Tracking the dynamic evolution of participant salience in a discussion","source":"Ahmed Hassan, Anthony Fader, Michael H Crespin, Kevin M Quinn, Burt L Monroe, Michael Colaresi, and Dragomir R Radev. 2008. Tracking the dynamic evolution of participant salience in a discussion. In Proceedings of Coling."},{"authors":[{"first":"Marti","middle":"A","last":"Hearst"}],"year":"1997","title":"Texttiling: Segmenting text into multi-paragraph subtopic passages","source":"Marti A Hearst. 1997. Texttiling: Segmenting text into multi-paragraph subtopic passages. Computational Linguistics."},{"authors":[{"first":"Julia","last":"Hirschberg"},{"first":"Diane","last":"Litman"}],"year":"1993","title":"Empirical studies on the disambiguation of cue phrases","source":"Julia Hirschberg and Diane Litman. 1993. Empirical studies on the disambiguation of cue phrases. Computational Linguistics."},{"authors":[{"first":"Mette","middle":"Terp","last":"Hoybye"},{"first":"Christoffer","last":"Johansen"},{"first":"Tine","last":"Tjornhoj-Thomsen"}],"year":"2005","title":"Online interaction effects of storytelling in an internet breast cancer support group","source":"Mette Terp Hoybye, Christoffer Johansen, and Tine Tjornhoj-Thomsen. 2005. Online interaction effects of storytelling in an internet breast cancer support group. Psycho-oncology."},{"authors":[{"first":"Hui","last":"Jiang"},{"first":"Keikichi","last":"Hirose"},{"first":"Qiang","last":"Huo"}],"year":"1999","title":"Robust speech recognition based on a bayesian prediction approach","source":"Hui Jiang, Keikichi Hirose, and Qiang Huo. 1999. Robust speech recognition based on a bayesian prediction approach. In IEEE Transactions on Speech and Audio Processing."},{"authors":[{"first":"Niels","last":"Landwehr"},{"first":"Mark","last":"Hall"},{"first":"Eibe","last":"Frank"}],"year":"2005","title":"Logistic model trees","source":"Niels Landwehr, Mark Hall, and Eibe Frank. 2005. Logistic model trees. Machine Learning."},{"authors":[{"first":"Elijah","last":"Mayfield"},{"first":"Carolyn","middle":"Penstein","last":"Rosé"}],"year":"2013","title":"Lightside: Open source machine learning for text","source":"Elijah Mayfield and Carolyn Penstein Rosé. 2013. Lightside: Open source machine learning for text. In Handbook of Automated Essay Evaluation: Current Applications and New Directions. 112"},{"authors":[{"first":"Elijah","last":"Mayfield"},{"first":"David","last":"Adamson"},{"first":"Carolyn","middle":"Penstein","last":"Rosé"}],"year":"2012a","title":"Hierarchical conversation structure prediction in multi-party chat","source":"Elijah Mayfield, David Adamson, and Carolyn Penstein Rosé. 2012a. Hierarchical conversation structure prediction in multi-party chat. In Proceedings of SIGDIAL Meeting on Discourse and Dialogue."},{"authors":[{"first":"Elijah","last":"Mayfield"},{"first":"Miaomiao","last":"Wen"},{"first":"Mitch","last":"Golant"},{"first":"Carolyn","middle":"Penstein","last":"Rosé"}],"year":"2012b","title":"Discovering habits of effective online support group chatrooms","source":"Elijah Mayfield, Miaomiao Wen, Mitch Golant, and Carolyn Penstein Rosé. 2012b. Discovering habits of effective online support group chatrooms. In ACM Conference on Supporting Group Work."},{"authors":[{"first":"Kanayo","last":"Ogura"},{"first":"Takashi","last":"Kusumi"},{"first":"Asako","last":"Miura"}],"year":"2008","title":"Analysis of community development using chat logs: A virtual support group of cancer patients","source":"Kanayo Ogura, Takashi Kusumi, and Asako Miura. 2008. Analysis of community development using chat logs: A virtual support group of cancer patients. In Proceedings of the IEEE Symposium on Universal Communication."},{"authors":[{"first":"Jason","middle":"E.","last":"Owen"},{"first":"Erin","middle":"O’Carroll","last":"Bantum"},{"first":"Mitch","last":"Golant"}],"year":"2008","title":"Benefits and challenges experienced by professional facilitators of online support groups for cancer survivors","source":"Jason E. Owen, Erin O’Carroll Bantum, and Mitch Golant. 2008. Benefits and challenges experienced by professional facilitators of online support groups for cancer survivors. In Psycho-Oncology."},{"authors":[{"first":"Bo","last":"Pang"},{"first":"Lillian","last":"Lee"}],"year":"2004","title":"A sentimental educa-tion: Sentiment analysis using subjectivity summarization based on minimum cuts","source":"Bo Pang and Lillian Lee. 2004. A sentimental educa-tion: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Association for Computational Linguistics."},{"authors":[{"first":"Bambang","last":"Parmanto"},{"first":"Paul","last":"Munro"},{"first":"Howard","middle":"R","last":"Doyle"}],"year":"1996","title":"Improving committee diagnosis with resampling techniques","source":"Bambang Parmanto, Paul Munro, and Howard R Doyle. 1996. Improving committee diagnosis with resampling techniques. In Proceedings of NIPS."},{"authors":[{"first":"James","middle":"W","last":"Pennebaker"},{"first":"J","middle":"D","last":"Seagal"}],"year":"1999","title":"Forming a story: The health benefits of narrative","source":"James W Pennebaker and J D Seagal. 1999. Forming a story: The health benefits of narrative. Journal of Clinical Psychology."},{"authors":[{"first":"Bernardine","middle":"M","last":"Pinto"},{"first":"Nancy","middle":"C","last":"Maruyama"},{"first":"Matthew","middle":"M","last":"Clark"},{"first":"Dean","middle":"G","last":"Cruess"},{"first":"Elyse","last":"Park"},{"first":"Mary","last":"Roberts"}],"year":"2002","title":"Motivation to modify lifestyle risk behaviors in women treated for breast cancer","source":"Bernardine M Pinto, Nancy C Maruyama, Matthew M Clark, Dean G Cruess, Elyse Park, and Mary Roberts. 2002. Motivation to modify lifestyle risk behaviors in women treated for breast cancer. In Mayo Clinic Proceedings."},{"authors":[{"first":"Andrei","last":"Popescu-Belis"}],"year":"2008","title":"Dimensionality of dialogue act tagsets: An empirical analysis of large corpora","source":"Andrei Popescu-Belis. 2008. Dimensionality of dialogue act tagsets: An empirical analysis of large corpora. In Language Resources and Evaluation."},{"authors":[{"first":"Vinodkumar","last":"Prabhakaran"},{"first":"Owen","last":"Rambow"},{"first":"Mona","last":"Diab"}],"year":"2012","title":"Predicting overt display of power in written dialogs","source":"Vinodkumar Prabhakaran, Owen Rambow, and Mona Diab. 2012. Predicting overt display of power in written dialogs. In Proceedings of NAACL."},{"authors":[{"first":"Rashmi","last":"Prasad"},{"first":"Nikhil","last":"Dinesh"},{"first":"Alan","last":"Lee"},{"first":"Eleni","last":"Miltsakaki"},{"first":"Livio","last":"Robaldo"},{"first":"Aravind","last":"Joshi"},{"first":"Bonnie","last":"Webber"}],"year":"2008","title":"The penn discourse treebank 2","source":"Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. In Proceedings of LREC."},{"authors":[{"first":"Megan","middle":"L","last":"Robbins"},{"first":"Elizabeth","middle":"S","last":"Focella"},{"first":"Shelley","last":"Kasle"},{"first":"Ana","middle":"Marı́a","last":"López"},{"first":"Karen","middle":"L","last":"Weihs"},{"first":"Matthias","middle":"R","last":"Mehl"}],"year":"2011","title":"Naturalistically observed swearing, emotional support, and depressive symptoms in women coping with illness","source":"Megan L Robbins, Elizabeth S Focella, Shelley Kasle, Ana Marı́a López, Karen L Weihs, and Matthias R Mehl. 2011. Naturalistically observed swearing, emotional support, and depressive symptoms in women coping with illness. Health Psychology, 30:789."},{"authors":[{"first":"Carolyn","middle":"Penstein","last":"Rosé"},{"first":"Yi-Chia","last":"Wang"},{"first":"Yue","last":"Cui"},{"first":"Jaime","last":"Arguello"},{"first":"Karsten","last":"Stegmann"},{"first":"Armin","last":"Weinberger"},{"first":"Frank","last":"Fischer"}],"year":"2008","title":"Analyzing collaborative learning processes automatically: Exploit-ing the advances of computational linguistics in computer-supported collaborative learning","source":"Carolyn Penstein Rosé, Yi-Chia Wang, Yue Cui, Jaime Arguello, Karsten Stegmann, Armin Weinberger, and Frank Fischer. 2008. Analyzing collaborative learning processes automatically: Exploit-ing the advances of computational linguistics in computer-supported collaborative learning. In International Journal of Computer Supported Collabora-tive Learning."},{"authors":[{"first":"Nikol","last":"Rummel"},{"first":"Armin","last":"Weinberger"},{"first":"Christof","last":"Wecker"},{"first":"Frank","last":"Fischer"},{"first":"Anne","last":"Meier"},{"first":"Eleni","last":"Voyiatzaki"},{"first":"George","last":"Kahrimanis"},{"first":"Hans","last":"Spada"},{"first":"Nikolaos","last":"Avouris"},{"first":"Erin","last":"Walker"}],"year":"2008","title":"New challenges in cscl: Towards adaptive script support","source":"Nikol Rummel, Armin Weinberger, Christof Wecker, Frank Fischer, Anne Meier, Eleni Voyiatzaki, George Kahrimanis, Hans Spada, Nikolaos Avouris, and Erin Walker. 2008. New challenges in cscl: Towards adaptive script support. In Proceedings of ICLS."},{"authors":[{"first":"Christina","last":"Sauper"},{"first":"Regina","last":"Barzilay"}],"year":"2009","title":"Automatically generating wikipedia articles: A structure-aware approach","source":"Christina Sauper and Regina Barzilay. 2009. Automatically generating wikipedia articles: A structure-aware approach. In Proceedings of ACL."},{"authors":[{"first":"Emanuel","middle":"A","last":"Schegloff"}],"year":"1968","title":"Sequencing in conversational openings","source":"Emanuel A Schegloff. 1968. Sequencing in conversational openings. American Anthropologist."},{"authors":[{"first":"Oliver","middle":"G","last":"Selfridge"}],"year":"1958","title":"Pandemonium: a paradigm for learning","source":"Oliver G Selfridge. 1958. Pandemonium: a paradigm for learning. In Proceedings of Symposium on Mechanisation of Thought Processes, Na-tional Physical Laboratory."},{"authors":[{"first":"Gerry","last":"Stahl"}],"year":"2012","title":"Interaction analysis of a biology chat","source":"Gerry Stahl. 2012. Interaction analysis of a biology chat. Productive multivocality."},{"authors":[{"first":"Lee","middle":"H","last":"Staples"}],"year":"1990","title":"Powerful ideas about empowerment","source":"Lee H Staples. 1990. Powerful ideas about empowerment. Administration in Social Work."},{"authors":[{"first":"Yla","middle":"R","last":"Tausczik"},{"first":"James","middle":"W","last":"Pennebaker"}],"year":"2010","title":"The psychological meaning of words: Liwc and computerized text analysis methods","source":"Yla R Tausczik and James W Pennebaker. 2010. The psychological meaning of words: Liwc and computerized text analysis methods. Journal of Language and Social Psychology."},{"authors":[{"first":"Simone","last":"Teufel"},{"first":"Marc","last":"Moens"}],"year":"2002","title":"Summariz-ing scientic articles: Experiments with relevance and rhetorical status","source":"Simone Teufel and Marc Moens. 2002. Summariz-ing scientic articles: Experiments with relevance and rhetorical status. Computational Linguistics."},{"authors":[{"first":"C","middle":"F","last":"Van Uden-Kraan"},{"first":"C","middle":"H C","last":"Drossaert"},{"first":"E","last":"Taal"},{"first":"E","middle":"R","last":"Seydel"},{"first":"M","middle":"A F J Van de","last":"Laar"}],"year":"2009","title":"Participation in online patient support groups endorses patients empowerment","source":"C F Van Uden-Kraan, C H C Drossaert, E Taal, E R Seydel, and M A F J Van de Laar. 2009. Participation in online patient support groups endorses patients empowerment. Patient Education and Counseling."},{"authors":[{"first":"R","last":"Vauth"},{"first":"B","last":"Kleim"},{"first":"M","last":"Wirtz"},{"first":"P","middle":"W","last":"Corrigan"}],"year":"2007","title":"Self-efficacy and empowerment as outcomes of selfstigmatizing and coping in schizophrenia","source":"R Vauth, B Kleim, M Wirtz, and P W Corrigan. 2007. Self-efficacy and empowerment as outcomes of selfstigmatizing and coping in schizophrenia. Psychiatry Research."},{"authors":[{"first":"Ingrid","last":"Wahlin"},{"first":"Anna-Christina","last":"Ek"},{"first":"Ewa","last":"Idvali"}],"year":"2006","title":"Patient empowerment in intensive carean interview study","source":"Ingrid Wahlin, Anna-Christina Ek, and Ewa Idvali. 2006. Patient empowerment in intensive carean interview study. Intensive and Critical Care Nursing."},{"authors":[{"first":"William","middle":"Yang","last":"Wang"},{"first":"Samantha","last":"Finkelstein"},{"first":"Amy","last":"Ogan"},{"first":"Alan","last":"Black"},{"first":"Justine","last":"Cassell"}],"year":"2012","title":"“love ya, jerkface:” using sparse log-linear models to build positive (and impolite) relationships with teens","source":"William Yang Wang, Samantha Finkelstein, Amy Ogan, Alan Black, and Justine Cassell. 2012. “love ya, jerkface:” using sparse log-linear models to build positive (and impolite) relationships with teens. In Proceedings of SIGDIAL."},{"authors":[{"first":"Gary","middle":"M","last":"Weiss"},{"first":"Haym","last":"Hirsh"}],"year":"1998","title":"Learning to predict rare events in event sequences","source":"Gary M Weiss and Haym Hirsh. 1998. Learning to predict rare events in event sequences. In Proceedings of KDD."},{"authors":[{"first":"Janyce","last":"Wiebe"},{"first":"Theresa","last":"Wilson"},{"first":"Claire","last":"Cardie"}],"year":"2005","title":"Annotating expressions of opinions and emotions in language","source":"Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation. 113"}],"cites":[{"style":0,"text":"Prabhakaran et al., 2012","origin":{"pointer":"/sections/2/paragraphs/1","offset":347,"length":24},"authors":[{"last":"Prabhakaran"},{"last":"al."}],"year":"2012","references":["/references/34"]},{"style":0,"text":"Wang et al., 2012","origin":{"pointer":"/sections/2/paragraphs/1","offset":425,"length":17},"authors":[{"last":"Wang"},{"last":"al."}],"year":"2012","references":["/references/49"]},{"style":0,"text":"Rosé et al., 2008","origin":{"pointer":"/sections/2/paragraphs/1","offset":576,"length":17},"authors":[{"last":"Rosé"},{"last":"al."}],"year":"2008","references":["/references/37"]},{"style":0,"text":"Pang and Lee, 2004","origin":{"pointer":"/sections/2/paragraphs/1","offset":721,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2004","references":["/references/29"]},{"style":0,"text":"Rummel et al., 2008","origin":{"pointer":"/sections/2/paragraphs/2","offset":214,"length":19},"authors":[{"last":"Rummel"},{"last":"al."}],"year":"2008","references":["/references/38"]},{"style":0,"text":"Adamson and Rosé, 2012","origin":{"pointer":"/sections/2/paragraphs/2","offset":235,"length":22},"authors":[{"last":"Adamson"},{"last":"Rosé"}],"year":"2012","references":["/references/1"]},{"style":0,"text":"Dillenbourg, 2002","origin":{"pointer":"/sections/2/paragraphs/2","offset":552,"length":17},"authors":[{"last":"Dillenbourg"}],"year":"2002","references":["/references/7"]},{"style":0,"text":"Stahl, 2012","origin":{"pointer":"/sections/2/paragraphs/2","offset":571,"length":11},"authors":[{"last":"Stahl"}],"year":"2012","references":["/references/42"]},{"style":0,"text":"Uden-Kraan et al., 2009","origin":{"pointer":"/sections/2/paragraphs/4","offset":511,"length":23},"authors":[{"last":"Uden-Kraan"},{"last":"al."}],"year":"2009","references":[]},{"style":0,"text":"Boehm and Staples, 2002","origin":{"pointer":"/sections/3/paragraphs/1","offset":200,"length":23},"authors":[{"last":"Boehm"},{"last":"Staples"}],"year":"2002","references":["/references/4"]},{"style":0,"text":"Staples, 1990","origin":{"pointer":"/sections/3/paragraphs/1","offset":351,"length":13},"authors":[{"last":"Staples"}],"year":"1990","references":["/references/43"]},{"style":0,"text":"Uden-Kraan et al., 2009","origin":{"pointer":"/sections/3/paragraphs/1","offset":433,"length":23},"authors":[{"last":"Uden-Kraan"},{"last":"al."}],"year":"2009","references":[]},{"style":0,"text":"Barak et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":458,"length":18},"authors":[{"last":"Barak"},{"last":"al."}],"year":"2008","references":["/references/3"]},{"style":0,"text":"Vauth et al., 2007","origin":{"pointer":"/sections/3/paragraphs/1","offset":603,"length":18},"authors":[{"last":"Vauth"},{"last":"al."}],"year":"2007","references":["/references/47"]},{"style":0,"text":"Owen et al., 2008","origin":{"pointer":"/sections/3/paragraphs/1","offset":691,"length":17},"authors":[{"last":"Owen"},{"last":"al."}],"year":"2008","references":["/references/28"]},{"style":0,"text":"Wahlin et al., 2006","origin":{"pointer":"/sections/3/paragraphs/1","offset":733,"length":19},"authors":[{"last":"Wahlin"},{"last":"al."}],"year":"2006","references":["/references/48"]},{"style":0,"text":"Pennebaker and Seagal, 1999","origin":{"pointer":"/sections/3/paragraphs/2","offset":202,"length":27},"authors":[{"last":"Pennebaker"},{"last":"Seagal"}],"year":"1999","references":["/references/31"]},{"style":0,"text":"Bandura, 1997","origin":{"pointer":"/sections/3/paragraphs/3","offset":79,"length":13},"authors":[{"last":"Bandura"}],"year":"1997","references":["/references/2"]},{"style":0,"text":"Hoybye et al., 2005","origin":{"pointer":"/sections/3/paragraphs/9","offset":38,"length":19},"authors":[{"last":"Hoybye"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"Ogura et al., 2008","origin":{"pointer":"/sections/3/paragraphs/9","offset":117,"length":18},"authors":[{"last":"Ogura"},{"last":"al."}],"year":"2008","references":["/references/27"]},{"style":0,"text":"Mayfield et al., 2012b","origin":{"pointer":"/sections/3/paragraphs/9","offset":137,"length":22},"authors":[{"last":"Mayfield"},{"last":"al."}],"year":"2012b","references":["/references/26"]},{"style":0,"text":"Hassan et al., 2008","origin":{"pointer":"/sections/3/paragraphs/10","offset":347,"length":19},"authors":[{"last":"Hassan"},{"last":"al."}],"year":"2008","references":["/references/18"]},{"style":0,"text":"Mayfield et al., 2012b","origin":{"pointer":"/sections/4/paragraphs/2","offset":96,"length":22},"authors":[{"last":"Mayfield"},{"last":"al."}],"year":"2012b","references":["/references/26"]},{"style":0,"text":"Adams and Martel, 2010","origin":{"pointer":"/sections/4/paragraphs/7","offset":364,"length":22},"authors":[{"last":"Adams"},{"last":"Martel"}],"year":"2010","references":["/references/0"]},{"style":0,"text":"Popescu-Belis, 2008","origin":{"pointer":"/sections/4/paragraphs/8","offset":107,"length":19},"authors":[{"last":"Popescu-Belis"}],"year":"2008","references":["/references/33"]},{"style":0,"text":"Wiebe et al., 2005","origin":{"pointer":"/sections/4/paragraphs/8","offset":201,"length":18},"authors":[{"last":"Wiebe"},{"last":"al."}],"year":"2005","references":["/references/51"]},{"style":0,"text":"Hoybye et al., 2005","origin":{"pointer":"/sections/4/paragraphs/8","offset":363,"length":19},"authors":[{"last":"Hoybye"},{"last":"al."}],"year":"2005","references":["/references/21"]},{"style":0,"text":"Mayfield et al., 2012b","origin":{"pointer":"/sections/4/paragraphs/8","offset":468,"length":22},"authors":[{"last":"Mayfield"},{"last":"al."}],"year":"2012b","references":["/references/26"]},{"style":0,"text":"Breck et al., 2007","origin":{"pointer":"/sections/4/paragraphs/8","offset":697,"length":18},"authors":[{"last":"Breck"},{"last":"al."}],"year":"2007","references":["/references/5"]},{"style":0,"text":"Schegloff, 1968","origin":{"pointer":"/sections/4/paragraphs/10","offset":198,"length":15},"authors":[{"last":"Schegloff"}],"year":"1968","references":["/references/40"]},{"style":0,"text":"Prasad et al., 2008","origin":{"pointer":"/sections/4/paragraphs/10","offset":495,"length":19},"authors":[{"last":"Prasad"},{"last":"al."}],"year":"2008","references":["/references/35"]},{"style":0,"text":"Weiss and Hirsh, 1998","origin":{"pointer":"/sections/4/paragraphs/11","offset":163,"length":21},"authors":[{"last":"Weiss"},{"last":"Hirsh"}],"year":"1998","references":["/references/50"]},{"style":0,"text":"Bouckaert, 2006","origin":{"pointer":"/sections/4/paragraphs/11","offset":238,"length":15},"authors":[{"last":"Bouckaert"}],"year":"2006","references":[]},{"style":0,"text":"Hirschberg and Litman, 1993","origin":{"pointer":"/sections/5/paragraphs/1","offset":234,"length":27},"authors":[{"last":"Hirschberg"},{"last":"Litman"}],"year":"1993","references":["/references/20"]},{"style":0,"text":"Hearst, 1997","origin":{"pointer":"/sections/5/paragraphs/1","offset":307,"length":12},"authors":[{"last":"Hearst"}],"year":"1997","references":["/references/19"]},{"style":0,"text":"Galley et al., 2003","origin":{"pointer":"/sections/5/paragraphs/1","offset":339,"length":19},"authors":[{"last":"Galley"},{"last":"al."}],"year":"2003","references":["/references/15"]},{"style":0,"text":"Pang and Lee, 2004","origin":{"pointer":"/sections/5/paragraphs/1","offset":449,"length":18},"authors":[{"last":"Pang"},{"last":"Lee"}],"year":"2004","references":["/references/29"]},{"style":0,"text":"Teufel and Moens, 2002","origin":{"pointer":"/sections/5/paragraphs/1","offset":694,"length":22},"authors":[{"last":"Teufel"},{"last":"Moens"}],"year":"2002","references":["/references/45"]},{"style":0,"text":"Sauper and Barzilay, 2009","origin":{"pointer":"/sections/5/paragraphs/1","offset":739,"length":25},"authors":[{"last":"Sauper"},{"last":"Barzilay"}],"year":"2009","references":["/references/39"]},{"style":0,"text":"Fan et al., 2008","origin":{"pointer":"/sections/5/paragraphs/4","offset":108,"length":16},"authors":[{"last":"Fan"},{"last":"al."}],"year":"2008","references":["/references/10"]},{"style":0,"text":"Parmanto et al., 1996","origin":{"pointer":"/sections/5/paragraphs/12","offset":362,"length":21},"authors":[{"last":"Parmanto"},{"last":"al."}],"year":"1996","references":["/references/30"]},{"style":0,"text":"Gütlein et al., 2009","origin":{"pointer":"/sections/5/paragraphs/15","offset":409,"length":20},"authors":[{"last":"Gütlein"},{"last":"al."}],"year":"2009","references":["/references/16"]},{"style":0,"text":"Parmanto et al., 1996","origin":{"pointer":"/sections/6/paragraphs/0","offset":94,"length":21},"authors":[{"last":"Parmanto"},{"last":"al."}],"year":"1996","references":["/references/30"]},{"style":0,"text":"Erp et al., 2002","origin":{"pointer":"/sections/6/paragraphs/0","offset":211,"length":16},"authors":[{"last":"Erp"},{"last":"al."}],"year":"2002","references":[]},{"style":0,"text":"Selfridge, 1958","origin":{"pointer":"/sections/6/paragraphs/2","offset":126,"length":15},"authors":[{"last":"Selfridge"}],"year":"1958","references":["/references/41"]},{"style":0,"text":"Erp et al., 2002","origin":{"pointer":"/sections/6/paragraphs/22","offset":503,"length":16},"authors":[{"last":"Erp"},{"last":"al."}],"year":"2002","references":[]},{"style":0,"text":"Franco et al., 2010","origin":{"pointer":"/sections/6/paragraphs/38","offset":179,"length":19},"authors":[{"last":"Franco"},{"last":"al."}],"year":"2010","references":["/references/11"]},{"style":0,"text":"Jiang et al., 1999","origin":{"pointer":"/sections/6/paragraphs/38","offset":246,"length":18},"authors":[{"last":"Jiang"},{"last":"al."}],"year":"1999","references":["/references/22"]},{"style":0,"text":"Landwehr et al., 2005","origin":{"pointer":"/sections/6/paragraphs/39","offset":75,"length":21},"authors":[{"last":"Landwehr"},{"last":"al."}],"year":"2005","references":["/references/23"]},{"style":0,"text":"Han et al., 2001","origin":{"pointer":"/sections/6/paragraphs/39","offset":464,"length":16},"authors":[{"last":"Han"},{"last":"al."}],"year":"2001","references":["/references/17"]},{"style":0,"text":"Tausczik and Pennebaker, 2010","origin":{"pointer":"/sections/6/paragraphs/40","offset":409,"length":29},"authors":[{"last":"Tausczik"},{"last":"Pennebaker"}],"year":"2010","references":["/references/44"]},{"style":0,"text":"Mayfield and Rosé, 2013","origin":{"pointer":"/sections/7/paragraphs/0","offset":48,"length":23},"authors":[{"last":"Mayfield"},{"last":"Rosé"}],"year":"2013","references":["/references/24"]},{"style":0,"text":"Mayfield et al., 2012a","origin":{"pointer":"/sections/7/paragraphs/0","offset":463,"length":22},"authors":[{"last":"Mayfield"},{"last":"al."}],"year":"2012a","references":["/references/25"]},{"style":0,"text":"Freund and Schapire, 1996","origin":{"pointer":"/sections/7/paragraphs/0","offset":749,"length":25},"authors":[{"last":"Freund"},{"last":"Schapire"}],"year":"1996","references":["/references/14"]},{"style":0,"text":"Breiman, 1996","origin":{"pointer":"/sections/7/paragraphs/0","offset":789,"length":13},"authors":[{"last":"Breiman"}],"year":"1996","references":["/references/6"]},{"style":0,"text":"Fraser, 1999","origin":{"pointer":"/sections/8/paragraphs/6","offset":857,"length":12},"authors":[{"last":"Fraser"}],"year":"1999","references":["/references/13"]},{"style":0,"text":"Robbins et al., 2011","origin":{"pointer":"/sections/8/paragraphs/7","offset":1194,"length":20},"authors":[{"last":"Robbins"},{"last":"al."}],"year":"2011","references":["/references/36"]},{"style":0,"text":"Pinto et al., 2002","origin":{"pointer":"/sections/8/paragraphs/7","offset":1419,"length":18},"authors":[{"last":"Pinto"},{"last":"al."}],"year":"2002","references":["/references/32"]}]}
