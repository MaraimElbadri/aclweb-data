{"sections":[{"title":"Resolving Ellipsis in Clarification Jonathan Ginzburg Dept of Computer Science King’s College, London The Strand, London WC2R 2LS UK ginzburg@dcs.kcl.ac.uk Robin Cooper Dept of Linguistics Göteborg University Box 200, 405 30 Göteborg, Sweden cooper@ling.gu.se Abstract","paragraphs":["We offer a computational analysis of the resolution of ellipsis in certain cases of dialogue clarification. We show that this goes beyond standard techniques used in anaphora and ellipsis resolution and requires operations on highly structured, linguistically heterogeneous representations. We characterize these operations and the representations on which they operate. We offer an analysis couched in a version of Head-Driven Phrase Structure Grammar combined with a theory of information states (IS) in dialogue. We sketch an algorithm for the process of utterance integration in ISs which leads to grounding or clarification."]},{"title":"1 Introduction","paragraphs":["Clarification ellipsis (CE), nonsentential elliptical queries such as (1a(i),(ii)) are commonplace in human conversation. Two common readings/understandings of CE are exemplified in (1b,c): the clausal reading is commonly used simply to confirm the content of a particular subutter-ance. The main function of the constituent reading is to elicit an alternative description or ostension to the content (referent or predicate etc) in-tended by the original speaker of the reprised sub-utterance.","(1) a. A: Did Bo finagle a raise? B: (i) Bo?/ (ii) finagle? b. Clausal reading: Are you asking if BO (of all people) finagled a raise/Bo FI-NAGLED a raise (of all actions) c. Constituent reading: Who is Bo?/What does it mean to finagle?","The issue of whether CE involves an ambiguity or is simply vague is an important one.1","2 Clearly, pragmatic reasoning plays an important role in understanding CEs. Some considerations do, nonetheless, favour the existence of an ambiguity. First, the BNC provides numerous examples of misunderstandings concerning CE interpretation,3","where a speaker intends one reading, is misunderstood, and clarifies his original interpretation:","(2) a. A: ... you always had er er say every foot he had with a piece of spunyarn in the wire/B: Spunyarn?/A: Spunyarn, yes/B: What’s spunyarn?","b. A: Have a laugh and joke with Dick./","B: Dick?/A: Have a laugh and joke with","Dick./B: Who’s Dick?","1","An anonymous ACL reviewer proposed to us that all CE could be analyzed in terms of a single reading along the lines of “I thought I heard you say Bo, and I don’t know why you would do so?”.","2","Closely related to this issue is the issue of what other readings/understandings CE exhibits. We defer discussion of the latter issue to (Purver et al., 2001), which provides a detailed analysis of the frequency of CEs and their understandings among clarification utterances in the British Na-tional Corpus (BNC).","3","This confirms our (non-instrumentally tested) impression that these understandings are not on the whole disambiguated intonationally. All our CE data from the BNC was found using SCoRE, Matt Purver’s dialogue oriented BNC search engine (Purver, 2001).","More crucially, the clausal and constituent readings involve distinct syntactic and phonological parallelism conditions. The constituent reading seems to actually require phonological identity. With the resolution associated with clausal readings, there is no such requirement. However, partial syntactic parallelism does obtain: an XP used to clarify an antecedent sub-utterance must match","categorially, though there is no requirement of phonological identity:","(3) a. A: I phoned him. B: him? / #he? b. A: Did he adore the book. B: adore? / #adored? c. A: We’re leaving? B: You?","We are used to systems that will confirm the user’s utterances by repeating part of them. These presuppose no sophisticated linguistic analysis. However, it is not usual for a system to be able to process CEs produced by the user. It would be a great advantage in negotiative dialogues, where, for example, the system and the user might be discussing several options and the system may make alternative suggestions, for a system to be able to recognize and interpret a CE. Consider the following (constructed) dialogue in the route-planning domain:","(4) Sys: Would you like to make that trip via Malvern? User: Malvern?","At this point the system has to consider a number of possible intepretations for the user’s utterance all of which involve recognizing that this is a clarification request concerning the system’s last utterance.","Appropriate responses might be (5a-c); the system should definitely not say (5d), as it might if it does not recognize that the user is trying to clarify its previous utterance.","(5) a. Yes, Malvern b. Malvern – M-A-L-V-E-R-N c. Going via Malvern is the quickest route d. So, you would like to make that trip via Malvern instead of Malvern?","In this paper we examine the interpretation of CEs. CE is a singularly complex ellipsis/anaphoric phenomenon which cannot be handled by standard techniques such as first order unification (as anaphora often is) or by higher order unification (HOU) on logical forms (see e.g. (Pulman, 1997)). For a start, in order to capture the syntactic and phonological parallelism exemplified in (3), logical forms are simply in-sufficient. Moreover, although an HOU account could, given a theory of dialogue that structures context appropriately, generate the clausal reading, the constituent reading cannot be so generated. Clark (e.g. (Clark, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the representations on which they operate. We then provide the requisite background on HPSG and on the KOS framework (Ginzburg, 1996; Bohlin et al., 1999), in which our analysis of ISs is couched. We sketch an algorithm for the process of utterance integration which leads to grounding or clarification. Finally, we formalize the operations which underpin clarification and sketch a grammatical analysis of CE."]},{"title":"2 Utterance Representation: grounding and clarification","paragraphs":["We start by offering an informal description of how an utterance","such as (6) can get grounded or spawn a clarification by an addressee B: (6) A: Did Bo leave?","A is attempting to convey to B her question whether the property she has referred to with her utterance of leave holds of the person she has referred to with the name Bo. B is required to try and find values for these references. Finding values is, with an important caveat, a necessary condition for B to ground A’s utterance, thereby signalling that its content has been integrated in B’s IS.4","Modelling this condition for successful grounding provides one obvious constraint on the representation of utterance types: such a representation must involve a function from or ","- abstract over a set of certain parameters (the contextual parameters) to contents. This much is familiar already from early work on context dependence by (Montague, 1974) et seq. What happens when B cannot or is at least uncertain as to how he should instantiate in his IS a contextual parameter","? In such a case B needs to do at least the following: (1) perform a partial update of the existing context with the successfully processed components of the utterance (2) pose a clarification question that involves reference to the sub-utterance u","from which","emanates. Since the original speaker, A, can coherently integrate a clarification question once she hears it, it follows that, for a given utterance, there is a predictable range of","partial updates + consequent clarification questions",". These we take to be specified by a set of coercion operations on utterance representations.5","Indeed we assume that a component of dialogue competence is knowledge of these coercion operations.","CE gives us some indication concerning both the input and required output of these operations. One such operation, which we will refer to as parameter identification, essentially involves as output a question paraphrasable as what is the in-tended reference of sub-utterance u","?. The par-tially updated context in which such a clarification takes place is such that simply repeating the segmental phonology of u","using rising intonation enables that question to be expressed. An-other existent coercion operation is one which we will refer to as parameter focussing. This involves a (partially updated) context in which the issue under discussion is a question that arises by instantiating all contextual parameters except for  and abstracting over",". In such a context, one","4","The caveat is, of course, that the necessity is goal driven. Relative to certain goals, one might decide simply to existen-tially quantify the problematic referent. For this operation on meanings see (Cooper, 1998). We cannot enter here into a discussion of how to integrate the view developed here in a plan based view of understanding, but see (Ginzburg, (forthcoming)) for this.","5","The term coercion operation is inspired by work on utterance representation within a type theoretic framework reported in (Cooper, 1998). can confirm that","gets the value B suspects it has by uttering with rising intonation any apparently co-referential phrase whose syntactic category is identical to","’s.","From this discussion, it becomes clear that coercion operations (and by extension the grounding process) cannot be defined simply on meanings. Rather, given the syntactic and phonological parallelism encoded in clarification contexts, these operations need to be defined on representations that encode in parallel for each sub-utterance down to the word level phonological, syntactic, semantic, and contextual information. With some minor modifications, signs as conceived in HPSG are exactly such a representa-tional format and, hence, we will use them to define coercion operations.6","More precisely, given that an addressee might not be able to come up with a unique or a complete parse, due to lexi-cal ignorance or a noisy environment, we need to utilize some ‘underspecified’ entity (see e.g. (Milward, 2000)). For simplicity we will use descrip-tions of signs. An example of the format for signs we employ is given in (7):7","6","We make two minor modifications to the version of HPSG described in (Ginzburg and Sag, 2000)). First, we revamp the existing treatment of the feature C-INDICES. This will now encode the entire inventory of contextual parameters of an utterance (proper names, deictic pronouns, indexicals) not merely information about speaker/hearer/utterance-time, as standardly. Indeed, in principle, relation names should also be included, since they vary with context and are subject to clarification as well. Such a step involves a significant change to how argument roles are handled in existing HPSG. Hence, we do not make such a move here. This modification of C-INDICES will allow signs to play a role akin to the role associated with ‘meanings’, i.e. to function as abstracts with roles that need to be instantiated. The second modification we make concerns the encoding of phrasal constituency. Standardly, the feature DTRS is used to encode immediate phrasal constituency. To facilitate statement of coercion operations, we need access to all phrasal constituents— given that a contextual parameter emanating from deeply embedding constituents are as clarifiable as immediate constituents. We posit a set valued feature CONSTIT(UENT)S whose value is the set of all constituents immediate or otherwise of a given sign (Cf. the mother-daughter predicates used in (Gregory and Lappin, 1999).) In fact, having posited CONSTITS one could eliminate DTRS: this by making the value of CONSTITS be a set of sets whose first level elements are the immediate constituents. For current purposes, we stick with tradition and tolerate the redundancy of both DTRS and CONSTITS.","7","Within the phrasal type system of (Ginzburg and Sag, 2000) root-cl constitutes the ‘start’ symbol of the grammar. In particular, phrases of this type have as their content an illocutionary operator embedding the appropriate semantic","(7)                                 root-cl PHON did bo leave CAT V[+fin]","C-INDICES  ,",",",", i,j CONT              ASK-REL ASKER i ASKED j MSG-ARG        question","PARAMS ","PROP SOA   leave-rel AGT TIME                    ","CTXT BCKGRD","utt-time( ),","precede( ,","), named(bo)(",")","CONSTITS  ","PHON Did , ","PHON Bo ,  ","PHON leave ,  PHON Did Bo leave                                 ","Before we can explain how these representations can feature in dialogue reasoning and the resolution of CE, we need to sketch briefly the approach to dialogue ellipsis that we assume."]},{"title":"3 Contextual evolution and ellipsis","paragraphs":["We adopt the situation semantics based theory of dialogue context developed in the KOS framework (Ginzburg, 1996; Ginzburg, (forthcoming); Bohlin et al., 1999). The common ground component of ISs is assumed to be structured as follows:8 (8) FACTS set of facts LATEST-MOVE (illocutionary) fact QUD p.o. set of questions  ","In (Ginzburg and Sag, 2000) this framework is integrated into HPSG (Pollard and Sag, 1994); (Ginzburg and Sag, 2000) define two new at-tributes within the CONTEXT (CTXT) feature structure: Maximal Question Under Discussion (MAX-QUD), whose value is of sort question;9 object (an assertion embedding a proposition, a query embedding a question etc.). Here and throughout we omit various features (e.g. STORE, SLASH etc that have no bearing on current issues wherever possible.","8","Here FACTS corresponds to the set of commonly accepted assumptions; QUD(‘questions under discussion’) is a set consisting of the currently discussable questions, par-tially ordered by","(‘takes conversational precedence’); LATEST-MOVE represents information about the content and structure of the most recent accepted illocutionary move.","9","Questions are represented as semantic objects compris-ing a set of parameters—empty for a polar question—and a and Salient Utterance (SAL-UTT), whose value is a set (singleton or empty) of elements of type sign. In information structure terms, SAL-UTT can be thought of as a means of underspecifying the subsequent focal (sub)utterance or as a potential parallel element. MAX-QUD corresponds to the ground of the dialogue at a given point. Since SAL-UTT is a sign, it enables one to encode syntactic categorial parallelism and, as we will see below, also phonological parallelism. SAL-UTT is computed as the (sub)utterance associated with the role bearing widest scope within MAX-QUD.10 Below, we will show how to extend this account of parallelism to clarification queries.","To account for elliptical constructions such as short answers and sluicing, Ginzburg and Sag posit a phrasal type headed-fragment-phrase (hdfrag-ph)—a subtype of hd-only-ph—governed by the constraint in (9). The various fragments analyzed here will be subtypes of hd-frag-ph or else will contain such a phrase as a head daughter.11","(9)        HEAD v","CTXT SAL-UTT","CAT","CONT","INDEX"," HD-DTR CAT  HEAD nominal","CONT INDEX","       ","This constraint coindexes the head daughter with the SAL-UTT. This will have the effect of ‘unifying in’ the content of the former into a contextually provided content. A subtype of hd-fragph relevant to the current paper is (decl-frag-cl)— also a subtype of decl-cl—used to analyze short answers: proposition. This is the feature structure counterpart of the -abstract"," ",".","10","For Wh-questions, SAL-UTT is the wh-phrase associated with the PARAMS set of the question; otherwise, its possible values are either the empty set or the utterance associated with the widest scoping quantifier in MAX-QUD.","11","In the (Ginzburg and Sag, 2000) version of HPSG information about phrases is encoded by cross-classifying them in a multi-dimensional type hierarchy. Phrases are classified not only in terms of their phrase structure schema or X-bar type, but also with respect to a further informational dimension of CLAUSALITY. Clauses are divided into inter alia declarative clauses (decl-cl), which denote propositions, and interrogative clauses (inter-cl) denoting questions. Each maximal phrasal type inherits from both these dimensions. This classification allows specification of systematic correlations between clausal construction types and types of semantic content.","(10)                       STORE CONT     proposition SIT SOA","QUANTS order( )","","NUCL","    MAX-QUD          question PARAMS neset PROP     proposition SIT SOA QUANTS NUCL","           ","HD-DTR","STORE ","","set(param)                        The content of this phrasal type is a proposition: whereas in most headed clauses the content is entirely (or primarily) derived from the head daughter, here it is constructed for the most part from the contextually salient question. This provides the concerned situation and the nucleus, whereas if the fragment is (or contains) a quantifier, that quantifier must outscope any quantifiers already present in the contextually salient question."]},{"title":"4 Integrating Utterances in Information States","paragraphs":["Before we turn to formalizing the coercion operations and describing CE, we need to explain how on our view utterances get integrated in an agent’s IS. The basic protocol we assume is given in (11) below.12 (11) Utterance processing protocol","For an agent B with IS",": if an utterance","is Maximal in","PENDING:","(a) Try to:","(1) find an assignment in","for",", where","is the (maximal","description available for) the sign associated with","(2) update LATEST-MOVE with",":","1. If LATEST-MOVE is grounded, then FACTS:= FACTS + LATEST-MOVE; 2. LATEST-MOVE := (3) React to content(u) according to querying/assertion protocols. (4) If successful,","is removed from PENDING (b) Else: Repeat from stage (a) with MAX-QUD and SAL-UTT obtaining the various values of coe   ",", where ","is the sign","associated with LATEST-MOVE and coe","is one of the","available coercion operations; 12 In this protocol, PENDING is a stack whose elements","are (unintegrated) utterances. (c) Else: make an utterance appropriate for a context such that MAX-QUD and SAL-UTT get values according to the specification in coe   ",", where coe is one of the available coercion operations.","The protocol involves the assumption that an agent always initially tries to integrate an utterance by assuming it constitutes an adjacency pair with the existing LATEST-MOVE. If this route is blocked somehow, because the current utterance cannot be grounded or the putative resolution leads to incoherence, only then does she try to repair by assuming the previous utterance is a clarification generated in accordance with the existing coercion operations. If that too fails, then, she herself generates a clarification. Thus, the prediction made by this protocol is that A will tend to initially interpret (12(2)) as a response to her question, not as a clarification:","(12) A(1): Who do you think is the only person that admires Mary? B(2): Mary?"]},{"title":"5 Sign Coercion and an Analysis of CE","paragraphs":["We now turn to formalizing the coercion operations we specified informally in section 2. The first operation we define is parameter focussing:","(13) parameter focussing  :       root-cl","CTXT-INDICES      CONSTITS   ","CONT    CONTENT                ","CONTENT MSG-ARG question PROP"," SAL-UTT MAX-QUD    question","PARAMS   PROP           ","This is to be understood as follows: given an utterance (whose associated sign is one) which satisfies the specification in the LHS of the rule, a CP may respond with any utterance which satisfies the specification in the RHS of the rule.13","More specifically, the input of the rules singles out a","13","The fact that both the LHS and the RHS of the rule are of type root-cl ensures that the rule applies only to signs associated with complete utterances. contextual parameter",", which is the content of an element of the daughter set of the utterance 2 . Intuitively,","is a parameter whose value is problematic or lacking. The sub-utterance 2 is specified to constitute the value of the feature SAL-UTT associated with the context of the clarification utterance","",". The descriptive content of","","is a question, any question whose open proposition 3 (given in terms of the feature PROP) is identical to the (uninstantiated) content of the clarified utterance. MAX-QUD associated with the clarification is fully specified as a question whose open proposition is 3 and whose PARAMS set consists of the ‘problematic’ parameter",".","We can exemplify the effect of parameter focussing with respect to clarifying an utterance of (7). The output this yields, when applied to Bo’s index 1 , is the partial specification in (14). Such an utterance will have as its MAX-QUD a question cq","paraphrasable as who",", named Bo, are you asking if t left, whereas its SAL-UTT is the sub-utterance of Bo. The content is underspecified:","(14)                   ","CONT MSG-ARG","question","PROP",""," SAL-UTT MAX-QUD               question","PARAMS  ","","PROP SOA","          ASK-REL ASKER i ASKED j MSG-ARG      question","PARAMS  ","PROP SOA","","leave-rel AGT  TIME","","                                             ","This (partial) specification allows for clarification questions such as the following:","(15) a. Did WHO leave? b. WHO? c. BO? (= Are you asking if BO left?)","Given space constraints, we restrict ourselves to explaining how the clausal CE, (15c), gets analyzed. This involves direct application of the type decl-frag-cl discussed above for short answers. The QUD-maximality of cq","allows us to analyze the fragment as a ‘short answer’ to cq",", using the type bare-decl-cl. And out of the proposition which emerges courtesy of bare-decl-cl a (polar) question is constructed using the type dir-is-intcl.14 (16) S                      dir-is-int-cl CONT                    question","PARAMS  PROP              ask-rel ASKER i ASKED j        question","PARAMS ","PROP SOA   leave-rel AGT TIME                                                            S              decl-frag-cl CONT CTXT         MAX-QUD    question PARAMS ","INDEX   PROP   SAL-UTT","CAT","CONT","INDEX","                     ","CAT NP","CONT INDEX"," Bo","The second coercion operation we discussed previously is parameter identification: for a given problematic contextual parameter its output is a partial specification for a sign whose content and MAX-QUD involve a question querying the content of that utterance parameter:","14","The phrasal type dir-is-int-cl which constitutes the type of the mother node in (16) is a type that inter alia enables a polar question to be built from a head daughter whose content is propositional. See (Ginzburg and Sag, 2000) for details.","(17) parameter identification  :       root-cl CTXT-INDICES     CONSTITS   ","CONT                        ","CONTENT MSG-ARG question PROP"," SAL-UTT MAX-QUD         question PARAMS  INDEX    PROP   SOA   content-rel SIGN CONT                          ","To exemplify: when this operation is applied to (7), it will yield as output the partial specification in (18):","(18)                     ","CONT MSG-ARG question PROP"," SAL-UTT     PHON bo CAT NP CONT","INDEX","","CTXT","BCKGRD","named(Bo)(",")    MAX-QUD         question PARAMS ","INDEX   PROP   SOA   content-rel SIGN CONT                               ","This specification will allows for clarification questions such as the following: (19) a. Who do you mean BO?","b. WHO? (= who is Bo)","c. Bo? (= who is Bo)","We restrict attention to (19c), which is the most interesting but also tricky example. The tricky part arises from the fact that in a case such as this, in contrast to all previous examples, the fragment does not contribute its conventional content to the clausal content. Rather, as we suggested earlier, the semantic function of the fragment is merely to serve as an anaphoric element to the phonologically identical to–be–clarified sub-utterance. The content derives entirely from MAX-QUD. Such utterances can still be analyzed as subtypes of head-frag-ph, though not as decl-frag-cl, the short-answer/reprise sluice phrasal type we have been appealing to extensively. Thus, we posit constit(uent)-clar(ification)-int-cl, a new phrasal subtype of head-frag-ph and of inter-cl which encapsulates the two idiosyncratic facets of such utterances, namely the phonological parallelism and the max-qud/content identity:","(20)   CONT CTXT","MAX-QUD","SAL-UTT","PHON","    H ","PHON ","Given this, (19c) receives the following analysis:","(21)                 constit-repr-int-cl CONT    question","PARAMS  ","PROP content( ,",")   CTXT    MAX-QUD","SAL-UTT  PHON CAT  NP   HD-DTR PHON CAT                  "]},{"title":"6 Summary and Future Work","paragraphs":["In this paper we offered an analysis of the types of representations needed to analyze CE, the requisite operations thereon, and how these update ISs during grounding and clarification.","Systems which respond appropriately to CEs in general will need a great deal of background knowledge. Even choosing among the responses in (5) might be a pretty knowledge intensive business. However, there are some clear strategies that might be pursued. For example, if Malvern has been discussed previously in the dialogue and understood then (5a,b) would not be appropriate responses. In order to be able to build dialogue systems that can handle even some restricted aspects of CEs we need to understand more about what the possible interpretations are and this is what we have attempted to do in this paper. We are currently working on a system which integrates SHARDS (see (Ginzburg et al., 2001), a system which processes dialogue ellipses) with GoDiS (see (Bohlin et al., 1999), a dialogue system developed using TRINDIKIT, which makes use of ISs modelled on those suggested in the KOS framework. Our aim in the near future is to in-corporate simple aspects of negotiative dialogue including CEs in a GoDiS-like system employing SHARDS."]},{"title":"Acknowledgements","paragraphs":["For very useful discussion and comments we would like to thank Pat Healey, Howard Gregory, Shalom Lappin, Dimitra Kolliakou, David Milward, Matt Purver and three anonymous ACL reviewers. We would also like to thank Matt Purver for help in using SCoRE. Earlier versions of this work were presented at colloquia at ITRI, Brighton, Queen Mary and Westfield College, London, and at the Computer Lab, Cambridge. The research described here is funded by grant number R00022269 from the Economic and Social Research Council of the United Kingdom, by INDI (Information Exchange in Dialogue), Riksbankens Jubileumsfond 1997-0134, and by grant number GR/R04942/01 from the Engineering and Physical Sciences Research Council of the United Kingdom."]},{"title":"References","paragraphs":["Peter Bohlin, Robin Cooper, Elisabet Engdahl, and Staffan Larsson. 1999. Information states and dialogue move engines. Gothenburg Papers in Computational Linguistics.","Herbert Clark. 1996. Using Language. Cambridge University Press, Cambridge.","Robin Cooper. 1998. Mixing situation theory and type theory to formalize information states in dialogue exchanges. In J. Hulstijn and A. Nijholt, editors, Proceedings of TwenDial 98, 13th Twente workshop on Language Technology. Twente University, Twente.","Jonathan Ginzburg and Ivan Sag. 2000. Interrogative Investigations: the form, meaning and use of English Interrogatives. Number 123 in CSLI Lecture Notes. CSLI Publications, Stanford: California.","Jonathan Ginzburg, Howard Gregory, and Shalom Lappin. 2001. Shards: Fragment resolution in dialogue. In H. Bunt, editor, Proceedings of the 1st International Workshop on Computational Semantics. ITK, Tilburg University, Tilburg.","Jonathan Ginzburg. 1996. Interrogatives: Questions, facts, and dialogue. In Shalom Lappin, editor, Handbook of Contemporary Semantic Theory. Blackwell, Oxford.","Jonathan Ginzburg. forthcoming. Semantics and Interaction in Dialogue. CSLI Publications and Cambridge University Press, Stanford: California. Draft chapters available from http://www.dcs.kcl.ac.uk/staff/ginzburg.","Howard Gregory and Shalom Lappin. 1999. An-tecedent contained ellipsis in HPSG. In Gert We-belhuth, Jean Pierre Koenig, and Andreas Kathol, editors, Lexical and Constructional Aspects of Linguistic Explanation, pages 331–356. CSLI Publica-tions, Stanford.","David Milward. 2000. Distributing representation for robust interpretation of dialogue utterances. ACL.","Richard Montague. 1974. Pragmatics. In Richmond Thomason, editor, Formal Philosophy. Yale UP, New Haven.","Massimo Poesio and David Traum. 1997. Conversa-tional actions and discourse situations. Computational Intelligence, 13:309–347.","Carl Pollard and Ivan Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press and CSLI, Chicago.","Stephen Pulman. 1997. Focus and higher order unification. Linguistics and Philosophy, 20.","Matthew Purver, Jonathan Ginzburg, and Patrick Healey. 2001. On the means for clarification in dialogue. Technical report, King’s College, London.","Matthew Purver. 2001. Score: Searching a corpus for regular expressions. Technical report, King’s College, London.","David Traum. 1994. A Computational Theory of Grounding in Natural Language Conversations. Ph.D. thesis, University of Rochester."]}],"references":[{"authors":[{"first":"Peter","last":"Bohlin"},{"first":"Robin","last":"Cooper"},{"first":"Elisabet","last":"Engdahl"},{"first":"Staffan","last":"Larsson"}],"year":"1999","title":"Information states and dialogue move engines","source":"Peter Bohlin, Robin Cooper, Elisabet Engdahl, and Staffan Larsson. 1999. Information states and dialogue move engines. Gothenburg Papers in Computational Linguistics."},{"authors":[{"first":"Herbert","last":"Clark"}],"year":"1996","title":"Using Language","source":"Herbert Clark. 1996. Using Language. Cambridge University Press, Cambridge."},{"authors":[{"first":"Robin","last":"Cooper"}],"year":"1998","title":"Mixing situation theory and type theory to formalize information states in dialogue exchanges","source":"Robin Cooper. 1998. Mixing situation theory and type theory to formalize information states in dialogue exchanges. In J. Hulstijn and A. Nijholt, editors, Proceedings of TwenDial 98, 13th Twente workshop on Language Technology. Twente University, Twente."},{"authors":[{"first":"Jonathan","last":"Ginzburg"},{"first":"Ivan","last":"Sag"}],"year":"2000","title":"Interrogative Investigations: the form, meaning and use of English Interrogatives","source":"Jonathan Ginzburg and Ivan Sag. 2000. Interrogative Investigations: the form, meaning and use of English Interrogatives. Number 123 in CSLI Lecture Notes. CSLI Publications, Stanford: California."},{"authors":[{"first":"Jonathan","last":"Ginzburg"},{"first":"Howard","last":"Gregory"},{"first":"Shalom","last":"Lappin"}],"year":"2001","title":"Shards: Fragment resolution in dialogue","source":"Jonathan Ginzburg, Howard Gregory, and Shalom Lappin. 2001. Shards: Fragment resolution in dialogue. In H. Bunt, editor, Proceedings of the 1st International Workshop on Computational Semantics. ITK, Tilburg University, Tilburg."},{"authors":[{"first":"Jonathan","last":"Ginzburg"}],"year":"1996","title":"Interrogatives: Questions, facts, and dialogue","source":"Jonathan Ginzburg. 1996. Interrogatives: Questions, facts, and dialogue. In Shalom Lappin, editor, Handbook of Contemporary Semantic Theory. Blackwell, Oxford."},{"authors":[],"source":"Jonathan Ginzburg. forthcoming. Semantics and Interaction in Dialogue. CSLI Publications and Cambridge University Press, Stanford: California. Draft chapters available from http://www.dcs.kcl.ac.uk/staff/ginzburg."},{"authors":[{"first":"Howard","last":"Gregory"},{"first":"Shalom","last":"Lappin"}],"year":"1999","title":"An-tecedent contained ellipsis in HPSG","source":"Howard Gregory and Shalom Lappin. 1999. An-tecedent contained ellipsis in HPSG. In Gert We-belhuth, Jean Pierre Koenig, and Andreas Kathol, editors, Lexical and Constructional Aspects of Linguistic Explanation, pages 331–356. CSLI Publica-tions, Stanford."},{"authors":[{"first":"David","last":"Milward"}],"year":"2000","title":"Distributing representation for robust interpretation of dialogue utterances","source":"David Milward. 2000. Distributing representation for robust interpretation of dialogue utterances. ACL."},{"authors":[{"first":"Richard","last":"Montague"}],"year":"1974","title":"Pragmatics","source":"Richard Montague. 1974. Pragmatics. In Richmond Thomason, editor, Formal Philosophy. Yale UP, New Haven."},{"authors":[{"first":"Massimo","last":"Poesio"},{"first":"David","last":"Traum"}],"year":"1997","title":"Conversa-tional actions and discourse situations","source":"Massimo Poesio and David Traum. 1997. Conversa-tional actions and discourse situations. Computational Intelligence, 13:309–347."},{"authors":[{"first":"Carl","last":"Pollard"},{"first":"Ivan","last":"Sag"}],"year":"1994","title":"Head Driven Phrase Structure Grammar","source":"Carl Pollard and Ivan Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press and CSLI, Chicago."},{"authors":[{"first":"Stephen","last":"Pulman"}],"year":"1997","title":"Focus and higher order unification","source":"Stephen Pulman. 1997. Focus and higher order unification. Linguistics and Philosophy, 20."},{"authors":[{"first":"Matthew","last":"Purver"},{"first":"Jonathan","last":"Ginzburg"},{"first":"Patrick","last":"Healey"}],"year":"2001","title":"On the means for clarification in dialogue","source":"Matthew Purver, Jonathan Ginzburg, and Patrick Healey. 2001. On the means for clarification in dialogue. Technical report, King’s College, London."},{"authors":[{"first":"Matthew","last":"Purver"}],"year":"2001","title":"Score: Searching a corpus for regular expressions","source":"Matthew Purver. 2001. Score: Searching a corpus for regular expressions. Technical report, King’s College, London."},{"authors":[{"first":"David","last":"Traum"}],"year":"1994","title":"A Computational Theory of Grounding in Natural Language Conversations","source":"David Traum. 1994. A Computational Theory of Grounding in Natural Language Conversations. Ph.D. thesis, University of Rochester."}],"cites":[{"style":0,"text":"Purver et al., 2001","origin":{"pointer":"/sections/1/paragraphs/12","offset":138,"length":19},"authors":[{"last":"Purver"},{"last":"al."}],"year":"2001","references":["/references/13"]},{"style":0,"text":"Purver, 2001","origin":{"pointer":"/sections/1/paragraphs/14","offset":237,"length":12},"authors":[{"last":"Purver"}],"year":"2001","references":["/references/14"]},{"style":0,"text":"Pulman, 1997","origin":{"pointer":"/sections/1/paragraphs/23","offset":276,"length":12},"authors":[{"last":"Pulman"}],"year":"1997","references":["/references/12"]},{"style":0,"text":"Clark, 1996","origin":{"pointer":"/sections/1/paragraphs/23","offset":626,"length":11},"authors":[{"last":"Clark"}],"year":"1996","references":["/references/1"]},{"style":0,"text":"Traum, 1994","origin":{"pointer":"/sections/1/paragraphs/23","offset":733,"length":11},"authors":[{"last":"Traum"}],"year":"1994","references":["/references/15"]},{"style":0,"text":"Poesio and Traum, 1997","origin":{"pointer":"/sections/1/paragraphs/23","offset":746,"length":22},"authors":[{"last":"Poesio"},{"last":"Traum"}],"year":"1997","references":["/references/10"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/1/paragraphs/23","offset":1230,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Ginzburg, 1996","origin":{"pointer":"/sections/1/paragraphs/23","offset":1450,"length":14},"authors":[{"last":"Ginzburg"}],"year":"1996","references":["/references/5"]},{"style":0,"text":"Bohlin et al., 1999","origin":{"pointer":"/sections/1/paragraphs/23","offset":1466,"length":19},"authors":[{"last":"Bohlin"},{"last":"al."}],"year":"1999","references":["/references/0"]},{"style":0,"text":"Montague, 1974","origin":{"pointer":"/sections/2/paragraphs/4","offset":157,"length":14},"authors":[{"last":"Montague"}],"year":"1974","references":["/references/9"]},{"style":0,"text":"Cooper, 1998","origin":{"pointer":"/sections/2/paragraphs/16","offset":201,"length":12},"authors":[{"last":"Cooper"}],"year":"1998","references":["/references/2"]},{"style":0,"text":"Cooper, 1998","origin":{"pointer":"/sections/2/paragraphs/18","offset":123,"length":12},"authors":[{"last":"Cooper"}],"year":"1998","references":["/references/2"]},{"style":0,"text":"Milward, 2000","origin":{"pointer":"/sections/2/paragraphs/22","offset":213,"length":13},"authors":[{"last":"Milward"}],"year":"2000","references":["/references/8"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/2/paragraphs/24","offset":69,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Gregory and Lappin, 1999","origin":{"pointer":"/sections/2/paragraphs/24","offset":1357,"length":24},"authors":[{"last":"Gregory"},{"last":"Lappin"}],"year":"1999","references":["/references/7"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/2/paragraphs/26","offset":35,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Ginzburg, 1996","origin":{"pointer":"/sections/3/paragraphs/0","offset":98,"length":14},"authors":[{"last":"Ginzburg"}],"year":"1996","references":["/references/5"]},{"style":0,"text":"Bohlin et al., 1999","origin":{"pointer":"/sections/3/paragraphs/0","offset":139,"length":19},"authors":[{"last":"Bohlin"},{"last":"al."}],"year":"1999","references":["/references/0"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/3/paragraphs/1","offset":4,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Pollard and Sag, 1994","origin":{"pointer":"/sections/3/paragraphs/1","offset":68,"length":21},"authors":[{"last":"Pollard"},{"last":"Sag"}],"year":"1994","references":["/references/11"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/3/paragraphs/1","offset":93,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/3/paragraphs/22","offset":8,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Ginzburg and Sag, 2000","origin":{"pointer":"/sections/5/paragraphs/55","offset":206,"length":22},"authors":[{"last":"Ginzburg"},{"last":"Sag"}],"year":"2000","references":["/references/3"]},{"style":0,"text":"Ginzburg et al., 2001","origin":{"pointer":"/sections/6/paragraphs/1","offset":680,"length":21},"authors":[{"last":"Ginzburg"},{"last":"al."}],"year":"2001","references":["/references/4"]},{"style":0,"text":"Bohlin et al., 1999","origin":{"pointer":"/sections/6/paragraphs/1","offset":765,"length":19},"authors":[{"last":"Bohlin"},{"last":"al."}],"year":"1999","references":["/references/0"]}]}
