{"sections":[{"title":"A :SEMANTIC INTERPRETER FOR SYSTEMIC GRAMMARS Tim F. O'Donoghue","paragraphs":["t immy@uk, ac. leeds, ai"]},{"title":"Division of Artificial Intelligence School of Computer Studies The University of Leeds Leeds LS2 9JT. UK +44 532 33.5430","paragraphs":["ABSTRACT","This paper describes a method for obtaining the semantic representation for a syntax tree in Systemic Grammar (SG). A prototype implementation of this method -- the REVELATION1 semantic interpreter -- has been ldeveloped. It is derived from a SG generator foe a large subset of English -- GENESYS -- and is !thus, in contrast with most reversible grammars, fan interpreter based on a generator. A task decomposition approach is adopted for this reversal process which operates within the framework of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, p"]},{"title":"Introduction","paragraphs":["SG (see Butler [4] for a good introduction) is a useful model of lan~guage, having found many applications in the areas of stylistics, text analysis, educational linggistics and artificial intelligence. Some of these applications have been colnputational, the best known probably being Winograd's SHRDLU [22]. Howdver, most computational applications have been designed from a text-generation viewpoint (such as Davey's PROTEUS [6], Manta and Matthiessen's NmEL [16, 17] and Fawcett and rlhtcker's Â¢ENESYS [!0]).","Because of this text-generation viewpoint of systen tic grammarians, the mechanism for sentence analysis within SG (the reverse of the sentence generation process) h~ received much less attention. This paper describes one stage of the sentence analysis process: semantic interpretation.l","1 This assumes that Isentence analysis can be decomposed into two processes: syntactic analysis (parsing) plus semantic","In Fawcett's SG, 2 a syntax tree (whose leaves define a sentence) is generated from a set of semantic choices. R.EVELATION1 reverses this process: it attempts to find the set of semantic choices needed to generate a given syntax tree. In sentence generation, a tree is generated, but only the leaves (the words) are 'output', the rest of the tree is simply deleted. In tile reverse process, when a sentence is input, a syntax tree must first be found before it can be interpreted. REVELATION1 assumes that a separate SG parser (not discussed here) is available; for an example of such a parser see O'Donoghue [20]. Thus REVELATION1 directly mirrors the generator, while the parser mirrors tlle tree deletion process.","REVELATION1 has been developed within the PoPI.OG environment, a It is coded in a combination of PoPll [1] and Prolog [5] and utilizes GENESYS. GENESYS is a very large SG generator for"]},{"title":"English, written in Prolog (Fawcett and Tucker [10])","paragraphs":["and it is version PG1.5 that has been used for the development and testing of REVELATIONI. GENESYS and REVELATION are part of a much larger project, the COMMUNAL 4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in tim domain of personnel manageinterp|~etation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. tlere I assume a sequential scheme in which the parsing process passes a syntax tree to the interpreter.","2Fawcett's Systemic Functional Grammar [8, 9], his development of a HMlidayan SG.","3POPLOG is a multi-language development environment contaiifing incremental compilers for POPII (the base language), Prolog, Comnmn Lisp and Standard ML, an integrated editor and numerous support tools [12].","4The COMMUNAL Project at University of ~Vales College of Cardiff (UWCC) Computational Linguistics Unit and Leeds University School of Computer Studies was sponsored by RSRE Malvern, ICL and Longman. 129 who r71 open+ing I | ! the big-,I-esl"]},{"title":"7 one","paragraphs":["F r\"l Figure 1: A Typical Pal.5 Syntax Tree ment.","This is not the first time a semantic interpreter has been attempted for a large SG: Kasper [13] has developed a sentence analysis method (both parsing and interpretation together in my terminology) based on the NIGEL grammar. In his approach the SG is compiled into a Functional Unification Grammar (FUG) (see Kay [14], a representation language with some systemic links) and then existing (but extended) FUG parsing techniques are used to find a syntax tree plus an interpretation for a sentence.","The REVELATION1 approach differs from this compilation method since the interpretation is achieved within a systemic framework. No other SG-based model (to my knowledge) has been used for both generation and interpretation in this way. Systemic Grammar Fawcett's SG is a meaning-oriented model of language in which there is a large 'and/or' network of semantic features, defining the choices in meaning that are available. A syntax tree is generated by traversing multiple paths (see later) through this network, making choices in meaning, and so defining the meaning of the syntax tree to be generated. These choices fire realization rules which specify tile structural implication of choosing certain features; they map the semantic choices onto syntactic structures and so transform the chosen meaning into a syntax tree (and hence a sentence) which expresses that meaning.","As an example of the syntax trees which are gem erated by Pol.5, consider Figure 1. Systemic syntax trees consist of a number of levels of structure called units; the tree in Figure 1 has four: one clause (CI), two nominal groups (ngp) and a quantity-quality group (qqgp). The components (immedi-ate constituents) of each unit are elements of structure labelled to represent the functions fulfilled by that component with respect to its unit. For example: subject (S), main verb (M), second complement (C2) and ender (E) in the clause, superlative determiner (ds) and head (h) in the nominal groups, superlative deictic determiner (dds) and apex (a) in the quantity-quality group. Some items may expound more than one function in a unit, e.g. \"is\" flmctions both as operator (O) and period-marking auxiliary (Xpd) in the clause and is labelled with the conflated functional label O/Xpd. Some elements may be conflated with participant roles, e.g. \"who\" is a subject playing the role of agent (At) and so is labelled S/Ag. Similarly \"the big+est one\" is a complement playing the role of affected (Af) and hence is labelled C2/Af. The immedi-ate constituent of an element of structure is either a lexical item (either a word or punctuation, in which case we say that the item expounds the element, e.g. the lexical item \"one\" expounds h), or a further unit (when we say a unit fills the element, e.g. the unit qqgp fills ds).","Ilaving introduced the type of syntax tree that is generated, let us now consider the actual process of generation. The key concept in SG is that of choice between small sets of meanings (systems of semantic features). For example, the NUMBER system contains tile choices singular and plural. The choiee systems in a systemic grammar are linked together by 'and' and 'or' relationships to form a complex system network, specifying the preconditions and consequences of choosing features. Consider the system network presented in Figure 2 (an excerpt from eo 1.5 which contains ~450 systems, some containing many more features than the binary systems illustrated in this example). In the systemic notation curly braces represent conjunctions and vertical bars represent exclusive disjunctions, i.e. choice. The upper-case labels are the names of systems and 130","MOOD ] information__ [ directive"]},{"title":"I retrospective05 __.)","paragraphs":["Â• ] not-retrospective","kEXPl~CT I expect(15.4)_._ ] not-expect k V, TYPI~ ]"]},{"title":"I","paragraphs":["pas t-from- expect (15.7) not-past-from-expect immediate-expect(15.6) unmarked-expect (1 S.5 ) Figure 2: A fragment of the English 'tense' Network directive information, information, information, information, information, information, information, retros )strive, not-expect ..................................................................... \"touch\" retrol mctive, expect, immediate-expect ................................... \"has beenahout to touch\" retros ~sctive, expect, unmarked-expect .................................... \"has heengoing to touch\" not-retrospective, expect, immediate-expect, past-from-expect ......... 'qsabout to have touched\" not-retrospective, expect, immediate-expect, not-past-from-expect ............ 'qsahout to touch\" not-retrospective, expect, unmarked-expect, past-from-expect ........... \"is going to have touched\" not-retrospective, expect, unmarked-expect, not-past-from-expect .............. \"is going to touch'","t Figure 3: Examples of 'tense' Selection Expressions and their realizations ]","15.5 : unmarked-expect : G Q 73, G < \"going to\".","15.6 : immediate-expect : G @ 73, G < \"about to\".","15.7 : past-from-expe'ct : Xpf @ 85, Xpf < \"have\", if period-marked then Xpd <+ \"en\" else if unmarked-passive then Xp <+ \"en\". Figure 4: iRealisation Rules the lower-case labels are the names of the features in those systems. Each sjrstem has an entry condition; a precondition which must be met in order to enter the system and make a choice. For example, to enter the RETR0 (retrOspectivity) and EXPECT (expectation) systems, information must have been chosen. To enter the PFE (past from expectation) system, both not-ret~ospective and expect must have been chosen. The :sets of choices in meaning defined by this network fr:agment are listed in Figure 3. Each set of choices is a selection expression, i.e. a path (typically bifurcating) through the network.","Associated with certain features are realization rules. In Figure 2, the bracketted numbers are pointers to realization rules;i thus realization rule 15.7 is triggered by the feature past-from-expect. A realization rule specifies the structural consequences of choosing a feature; they map the semantic choices onto syntactic structures. Often conditions are in-volved; consider the realization rules shown in Figure 4 (PG1.5 contains ~500 realization rules, many of which are far more complex than these examples). The main types of rule are:","* Components Rules: ElaN, stating that the element E1 is at place II in the current unit (thus placing an ordering on the components of the unit currently being generated). These place numbers are relative rather than physical; an element at place S states that the element (if realized) will appear after elements whose places are less than N and before those elements whose places are greater than 1I. Filling Rules: is_filled_by U, defining the unit U to be generated, e.g. U=ngp.",". Conflation Rules: F2 by F1, stating that the two functions F1 and F2 are conflated with one another in the current unit (e.g. a Subject which also functions as an Agent).",". Exponence Rules: El<Word, stating that the element El is expounded by an item (e.g. N<\"open\"), i.e. exponents creates terminal constituents.","Â• Re-entry Rules: for F re_enter_at f, stating that the function F is filled by a unit which is generated by re-entering the network atthe feature :t.","Â• Preference Rules: for F prefer If...], 131","Selection Expressio~ ~ for CI filling Z / t ! I , ' , [ Subtaskial [ Subtasklb]","Selection Expression~ [ Selection Expressio d","for ngp filling S | I for ngp filling C2 | AND-node AND-node OPv-node OR-node","I","Selection Expressio~","for qqgp filling as | Figure 6: AO Tree Primitives Figure 5: A Prototype Semantic Representation stating that when re-entering to generate a unit to fill the function F, the features [:f... ] should be preferred, either absolutely (i.e. 'pre-selection') or tentatively (expressed as a percentage).","A sentence is generated by generating the syntax tree for the sentence, the leaves in this tree being the words of the sentence. The tree is generated by generating each of its units in a top-down fashion. Each unit is generated by a single pass through the system network. This pass is expressed as a selection expression which lists the features chosen on that pass. For example, suppose we wanted to generate the sentence \"the prisoner was going to have been killed\". The selection expression for the clause would contain the features (plus many others, of course): information, not-retrospective, expect, unmarked-expect, past-from-expect. Any realization rules associated with features in the selection expression are then executed. Rules 15.5 and 15.7 in Figure 4 generate a structure whose leaves are \"... going to ... have ... (be)en ...\". For example, to generate the clause structure in Figure 1, the following realization statements were executed: is_filled_by C1 S@35, 0@37, M@94, C2@I06, E@200 hg by S, Xpdby 0, Af by C2 O<\"is\", N<\"open\", M<+\"+ing\", E<\"?\" for Ag re_enter_at stereotypical_thing for Af re_enter_at thing The re-entry realization statements show which functions are to be filled by re-entering the system network to generate further units. Re-entry can be thought of as a recursive function call which generates a lower layer of structure in the tree -- but typically with some of the choices 'preferred' via the preference realization statement. Thus the syntax tree in Figure 1 is generated with four passes: the clause is generated first, followed by the nominal group filling the subject agent, followed by the nominal group filling the affected complement, and finally the quantity-quality group filling the superlative determiner.","The information required to generate a syntax tree can be expressed as a tree of selection expressions; this is the semantic representation for the sentence. Each node in the semantic representation corresponds to a unit in the syntax tree and is labelled by the selection expression for that unit. For example, a semantic representation of the form shown in Figure 5 is needed to generate the syntax tree in Figure 1. Interpreting a Syntax Tree Given a syntax tree, the aim of interpretation is to find the semantic representation which would generate that tree. This semantic representation includes all the features that are needed to generate the tree and so defines the 'meaning content' of the syntax tree.","In the process of generation, a syntax tree is generated by generating its units; in the process of interpretation a syntax tree is understood by interpreting all of its units in a precisely analogous way. Thus a unit interpretation is the selection expression which generated that unit. In general there can be more than one selection expression for any given unit, since the same syntactic structure can have more than one meaning, just as a whole sentence can have more than one meaning. The potential unit interpretations are defined by constructing an AO tree ~ whose goal (root) is to prove unit realization, i.e. prove that the unit can be generated. Each potential solution of this AO tree defines a poten-","5 AO (AND/OR) trees provide a means for describing task decomposition. These structures were first proposed by Slagle [21] and have since been used in a variety of applications including symbolic integration and theorem proving (Nilsson [18] lists a number of applications with references). The AO tree notation used throughout this paper is illustrated in Figure 6 with leaves -- terminal tasks which cannot be decomposed any further -- being represented as bold nodes. 132"]},{"title":"I","paragraphs":["Realisation of Descriptor 1 Unit Interpret, atio d"]},{"title":"I I Unit ea|isationl","paragraphs":["[ Realis'ation of Realisation of [ Descriptor i ["]},{"title":"I","paragraphs":["........ Descriptor n I Figure 7: Decomposition of Unit Interpretation tial selection expression for the unit. The semantic representation for the tree is given by some feasible combination of the :potential selection expressions for each unit in the: syntax tree. Not all combina-tions of selection expressions are feasible since the generation passes, alnd hence the selection expres- i sions, are"]},{"title":"interdepelident.","paragraphs":["Thus:","Â• A pass is dependent upon previous, higher passes througl~ the use of the unary boolean operators on_.p~ev_pass and on_first_pass in conditions inside realization rules. These operators are usdd to test the values of features in passes for ~igher units in the syntax tree. For example !the condition on..:first_l~ass written is only true if uritten is selected on the first pass.","Â• Subsequent passes are dependent upon the pre-sclections that are made with the preference rules. For example, when generating a que:stion (such as that in Figure I) it is n#cessary to pre-select the feature seeking-'specification-of-thing for the nominal group which fills the subject agent. This t ensures that a Wh-subject is generated."]},{"title":"Decomposing Unit Interpretation","paragraphs":["The first step in unit interpretation is the decomposition of the :unit's structure into a set of descriptors; 6 each describing a different aspect of the unit's structure. For example, the descriptors required to describe the clause in Figure 1 are: unit (c1) el(1,s), el(2,0), el(3,M), e1(4,C2), el(5,E) conf(S,Ag), conf(O,Xpd), conf(C2,Af) stem(O, \"is\"), .stem(M,\"open\"), stem(E, \"?\") suff ix (M, \"+ing\" )","6A descriptor is simply an abstract description of a realization; it attempts to ~apture the effect of the realization statements without using any of their syntax."]},{"title":"re_enter(S,Ag), re_enter(C2,Af)","paragraphs":["Tile unit descriptor specifies the name of the current unit, the el descriptor specifies the ordering of the component elements, the Â¢on:f descriptor specifies the conflation relationships, the stem and suffix descriptors specify the items expound-ing lexical elements, and the re_enter descriptor specifies the non-terminal elements requiring a subsequent pass to generate a unit to fill them. Decomposition 1 [Unit Interpretation] Unit interpretation is achieved by proving that the unit can be realized. To do this, the unit's structure is described, using a set of descriptors, and hence unit realization is decomposed into a number of separate realizations, with one realization for each descriptor. Thus unit interpretation is achieved by realizing"]},{"title":"all","paragraphs":["descriptors (hence realizing the whole unit). This decomposition is illustrated in Figure 7.","Each descriptor is realized by some realization statement (which will appear somewhere in the realization rules). There is a simple mapping between descriptors and suitable realization statements. For some descriptors there is only a single suitable realization statement: for example, unit(U) is only realized by the statement is_filled_by O. Other descriptors can be realized by a number of different realization statements: for example, el(i,Eli) is realized by statements of the form EliQN, where the place N is greater than the places for Eli_i and less than the places for Eli+l. This ensures correct ordering of the constituent elements.","For each descriptor, a search of the realization ruh,s is performed to find any statements which realize the descriptor. For example, for the descriptor unit(el) we would search for all occurrences of is_filled.by Cl in the realization rules. After the search is complete there will be a set of potentially active rules for each descriptor, with each potentially active rule containing a suitable statement (or possibly more than one suitable statement) that 133","Descriptor Realisation ]","I","[ Suitable Statementsl ' I ' I","I J I t. I I r ......... 3","IOccurrencel I .............. IOccurrenceil ............. IOccurrencen ]","' ] '","f--- --J\" ---- \"I f- -- --L -- -- -I",", , I I , ,"]},{"title":"I ule ctivatioo I I O.e P,eco.ditioo holds I I l I","paragraphs":["[ Precond 1 = T] .... I Preco-~m= W I Figure 8: Decomposition of Descriptor Realisation would realize the descriptor. Associated with each potentially active rule is a set of preconditions, one precondition for each suitable statement. (If the statement has no precondition, then the set of preconditions will be empty.) Decomposition 2 [Descriptor Realization] Proving that a descriptor can be realized is decomposed into (i) activating any one of its potentially active rules, and (ii) proving that any one of the preconditions associated with that rule holds true (assuming there are any preconditions). This decomposition is illustrated in Figure 8.","What is required for a rule to be active? A rule can only be active if there is a feasible path (feasible in the sense that all features on that path can be selected) through the system network to a feature associated with that rule. There will be at least one potential path to each rule; 'at least' is required since a rule can have more than one potentim path if (i) it is associated with more than one feature or (ii) it is dependent upon a disjunctive entry condition. Thus the potential paths to a rule can be represented as a boolean expression; i.e. as an exclusive disjunction of conjunctions: pathl xor path2 xor ... xor pathN where the path components are conjunctions composed from the features in each potential path and the exclusive disjunction represents choice between potential paths. This expression can be simplified into an expression of the form: common and (variantl xor ... xor variantN) where common is a conjunction of features that is common to all potential paths and variantl Â•..","variantN are the conjunctions of features peculiar to each potential pathÂ• This expression can be considered as a precondition for rule activation and so must be true for the rule to be active. Decomposition 3 [Rule Activation] Rule Activation is achieved by activating one of the potential paths to that rule. The potential paths can be decomposed into a common component and a number of variant components. One potential path is active if and only if the common component is active and its variant component is also active. This decomposition is illustrated in Figure 9.","At this stage in the decomposition all tip nodes are problems of the form 'boolean expression = T', i.e. satisfiability problems. In order to define how satisfiability problems are solved, the concept of a truth function must first be introduced. A truth function is a mapping between features and a three valued logic (with truth values false, true and undefined) which defines the value of each feature; true indicating selected and false indicating not selectedÂ• Tile problem of satisfiability for a boolean expression involves finding a truth function such that the boolean expression evaluates ? to be true, such a truth function is called a satisfying truth function for tile boolean expression. Unfortunately, this is all intractable problem since a disjunction with n disjuncts can have 3\"-1 potential satisfying truth functions, i.e. the task is exponential in problem size (in fact, the problem of satisfiability has the honor of being the first NP-Complete problem; see Garey and Johnson [11]). As is the case with inherently intractable problems; it is not worth searching for an efficient, exact algorithm to perform the task; it is","7Evaluation is performed with respect to Kleene's three valued logic [15]. 134 , I"]},{"title":"I Oo~on Path is Active I ' I 1 Â°Â°~Â°n Â°Â°rid-- ~1","paragraphs":["Rule Activation [ I"]},{"title":"[ Path Activation [ I I","paragraphs":["[ One Variant is Active [ I '0 I"]},{"title":"I v~ian~ ~ is Active I ........ I Variant n i. Aot've I I I I 0ondi = Â• I I~ond n = Â• I","paragraphs":["Figure 9: Decomposition of Rule Activation Interpret ell","I","I Re~|i'e [CI''''] I ! ........ r- [ ,!"]},{"title":"I '","paragraphs":["Only O~currence -7"]},{"title":"[ ~on.ru;ot.~. I I","paragraphs":["! [ P .... nditions["]},{"title":"I oo, oÂ°o~ked--,q","paragraphs":["I I I","[ First Occu ...... ]","!","[ Rule2.04 ]"]},{"title":"' I ~ I ~.Â°Â°t-p,-.-~ ..... I I","paragraphs":["I I","I","I s .... d O ...... *'\" I |","I I","[ Rule 6-21 I I Figure 10: Part of the AO Tree for Clause Interpretation more appropriate to:consider a less ambitious problem. Consider the problem of partial satisfiability: it is essentially the salfie as satisfiability except that it does not attempt to satisfy disjunctive components (since it is these components which make the satisfiability problem 'hard'). It requires a redefinition of a truth function: in partial satisfiability a truth function is a mappin~g between boolean expressions (rather than simply features) and truth values. For example, the expresÂ§ion (a or b) and Â¢ and not d is partially satisfied by the fimction v: v : v(a or b)=T, v(c)=T, v(d)=F Since disjunctions are effectively ignored, there is a single unique partially satisfying truth function for any boolean expression. Thus tip nodes labelled with satisfiability problems are (partially) decomposed into a numbei, of and-nodes; each and-node being labelled by a feature (possibly negated) or a disjunction which must be true. As an example of a fldly decomposed AO tree for unit interpretation, consider the skeleton tree in Figure 10 which defines the potential interpretations of the clause in Figure 1.","A potential solution of an AO tree is specified by a subset of the leaves that are necessary for the root task to be achieved. A backtracking search is used to generate potential solutions: since the AO tree is finite, it is possible to inspect the structure of the tree and order the search in such a way so that the minimum amount of backtracking is performed, s A feasible interpretation for a unit is one of the potential solutions in which the statements labelling the leaves are all consistent. There are two ways in which a leaf statement may be inconsistent:","s The search scheme involves incrementally evaluating and pruning the AO tree. Full details can be found in O'Donoghue [19], an in-depth report on the interpreter. 135","Selection Expression for CI filling Z I sitttation, congru.entt-sit, in.f?rrnatlon, seeker, no.cor~-modMity,"]},{"title":"I","paragraphs":["perloo-rnarkeaj alng[e-ou~l(ler-sth, matsri3|, two-role.process, I agent-c~ntre(l.trp, plUS-Sllecte~, ~tl~ent.~-th~me-mat.aou[ht, I oVert.~ffected:a.U, ogerl.~Hected.s~l.pr,~sentecl~ qver tÂ¢ affe~Yed, af- u nt hernatised, l c~nglng-colangujr&tion&J-st at e, c nangtng- posit Lone&J- con figuration , l cnanglng.state-ol.openness, tm &k e. opt n ,~.ge nt. ;5- t h e rne- a.f\" J","Selection Expression f(~r ngp fillings Selection Expllession for ng p filling C2 I s ' I think .rgcnt-thin.~stereotypi~.l-thing, [ ' thing K ,.t~aing~stereotypic&l-t,i,g, ' .... .... ...."]},{"title":"Ill","paragraphs":["putsrdex, s'~ekto,g-spec'~fi~&tmn-Ol-thtng, outslcter, cffltur~l-c|~s~stPc~.ttpn-recov~r&.vLe, Â•","I","nurn&n|ty.spec|neo.sst, human-sst, peTson-sat countlsn.ccr, selecteo-lrom.Dy-superl~tlv|z&t|on I","!","Sclection expression for qqgp filling ds","[ qpality, quality:of.thing, presentinK-qu~l.llty.?f-[.hi~g,"]},{"title":"I","paragraphs":["olmerlSlOrl-quallty, SIZe, big, not.po~enttally-oen&vloural-qu&lity . I Figure 11: A Semantic Representation found by REVELATION I","Â• The statements logically contradict, for example: leaves labelled a = T and a = F. Or b or"]},{"title":"e=Tandb=F,e=F.","paragraphs":["Â• The statements systemically contradict, for example: a = T and b = T when a and b are members of the same choice system (from which at most one feature can be chosen). The leaf statements in a feasible solution define which features must be true (i.e. selected) for the unit to be realized, i.e. they specify a selection expression for the unit. Results and Discussion The semantic representation found by REVELATION 1 for the syntax tree in Figure 1 is presented in Figure 11. We can get a flavor of the semantic representation by identifying key features: the sentence is a question"]},{"title":"(information, seeker)","paragraphs":["about an on-going event (period-marked) which involves opening something (make-open). It is a person that we are seeking (person-sst). The thing that is being opened is selected by superlativization (in fact it is the biggest) and it is recoverable from the previous discourse (the \"one\" referring to something that has previously been mentioned).","Unfortunately this semantic representation is in-complete. One of the factors contributing to this incompleteness is that of 'unrealized' selections: these are features which have no associated realization (e.g."]},{"title":"not-expect","paragraphs":["in Figure 2). Consider tile way in which interpretation works: it tries to prove that observed realizations have taken place and in so do-ing infer the features that were selected. However, if a realization does not take place as a (not necessarily direct) result of a selection, then there is no way to infer that the unrealized feature was selected. Consider the"]},{"title":"POLARITY","paragraphs":["system where there is a choice between positive and negative. The positive choice is unrealized where as negative is associated with the realization rule:"]},{"title":"17:negative: do_support, 0 <+ \"n't\".","paragraphs":["Suppose we have a positive clause, \"Who is opening the biggest one?\" (the example sentence from Figure 1). There is no way to tell from the structure of the clause that the sentence is positive. However by inspecting the realization rule associated with"]},{"title":"negative","paragraphs":["we find that the (unconditional) statement 0<+\"n't\" can never be active as this would realize the sentence \"Who isn't opening the biggest one?\". Thus rule 17 can never be active and so negative can't be chosen, hence positive must be chosen. Thus by a process of eliminating features which cannot be true, it is possible to determine unrealized features. REVELATION2 (currently under development) will attempt to implement this process of elimination by moving forward through the system network (after a partial semantic representation has been obtained) systematically verifying any realization rules that it meets, eliminating features that cannot be chosen and so possibly inferring something about unrealized features which need to be chosen.","The other factor contributing to incompleteness is the definition of partial satisfiability. Some features in the network do not have realization rules attached to them: typically these appear as conditions on statements in realization rules. However, if any of these features appear in disjunctive conditions or disjunctive entry conditions to systems, then nothing can be inferred about their values since the definition of partial satisfiability ignores all dis-"]},{"title":"136","paragraphs":["junctions. This problem can only be overcome by searching for (exact) satisfying truth functions from which all feature values can be inferred. REVELATION2 attempts to solve this problem by deferring the search for exact satisfying truth functions until after a partial in,terpretation has been obtained: the partial interpretation is obtained as for REVELATION1, and then any disjunctions that have been ignored while obtaining this interpretation are exactly satisfied to try and fill the gaps in the partial interpretation.","In addition to the work on the next generation of interpreter, some work is being carried out on P(~ 1.5 to make it more efficient; it is being tuned for interpretation by simplifying and normalizing conditions in the realization rules. This involves 'tightening up' the conditions by su~bstituting xor for or wherever possible and reducin'g the scope of any valid disjunctions that remain (eig. a and (b or c) rather than a and b or a and c).","Clearly efficiency is a problem, since the AO trees explode into or-nod:es, through the use of (i) disjunctive entry conditions in the system network and (ii) disjunctive conditions in the realization rules. It [ has been proved (Brew [3]) that systemic classifica-tion is NP-Hard and is thus inherently intractable. This led to the choice of partial satisfiabillty rather than exact satisfiablility (which itself is NP-Ilard) in"]},{"title":"REVELATIONI,","paragraphs":["and the development of an efficient technique for isearching the AO trees which utilizes incremental ievaluation and pruning to reduce the number of backtracking points (full details in O'Donoghue [19])i The delayed use of exact satisfiability being inves!igated in REVELATION2 is similar to Brew's 'partial' algorithm for checking systemic descriptions. IBrew's checking algorithm has two stages, the first i being a simplification stage in which all disjunctive:entry conditions are eliminated from the system netivork by replacing them with a uniquely generated feature. The resultant simplified network can then be searched efficiently. The second stage involves checking all of the features generated in the first stage, each generated feature referring to a disjunctive entry c~ondition. IIere also we find a delaying tactic in which disjunctions are satisfied as late as possible in the search.","Although no theoretical calculations as to the complexity of the REVELATION1 method and Pc, l.5 have been nndertaken, we can get a feel for the scale of the problem by considering the amount of CPU time that was needed to obtain the semantic representation of Figure 1!1. On a SPARCstation 1 with"]},{"title":"16M","paragraphs":["this task required ,~25 CPU seconds, with this time being halved on a Sun 4/490 with 32M. When reading these timings bear in mind that REVELATION1 is coded in POPLOG languages which are incrementally compiled into an interpreted virtual machine code."]},{"title":"Conclusions","paragraphs":["REVELATION1 has demonstrated that Fawcett's SG is a bi-directional formalism, although in the case of PG 1.5, some reorganization was required to make it run ill reverse. The main problem in reversing a SG seems to be that systemic grammars are written from a predominantly text-generation viewpoint. In developing their grammars systemic grammarians are concerned with how the grammar will generate rather than its suitability for interpretation. For instance, special care ought to be taken when expressing conditions in realization rules: writing a xor b rather than a or b can be a godsend to an interpreter. Similarly, simplifying and normalizing conditions so that they are as simple and specific as possible is a great aid to interpretation. It reduces the search space and hence speeds up interpretation -- even though, from a generative point of view, it may make more sense to express a condition in a 'long winded' fashion that captures the generaliza-tion the linguist is attempting to make.","Fawcett states (private communication) that in developing his version of SG (which is different in a number of ways -- especially in the realization component -- from the NIGEL grammar of Mann and Matthiessen) he always had in mind its potential for reversibility. Perhaps the surprising thing is not that modifications in GENESYS are indicated by work on REVELATION, but how"]},{"title":"few","paragraphs":["modifications appear to be required. Clearly, the need now is for close collaboration between the builders of the successor versions of GENESYS and and the successor versions of REVELATION. Current research has precisely this goal; and we shall report the results in due course.","REVELATION1 combined with Fawcett's SG appears to be a step in the right direction towards a hi-directional systemic grammar. REVELATION2 may take a step closer. But a bi-directional systemic grammar will only be achieved when interpretation-minded people and generation-minded people get together and collaborate in developing such a grammar. 137"]},{"title":"Acknowledgements I would like to thank Eric Atwell and Clive Souter (Leeds University) for their valuable contributions to earlier drafts of this paper and Robin Fawcett (UWCC) for his comments and suggestions on the final version. References [1] Rosalind Barrett, Allan Ramsay, and Aaron Sloman. POPII: a Practical Language for Artificial Intelligence. Ellis tlorwood, Chichester, 1985. [2] James D. Benson and William S. Greaves, editors. Systemic Perspectives on Discourse: selected papers from the 9th International Systemic Workshop. Ablex, London, 1985. [3] Chris Brew. \"Partial Descriptions and Systemic Grammar\". In Proceedings of the 13th International Conference on Computational Linguistics (COLING '90), 1990. [4] Christopher S. Butler. Systemic Linguistics: Theory and Applications. Batsford, London, 1985. [5] William F. Clocksin and Chris S. Mellish. Programming in Prolog. Springer Verlag, 3rd edi-tion, 1987. [6] Anthony Davey. Discourse Production: A Computer Model of Some Aspects of a Speaker. Edinburgh University Press, 1978. [7] David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, editors. Natural Language Parsing: psychological, computational and theoretical perspectives. Studies in Natural Language Processing. Cambridge University Press, 1985. [8] Robin P. Fawcett. Cognitive Linguistics and Social Interaction, volume 5 of Exeter Linguistic Studies. Julius Groos Verlag, Heidlberg, 1980. [9] Robin P. Fawcett. \"Language Generation as Choice in Social Interaction\". In Zock and Subah [24], chapter 2, pages 27-49. [10] Robin P. Fawcett and Gordon H. Tucker. \"Demonstration of GENESYS: a very large semantically based Systemic Functional Grammar\". In Proceedings of the 13th International Conference on Computational Linguistics (COLING '90), 1990. [11] Michael R. Garey and David S. Johnson. Computers and Intractability: A Guide to the The-ory of NP-Completeness. Freeman, San Francisco, 1979. [12] John Gibson. \"AI Programming Environments and the POPLOG System\". In Yazdani [23], chapter 2, pages 35-47. [13] Robert T. Kasper. \"An Experimental Parser for Systemic Grammars\". In Proceedings of the lgth International Conference on Computational Linguistics (COLING '88), August 1988. Also available as USC/Information Sciences In-stitute Reprint RS-88-212. [14] Martin Kay. \"Parsing in Functional Unification Grammnar\". In Dowty et al. [7], chapter 7, pages 251-278. [15] Stephen C. Kleene. Introduction to Metamath. ematics. North-Holland, 1952. [16] William C. Mann and Christian M. I. M. Matthiessen. \"NIGEL: A Systemic Grammar for Text Generation\". In Benson and Greaves [2]. Also available as USC/Information Sciences Institute Reprint RS-83-105. [17] Christian M. I. M. Matthiessen and John A. Bateman. Text Generation and Systemic-Functional Linguistics: experiences from English and Japanese. Pinter, London, 1991. (in press). [18] Ntis Nilsson. Principles of Artificial Intelligence. Springer Verlag, 1983. [19] Tim F. O'Donoghue. \"The REVELATION1 Semantic Interpreter\". COMMUNAL Report 22, School of Computer Studies, University of Leeds, 1991. [20] Tim F. O'Donoghue. \"The Vertical Strip Parser: a lazy approach to parsing\". Report 91.15, School of Computer Studies, University of Leeds, 1991. [21] J. R. Slagle. \"A Heuristic Program that Solves Symbolic Integration Problems in Freshman Calculus\". In E. Feigenbaum and J. Feldman, editors, Computers and Thought, pages 191-203. McGraw=Hill, New York, 1963. [22] Terry Winograd. Language as a Cognitive Process, Volume I: Syntax. Addison Wesley, 1983. [23] Masoud Yazdani, editor. Artificial h~telligence: principles and applications. Chapman Hall, 1986. [24] Michael Zock and Gerard Subah, editors. Advances in Natural Language Generation (Volume 2). Pinter, London, 1988.","paragraphs":["138"]}]}
