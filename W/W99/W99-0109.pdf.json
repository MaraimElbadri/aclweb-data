{"sections":[{"title":"Cb or not Cb? Centering theory applied to NLG","paragraphs":["Rodger Kibble","Information Technology Research Institute","University of Brighton","Lewes Road","Brighton BN2 4GJ","U.K. Rodger. Kibble@itri. brighton, ac. uk","Abstract Centering theory (CT) has been mostly discussed from the point of view of interpretation rather than generation, and research has tended to concentrate on problems of anaphora resolution. This paper examines how centering could fit into the generation task, separating out components of the theory which are concerned with planning and lexical choice. We argue that it is a mistake to define a total ordering on the transitions CONTINUE, PJZTAm, SHIFT and that they are in fact epiphenomenal; a partia/ordering emerges from the interaction between cohesion (maintaining the same center) and salience (re-all.qing the center as Subject). CT has generally been neglected by NLG practitioners, possibly because it appears to assume that the center is determined according to feedbsch from the surface grammar, to text planning, but we argue that this is an artefactual problem which can be eliminated on an appropriate interpretation of the CT rules. 1 What is Centering? Centering theory (C~) is a theory of discourse structure which models the interaction of cohesion and salience in the internal organlsation of a text. The main assumptions of the theory as presented by (Gross et a11995 (GJW), Brennan et al 1987) rare:","1. For each utterance in a discourse there is precisely one entity which is the centre of attention or center.","2. There is a preference for consecutive utterances within a discourse segment to keep the same entity as the center, and for the most salient entity ~realised n in an utterance to be interpreted as the center of the following utterance.","3. The center is the entity which is most likely to be pronominalised. These principles will be more precisely explicated in Sect. 2.","CT has proved attractive to NLP researchers because of the elegance and simplicity of the core proposals; it provides a framework for analysing text without having to make tough decisions about what a partfcular utterance is \"about\", since all notions are defined in purely structural terms.","Much research in CT has concentrated on interpretation, particularly reference resolution, developing algorithms to resolve anaph0ric expressions based on the assumption that the text is constructed according to Rules 1 and 2. So researchers have focussed on filling in de~ tails of the theory which were left unspecified: what counts as an utterance, and how should transitions be handled in complex sentences (Kameyama 1998; cf Suri and McCoy 1994)? how is salience ranking determined (Gordon et"]},{"title":"al","paragraphs":["1993; Stevenson et"]},{"title":"al 1994;.","paragraphs":["Strube and Hahn 1996)? what counts as ~r~Migstion ~ - does this include bridging references (Strube and Hahn op cit.)? how do centering tra~L~itions relate to discourse segment boundaries (Walker 1998, Passoneau"]},{"title":"1998)?","paragraphs":["In fact I will leave many of these issues aside for the purposes of this paper; I will not examine the empirical adequacy of CT, for which the reader is referred to papers cited above and • others collected in Walker et al (1998). I will take a different approach, which is to examine how the dements of CT can be applied to the planning of texts, with the rules and constraints interpreted as instructions to a generator rather than a guide for interpretation. To avoid introducing too many complications I shall assume 72"]},{"title":"Cb(Un)' = Cp(U.) Cb(Un) ~ Cp(Un)","paragraphs":["Cb(Un) =\" Cb(Un-l) or Cb(Un-.l) undefined Continue"]},{"title":"Retain","paragraphs":["Cb(Un) ~ Cb(Un-[)"]},{"title":"Smooth Shift Rough Shift","paragraphs":["Figure 1: Centering Transitions Constra/nts \" C1. There is precisely one Cb. C2. Every element of Cf(Un) must be realised inUn. C3. Cb(U.) is the highest-ranked element of C/(U.-I) that is realised in Un."]},{"title":"Rules","paragraphs":["RI. If some element of Cf(Un-l) is realised as a 1~ronoun in/.)', then so is Cb(Un). (Strong version: if Cb(Un) = Cb(Un-1), a pronoun should be used.) 112. Continue is preferred over Retain which is preferred over Smooth Shift which is preferred over Rough Shift ....."]},{"title":"@ O O O O @ O O O O O @ O O O O O O O @ O @ @ @ O","paragraphs":["Figure 2: Centering a Ucanonical ~ formulation of CT as outlined by Walker et al. (1998, Chapter 1) and the schematic ~consensus ~ generation architecture described by Reiter and Dale (Reiter 1994; Reiter and Dale 1997). This consists a ~pipelins\" of distinct tasks:","Text Planning- deciding the content of a message, and organising the component propositions into a text tree;","Sentence Planning - aggregating propositions into clausal units and choosing lexical items corresponding to concepts in the knowledge base, including referring expressions"]},{"title":"(RE);","paragraphs":["Linguistic re_8!isation which takes care of surface details such as agreement, orthography etc."]},{"title":"\"","paragraphs":["Previous researchers have implemP.nted pronominalisafion decisions using CT, and so have located Centering as part of RE generation (e.g., Dale 1992, Passoneau 1998), while Mittal et al (1998) have a ~centering module\" which forms part of Sentence Planning and seeks to realise the center as Subject in successive sentences. In what follows I will try to separate out the tasks which make up centering theory and argue that the way to implement CT is not as a discrete module but as a series of constraints on the various levels of the generation process from Text Planning Constraints and Rules to RE generation. I shall also briefly note points of comparison with systems discussed by CAhill and Reape (1998) in a survey of applied NLG systems, and conclude with some remarks on the applicability of my proposals to the \"reference architecture n envisaged by Cahill et al. (1999), RAGS (1999). 2 TrAnsition rules The rn~in clahns of CT are formalised in terms of C5, the \"backward-looking center ~, C/, a list of ~'orward-looking centers z for each utterance Un, and Cp or ~preferred center z, the most salient candidate for subsequent utter* ances. Cf(Un) is a partial ordering on the entities mentioned (or ~lised n) in Un, ranked by grammatical role, e.g. SUBJ ) DIR-OBJ > INDIR-OBJ"]},{"title":"~> COMP(S) ~> A.DJUNCT(S). C~(Un) is the highest ~,,ked member of C/(U,J (usually susJ), and is predicted to be Cb(U,+~). C.f is partial/), ordered in most accounts, which","paragraphs":["leaves open the possibility that there is no -nlque Cb. AJSO, if two successive utterances have no referent in common the second Will ha~ no"]},{"title":"Cb.","paragraphs":["Successive pairs of utterances are characterised in terms of tmns/t/on.~ as defined in Figure 1; for instance if two consecutive utterances have the same Co, and the Cb in the second utterance occurs in Subject position, this is classified as a CONTINUE transition. A text is judged to be coherent to the extent that transitions follow the preference ordering given in Rule 2 (Fig 73 ̧ 2); and on the assumption that the text is coherent, pronominalisation is predicted to conform to Rule 1.","The notion of \"realisation\" is subdivided into \"direct' and \"indirect\": an entity is directly realised in an utterance if it is the denotation of an overt NP (or a zero pronoun where this is syntactically licensed), while \"indirect realisation\" covers for example subsectional anaphora, possessive pronouns and inferential links such as bridging reference. Corpus~based investigations of CT have tended to concentrate on direct realisation, since ~nnotation of indirect anaphoric links depends on theoretically-based decisions and it may be difficult to achieve reliability in this area. This has obvious implications for the resulting measure of coherence, which I return to below. 2.1 Salience and cohesion Transitions are defined in terms of tests which I shall call cohesion: Cb(Un) = Cb(U~-l), and salience: ~(Un) = ~v(Un). There are four possible combinations, which are displayed in Fig. 1. The most preferred case is where both apply, namely co~Imm, and the least preferred is where neither apply, ItOUQH S~. For the intermediate cases there are three logical possibilities: prefer cohesion (It,\"rAm), prefer salience (SMOOTH SHIFt) or allowboth equally. There is no obvious way to settle this a pr/or/, but Walker et al (1998, Ch. 1) ~ipulate that ~\"rAm is preferred over SMOOTH SHIFT. Evidence for this position is not conclusive, and in-deed di Eugenio (1998), Passoneau (1998) and Hurewitz (1998) all found a higher percentage of shifts than retains. This suggests either that salience is a stronger requirement than cohesion or that it.is easier to satisfy. \"That is, the l~n. guages studied (English and Italian) may be sufficiently flexible that there is usually some way to realise 6'b as Subj (or first-mention) but on the other hand the same 6'b can only be main-tained for a- finite n,,mher of utterances.","I suggmtthat these results should be treated with some caution since it is not dear that the authors have the same assumptions about the claims of CT or that what they are testing directly reflects formulations of CT in the more theoretical literature. For instance Passoneau (1998) refers to two variantS of CT: \"Version A\" based on Brennan et al (1987) and ~Version B\" taken from Kameyama et al (1993). Passoneau does n~t address the issue of direct vs indirect realisation and it appears from the examples given that she only takes account of entities realised by a full NP or (possibly null) pronoun. The analysis according to Version B results in a count of 52% NULL transitions, i.e. no Cb, which gives the impression that CT is in fact a rather poor measure of coherence, It is probable that a higher measure might have been obtained if Passoneau had allowed entities to be added to the U/'s by inference, as discussed in (Brennan et al, op cit.). It is of course impossible to verify this without access to the original texts, but it is instructive to consider the-following example from Strube and Hahn"]},{"title":"(1996):","paragraphs":["(1) a. Ein Reserve-Batteriepack vereorgt den 316LT ca. 2 Minuten mit Strom. (A reserve battery pack - supplies- the 316LT- ca. 2 minutes - with power.) b. Der Status des Ak/ms wird dem An-"]},{"title":"wemier anges .","paragraphs":["(The status of- the accumulator- is - to the user- indicated.) S & H treat Ak/m in the (b) sentence as indirectly ~;|~ing the 316LT (a kind of computer) in the (a) sentence, so the latter becomes the Cb of (b) resulting in a CONTINtrJS transitio~ If the authors had only taken account of direct realisations this would be analysed as a NULL tr~nRition.","Furthermore, a preponderance of shifts over continues may reflect the domain and content rather than the organlp-~tion of a text. In fact it can be seen that sequences of smooth shifts are rather natural in certain kinds of narrative or descriptive texts; see example"]},{"title":"(2).","paragraphs":["(2) The name of your medicine is Rhinocort"]},{"title":"Aqu","paragraphs":["It contains budmonide. This is one of a group of medicines called corticosteroid~ SMOOTH SHIFT These can help to relieve the symptoms of hay fever or rhinitis. SMOOTH SHIFT (pharmaceutical leaflet) • This does not appear to be an incoherent text,"]},{"title":"0 0 @ @ @ 0 0 @ @ 0 @ @ 0 0 0 0 0 0 @ @ @ @ @ @ @ 0 0 0 @ @ 0 @ 0 @ @ @ @ @ @ O Q O O O O O @ @ O O O O O O O O O O @ O O O O O O O O O @ O O O","paragraphs":["but there is no way that the c°ntent could be rearranged to turn the shifts into continues. 2.2 Deconstructing the transitions Strube and Hahn (1996) question the canonical ordering of transitions, partly on the grounds that this ordering fails to predict the P~TAIN - SHIFT pattern which has been claimed by many researchers to signal a segment boundary or the introduction of a new =discourse topic\". (See Section 3.2 below.) Recall that the"]},{"title":"Up is de-","paragraphs":["fined as the most salient entity realised in Un, which is predicted to be the"]},{"title":"Gb","paragraphs":["of U,+l. How-ever this \"prediction\" is not in fact cashed out in the rul~ for centering transitions, which take no account of whether"]},{"title":"Cp(Un) is","paragraphs":["actually realised in U,+l. S & H (op cit., p. 275) propose the principle of cheapness which is satisfied if"]},{"title":"Cp(U.) = Cb(U.+ l).","paragraphs":["\"Cheapness\" is claimed to minimise the inferential costs of processing sequences of utteranCes, and is proposed as a constraint on pairs of successive transitions as a replacement for the canonical orderings in Rule 2. We call a tr~n.qition pair cheap if the backward-looldng center of the current utterance is correctly predicted by . the preferred center of the"]},{"title":"immediately","paragraphs":["preceding utterance, i.e~,"]},{"title":"Cb(Ui) = Cp(U,-d...","paragraphs":["In fact it turns out that although cheapness appears to be a sensible principle, it does not neatly partition the types of transition pairs; in particular, this principle does not necessar-Uy hold of all s~rAm - SMOOTH SHIFT sequences. S & H propose to rectify this by re-defining the transitions, with an additional test"]},{"title":"Cb(Ui)","paragraphs":["= Cp(0'/-t) to subdivide CONTIN~ and mOOTS smFr (Strube, p.c.; Strube and HAhn forthcoming).","In what follows I will also argue against the canonical ordering though on different grounds: one cannot in general predict a .preference for Retain over Shift, for the simple reason that there is no point at which the choice between these two alternatives arises. Rather, at different points in the generation process there is a choice between maintaining the .~me"]},{"title":"Cb","paragraphs":["or choosing a new. one, and a choice of which entit), (Cbor non-Cb) to make salient. So the various transition types emerge in a partial ordering from the interaction between salience and cohesion. Note that if we also include Strube and Hahn's \"cheapness\" principle, there is potential competition with salience in cases where"]},{"title":"Cb(Un) ~ Cb(Un+l).","paragraphs":["That is, we will need a way to decide which entity to realise as"]},{"title":"Cp","paragraphs":["in cases where there are two candidates~ one of which is the current G'b and the other the"]},{"title":"Cb","paragraphs":["of the following sentence. In the remainder of this paper I will not directly incorporate the \"cheapness\" principle but will suggest thatsimilar results are obtained with an appropriate interpretation of Constraint 3 in the context of generation. 3 Architecture If we decompose the rules and constraints into separate specifications we see that they potentially fall under quite different headings in the ,schematic architecture described above. The tr_~,sitions mentioned in Rule 2 are defined in terms of two principles which I have called cohesion (maintaining the same ~ from one utterance to the next) and salience (realising the"]},{"title":"Cb as Cp,","paragraphs":["normally Subject). If we consider these"]},{"title":"as p|ann|ng","paragraphs":["operations, cohesion naturally comes under Text Planning and salience under Sentence"]},{"title":"pl~nnlng,","paragraphs":["while Rule I concern-ing pronominalisation falls under the Referring Expression component of Sentence Planning. 3.1 Text Planning A text planner which operated according to C~ would seek to order clauses within ~ segment to"]},{"title":"m~t~m the same Cb","paragraphs":["in a sequence of clauses. There are two related issues which compUcate this project: firstly, Constraint 3 in Fig. 2 implies a requirement for/~ to determlne the Cb. In addition, there is a potential conflict between top-dow~ hierarchical RST-type planning and sequential centering rules. 3.1.1 Identifying the C'b Constraint 3 states that ~for each utterance U~ in a discourse segment D... The center,"]},{"title":"Cb(Ui, D) is","paragraphs":["the highest-ranked element of"]},{"title":"C/(Ui-I,D)","paragraphs":["that is realised in"]},{"title":"Ui.\"","paragraphs":["(Walker et al 1998:3). There are two different implementation strategies which could satisfy this constraint: 75 ̧","1. Take the ranking of Cf(Ui-h D) as given and use this to identify the Cb.","2. Take the Cb as given and plan the realisation of Ui-~ to make this entity the highest-ranked. The first strategy is clearly appropriate for interpretation (cf Brennan et al 1987) but for gene.ration the issue is less clear-cut. Either the generator \"interprets\" its own output to designate Cb in terms of the grammatical structure of the previous utterance, in which case there have to be separate principles for deciding on the grammatical structure, or Cb is independently defined in the text plan and this information is used to plan the sentence structure.","According to the pipelining principle information cannot flow 'backwards' between tasks. In a pipelined system, the ~a!isation of an entity as Cp may have the effect of setting up an expectation on the reader'S part that this entity will be Cb of the following utterance, but it Cannot influence the decision made by text planning. This would mean that the 6\"b will no longer be defined as in Coustraint 3 but must be independently designated by the text planner as the centre of attention in an utterance. In fact the resulting distribution of tasks would be rather similar to the Gossip system (Carcagno and Iordanskaja 1989) as described by Ca/aiR and Reape (1998): First, the planner produces \"sentence-sized semantic nets\" which it marks with theme-rheme information. ... Furthermore, the theme/theme constraints influence clause ordering, ...pronominalisation ...and lexical choice.","An implementation of CT with feedback seems likely to fit more naturally into an in- ¢rernenta/architecture, where generation tasks may. be carried out on an utterance-by-utterance basis in contrast to top-down generation of a text tree for an entire discourse. In incremental systems it is possible in principle to plan the content of an utterance according to which entity is currently made salient by its surface grammatical role, whereas this would not in general be possible in a top-down pipelined system. In fact it turns out that incremental generators tend to perform sentence planning incrementally but not text planning. (See e.g. Reithinger 1991, DeSmedt and Kempen 1991.)","Ill fact I would argue that the feedback problem is only an artefact of an interpretation of Constraint 3 as an implication rather than a constraint. The ~implicational ~ interpretation is that if an entity a is Cp of Un and is realised in Un+l, it should be designated as Cb of Un+l. The declarative interpretation is non-directional and simply equates Cb of Un+l with the most salient entity rea lised in Un which is also realised in Un+l. The way to implement this while keeping to the pipelining principle is to assume that the text planner independently designates the \"theme \", \"topic ~ or intended centre of attention in each clause, which is marked aS Cb if it is realised in the previous clause, and to have the Sentence Planner promote an entity to salience in Un if it is Cb of Un+l. So the text planner should annotate each clausal node Un in the text tree with the following information:","Cb"]},{"title":"of[/.","paragraphs":["Cb of U._l Cb"]},{"title":"of Un+l","paragraphs":["The sentence planner will then make use of this information to decide on pronominali.qation according to the values of the current and previous Cb, and on promotion of arguments to salience depending on the current and ]ollowing Cb. Some concrete proposals are discussed in Section 3.2, \"Sentence Planning ~. The general division of labour is outlined in Fig. 3. 3.1.2 Top-down Text Planning The reader may be disappointed that no independent definition of ~topic\" or \"theme\" is of-feted. In fact we consider that this may be out-side the scope of CT. When used for interpretation, CT offers a set of rules of thumb to guide the system in identifying the centre of attention in each utterance and finding probable an-tecedents for anaphors, but the notion of ~centerhood\" is not defined separately from these rules. When used for generation, the most C~ can offer is to take the topic or theme as 9/yen and exploit the centerln~ rules and constraints to construct the text in a way which foregrounds these entities and enables the user to correctly identify antecedents. So CT has to sit on top of an independently specified treatment of information structure. One candidate is Strube and Hahn's (1996) reformulation of the notions of","76"]},{"title":"0 0 0 0 @ 0 @ 0 @ 0 @ 0 @ 0 0 0 0 0 @ @ 0 @ 0 @ 0 0 0 0 @ 0 @ 0 O @ O O O e O @ O O O O O O @ O O O O e O @ O O O O O O O O O O O O O O O O O","paragraphs":["Text Planning"]},{"title":"1. Content determination.","paragraphs":["2. Discourse planning: order clauses"]},{"title":"Ui","paragraphs":["(within segments) to maximise","continuity of reference.","For each clause Un:","o Designate at most one argument as"]},{"title":"Ub(U~,),","paragraphs":["which must be an argument of U,z-I. (If intersection of"]},{"title":"Ufs(U,)","paragraphs":["and"]},{"title":"Ufs(U~_l)","paragraphs":["has only one member, that member is"]},{"title":"Ub.)","paragraphs":["o Annotate clause node with IDs of"]},{"title":"Ub(Un), Ub(Un-l) and Cb(Un+l).","paragraphs":["Sentence Planning"]},{"title":"1. $ente'nce aggregation.","paragraphs":["2. Lexica/isation: select verb form for Un so that"]},{"title":"a. Cb(U,+t)","paragraphs":["is most grammatically salient of intersection of"]},{"title":"Cfs(U,) and Cfs(U,+t);","paragraphs":["b. subject to (a),"]},{"title":"Ub(Un)","paragraphs":["is reafised in most salient available position. 3. Referring expression generation: working hypotheses ."]},{"title":"Cb(U,)","paragraphs":["may be pronominalised ifi o Cb(U.)"]},{"title":"= cb(u._,) (QJw 83)","paragraphs":["o C b(U.) = cp(u._~)"]},{"title":"(Brenn~ 98)","paragraphs":["Figure 3: Locating centering tasks in the pipeline"]},{"title":"theme and theme.","paragraphs":["Another pomibi]ity, which is currently under investigation, is to experiment with the effects of rhetorical structure on choice"]},{"title":"of Cb.","paragraphs":["I've assumed above that the task of main-raining continuity of reference can be located in the Text Planner. That is, the TP would be responsible both for annotating the"]},{"title":"Cb","paragraphs":["in each utterance, and for organising the text so that the same"]},{"title":"Cb is","paragraphs":["m~intained over a sequence of clauses. However, according to Reiter and Dale (1997) a more common method of structuring text is to make use of \"discourse relations, such as those described by Mann and Thompson (1987), which do not explicitly take continuity of reference into account. Richard Power (p.c.) has proposed that the implementation of CT in an RST-ba~i text planner can be treated as an opt~mi-*-~tion problem. That is, the text plan is iuitiAlly taken to be a tree structure with discourse relations defined on adjacent nodes but at most a partial specification of linear order. The problem will then consist of selecting a Ub for each propositional leaf node in such a way as to maximise the coherence of the text according to centering rules. This is an area of active research. Cheng (MS) has proposed a similar strategy for maintaining local coherence in a text planner using a genetic algorithm.","Another issue is whether the CT rules, which ass-me a \"flat\" sequence of utterances, will re-main valid for a hierarchical/); structured text plan. In fact it is an open research question whether CT should operate in this manher or whether the rules should be reformufated to take account of dominance in addition to precedence; di~erent positions are taken by Kameyama (1988) and Suri and McCoy (1994). 3.2 Sentence planning According to the re-interpretation of CT which was sketched above, Sentence Planning may promote an entity for salience if it is the"]},{"title":"Cb","paragraphs":["of the current"]},{"title":"or .following","paragraphs":["utterance. There is dearly potential competition between these two factors which will be discussed shortly. The preference for rp~di~mg Cb as ~ can be hnplemented by choosing a verb form which projects G'~ in subject position. Some poes~ilities are franker alternation:"]},{"title":"buy/sd~ gi~/receive, bor-","paragraphs":["row/qend etc, or pamivisation:"]},{"title":"your doctor ma~/ prescribe this medicine for gout vs this mtdicine ,~y be pr~cnbed .for gout.","paragraphs":["If we compare the attested example (2) with the constructed (3) it is clear that the former reads more naturally: . O) Hypoglycaemia"]},{"title":"(Cb)","paragraphs":["may cause faintness, sweating, shaking, weakness and confusion. It m~y be due to lack of food or too high a dose of the medicine.CONTINU8 It can be put right by eating or drinking something sugary.CONTINU~- 77 (pharmaceutical leaflet)","(4) -..Hypoglycaemia may cause faintness, sweating, shaking, weakness and confusion. A lack of food or too high a dose of the medieinemay cause it.RETAIN Eating or drinking something sugary can put it right.RETAIN (modified example) Hurewitz (i998) examined the use of passives to promote cohesion and salience and found that in both written texts and speech approximately 75% of passives had either the CONTINUE or SMOOTH-SHIFT transition. In each case the effect is to promote Gb to Subject in accordance with the salience principle. (For written texts this proportion was not signiRcantly different from a control sample, whereas with the spoken passages the proportion was slightly higher than in the'control.)","One system which explicitly makes Use of CT is the Caption Generation System (CGS) reported in (Mittal et al 1998). This system has a separate \"centering module\" which orders arguments within a clause to improve coherence of a text but does not influence the order of clauses. Thus only the salience principle is implemented and the centering task is located as part of Sentence Planning:. the speci-l!.~ed Centering Module receives Control after clauses have • been ordered and aggregated (op cit:454). The strategy adopted is to keep ~the highest-ranking forward-looking center of the first clause of the segment ... as the Cp(Ui) of a/l the following clauses in the same segment\" (op cit:456; my emphasis). Clearly this strategy isunlikely to generalise to a"]},{"title":"variety of","paragraphs":["domtt;na. As mentioned above there is a potential con-"]},{"title":"met betwe~ Co~t 3 (make Cb(U.+t)","paragraphs":["salient) and salience (make Cb(U,) aslient). As noted in Sect. 2.2 there may also be compe, tition between salience and Strube & Halm's cheapness principle, which can be seen as a stronger version of C3. There are different ways this conflict could be tadded in the cases where it arises aad I will consider one of them, which is to let C3 win out over salience.","Consider a text with four clauses Ul - U4. which all have a and b among their arguments. Let a be the Cb of Ul- U2 and b the Cb of Us- U#. According to salience and C3, b will be Cp of /]3 since it is Cb of that clause and the following one. For U2 there is competition between a and b to be Up, and this is decided by C3 in favour of b. Finally I a is chosen as Up of Ul. The result is as follows:","UI : Cb f a, Cp = a","U2:Cb=a, Cp=b","U3 : Cb f b, Cp = b","U4 : Cb = b, Cp = b In terms of the conventional transitions this works out as"]},{"title":"U~/U2:","paragraphs":["RETÎN"]},{"title":"U2/U3:","paragraphs":["SMOOTH SHIFT"]},{"title":"us/u~: COnTINUa","paragraphs":["This is consistent with Strube and Hahn's (1996) observation that \"a II~rAIN transition ideally predicts a SMOOTH ssw'r in the following utterance\". Brenuan et al (1987) make a very similar claim: A computational system for 9e-em-tion would try to plan a retention as a signal of an impending shift, so that after a retention, a shift would be preferred rather than a continuation. Grosz et al (1995) give the following example of the ~Am - SHIFT pattern:","(5) a. John has had trouble arranging his vacation.","b. He (Cb; John) cannot find anyone to take over his responsibilities.","c. He (C/~, John) called up Mike yesterday to work out a plan. CONTINUB","d. Mike hasannoyed him (Cb; John) alot recently, lt~rAIN","e. He (Cb; Mike) called John at 5 am on Friday last week. smrr Under the approach outlined here, which as-sumes that the Cb is independently designated,","• the system does not needto plan particular transition types or even to know about them; the desired effects come about as a result of Iocal decisions by the sentence planner using information from the text pl-nner.","• Example (5) incidentally illustrates a limita-tion of CT in its Canonical version: the theory","l'~lle w~rd a~ does not imply that these decisions are .taken in sequence. 78"]},{"title":"@ 0 0 @ 0 0 0 0 0 @ @ 0 0 0 0 @ @ @ 0 0 @ 0 @ @ 0 0 @ @ @ 0 0 0 0 0 @ @ 0 0 0 0 0 0 @ @ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0","paragraphs":["correctly predicts the pronominal choices in (5C - e) but has nothing to say about the decision to make Mike rather than John the Subject of (Sd). In fact, we can construct a variant of this text which follows centering rules more faithfully, though it does not read any more naturally: (6) e.","& John has had trouble arranging his va-","cation.","b. He cannot find anyone to take over his","responsibilities. (Cb -- John)","c. He called up Mike yesterday to work","out a plan."]},{"title":"(CONTINUE;","paragraphs":["Cb = John)","d. He has been pretty annoyed with Mike recently."]},{"title":"(colqzlm~;","paragraphs":["Cb John) He got a call from him (Mike) at 5 am on Friday last week. (CONTrol; Cb = John) If we examine the discourse structure of example (5), it seems that the discourse as a whole is about John but (Sd,e) form a parenthetical section which tells us something about M/ke. So although a blind application of centering rules would judge:(6) to be more coherent, (5) is in fact maximally coherent within the constraints of the structure of the discourse.","To snmmarise: we assvme that for each utterance U, the text planner has identified Cb(U,), Cb(U.-1) and Cb(U.+d. The task for the sentence planner is to select a verb form or some other syntactic device to malise Cb(Un+l) as the most salient of those entities which are reAl|.~ed in U. and U.+t, and subject to this, to realise"]},{"title":"Cb(gJ'.) in","paragraphs":["the most salient position available. (See Figure 3,) So for example if Cb(Un) is not to be realised in U,÷t, it will normally be realised as Cp(U,); but if it/8 to be realised in Un+I then the Cb of U,+t will be at least as highly ranked in Un as the Cb of Un. Tlfisstrategy predicts the Ralisation of M//~ rather than John as"]},{"title":"Cp in (5d)","paragraphs":["above. 3.3 Referring Expressions The contribution of CT to Referring Expression (RE) generation is to decide on pronominalisation. Rule 1 (Fig. 2) which concerns pronominalisation has a strong and a weak formulation: tile strong one is that a pronoun should be used for the Cb if it is the same as the Cb of the previous utterance, the weak one is that the Cb must be pronominalised if anything is. In the context of generation it is probably safer to use the strong version. Brennan (1998) proposes, arguing from corpus analysis, that the Cb should be pronominalised only if it is Cp of the previous utterance. Robert Dale's RPICURE system employs the terminology of CT in Con° nection with RE generation, as does the ILEX system reported in (O'Donnell et al 1998). Both these systems implement a variant of Rule 1 to determine whether to pronominalise the center (Dale) or Cb (ILEX), though in neither case is the center identified according to the standard apparatus of CT. In ILEX the Cb is designated by the text planner without reference to the content of the previous sentence, and it may be pronominal|.qed if it is the same as the previous sentence's \"Cb\". Dale's IZPIOURE identifies the center with Uthat entity which is the result of the previously described operation\" (Dale 1992:170). Passoneau (1998) constructed input for a prototype generator by \"hypothesis-ing\" a Cb for each proposition in a text based on the salience of entities in a Situation. Passoneau's system uses centering constraints to decide whether to realise entities as definite pronouns, minimal NPs or full NPs. 4 Conclusions and future work CT has developed primarily as a tool for analysing the structure of a given text and identifying the most likely candidates for anaphora resolution. In this paper we sought to deter° mine whether the principles underlying the constraints and rules of the theory can be Uturned round\" and used as planning operators for generating coherent text,. As a side-effect of this enterprise we have articulated a ~streamlined\" formulation of CT in terms of the principles of salience and cohesion, and argued that the preferences for the different transition types emerge in a partial ordering f~om the interaction between these principles. These principles are rather heterogenous, a fact which is obscured by combining them in the transition definitions, and can be implemented as encapsulated tasks distributed between text planning, 79 sentence planning and RE generation. It may turn out that individual components such as the cohesion principle do not need to be explicitly stated but emerge as by-products from higher-level text planning.","As noted at various points in this paper CT has never been more than partially implemented in NLG systems. This may be due to a belief on the part of NLG practitioners that CT gets things the wrong way round, by relying on surface grammatical realisation to determine the • centre of attention in an utterance. If this be-lld is commonly held (and anecdotal evidence suggests that it is), I argue that it is mistaken. In interpretation systems the principles of CT guide the system in identifying the centre of attention and in choosing likely referents for anaphors. In NLG systems, if there is a notion of \"topic\" or \"theme = this should be designated by the text planner, while the CT rules allow the sentence planner to promote this entity to salience to keep it as the user's \"centre of attention\".","However, a more fuDd~mental explanation for the neglect of CT in the generation literature is provided by the fact that a faithful implementation in a pipelined system turns out to require an independent way of designating the central entity in a proposition, and this itself is a problem which has not had much attention in the development of NLG systems 2. So the next stage in this research will Concentrate on developing a characterisation of Cb based on semantic content and information structure, tak-ing account of e.g. the proposals of Strube and Hahn (1996) and experimenting with optlmisation algorithms as discussed in section 3.1.2 above.","As mentioned above the Reiter model has been questioned by members of the RAGS project in Brighton and Edinburgh who are actively engaged in developing a \"Teference\" archi tecture for NLG. (See Cahlll et al., 1999, RAGS 1999.) To date' the group has concentrated on specifying the data structures which are re-quired at various stages of the generation task and has identified a number of discrete functions such as rhetorical structuring, aggregation, ~Thk appHm at lea~ to applied systems;, see CahiU","• and Reape 1998. One exception appears to be the GOS-.","SIP system described in Caragno and Iordaaskaja 1989. coherence etc., without specifying a strict order for the execution of these functions. It is too early to assess how the proposals of this paper would fit into the RAGS scheme, but I anticipate that, as with the Reiter architecture, the conclusion would be that referential coherence is not the task of a discrete module but imposes constraints on a number of different modules.","It has been noted that the way the \"realise\" relation is interpreted can have significant implications for the coherence of a text as measured by CT, and that corpus analysis has of-ten concentrated ondirectly realised Cb's. An exception is Hahn, Strube and Markert's (1996) treatment of bridging reference, or \"textual ellipsis\" in their terminology. As these authors note there have been rather few implemented systems which are able to interpret bridging references in a principled way, and research in NLG is particularly weak in this area. SO, a faithful implementation of CT in generation systems will depend in part on progress in the generation of bridging references. This is an area for future research.",".... It is intended that the procedures described in","\"this\" paper will be implemented in ICONOCLAST, an authoring tool which enables domain experts to create a knowledge base through a sequence of interactive choice-- and generates hiexarchitally structured text according to various stylistic constraints (See Power and Scott 1998). Acknowledgements This work was carried out as part of the GNOME project (Generating Nominal Expressions) which is s collaboration between ITRI in the University of Brighton and the H~tc in the ~nlversities of Edinburgh and Durham, funded by the EPSRc under grant reference GR/L51126. I would like to thank ITRX and GNOME colleagues for helpful feedback, particularly Christy 1)o-ran, Renate Henschel, Richard Power and Kees van Deemter, as well as two anonymous referees."]},{"title":"References S Brennan, M","paragraphs":["W, lker Priedman and C Pollard 1987. A Centering Approach to Pronouns. In Proc. 25th AC[, :115-62. L C-hill, C Doran, R Ev-n-, C Mellish, D Palva, M Reape and D Scott 1999. In search of a reference architecture for NLG systems. In Proc. 80 EWNLG'99. L Cahill and M Reape 1998~ Component tasks in Applied I:4atural Language Generation Systems. RAGS Project Deliverable, available at www. i tri. brighton, ac. uk/proj ects/rags. D Caragno and L Iordanskaja 1989. Content Determination and Text Structuring in GOSSIP. In Eztended Abstracts o.f ENLG'89. H Cheng MS. Experimenting with the Interaction between Aggregation and Text Planning. Unpublished paper, Division of InformatiC~, University of Edinburgh. R Dale 1992, Generating Re/erring Expreasions, Cambridge, MA/London:MIT Press. K De Smedt and G Kempen 1991. Segment Grammar: a Formalism for Incremental Sentence Generation. In C Paris, W Swartout and W Mann (eds), Natnral Language Ge.era6on in Artificial lnteUigence and Computational Linguistics. B Di Eugenio 1996. The discourse functions of Italian subjects: a centering approach. In Proe. GOLING96. B Di Eugeni0 1998. Centering in Italian. In Walker et al (eds)"]},{"title":"Centering Th~j","paragraphs":["in Discourse. P Gordon, B Grosz and L Gilllom 1993. Pronouns, Names and the Centering of Attention in Discourse."]},{"title":"Co#nitiee Scien~","paragraphs":["17/3:311-47. B Grosz, A Joshi and S Weinsteln 199.5. Centeriag: a framework for modelling the local coherence of discourse."]},{"title":"Comput~iond Linguistics,","paragraphs":["21/2: 203-25. U Hahn, M Strube and M Markert 1996. Bridging Textual Ellipses. In Prec. e/COLING-96. F Hurewitz 1998. A Quantitative Look at Discourse Coherence. In Wall~ et al (ecb) Centering Theory in Du~.rs¢ M Kameyama 1998. In~tential Centering: A Case Study. In Walker et al (eds) Centering Theory in Diso~rse. M Kameyamm, R Pammneau and M Poeslo 1993. Temporal C4mtefinfr In Prec. o~ $1stACL. W M--, and S Thompson 1987. Rhetorical Structure Theory: A Theory of Text Organisation. In L Polanyi (ed.), The 3ble~ure oj r D/acoerse V Mittal, J Moore, G Carenini and S Roth 1998. Describing Complex Charts in Natural Language: A Caption Generation System. Computational Linguistics, 24/3:431-468. • R Power and D Scott 1998. Mult'flingual authoring using ffedback texts. In Prec."]},{"title":"COLING/ACL","paragraphs":["'98 RAGS 1999. The RAGS Project. Towards a Reference Architecture for Natural Language Generation Systems. Technical report ITRI-99-14, ITRI, University of Brighton. Available at wwu. itri. brighton, ac. uk/proj ects/rags. E Reiter 1994. Has a consensus NL generation architecture appeared, and is it psycholinguistically plausible? In Proc. INLG 7.'163-70. E. Reiter and R. Dale (1997). Building Applied Natural-Language Generation Systems. Journal o.f Natural-Language Engineerin9 3:57-8Z N Reithinger 1991. POPEL - A Parallel and Incremental Natural Language Generation System. In C Paris, W Swartout and W Mann (eds), Natural Languafe Generation in Artificial Intelligence and Computational Linguistic. R Stevenson, R Crawley and D Kleinman 1994. Thematic roles, focus and the representation of events. Laf~3nage and Cognitive Proc_e~_es, 9:519-48. M Strube and U H,h- 1996. Fancfional Centering. In Proceedings ACL 34:270-77. M Strube and U Hahn 1999. Functional Centering:. Grounding Referential Coherence in Informarion Structure. To appear in Computational Linguistics. L Suri and K McCoy 1994. RAFT/RAPR and Centering: A Comparison and Discussion of Probl~ Related to ProcemingComplex Sentences. GompeMtional linguistics 20/2:30!-17. M Walker 1998. Centering, Anaphora Resolution and Discourse Structure. In Walker et al (eds) Centering Theory in Disanwse. M Walker, AK Joshl and E Prince (eds) 1998. Centering Theory in Disburse. Oxford: Clarendon Preu. 81"]}]}
