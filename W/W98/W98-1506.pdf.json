{"sections":[{"title":"Measures for corpus similarity and homogeneity Adam Kilgarriff' ITRI, University of Brighton Abstract","paragraphs":["How similar are two corpora? A measure of corpus similarity would be very useful for NLP for many pur poses, such as estimating the work involved in porting a system from one domain to another. First, we dis cuss difficulties in identifying what"]},{"title":"we","paragraphs":["mean by 'corpus similariti: human similarity judgements are not fine grained enough, corpus similarity is inherently multi dimensional, and similarity can only be interpreted in the light of corpus homogeneity. We then present an op erational definition of corpus similarity \\vhich addresses or circumvents the problems, using purpose-built sets of aknown-similarity corpora\". These KSC sets can be used to evaluate the measures. We evaluate the mea sures described in the literature, including three vari ants of the information theoretic measure 'perplexity'. A"]},{"title":"x","paragraphs":["2-based measure, using word frequencies, is shnwn to be the best of those tested."]},{"title":"The Problem","paragraphs":["How similar arc two corpora? The question arises on many occasions. In NLP, many useful results can be generated from corpora, but when can the results de veloped using one corpus be applied to another? How much will it cost to port an NLP application from one domain, with one corpus, to another, with another? For linguistics, does it matter whether language researchers use this corpora or that, or are they similar enough for it to mal<e no difference? There are also questions of more general interest. Looking at British national newspa pers: is the Independent more like the Guardian or the Telegraph?'","What are the constraints on a measure for corpus similarity? The first is simply that its findings cor respond to unequivocal human judgements. It must * Kilgarriff's part of the work was undertaken under EP","SRC grant GR/K/18931 1 The work presented here develops and extends that pre","sented in Kilgarriff (1997)."]},{"title":"46 Tony Rose Canon Research Centre Europe","paragraphs":["match our intuition that, eg, a corpus of syntax papers is more like one of semantics papers than one of shop ping lists. The constraint is key but is weak. Direct human intuitions on corpus similarity are not easy to come by, firstly1 because large corpora, unlike coherent texts, are not the sorts of things people read, so people are not generally in a position to have any intuitions about them. Secondly, a human response to the ques tion, ((how similar are two objects)), where those objects are complex and multi-dimensional,"]},{"title":"will","paragraphs":["themselves be multi-dimensional: things will be similar in some ways and dissimilar in others. To ask a human to reduce a set of perceptions about the similarities and differences between two complex objects to a single figure is an exereise of dubious value.","This serves t;o emphasise an underlying truth: corpus similarity is complex, and there is no absolute answer to \"is Corpus 1 more like Corpus 2 than Corpus 3?\". All there arc, are possible measures which serve par ticular purposes more or less well. Given the task of costing the customisation of an NLP system, produced for one domain, to another, a corpus similarity measure is of interest insofar as it predicts how long the porting will take. It could be that a measure which predicts well for one NLP system, predicts badly for another. It can only be established whether a measure correctly predicts actual costs, by investigating actual costs.2","Having struck a note of caution, we now proceed on the hypothesis that there is a single measure which cor rc~sponds to pre-theoretieal intuitions about 'similarity' and which is a good indicator of many properties of interest ··- customisation costs, the likelihood that lin guistic findings based on one corpus apply to another, etc. We would expect the limitations of the hypothesis to show through at some point, when different measures arc shown to be suited to different purposes1 but in the current situation, where there has been almost no work","2","Cf. Ucbcrla (1997), who looks in detail at the appro","priateness of perplexity as a measure of task difficulty for","spe(~ch recognition, and finds it wanting. Corpus I Corpus 2 Distance Interpretation ·-- equal equal equal same language variety /ies equal equal high different language varieties high low high corpus 2 is homogeneous and falls within","the range of 'general' corpus 1 high low higher corpus 2 is homogeneous and falls outside","the range of 'general' corpus 1 high high low impossible low low a bit lower overlapping; share some varieties high high a bit lower similar varieties","- Table I: Interactions between homogeneity and similarity: a similarity measure can only be interpreted with respect to homogeneity. High means a large distance between corpora, or large within-corpus distances, so the corpus is heteroge neous/corpora are dissimilar; low, that the distances are low, so the corpus is homogeneous/corpora are similar. High, low and equal are relative to the other columns in the same row, so, in row 2, 'equar in the first two columns reads that the within-corpus distance (homogeneity) of Corpus I is roughly equal to the within-corpus distance of Corpus 2, and 'high' in the Distano~ column readt> that the distance between the corpora is substantially higher than these within-corpus distances. on the question, it is a good starting point."]},{"title":"Similarity and homogeneity","paragraphs":["How homogeneous is a corpus? The question is both of interest in its own right, and is a preliminary to any quantitative approach to corpus similarity. In its own right) because a sublanguage corpus) or one contain ing only a specific language variety, has very different characteristics to a general corpus (Biber, 1993) yet it is not obvious how a corpus's position on this scale can be assessed. As"]},{"title":"a","paragraphs":["preliminary to measuring corpf.ls similar ity, because it is not clear what a measure of similarity would mean if a homogeneous corpus (of, ,eg, software manuals) was being compared with a heterogeneous one (eg. Brown). Ideally, the same measure can be used for similarity and homogeneity, as then, Corpus !/Cor pus 2 distances will be directly comparable with het erogeneity (or \"within-corpus distances\") for Corpusl and Corpus2. This is the approach adopted here.","Not all combinations of homogeneity and similar ity scores are logically possible. A corpus cannot be much more similar to something else than it is to itself. Some of the permutations) and their interpretations) are shown in Table 1.","The last two lines in the table point to the differences between general corpora and specific corpora. High within-corpus distance scores will be for general cor pora) which embrace a number of language varieties. Corpus similarity between general corpora will be a matter of whether all the same language varieties are represented in each corpus) and in what proportions. Low within-corpus distance scores will typieally relate to corpora of a single language variety) so here, scores"]},{"title":"47","paragraphs":["may be interpreted as a measure of the distance between the two varieties."]},{"title":"Related Work","paragraphs":["There is very little work which explicitly aims to measure similarity between corpora. Johansson and Hofland (1989) aim to find which genres, within the LOB corpus, most resemble each other. They take the 89 most common words in the corpus) find their rank within each genre, and calculate the Spearman rank correlation statistic ('spearman,).","Rose, Haddock, and Tucker (1997) explore how per-"]},{"title":"'","paragraphs":["formance of a speech recognition system varies with the size and specificity of the training data used to build the language model. They have a small corpus of the target text type1 and experiment with 'growing) their seed cor pus by adding more same-text-type material. They use spearman and log-likelihood (Dunning, 1993) as mea sures to identify same-text-type corpora. Spearman is evaluated below.","There is a large body of work aiming to find words which are particularly characteristic of one text, or cor pus) in contrast to another, in various fields including linguistic variation studies (Rayson, Leech, and Hodges, 1997), author identification (Mosteller and Wallace, 1964) and information retrieval (Salton, 1989; Dun ning, 1993). Biber (1988, 1995) explores and quantifies the differences between corpora from a sociolinguistic perspective. While all of this work touches on corpus similarity, none looks at is as a topic of itself.","Sekine (1997) explores the domain dependence of parsing. He parses corpora of various text genres and counts the number of occurrences of each subtree of depth one. This gives him a subtree frequency Jist for each corpus, and he is then able to investigate whieh subtrees arc markedly different in frequency be tween corpora. Such work is highly salient for cus tomising parsers for particular domains. Subtree fre quencies could readily replace word frequencies for the frequency-based measures below.","In information-theoretic approaches, perplexity is a widely-used measure. Given a language model and a corpus, perplexity \"is, crudely speaking, a measure of the size of the set of words from which the next word is chosen given that we observe the history of ... words''"]},{"title":"•","paragraphs":["(Roukos, 1996). Perplexity is most often used to assess how good a language modelling strategy is) so is used with the corpus held constant. Achieving low perplex ity in the language model is critical for high-accuracy speech reeognition1 as it means there are fewer high likelihood candidate words for the speech signal to be compared with.","Perplexity can be used to measure a property akin to homogeneity if the language modelling strategy is held constant and the corpora arc varied. In this case) perplexity is taken to measure the intrinsic difficulty of the speech recognition task: the less constraint the domain corpus provides on what the next word might be, the harder the task. Thus Roukos (1996) presents a table in which different corpora are associated \\vith different perplexities.","Perplexity measures are evaluated below."]},{"title":"\"Known-Similarity Corpora\"","paragraphs":["A \"Known-Similarity Corpora11","(KSC) set is built as follows: two reasonably distinct text types1 A and B1 arc taken. Corpus 1 comprises 100% A; Corpus 2, 90% A and 10% B; Corpus 3, 80% A and 20% B; and so on. We now have at our disposal a set of fine-grained statements of corpus similarity: Corpus 1 is more like Corpus 2 than Corpus 1 is like Corpus 3. Corpus 2 is more like Corpus 3 than Corpus 1 is like Corpus 41 etc. Alternative measures can now be evaluated1 by deter mining how many of these 'gold standard judgements1 they get right. For a set of n Known-Similarity Corpora there are n (.( .. l) ) . t 1-"]},{"title":"+ .. 2_)n- ') -:2·--","paragraphs":["1 t:::=l gold standard judgements (see Appendix for proof) and the ideal measure would get all of them right. Mea sures can be compared by seeing what percentage of gold standard judgements they get right.","Two limitations on the validity of the method are, first1 there are different ways in \\'Vhich corpora can be different. They can be different because each represents one language variety, and these varieties are different1"]},{"title":"48","paragraphs":["or because they contain different mixes, with some of the same varieties. The method oi1ly directly addresses the latter model.","Second, if the corpora are small and the difference in proportions between the corpora is also small) it is not clear that all the 'gold standard) assertions are in fact true. There may be a finance supplement in one of the copies of the Guardian in the corpus, and one of the copies of AccC'lmtancy may be full of political stories: perhaps, then1 Corpus 3 is more like Corpus 5 than Corpus 4. This was addressed by selecting the two text types with care so they were similar enough so the measures were not 100% correct yet dissimilar enough to make it likely that all gold-standard judge· ments \\Vere true1 and by ensuring there was enough data and enough KSG·sets so that oddities of individual cor pora did not obscure the picture of the best overall mea sure."]},{"title":"Measures","paragraphs":["All the measures use spelt forms of words. None make use of linguistic theories. Comments on an earlier ver sion of the paper included the suggestion that lemmas1 or word senscs 1 or syntactic constituents) \\vere more ap propriate objects to count and perform computations on than spclt forms. This would in many ways be desirable. However there are costs to be considered. To count1 for example1 syntactic constituents rcquires1 f1rstly1 a theory of what the syntactic constituents are; secondly) an account of how they can be recognised in running text; and thirdly1 a program which performs the recognition. Shortcomings or bugs in any of the three will tend to degrade performancc1 and it will not be straightforward to allocate blame. Different theories and implementations are likely to have been developed with difl'erent varieties of text in focus 1 so the degrada tion may well effect different text types differentially. Moreover, practical users of a corpus-similarity mea sure cannot be expected to invest energy in particular linguistic modules and associated theory. To be of gen eral utility) a measure should be as theory-neutral as possible.","While we are planning to explore counts of lemmas and part-of-speech catcgories1 in these experiments we consider only raw word-counts."]},{"title":"Word Frequency measures","paragraphs":["Two word frequency measures were considered. For each, the statistic did not dictate which words should be compared across the two corpora. In a preliminary in vestigation we had experimented with taking the most frequent 10, 20, 40 ... 640, 1280, 2560, 5120 words in the union of the two corpora as data points, and had achieved the best results with 320 or 640. For the ex periments below, we used the most frequent 500 words.","Both word-frequency measures can be directly ap plied to pairs of corpora, but only indirectly to measure homogeneity. To measure homogeneity: L divide the eorpus into 'slices';","2. create two subc:orpora by randomly allocating half the slices to each; 3. measure the similarity between the subcorpora; 4. iterate with different random allocations of slices;","5. calculate mean and standard deviation over a.ll iter ations.","Wherever similarity and homogeneity figures were to be compared, the same method was adopting for calcu lating corpus similarity, with one subcorpus comprising a random half of Corpus 1, the other, a random half of Corpus 2."]},{"title":"Spearman Rank Correlation Co-efficient","paragraphs":["Ranked wordlists are produced for Corpus 1 and Corpus 2. For each of the n most common words! the difference in rank order between the two corpora is taken. The statistic is then the normalised sum of the squares of these differences, Comment Spearman is easy to compute anc~ds inde pendent of corpus size: one can directly compc\\:re ranked lists for large and small corpora. However thpre was an a priori objection to the statistic. For very frequent words, a difference of rank order is highly significant: if the is the most common word in corpus 1 but only 3rd in corpus 2, this indicates a high degree of difference be tween the genres. At. the other end of the scale, if /!read is in 4.00th position in the one corpus and 500th in the other, this is of no significance, yet Spearman counts the latter as far more significant than the former."]},{"title":"x2","paragraphs":["For each of the n most common words, we calculate the number of occurrences in each corpus that would be expected if both corpora were random samples from the same population. If the size of corpora 1 and 2 are N1, N2 and word w has observed frequencies Ow 1, ow 2 , then expected value ew 1 :;:;;:"]},{"title":"N","paragraphs":["1"]},{"title":"x~w~","paragraphs":["1"]},{"title":";","paragraphs":["0"]},{"title":"\"''","paragraphs":["2"]},{"title":")","paragraphs":["and l,il.;:ev.,ri,se , 1- 2 for Cw,2; then","2 ,~(o-e)2 X"]},{"title":"='\"'","paragraphs":["e"]},{"title":"49","paragraphs":["Co1nn1ent The inspiration for the statistic comes from the"]},{"title":"x","paragraphs":["2","-test for statistical independence. As Kil garriff (1996) shows, the statistic is not in general ap propriate for hypothesis-testing in corpus linguistics: a corpus is never a random sample of words, so the null hypothesis is of no interest. But once divested of the hypothesis-testing link,"]},{"title":"x","paragraphs":["2 is suitable. The (o- e) 2"]},{"title":"je","paragraphs":["term gives a measure of the difference in a word's fre quency lx~t\\veen two corpora, and, while the measure tends to increase with word frequency, in contrast to the raw frequencies it does not increase by orders of magnitude.","The measure docs not directly permit comparison be tween corpora of different sizes."]},{"title":"Perplexity and Cross-entropy","paragraphs":["From an information-theoretic point of view, prima fa cie, entropy is a well-defined term capturing the infor mal notion of homogeneity, and the cross-entropy be-· tween tvw corpora captures their similarity. Entropy is not a quantity that can be directly measured. The standard problem for statistical language rnodelling is to aim to find the model for which the cross-entropy of the model for the corpus is as low as possible. For a perfect language model, the cross-entropy would be the entropy of the corpus (Church and Mercer, 1993; Charniak, 1993).","With language modelling strategy held constant, the cross-entropy of a language model (LM) trained on Cor pus 1: as applied to Corpus 2, is a similarity measure. The cross-entropy of the LM based on nine tenths of Corpus 1, as applied to the other 'held-out' tenth, is a measure of homogeneity. We standardised on the 'teqfold cross-validation' method for measures of both similarity and homogeneity: that is, for each corpus, we dividE~d the corpus into ten parts3","and produced ten LMs, using nine tenths and leaving out a different tenth each time. (Perplexity is the log of the cross-entropy of a corpus with itself: measuring homogeneity as self similarity is standard practice in information theoretic approaches.)","To measure homogeneity, we calculated the cross entropy of each of these LMs as applied to the left-out tenth, and took the mean of the ten values. To mea sure similarity, we calculated the cross-entropy of each of the Corpus 1 LMs as applied to a tenth of Corpus 2 (using a different tenth each time). We then repeated the procedure with the roles of Corpus 1 and Corpus 2 reversed, and took the mean of the 20 values.","3","For the KSC corpora, we ensured that each tenth had an appropriate mix of text types, so that, eg, each tenth of a corpus comprising 70% Guardian, 30% BMJ, also comprised 70% Guardian, 30% BMJ.","All LMs were trigram models. All LMs were produced and calculations performed using the CMU /Cambridge toolkit (Rosenfeld, 1995).","The treatment of words in the test material but not in the training material was critical to our procedure. It is typical in the language modelliug community to repre sent such words with the symbol UNK, and to calculate the probability for the occurrence of UNK in the test corpus using one of three main strategies.","Closed vocabulary The vocabulary is defined to in-· elude all items in training and test data. Probabili ties for those items that occur in training but not test data) the 'zerotons\\ are estimated by sharing out the probability mass initially assigned to the singletons and doubletons to include tbe zerotons.","Open, type 1 The vocabulary is chosen indepen dently of the training and test data, so the probability of UNK may be estimated by counting the occurrence of unknown words in the training data and dividing by N (the total number of words).","Open, type 2 The vocabulary is defined to include all and only the training data, so the probability of UNK cannot be estimated directly from the training data. It is estimated instead using the discount mass cre ated by the normalisation procedure. All three strategies were evaluated."]},{"title":"Data","paragraphs":["All KSC sets were subsets of the British National Cor pus (BNC)'. A number of sets were prepared as follows.","For those newspapers or periodicals for which the BNC contained over 300,000 running words of text, word frequency lists were generated and similarity and homogeneity were calculated (using"]},{"title":"x","paragraphs":["2","). We then se lected pairs of text types which were modemtely dis tinct, but not too distinct, to use to generate KSC sets. (In initial experiments, more highly distinct text types had been used, but then both Spearman a.nd"]},{"title":"x'","paragraphs":["had scored 100%, so 'harder' tests involving more similar text types were selected.)","For each pair a and b, all the text in the BNC for each of a and b was divided into 10,000-vwrd tranche:=L These tranches were randomly shuff-led and allocated as follows: first 10 of"]},{"title":"a","paragraphs":["into bOa next 9 of"]},{"title":"a,","paragraphs":["first 1 of b into b1a next 8 of"]},{"title":"a,","paragraphs":["next 2 of b into b2a next 7 of a, next 3 of b into b3a 4 http:/ /info.ox.ac.ukjbnc"]},{"title":"50","paragraphs":["until either the tranches of"]},{"title":"a","paragraphs":["orb ran out, or a complete 11-corpus KSC-set was formed. A sample of KSC sets are available on the web. 5","There were 21 sets containing between 5 and 11 corpora. The method ensured that the same piece of text never occurred in more than one of the corpora in a KSC set.","The text types used were: Accountancy (ace); The Art Newspaper (art); British Medical Journal (bmj); Environment Digest (env); The Guardian (gua); The Scotsman (sco); and Today ('low brow' daily newspaper, tod).","To the extent that some text types differ in content, whereas others differ in style, both sources of variation are captured here. Accountancy and The Art News paper are both trade journals, though in very different domains, while The Guardian and Today are both gen eral national newspapers, of different styles."]},{"title":"Results","paragraphs":["For each KSC-set, for each gold-standard judgement the 1","Correct answer' was known, eg., 11","the similarity 1,2 is greater than the similarity 0,3\". A given measurE either agreed with this gold-standard statement, or dis agreed. The percentage of times it agreed is a measun of the quality of the measure. Results for the caseE where all four measures were investigated are presented in Table 2.","- spear"]},{"title":"x\"","paragraphs":["closed type 1 type 2 KSC-set accgua 93.33 91.33 82.22 81.11 80.44 art_gua 95.60 93.03 84.00 83.77 84.00 brnj_gua 95.57 97.27 88.77 89.11 88.77 env_gua 99.65 99.31 87.07 84.35 86.73 Table 2: Comparison of four measures","The word frequency measures outperformed the per· plexity ones. It is also salient that the perplexity mea· sures required far more computation: ca. 12 hours on"]},{"title":"c","paragraphs":["Sun, a ... s opposed to around a minute. Spearman and x 2","were tested on all 21 KSC-sets, anc"]},{"title":"x'","paragraphs":["performed better for 13 of them, as shown in Table 3","spear :;?\"tie total Highest score 5 13 3 21 Table 3: Spearman/x' comparison on all KSCs 5 http'"]},{"title":"I I","paragraphs":["www' itri' bton. a c. uk"]},{"title":"r","paragraphs":["Adam. Kilgarriff /KSC"]},{"title":"I","paragraphs":["The difference was significant (related t-test: t=4.47, 20DF, significant at 99.9% level)."]},{"title":"x","paragraphs":["2","was the best of","the measures compared."]},{"title":"Conclusions and further work","paragraphs":["\\Ve have argued that computational linguistics is in ur~ gent need of measures for corpus similarity and homo geneity. Without one, it is very difficult to talk ac curately about the relevance of findings based on one corpus) to another, or to predict the costs of porting an application to a new domain. We note that corpus simila.rity is complex and multif<lceted, and that differ ent measures might be required for different purposes. However, given the paucity of other work in the"]},{"title":"Held,","paragraphs":["at this stage it is enough to seek a single measure which performs reasonably.","The Known-Similarity Corpon.t method for evaluat ing corpus-similarity measures was presented, and rnen sures discussed in the literature were compa.red using it. For the corpus-size used and this approach to <Walua tion,"]},{"title":"x","paragraphs":["2","and Speannan both perfon:ned better than auy of three cross-entropy measures. These measures have the advantage that they are cheap and straightforward to compute."]},{"title":"x","paragraphs":["2","outperformed Spearman.","Further work is to include: 0 developing a scale-independent"]},{"title":"x","paragraphs":["2","-based statistic","e investigating a 2-dimensional measure for simila.rity1","with one dimension for closed-class \\vords and an","other for open-class words 1 to see whether differences","in style and in domain can be distinguished f1l evaluation of a log-likelihood-bttsed"]},{"title":"measj,lY~~'","paragraphs":["and of different vocabulary-sizes for open models. Then it will be possible to eompare the 500-word {ncasure for spearman and"]},{"title":"x","paragraphs":["2","more directly with the perplQxity measures","e gathering data on the actual costs of porting systems, for correlation with results given by similarit.y mea sures","$ comparing the method with Biber1 S feature-set and","analysis."]},{"title":"References","paragraphs":["Biber1 DouglaB. 1988. Variation across speech and writ ing. Cambridge University Press.","Biber1 Douglas. 1993. Using register-diversified cor·· pora for general language studies. Compnt:ational Linguistics, 19(2):219 242.","Biber1 Douglas. 1995. Dimensions in Register Varia tion. Cambridge University Press."]},{"title":"51","paragraphs":["Charniak, Eugene. 1993 Statistical La · L , · , nguage e(Lm-ing. MI1 Press, Cambridge, Mass.","Church, Kenneth W. <md Robert L. Mercer. 1993. In troductiOn to the special issue on computation8.1Un guisties using large corpora. Computational Linguis tics, 19(1):1-24.","Dunning, Ted. 1993. Accurate methods for the statis tics of surprise and coincidence. Computational Lin guistics, 19(1):61- 74.",".Johansson1 Stig and Knut Hofland, editors. 1989. Fre quency Analysis of English vocalntlaTy and grammm\\ based on the LOB corpns. Clar8ndon, Oxford.","Kilgarrifl', Adam. 1996. Which words are particularly chara.cteristie of a text? a survey of statistical ap proaches. In Language Engineering for Document Analysis and Recognition1 pages 33·--40, Brighton, England, April. AISB Workshop Series.","Kilgarriff1 Ada.m. 1997. Using word frequency list~> to measure corpus homogeneity and similarity between corpora.."]},{"title":"In","paragraphs":["Proceedings,"]},{"title":"ACL SIO-DAT","paragraphs":["workshop on very large corpora1 pages 231---245 1 Beijing and Hong Kong 1 August.","Mosteller, Frederick and David L. Wallace. 1964. Ap plied Bayesian and Classical lnfer·encc - The Case of The Federalist Papers. Springer Series in Sa.tistics, Springer-· Verlag.","Rayson, Paul1 Geoffrey Leech, and Mary Hodges. 1997. 1Socia.l differentiation in the use of English vocabu lary: some analysis of the conversational component Of the British National Corpus. Interrwtional Jov.r nal of Corpus L-ing?tistics, 2(1):133~152.","Rosel Tony, Nicholas Haddock1 and Roger 'J\\1cker. 1997. The effects of corpus size and homop;eneity on language model quality. In Proceedings, ACL SIG DAT workshop on very large corpora, pages 178~~~191, Beijing and Hong Kong) August.","Rosenfeld, Ronald. 1995. The CMU Statistical Lan guage Modelling Toolkit and its usc in the 1994 ARPA CSR Evaluation. In Proc. Spoken Language Technology Workshop, Austin 1 Texas.","R.oukos 1 Salim1 1996. Language Representation) cha.p· ter 1.6. National Science Foundation and European Cormnission) Wl'lW. cse. ogi/CSLU/HLTsurvey. html.","Salton, Gerard. 1989. Automatic Text Processing. Addison-Wesley.","Sekine, Satshi. 1997. The domain dependence of pars ing. In Proc. Fifth Conference on Applied Natural Language Processing, pages 96·102, Washington DC, April. ACL.","Ueberla, Joerg. 1997. Towards an improved per formance measure for language models. Tech nical Report DERA/CIS/CIS5/TR97426, DERA. cmp-lg/9711009."]},{"title":"Appendix","paragraphs":["The proof is based on the fact that the number of simi larity judgements is the triangle number of the number of corpora in the set (less one), and that each new sim ilarity judgement introduces a triangle number of gold standard judgements (once an ordering which rules out duplicates is imposed on gold standard judgements).","• A KSC set is ordered according to the proportion of text of type 1. Call the corpora in the set I. .. n.","• A similarity judgement ('sim') between a and b (a, b) compares two corpora. To avoid duplication, we stipulate that a<b. Each sim is associated with a number of steps of difference between the corpora: dif(a,b)=b-a.","• A gold standard judgement ('gold') compares two sims; there is only a gold between a, b and c,d if a<b and c<d (as stipulatNI above) and also if a<=c, b>=d, and not (a=c and b=d). Each four-way com parison can only give rise to zero or one gold, as en forced by the ordering constraints. Each gold has a difference of difs ('difdif') of (b-a)-(d-c) (so, if we compare 3,5 with 3A, difdif=l, but where we com pare 2,7 with 3,4, difclif"]},{"title":"=","paragraphs":["4). difdif(X,Y)"]},{"title":"=","paragraphs":["dif(X)· dif(Y).","• Adding an nth corpus to a KSC set introduces n-1 sims. Their difs vary from 1 (for (n-1),n) to n-1 (for 1,n).","• The number of golds with a sim of dif rn as first term is a triangle number less one,"]},{"title":"2:;:","paragraphs":["2 i. or m(n~.-J-l) - 1 For example, for 2,6 ( dif=4) there are 2 golds of difdif 1 (eg with 2,5 and 3,6), 3 of difdif 2 (with 2,4, 3,5, 4,6), and 4 of difdif 3 (with 2,3, 3,4, 4,5, 5,6).","• With the addition of the nth corpus, we intro duce n-1 sims with difs from 1 to n-1, so we add 2::;~~1","i(iil) - 1 golds. For the ·whole set, there are 2::;~"]},{"title":"1 I:;:;\\","paragraphs":["iU~Il ··· 1 and collecting up repeated terms gives 2::;~"]},{"title":"1 (n- i)('(i;-rl -","paragraphs":["1)"]},{"title":"52","paragraphs":[]}]}
