{"sections":[{"title":"Dynamic Coreference-Based Summarization Breck Baldwin Thomas S. Morton Institute for Research Department of Computer in Cognitive Science and Information Science University of Pennsylvania University of Pennsylvania {breck,tsmorton}©linc.cis.upenn.edu Introduction","paragraphs":["\\Ve ha.ve developed a query-sensitive text summariza tion technology \\Vell suited for the task of determining whether a. document is relevant to <'-\" query. Enoug;h of the docurnent is displayed for the user to determine whether the document should l:H~ read in its entirety. Evaluations indicate that sununarics are classif-ied for relevauce uearly as well as full documents. This ap proach i.s based on the concept that a good SltJnrnary will repn-)sent each of the topics in the query and is n'alized by ~electing smltcnc<-!S from the document un til all the phrases in the query which are represented in the sumiHa.ry are (covered.' A phrase in th<:; docu-"]},{"title":". '","paragraphs":["Jllcnt is considered to cover a phraf:le in the qu(~r:Y if it is cmeferent \\Vith it. This approach maxirnizes the space of <!ntities reta.incd in th(:: summ<Jxy with minimal re dnnda.ncy. 'rhe software is built upon the CAMP NLP spt.cm"]},{"title":"[2]. Problem Statement","paragraphs":["Given the relative immaturity of sunlmari;~,ation tech·· nologi<~s and their evaluation, it is \\vorthwhile to de scribe our approach in d<:;ta.il and t.he problems it is intended to solve. An important aspect of our tcch Hiqm: is that. we produce sentence c~xtraetion summaries which are constructed by selecting sc·mtlmces from the som·cc document. In aclditicm, our sununarie':l arc fo cnsed on providing relevant information about a query. \\Ve feel that. the current state-of-the-art techniques are better equipped to prod nee high quality query-sensitive summa.rics than gmwric summaries. Our goal is to pro dun: 'indicative' summaries [4] which allow"]},{"title":"a.","paragraphs":["user to dPtcrmilw whether the document is relcv;:tnt to his or lwr quQry. The ;.;mnmary is not intended to replace the docnrnent or provide answers to questions directly but nw.:y h<-tve this effect.","Casting our technology in terms of a product, we sec~ t.hc application as an intermediate step between view-"]},{"title":"1","paragraphs":["ing entire documents and the output of an information retrieval engine~. Instead of looking at either headlines or an entire document, the user \\voulcllook at the sum rnaries of the documents and then decide whether the document merited further reading."]},{"title":"Approach","paragraphs":["We conducted a simple experiment with sumrru-.1..ries pro duced in the"]},{"title":"TIPSTER","paragraphs":[".snmrna.rization dry run [G]. For 5 queries \\vith 200 documents each, \\ve took the set of summaries produced by the 6 dry-run participants and retained only those summa.ri<~s that were true positives, i.e., the~ sumrna.ry was judged 'rdevant' and the full document was judged trclevaJlt'. Over a.ll the quei'ies, at least one of the six system~ produced a truc posi,tive ~umma.ry for H6.6% of the documents, although no individual system performed nearly at that leveL This meant that some existing technology produced a correct summary for almost every relc~vant document. Hence we viewed the problern as one of balancing the ea.pabilities of our system to behave like the amalga mated systern implicit in joined output. 13ased on this result we a.re confident that this class of summarbm tion is tractable with current technologies and this has strongly motivated our design decisions.","Upon encountering a query like t~n.c~porting on possibility of and search for extra-terrestrial life/intelligence.\" l","we assume that the user has defined"]},{"title":"a..","paragraphs":["class of actions, ideas, c.tndjor entities that he or she is interested in. The job of an information retrieval engine is to find instantiations of those classes in text documents in some database. \\A..!e vimv summarization as n.n additional step in this process ,,,here we attempt to present the user \\:vith the smallest collection of sentences in the document that instantiate the user specified classes and do not mislead the user about the overall content of the document. By doing sol we can greatly shortcu the amount of the document that the user must read in order to determine whether the document is relevant for the user's needs.","Just as information retrieval algorithms approxi wate document relatedness by examining various string matchings between the query and the text, we approx imate certain classes of corc~fcrence between the query and the tc:xt by examining linguistic information. These curefereuce relations include identity of reference and part-whole relations for nominal and verbal phrases. 1 This moves us a step closer to reasoning at a more appropriate kv(~l of generalization, for summarization, which is still tedmologica.lly feasible. Below are (~xam­ plcs indicating the classes of relatedness that we are trying to capture."]},{"title":"'I'he identity relation between the query and the document","paragraphs":["Noun phrase con-{erence is the best understood class of relations that we compute. For exampl(~, there is corefc:'rence between 'Federal Emergency Managernc~nt AJ-'.,('IH:y 1","in tlw query a.nd the acronym 'FEtviA' in the rl(H'I!lllCilt below: (j'U('Xy: \\~That is the main functio11 of the Fed eral En1ergency Management Agency and the funding level provided to meet emergencies? Ooc'wment,: ..."]},{"title":"FEMA","paragraphs":["a.gree::> that \"fine-tuning\" is needed to the 1974 act establishing a coordinated federal program to prepare for and respond to hur ricaJWS) t.orrJ<-vloes) storms and floods. Sillc(~ these noun phra.Bes refer to the sarne entity in the world, S<-~JJtenc(~S that mention the orr;anization would !H' particularly valuable in a summary. 1'his class of cordcn:nce can include people) cornpa.xlics and objects snc:h as automobiles or aluminum siding. It need not lw n~stricted to proper nouns as it is possible to refer to an entit.Y using common nouns, i.e. (the agency' and ))l'OIJOUnS.","Identity also holds betwetm events mentioned in the qucr.Y and document. Sometimes tlH~ evc~nt that a query d(~scribe.H h; the best. indicator of what document should b(~ r(~trieved, and correspondingly what sentences are ;l.ppropriate for a sumrnary. Consider the following: ()nm·y: A reh:vant document will provide new the ori(~S about the 1960's assassination of Presi d(~nt. Kennedy. Doc:u:ment: ... The H.ouse Assassinations Commit t<~(~ concluded in 1978 that Kennedy was ((prob ably') assassinated as the result of a conspiracy 1","It i~ not clear whether more sophisticated annotations","Me appropriate for information retrieval) and perhaps more","t:o the point, it i~ not clear that there are sufficient resources","t.o proces~ 2 GB collections of data."]},{"title":"2","paragraphs":["involving a second gunma11) a finding that broke from the Warren Commission)s belief that l..~ce Har vey Oswald acted alone in Dallas on Nov. 22) 1963. The noun phrase (the 1960's assassination' refers to an event, which is the same as the one referred to in the document with the verb 'assassina.vxr. Note also that there is coreference between 'President l<<'~l111C:~dy' and 'Kennedy' in the document."]},{"title":"The part-whole relation between the query and the document","paragraphs":["In addition to the identity relation) phrases in a text which refer to parts of an entity or concept mentioned in the query will likely provide useful information) and therefore should be included in a. summary. Finding t.hese relations in in general is beyond the scope of this paper, however) our approxirnation of"]},{"title":"a.","paragraphs":["subclass of these relaJions proved helpful f(n· <J number of queri(~S.","A strong example of the part-\\vhoh' rela.tion oc curs wlw11 a country is nwntioned in the query and a province or city within that country is mentioned in the docurnent. For exa.rnple: (Jum·y: Document will discuss efforts by the~ black majority in South Africa to overthrow domina .. tion by the white minority government~. Docurnenl: About. DO soldiers have buen arrested and face possible death sentenCl)S stemming from a coup attempt in Bophuthatswana, ... Rebel sol diers staged the ta.keover bid \\V(~dnesda.y, detain ing homeland President Lucas lVIangoJw. Bophuthatswana is im;idc Sont.h Africa) and sentences that rncntion it are clca.rly good candida.t(-:s for inclusion in a summary.","We also consider pa.rt-w!Jole relations between events as in t.he. relation bctw('.Gll 'overthrow' and :staged' and 'detained'. Those events are sulJ .. parts of OV(~rthrow events, and as such) sentences that contain sub-parts of the events a.re reasonable ca.11didates for inclusion in summaries."]},{"title":"Implementation","paragraphs":["The surnmarization tecllllique was developed i:vithin the CAMP NLP framework. This s.vstem provides an in tegrated environment in which to a.ccess many levels of linguistic information as W(~ll <ls world knowledge. Its main components include:: n<:-:unc:d entity reeogni tion, tokcni~ation, sent.CllCe <letc:ctioll, part .. of-speecll tagging, morphological a.nalysi~, parsing, argument dc tectiou, a.nd corofcrence n~solut.ion. rvlany of the tech niques used for these tasks perform at or nea.r the st.ate of t-he art and are describerl in more depth in p2) 9) 8: 71 51 1) 2). The system produces coreference annotated documents ·which serve as the input to the :Slllllmarization algorithm."]},{"title":"Relating the query to the document","paragraphs":["The relationships discu::;sed previously are approxi mated via a series of associationH between tokens in the query, headline, and the body of the docurnent. Event references arc captured by associating verbs or nominal izations in the query with verbs and nominali:.::;ations in the cloc1nnent.","Given three verhal forms v1 in the qttery1 v2 in the document) and V:} in the set of all verbal forms 1 where a verbal form is the morphological root of a verb or the vc~rb root corresponding to a nominalization1 v1 is associated with 1)","2 if at leaflt one of the following criteria an~ met: I. (u,"]},{"title":"cJ -v,)","paragraphs":["1\\p(u,,v,)/(p(vJ)p(vz)) 2:5 2- (v,"]},{"title":"=","paragraphs":["-uz) 1\\ (3v,"]},{"title":"l","paragraphs":["v,"]},{"title":"I","paragraphs":["p(v,,-v,)/p(v,)p(v,) 2: 5)",":;_ (-o, --- v2) 1\\ ((8nbject(v,) subject(v,)) V","(objcd(v1 )"]},{"title":"=","paragraphs":["objcct(1!z))) Here p(v;) is the probability that 1Ji occurs in a docu nwut and p(!Ji 1 v.7) is thr~ probability that Vi and Vj occur iu the same document. ThcsQ probabilities are based on frequencies gathered frorn approximately 45,000 Wall Street .Journal articles. Criterion 1 is a mcasmT of mu tnal ill formation between t\"wo verbs. Criteriori"]},{"title":"2","paragraphs":["is used","to ruh~ out frequently occurring verbs such a::; \"ben and","\"make\". Criterion 3 allows for verbs which arc ruled out","by criterion 2 to be associated when additional context","is available. Thi;.; is important since some queries only","contain verbal forms which are ruled out by criterion 2.","Hdationships between proper nouns arc made on the","hasis of string matches, acronym matching) and dictio","nary lookup. Acronyms arc determined either through","a table lookup or an appositive construction occurring","ill the document which designates the acronym for a","specif-ic proper noun. A proper noun in the query is","considered associated with"]},{"title":"a.","paragraphs":["proper noun in the docu lllcnt if it matches tJ:-w string or acronym of the proper nonn in the document or it appears in the definition of the proper noun in the docum<~nt. A reverse dictio nary lookup often a.llows cities to be associated with the country they are in.","A token in the query 1:vhich is a lowercase noun or adjective ir:; associated with any token in the docu nwut which matches its morphological root and part of speech.","TokenR which occur in the headline are associated with tokens in the document body using the same cri teria as the query1 with the exclusion of the dictionary"]},{"title":"3","paragraphs":["lookup. The dictionary lookup was exduded because the headline will likely use the same lt~xiealization of a proper noun as that used in a document. This is less likely to be the case with the query."]},{"title":"Selecting a sentence","paragraphs":["The associations discussed in the previous section arc used to rank and sek:ct sentences from the document. Every token in the document which is associated with the same token in the query or headline is considered to be in the Ra.me corc.fcrencc chain. A sentence which contains any token in a given coreference chain is said to cover that chain.","The following scores are computed for each sentence in the document:","1. The number of coreference chains from the query which are covered by the sentence and haven)t been covered by a previously ticketed sentence.","2. The number of noun coreference chains from the query which are covered by the sentence and the num ber of verbal tcrrns in the sentence which are chained to the query.","3. The number of coreferencc chains from the headline which are covered by the sentence and haven1","t been covered by a. previously selected sentence.","4. The number of Houn coreference chains from the l;eaclline which are covered by the seutence and UH:.: number of verbal terms in the sentence which <Jre chained to the headline.","5. The number of corcference chains which are covered by the sentence and haven 1","t been covered by a previ ously nelected sentence.","6. The number of noun co reference chains which are cov ered by the sentence.","7. The index of the sentence; in the documenti sentences are sequentially numbered."]},{"title":"The","paragraphs":["sentences are sorted based 011 the above scores1 where the ith scoring Criteria is only considered in case of a tie for all criteria less than 'i. Scores 1-6 are ranked in descending order while score 7 is ranked in ascending order. The top-ranked sentence is sclectE!d 1 and scores 11 31 and 5 are recomputed in order to select the next sentence. Selection halts v,rhen all coreference chains in the query have be~:n covered a.nd the summary contains at least 4 sentences.","Scores 1 and 2 are used to select sentences 1vhich are related to the query. Scores 3 and 4_ are motivated by documents which have 1 or 2 sentences whieh appear related to the query but if presented alone would give a. false impression of the true content of the document. Thus sentences related to the headline are presented to provide additional background. Consider the following example: Onery: \\Vhat evidence is there of paramilitary ac tivity in the U.S.? Summoxy: ... Last month the extremists used rocket-propelled grenades for the first time in three attacks on police and paramilitary units .... This sentenc(~ was selected because it contains tol~Jms which a.re in coreference chains with tokens in the query; however 1 alone it is potentially misleading because the place of the attack is not mentioned. This ambiguity is resolved when the following sentence is selected because it is well associated with the headline. Sv.mmoxy: . Sikh militants may have acquired one or two U .S.-made Stinger anti-aircraft missiles and hidden them inside the Golden Temple) the Sikh faith)s holiest shrine) Punjab police officials sr.tid Saturday .. This provide::; enough background information for the reader to realize that the para-military activity is not t.a.ldng place in the U.S. and thus that the document is ineh-;vanl to the query.","Likewise) scores 5 and 6 act similarly to 3 and 4 for documents which do not contain a headline. \\Ve found t.his particularly important for advertisements which of ten don )t state a product or company name in the be ginning of the document) but will repeat these names nunH::rous times throughout the document."]},{"title":"Generating the summary","paragraphs":["Once ;-;entcnces have been selectE:~d) they arc presented iu the order they occurred in the document. Pro nouns which do not have a referent in the previous sen tence of the summary a.re filled with a more descriptive string whenever a referent can be determined. If space is of c:oncern) prepositional phrases attached to nouns (which are not nominalizationsL appositives) conjoined noun phrases and relative clauses are removed) provided th<~y contain no tokens associated with the query or the headline. Since determining pronoun referents and the selection of clauses for removal are subject to errors, filled pronouns arc placed in square brackets and re moved clauses are replaced with an ellipsis to indicate l.o the reader that the original text has been modified."]},{"title":"Example summary","paragraphs":["An t~xa.mple summary which demonstrates many of the features of our systen1 appears below. It has been con-"]},{"title":"4","paragraphs":["strained to be approxirna.tely 10% of the original docu ment length) so it is not representative of the summaries used in the evaluation) but it contains examples of the of both pronoun filling and cl<wsc deletion.","The last sentence in the summary was selected first because the tokens ('death))) ({sentence')) a kill))) and \"term\" were associated with the norninalization ((pun ishmenf). The stranded pronoun \"ie\\ has also been filled. Sentence 2 was selected next because of the match-up between the verb ((is)) and the object ((deter rene) in the document and the query. Finally) the first sentence was chosen because th(~re is another mention of the prison name ((Marion)) in the document. This summary differs from the one generated when the 10% length constraint is not imposed) because sonw higher ranked sentenees were passed over since their inclusion would have exceeded the length restriction. Query: Is there data ava.ila.ble to sugg(~tit that cap ital punishment is a deterrent to erirne? Surnrnar-y: ((IVIarion is basically the end of the line/) Bogdan s;:.tid.","There is no deterrent to keep them from doing this again, Additionally, [the pending Senate bill] would cre ate five new death penalty offenses: murder by a federal inmate serving"]},{"title":"a.","paragraphs":["life sentence; drug king pins in a continuing criminal enterprise even if no murders occur; drug kingpins \\vho try to kill to ob struct justice; drug felons who unintentionally kill with aggravated recklessness; and people who kill with a firearm during"]},{"title":"a.","paragraphs":["violent ... crime."]},{"title":"Evaluation","paragraphs":["In order to evaluate our summarization algorithm) we selected 10 unseen queries from tl-w Text REtrieval Con ference (TREC) document collection. Summaries were generated for 200 documents) 20 per query) and asses sors2 were asked to makn relevance judgments based on the summaries. A document was considered relevant if it contained the information requested in the query or if the a..ssessor believed t.hat the full doeument would likely contain this information. Tlw relevance judgments were then com pared to those made by the TREC assessors using the full documeut. This comparison places a sum mary in one of the following categories: e a"]},{"title":"=","paragraphs":["judged relevant, full document. is relevant s b"]},{"title":"=","paragraphs":["judged relevant) full document is irwlevant","e c = judged irrelevo.J1t) full clocurnent is relevant","2","Each a.uthor served as an assessor making judgments for","100 documents across 10 queries. ., d :::: judged irrelevant, full docurncnt iH irrelevant Fr('cision, recall, and a.cc:uracy are thc:n computed as fullows:"]},{"title":"pn;cision","paragraphs":["= a/ (a+ b) recall"]},{"title":"=","paragraphs":["a/ ( a·h) accuracy~' (a·Hl)/(a·i·b+c+cl)","CoiUJWCHsion is computed over the mnnber of uon \\rltit.cspace characters in the summa.ry and the original docunwnL. Here compression is defined as the perc:ent ilgl' of the docmnent that was not included in the sum nJar.y:","co1npressioll ::-:: (lc.n.iJih,~,\"\"\"'~\" 1 --1-r:ngUr,\"\"'\"'\"\"\")","l (.\"II","r;tha oc·\" \"'\"\" t Tlw n~sult..c..; from our experirnent are shown in the fol lowing table:"]},{"title":"~l5:C:Cision-~=:j=82,s%+- 101/(101+21) ·j ' Il~<c~l-~l,-r-~?~'YC)±· _1(~1lE9~.±.~2L __ . I","paragraphs":["c:()lllJl'::'':;Sion r_8_2,~ (7046~(i:_l_212722[~9'!Q§Q"]},{"title":"i \\cc\\l)_<rcy··-······ 75,9'!/o ____ (ll)1::t_492l?OQ. __ _","paragraphs":[".·\\ S(~coud evaluatiou on 910 docum.ent.s was performed fur"]},{"title":"['1].","paragraphs":["These: resnlts superficially appear significantly \\\\·orsc-~ than those from the initial evaluation however a JJJOn~ careful analy~is (provid<·~d ill the discussion sec t ion) shows that they are in fact. similar Lo the results of Llw previous evaluation. [ l'rc•crsrorr"]},{"title":"~so 3% -322/(:i22+79) I","paragraphs":["Hc·c·cl!l - --"]},{"title":"!i7 G% :J2f;(ml","paragraphs":["2:J7)"]},{"title":"I ~Cc7tllj)l(~Swn -8:3 0% _ _,_ ,_","paragraphs":[",\\~Ill~~y~~--·"]},{"title":"GS 3% -(32Z+272)/9l0 Discussion","paragraphs":["\\\\'(' view the results of the flrst evaluation as promising iu !.hat. they compare favorably \\vith inter-assessor con :---:istcncy using the entire document. [1 1] reports unani JJHHlS relevance judgments by three assessors for 71.7%"]},{"title":"or","paragraphs":["Llw documents. Interpolating this figure to two as :-;(-'SSors yields an 80.1% agreement figure. Using sum lllari(-~S which on average are only 17.2% of the original (l(J(:\\llli<-:nt1 our assessors rnatchwl t.hc 'l'H.EC a,c..;sessors for 7D.O% of the documents.","The second evaluation yielded a nmch lower recall hgun-' while precision remained compa.rablc. This) hmv ('\\\"('L is also the case when the sa.nw assessors judgmcmts on the full docmncnts are compared to those of the TH.EC assessors. These results are as follows:","Precision 83.5%","r-l~ccarr·--"]},{"title":"o'f5% -167 7(167+33)","paragraphs":["_1_6ij_Q62.±~QL","Compression 100.0% ·Acc;rracy·-·"]},{"title":"69.3\"'%', +-.\"(lfi7IT24j/42o","paragraphs":["L__~·C..",".... __ .L_.:.:..:..:.c...J..","\\Ve viC\\01.-' these results as favorabk a::; well since our ac","cnra.ey is 65.3% using 17.0% of the docurnent on average"]},{"title":"5","paragraphs":["compared to G9.3% accuracy using the entire clocunwnt . The discrepancy between the two evaluations appears to be based on the assessors in the second evaluation using a stricter criteria for relevance than that used by the previous evaluation's assessors or the TH.EC asses sors.","It was noted after the first evaluation that difienmt criteria for relevance acconnted for some of the disagree ment between our assessors and t.hc THEC assessors. lvL-my documents considered relevant wen: marked as ir relevant due to different uot.iow.; of relevance aJHl not be cause the snrnrnc1ry failed to provide material on which to base a correct. decision. These difficulties only hin der the evaluation of a summat\")l system a.ncl not its use in an application, since a user will have a clear idea. of his or her intentions when determining"]},{"title":"a.","paragraphs":["document's relevance.","As we mentioned previously: our approach has been to ba.la.nce methods of n~l<_lting Lbe query to sentences in the document. The uearly 100% reca-ll of the dry-run summaries encoura .. gecl us) and we even used the output of those sumrna.ries to provide a tcst-hed for evaluating our summarie::>. Although we never actively sought to emulate aspects of other syst.ellls directly) our final algo rithm does share smne basic id(~as aud a.pproacher-:; from those~ systerns. Some of the similarities are listed below:"]},{"title":"In [3L","paragraphs":["they eliminate redunclnnt iuforma.tion from summaries by dassifying sent(:mce.s a.ccording to Max imal MarginaJ RelevaJlCe (IVll\\IIH.). lVIMH. ra.uks t.(::xt clninks according to their dissimilarity to one another. Sun,unaries ean then be produced with sentences that an-: maximally dissimilar1 tll(-~relJy increasing the likeli hood that distinguishing iufonnation will be in the sum mary. One GU1 view our coverage requirement for terms in the query as an a.t.tempt to pick clissimila.r r-;entences from the document. Instead of IVUVIH. 1 we ur-;e t.he fact that a sentence which does not contain redundantly re ferring phrases t.o the query is mon: highly ranked than a sentence that docs.","Our individual t>entc:nce scoring algorithm shares some properties with [10]. Their approach includes scores for anaphoric density) string equivalence 1vith the title or headline of a document, and position of the sen tence in the document. I-Imvever, we do not. t.akc ad vantage of overt cues for summa.ry sf;nt.c.nces) such as :in summa.ry) or 'in conclusion)) nor do we use tempo ral information in generating a sum1m1ry.","Like many systems) we do a form of word expan sion in atternpting to n~la.tc the query to the document. However) th(-~ fact that 1vc restrict expansion to proper nouns and verbs and their nominalihations is notable. \\Ve found this limited set of c:xpan::;ion::; re::;tricts the re httions between the t.ext and the query well and a.lso fits within the framework of part-whole relation::; in coref <:rence. \\Ve did not ccmsider part-whole relations for common nouns, because in practice we have not had vc~ry good results limiting over--generation in that do nwin."]},{"title":"Conclusions and Future Work","paragraphs":["\\\\Te have developed and test(~d a query-sensitive text summarization system that is nearly as effective as full text doeu1nents for determining whether a doc:ument is rcl<-~vant to the query. The system uses a limited class of cord\"ercncc-based relations between the query and the document to select sentences which represent instanti ations of entities, events) or concepts articulated in the quer_y. The algorithm is implemented within the CAMP NLP systern and utilizes linguistic generalizations like pa.rt-of-spt~ech, parsing and predicate-argument struc ture,",". \\n is:·me in evaluating our syster:n is that the input data ha~ been selected by an information retrieval cn g,illt:. As such) we have no data. on how well our sum Juaries would work on relevant documents that the in fonlla.tion retricva.l engine fails to retrieve. These cn ginc~s tend to select documents based on string matching a.ud we have shown tha.t our summarization technology do(~S an excellent job of ~ummarizing them. However) U1c information retrieval engine may be acting as an ad \\'<llltag(-~Ous filt<-:r on the space of documents. It would ])(' iut.<~resting to do experiments on relevr_lllt documents I ll<lL coutain very few string matches 'vith the query.","fu thC' future we hopn to improve the accuracy of the r·_nn'fe.r<'JJCC'. relations. Specifically, we \\vill focus on the rct'op.;nition of events which we believe are very impor~ L<tlJL Lo a large class of queries."]},{"title":"Acknowledgments","paragraphs":["\\V<' would like to acknowledge three anonymous review ('1'~ for Llwir helpful comments. and Tonia Bleam for pmviding asse~sments during the development of thiB syst(~lJ.l."]},{"title":"References [I]","paragraphs":["Breck Baldwin. CogNIAC: High precision coref enmce with limited knowledge and linguistie re sources. In Pmccedings of the ACL WoTkshop on Openthono..l F'acf;ors in Pnzct?:cal, Rolmst Anaphom n:solni,ion for UnTesf,Tic.ted Texts) pages 38---45) iVJ.a.drid) Spain) .June 1997.","[2] Breck Baldwin, Christine Doran, .Jeffrey C. Rey ua.r) I\\!Jicha.el Niv) B. Srinivas) and iVIark Wasson. EAGLE: An extensible architecture for general lin guistic engineering. In Proceedings of RIA0~97, lVfontreal) 1997."]},{"title":"6","paragraphs":["[3] Michael Bett and .J adc Goldstein. Automated query-relevant document summarization. In"]},{"title":"Pm","paragraphs":["ceedings of Tipster· Te:Dt Phase III 12-Month Work shop, 1997."]},{"title":"[4]","paragraphs":["Michael Chrzanowski, Therese Firmin, Lynette Hirsclunan) David House, Inderjec\\L Nia.ni) Leo Obrst) Sara Shelton) Beth Sundheim1 and San dra Wagner. (SUMMAC) call for participa tion. http:/ j www. tipster.org/ summca.ll.htm, Jan nary 1998."]},{"title":"[5]","paragraphs":["Michael John Collins. A New Statistical Parser Based on Digram Lexical Dependencies. In Pro ceedings of the 34th Anmwl Meeting of the ACL, 1996"]},{"title":"[6]","paragraphs":["Therese Hand. Tipster summarization evaluation taslcdry-run evaluation results. In Proceedings of TipsteT Te:ct Phose III 12-Month Wor-kshop, !997 ."]},{"title":"[7]","paragraphs":["Daniel"]},{"title":"Karp)","paragraphs":["Yves Schabes1 Martin Zaidel, and Dania Egedi. A freely available wide eovcrage morphological analyzer for english. In P1-occedings of the 15th lnternoJional Confen;nr;c on Cumpnta~ t,ional Linguistics) 1994.","[8] Ad wait Ratnaparkhi. A Maximum Entropy Part of Speech Tagger. In Eric Brill cul.d Kenneth Church) editors) Confen:nce on J-i}mpin:co,l MdJwrls -in Nat nml Langnage Process1>n,_r]) University of Pennsyl vania1 May 1.7~18 1996."]},{"title":"[9]","paragraphs":["Jdfrcy C. Il.<>ynilr and Adwait Ratna.parkhi."]},{"title":"A","paragraphs":["maximum entropy approach to identifying sen~ tence boundaries. In Proceedings of the Fifth Con ference on Applied NoJnntl Lang'ltage Processing, pages 16 19, Washington, D.C., April 1997.","[10] Tomek Strzalkowski) F~~ng Lin) .Jin \\Nang) Lang don VVhitc) and Bowden \\~lise. Natural language information retrieval and summarization. In Pro ceedings of Tipster Te.?:i Phase III 12-Month Work shop, 1997.","[11 J Ellen M. Voorhees and Donna Hannan. Overview of"]},{"title":"the","paragraphs":["fifth"]},{"title":"Text","paragraphs":["REtrieval Conference (TREC-5). In Pmccedings of the Fifth Te.xl; REtr·icval Confer ence {TREC-5}, pages I 28. NIST 500-238, 1997."]},{"title":"[12]","paragraphs":["Nina Wacholder, Yael R.avin 1 and Misook Choi. Disambiguation of proper mt.mes in text. In Pro cecdi,ngs of t.he Fifth Confenmcc o·n Applied Natu ro,l Lan,rrnage Pmccssi11.g1 l\\tlay 1997."]}]}
