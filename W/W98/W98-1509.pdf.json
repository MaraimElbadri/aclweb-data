{"sections":[{"title":"An Empirical Approach to Text Categorization based on Term Weight Learning Fumiyo Fukumoto and Yoshimi Suzukit Department of Computer Science and Media Engineering, Yamanashi University 4-3-11 Takeda, Kofu 400-8511 Japan","paragraphs":["{ fukumoto@skyc,ysuzuki©suwa t} .esi.yamanashi.a.c.jp"]},{"title":"Abstract","paragraphs":["In this paper) we propose a method for text categoriza Lion task using term weight learning. In our approach, learning is to learn true keywords from the error of clus tering results. Parameters of term weighting are then estimated so as to maximize the true keywords and min imize the other words in the text. The characteristic of our approach is that the degree of context dependency is used in order to judge whether a word in a text is a true keyvv·ord or not. The experiments using Wall Street Journal corpus demonstrate the effectiveness of the method."]},{"title":"Introduction","paragraphs":["\\~Vith increasing numbers of machine readable docti ments becoming availa.ble, an automatic text catego rization which is the classification of text with respect t.o a. set. of pre-categori;.:ed texts) has become a trend in IR and NLP studies."]},{"title":".I","paragraphs":["One of the important issues in text cHtegoriza. t.ion task is hc)\\\\1 to characteri;.:e texts whicl.1 are pre categorized. There are at least two stat.lstica.l ap proaches t.o cope with the issue) i.e. statistical approach that relies mainly on ( 1) surface information of words in texts, and (2.) senwntic infonnation of \\VOrds in texts.","Statistical approach based on surface information of words has been widely studied in"]},{"title":"IR.","paragraphs":["One represen tative is a vector model. In this model, each text. is represented by a vector, i.e. every text which should be classified a.nd texts which are pre-categorized in a training phase are characterized by a vector, each di mension of which is associated with a specific word in Lcxts) and every coordinate of the text is represented by term weighting. Then) some similarity measure is used and the text is assigned to the most sema.n tica.lly similar set of texts which are pre-ca.t.egori;.:ed. Term weighting method is widely studied [Luhn 1958], [Salton and Yang1973], [Salton\\988], [.Jones1973]. Guthrie a.nd Yuasa. used word frequencies for weight ing [Guthrie and Walkerl994], [Yuasa et al.l995], and Tokunaga used weighted inverse document frequency (WIDF) which is a word frequency within the docu ment divided by its frequency throughout the entire"]},{"title":"71","paragraphs":["document collection [Tokunaga and Iwayama1994].","The other approach is based on a probabilistic model. This approach is widely used, since it has solid formal grounding in probability theory. I way am a et. al. proposed a probabilistic rnodel called Sin gle mndom Variable with Multiple Values (SVMV) [Iwayama and Tokunaga\\994]. They reported that t.he result of their experiment using"]},{"title":"S VM V","paragraphs":["was better than","other probabilistic models; Component Theory(CT)","[Kwok\\989], Probabilistic Relevance Weighting(PRW)","[Robertson and Jones\\976] and Retrieval with Proba","bilistic Inde,;ing(RI'I) [Fuhr!989] in the task of catego","rizing news articles from the Wall Street. Journal( W8J).","Most previous approaches seem to show the effect in en","tirely difl'erent texts, such as 'weather forecasts', 'medi","cal reports) and 'computer manuals). Because each dif","ferent text is characterized by a large number of words which appear frequently in one text, but. appear sel","dom in other texts. However) in some texts from the","same domain such as 'weather forecasts') one encoun","terS quite a large number of words which appear fre","quently over texts. Therefore, how to characterize every","text is a serious problem in such the restricted subject domain. The other statistical approach is based on seman tic information of words. The technique developed by VVa.lker copes with the discrimination of polysemy [Walker and Amslcrl986]. The basic idea of his ap proach is that to disambiguate word-senses in articles might affect Lhe accuracy of context dependent classi fication, since the meaning of a. word characterizes the domain in which it is used. He used the semantic codes of the Longman Dictionary of Contemporary English to determine the subject domain for a set of texts. For a given t.ext, each word is checked against the dictio nary t.o determine the semantic codes associated with it.."]},{"title":"By","paragraphs":["accumulating the frequencies for these senses and then ordering the list of categories in terms of fre quency) the subject matter of the text can be identified. However, Fukumoto reported that when using disam biguated word-senses within texts ( 49 different texts) each of which consists of 3,500 sentences) were up to only 7.5% as those when using word frequencies for weighting, since in a restricted subject domain such as Hia.l/ St.reet Journal, lots of nouns in articles were used with the same sense. As a result, the results of word sense disambiguation did not strongly contribute to an accurate classification (Fukumoto and Suzuki1996J.","Blosseville et. al. proposed an automated method of classifying research project descriptions using tex tual and non-textual information associated with the projects. Textual information is processed by two meth ods of analysis: a NL analysis followed by a statisti cal analysis. Non-textual information is processed by a symbolic learning technique. T'he results using two classification sets showed that"]},{"title":"90.G%","paragraphs":["for"]},{"title":"7","paragraphs":["classes and 70.9% for 28 classes could be classified correctly. Their method, however, requires a great effort, since the in put data are not raw textual data, but rather the result of deep synta.ctic and semantic analysis of textual data.","In this paper, we propose an a!Lernative rnethod for an automatic classification, i.e. a. method for term weight learning which is used to characterize texts. In our approach, learning is to learn true keywords from the error of clustering results. Parameters of term weighting are then estimated so as to maximize the true keywords and minimize the other words in the text. The characteristic of our approach is that the degree of con text dependency is used in order t.o judge whether a word in a text is a true keyword or not. \\Ve applied our technique to the task of categorizing news articles from 1989 VVSJ in order to see how our method can be used effectively to classify each text into a. suitable category.","In the following sect.ions1 we first present a basic idea of context dependency, and describe how to recognize keywords. Next, we describe methods for term \\Veight lca.rnillg and for classifying texts using term weight. leaming. Then, we present a method for categoriza tion task. Finally, we report on some experiments tn order to show the effect of the method."]},{"title":"Training the Data Recognition of Keywords In","paragraphs":["our approach, learning is to learn true keyv·wrds from the error of clustering results. The basic idea of our tenn weight learning is to use the fact that whether a word is a key in a text or not depends on the domain to which the text belongs.","\\Ve will focus on the WSJ corpus. Let 'stake' be a. keyword and 'today' not be a keyword in the text (art.icle). If the text belongs l.o a restrict.ed subjeet domain, such a..\"l 'Economic news', there are other texts which are related to the text. Therefore, the frequency of 'stake) and 'today' in other texts are similar to each other. Let us further consider a broad coverage domain such as a.ll texts of the WS'J; i.e. the text containing the words 'stake' and 'today' belong::; to the YVSJ which consists of different subject domains such as 'Economic ne,vs' or (International news'. 'Today' should appear frequently with every text. even in such a .. domain, while 'stake' should not. Our technique for recognition of"]},{"title":"72","paragraphs":["true keywords explicitly exploits this feature of context dependency of word: how strongly a. word is related to a given context?","Like Luhn's assumption of keywords, our method is based on the fact that a writer normally repeats cer tain words (keywords) as he advances or varies his ar guments and as he elaborates on an aspect of a subject [Luhn1958]. Figure 1 shows t.he structure of the WSJ corpus. Economic International news news","xxxx yyyy Text"]},{"title":"••• [ZJ [1 Q","paragraphs":["0"]},{"title":". -~-------------~~ ~~~--------~ ...","paragraphs":["o: Keyword Figure 1: The structure of the WSJ corpus"]},{"title":"•••","paragraphs":["In Figure 1, (xxxx' and 'yyyy' shows a title name of a text. which belongs to the category, 'Economic news' and 'International news', respectively.","VVe introduce a degree of context dependency into the structure of t.he WSJ corpus shown in Figure 1 in order to recognize keywords. A degree of context de pendency is a measure showing how strongly each word is related to a particular paragraph or text. In Figure 1, let"]},{"title":"'0'","paragraphs":["be a keyword in the text 'xxxx'. According to Luhn 's assumption,"]},{"title":"'0'","paragraphs":["frequently appears through out paragraphs. Therefore, the deviation value of"]},{"title":"'0'","paragraphs":["in the pa.ragraph is sma.ll. On the other hand, the de viation value of"]},{"title":"'0'","paragraphs":["in the text is larger than that of the paragraph, since in texts,"]},{"title":"'0'","paragraphs":["appears in the par ticular text, 'xxxx'. \\Ve extracted keywords using t.his feature of the degree of context dependency. In Figure 1, if a word is a keyword in a. given text., it satisfies that. the deviation value of a word in the paragraph is smaller than that. of the text, a.nd is shown in formula (1) [Fukumoto et aU997]. where,"]},{"title":"p2","paragraphs":["X wj"]},{"title":"<","paragraphs":["\"'\" ( jJ2 ) L...-j.::::l X wj - iiw 1D ( -"]},{"title":")'","paragraphs":[".Twj -- Vwj Vwj"]},{"title":"( 1)","paragraphs":["(2) (3)"]},{"title":"(4)","paragraphs":["In formula"]},{"title":"OL","paragraphs":["w of xP~ and x'l~~ is a word in para graph and text, respectively. xP"]},{"title":"1","paragraphs":["~ and x'l~, is the devi ation value of a set of paragraph and text, respectively. In formula (2), n is the number of paragraphs, and iiw is the mean value of the total frequency of word w in paragraphs which consist of n. In formula (3), Xwj is the frequency of word w in the j-th paragraph. Vwj in formula (3) is shown iu ( 4) where m is t.he number of different words and n is the number of paragraphs 1","."]},{"title":"Term Weight Learning","paragraphs":["In our method, non-overlapping group average cluster ing algorithm based on frequency-based term weight ing is applied to every text which is pre-categorized. If a text which could not be clustered correctly in the process of clustering, then, recognition of keywords is perfonned.","Let I~ and"]},{"title":"Tc'","paragraphs":["be Lhe same category and Ty not be the same one with"]},{"title":"Tx.","paragraphs":["Let also"]},{"title":"T.r:","paragraphs":["and 7~ be judged to be the same category incorrectly. Recognition of keywords is shown in Figure 2. In Figure 2, (a-1) and (b-1) are t.he procedures t.o ex tract keywords, and (a-2) and (b-2) are the procedures to extract other words. In (a), for example, when w is judged to be a keyword, term weighting of w is ct x J(w), where f(w) is a frequency of w. On t.he other hand, when w is judged not to be a keyword, Lerrn weighting of w is (3 x"]},{"title":"f(","paragraphs":["w ). Here, c.t and (3 is a variable","which is concerned with a. true key\\vorcl and the other","') xP2","words, respectively-."]},{"title":"In xr1,· < I","paragraphs":["shown in ~''fgure 2, the texts are 1·~ and 7~."]},{"title":"Clustering Texts based on Term Weight Learning","paragraphs":["The clustering algorithm for pre-categorization of texts is shown in Figure 3. As shown in Figure"]},{"title":"3,","paragraphs":["the algorit.hrn is composed","of three procedures: Make-Initial-Cluster-Set,","Apply-Clustering and Tcnn-Weight-Learning3",".","l. Make-Initial-Cluster-Set The procedure Make-Initial-Cluster-Set produces"]},{"title":"all","paragraphs":["possible pairs of texts in the input with their sim ilarity values. Firstly, every text which is the pre categorization of texts is represented by a. vector. Us ing a. term weighting method, every text vwuld be 1 ln formulae {2), {3) and (4), we ca.n repla.ce xP,~ with","x'l~,. 2 fn the experiment, two procedures arc performed alter","natively; (1) increment value of n is set to 0.001 and"]},{"title":"f3","paragraphs":["is a","constant value, (2) decrease value of ,8 is set to 0.001 and n","is a constant value. 3 The largest value of n is cmpirica.lly det-ermined."]},{"title":"73","paragraphs":["begin do Make-Initial-Cluster-Set for i := 1 to m(l~-l) do","do Apply-Clustering","if"]},{"title":"T.\"t·","paragraphs":["such that]~. does not belong to","the correct cluster","then do Term-Weight-Learning","do Make-Initial-Cluster-Set","endJf endJOr","end i := 1 Figure 3: Flow of t.he algorithm represented by a vector of the form"]},{"title":"(5)","paragraphs":["where :r is the number of nouns in a text and x·ij is a frequency with which t.he noun"]},{"title":"xj","paragraphs":["appears in text"]},{"title":"7i.","paragraphs":["Given a vector representation of texts T1, · ·, 1·~n (where rn is the number of texts) as in formula"]},{"title":"(5),","paragraphs":["a similarity between two texts 7i. and"]},{"title":"1j","paragraphs":["would be ob tained by using formula"]},{"title":"(6).","paragraphs":["The sim.ila.rity between"]},{"title":"1\"i","paragraphs":["and 7j is measured by the inner product of their normalized vectors and is defined as follows:"]},{"title":"S'im(:li, 7j) (6)","paragraphs":["The greater the value of"]},{"title":"S'im('Ti,","paragraphs":["'lj) is, the more sim ilar Ti and 7j. For texts T1, · · ·, 'J'm-1 and T'm, we calculate Lhe similarity value of all possible pairs of tbxt.s. 'I'he result is a. list of pairs which arc sorted in the descending order of their similarity values. 'The li~t. is called ICS (Initial Cluster Set). In the FOR loop in the algorithm, a pair of texts is retrieved from"]},{"title":"ICS,","paragraphs":["one at each iteration, and passed to the next two procedures.","2. Apply-Clustering ln this procedure, the clustering algorithm is applied to t.he sets and produces a set of clusters, which are ordered in the descending order of their seman tic similarity values. We adopted non-overlapping group average method in our clustering technique (.Jardine and Sibsonl968]. Let 1~ and"]},{"title":"T,,","paragraphs":["be the same category"]},{"title":"and Ty","paragraphs":["not be the same one with"]},{"title":"T:t..","paragraphs":["Let also"]},{"title":"Tx","paragraphs":["and 'I~ be judged to be the same category incorrectly. The next procedure, Tertu Weight-Learning is applied to 7~, 7~, and 7~.",":3. T(~l'ln- Weight-Learning For T_.,_.,"]},{"title":"'J'x,","paragraphs":["and"]},{"title":"Ty (Ty'),","paragraphs":["recognition of key,vorcls","shown in Figure 2 is applied, and every text would","be represented by a vector of the form"]},{"title":"1:: (7)","paragraphs":["begin (a) if]~, such that]~, and 1~ be the same category exists","for all w such that"]},{"title":"Tr","paragraphs":["n I~ 'f . fi xP' 1 d . I I f 7' 7' T T 1 w sat.1s es ~"]},{"title":"<","paragraphs":["an· tv IS t. tc e cment. o x n x' or y n y'","(a.-1) then w is judged to be a. keyword and paruneter of term weighting of w is set too: (I <a< 10)","P'","else if w does not satisfy ~"]},{"title":"1","paragraphs":[",. ·"]},{"title":"<","paragraphs":["1 and w is the element of Tx n T~., or T~ n 'J~, X w","(a-2) then w is judged not t.o be a keyword and parameter of term weighting of w is set to /3 (0 < {3"]},{"title":"<","paragraphs":["1) end_if","end_for","{b) else","for all w such that l'x n 1;",".p2 if w satisfies ~"]},{"title":"72","paragraphs":["'"]},{"title":"<","paragraphs":["1 and w is the clement of"]},{"title":"1'x","paragraphs":["n 1:.,","X w","(b-1) tlHm w is judged to be a. keyword and parameter of terrn weighting of m is set to cr (1"]},{"title":"<","paragraphs":["n·"]},{"title":"<","paragraphs":["10) else if w does not satisfv"]},{"title":"~7","paragraphs":["1"]},{"title":"~.","paragraphs":["2"]},{"title":"<","paragraphs":["I and w is the element of"]},{"title":"1~","paragraphs":["n"]},{"title":"7~.~","paragraphs":["• X u . (b-2) then w is judged not to be a keyword and parameter of term weighting of w is set to (3 (0"]},{"title":"<","paragraphs":["{J"]},{"title":"<","paragraphs":["!)","end_if end_for","end _if","end Figure 2: Recognition of key,.vords \\vhcre :r is the number of nouns in a. text and XIj IS as follO\\vs;"]},{"title":"l","paragraphs":["0 x~ docs not appear ]J')"]},{"title":"Ti","paragraphs":["J ct X"]},{"title":"f(Xj) X'","paragraphs":["is a keyword and / j"]},{"title":"x:j","paragraphs":["appears lll"]},{"title":"1i f!","paragraphs":["X"]},{"title":"f(Xj) X j","paragraphs":["is not a keyword and appears m"]},{"title":"1i","paragraphs":["where j(Xj) is a frcqueucy with which t.bc noun Xj appears in text"]},{"title":"Ti.","paragraphs":["(1' and j3 are cst.irnat.ed so as to maximize S'im('l~, Tr:') ~t~ld ,-~~'in;(?;,, 7~')_, among all possible pairs of texts, 1~:, 1x', 1y and .ly'· Make-Initial-Cluster-Set where every text except T~., T~·', I~ and 7~, would be represented by a vector of the forrn shovn1 in formula (5) and 'I~, 1~:', ~[~ and '1-~, would be represented by a vector shown in formula (7), is applied to an arbitrary pa.ir in texts, and t.he procedures a.re repeated.","If the newly obtained cluster contains all the texts in input., the whole process terminates."]},{"title":"Category Assignment","paragraphs":["For the training data, 'I'1 , · · · 1 l~n (where rn is the num ber of texts), clustering algorithm which is shown in Figure 3 is applied) and a.ll texts arc c.lassified into a. suitable category. Given a. new text"]},{"title":"T","paragraphs":["which should be classified,"]},{"title":"T","paragraphs":["would be represented by a term vec tor of the fonn shown in formula (5). The similarities between"]},{"title":"T","paragraphs":["and each text of the training data are ca.leu l.::tted by using formula (6). Then, T1, · · ·, 1;n are sorted in the descending order of their similarity values. T is"]},{"title":"74","paragraphs":["assigned to the categories ''vhich are assigned to J}: · · ·, 'I~n with the descending order of their similarity values.","Le.wis proposed the proport-ional assignm.cnt sfnd cgy based on the probabilistic ranking principle [LewisHl92]. Ea.ch category is assigned to its top scor-· ing texts in proportion to the number of times the cat egory was assigned in the training data. For example, a. category assigned to 2% of the training Lcxt.s would be assigned to the top scoring 0.2% of the test. texts"]},{"title":"if","paragraphs":["the proportionality constant was 0.1, or to 10% of t.he test texts if the proportionality constant w<:ts 5.0. Vfe used this strategy for eva.luaLion."]},{"title":"Experiments","paragraphs":["VVe have conducted two experiments to examine the ef fect of our method. The first experiment, Text Cate gorization Experirnont shows hO\\v the results of term \\veight learning can be used effectively to categorize new texts. The second experiment, Cmnparison to Other Mcthods 1 we applied chi-sq·uarc method as a vector m-odel and lwaycuna's"]},{"title":"SVMVas","paragraphs":["a probabilistic m.odel to classify Lcxts [lwayama and Tokunaga.1994], and com pared Lhern with our method."]},{"title":"Data","paragraphs":["The training data we have used is 1989 Wall Street Jo·urnal ( WSJ) in ACL/DCI CD-ROM which consists of 12,380 texts [Liberm<ml991]. The WS'J are indexed \\Vith 78 categories. Texts having no category \\Vere ex cluded. 8,907 texts remained. Each having 1.94 cate gories on the average. The largest. category is wrender Offers, Mergers: Acquisitions (TNtvl)\" which encom passed 2,475 texts; the smallest one i~ \"H.ubber (H.UBY' 1 assigned to only 2 texts. On the average, one category is assigned to 443 texts. A II 8,907 texts were tagged by the tagger [!3rill1992]. We used nouns in the texts. Inflected forms of the same words are treated as single units. For example, 'share' and 'shares' arc treated as the same unit. We divided 8,907 t.ext.s into two sets; one for training( 4,454 texts), and the other for testing( 4,453 texts)."]},{"title":"Text Categorization Experiment","paragraphs":["Term weight learning is applied to 4,454 texts, and each word in the texts was weighted. For the result, we ap~ plied category assignment to the 4,453 test data. The best known measures for evaluating text categorization models are recall and precision, calculated by the fol lowing equations [Lewis1992]. Recall = Precision t.he number of categories that are correctly assigned to texts the number of categories that should be assigned to texts the number of categories that are correctly assigned to texts the number of categories that are assigned to texts Note that. recall and precision have somewhat mutually exclusive characteristics. To raise the recall value, one can simply assign many categories to each text. How ever, this leads to a degradation in precision, i.e. almost all the assigned categories are false. A bTeakevcn point might be used to summarize the balance between recall and precision, the point at which they are equal. VVe calculated breakeven points in the experiment. There sult of Text Categorization Experiznent. i,ls shmvn in Table 1. ·1","•","Table 1· The result of the experiment","Category Training data 'fest da.ta Breakeven 10 2,399 1A57 0 80 20"]},{"title":":J","paragraphs":[",893 2,452 0.77 30 5,178 3,508 0.77 10 5,828 3,991 0.76 50 7 ,:l44 4,998 0.77 60 8,475 5,976 0.76 70 11,489 6,148 0.75 78"]},{"title":"!","paragraphs":["1 ,649 7,305 0.75 In Table 1, <Category' shows the number of categories which are extracted at random. 'Training data) shows the number of training texts which are included in each category shown in the 'Category'. iv1ost of the texts in"]},{"title":"WS'J","paragraphs":["are classiHed into more than one category. Each having 1.94 categories on the average. 'Test data' in 'fable 1 shows the total nurnber of the texts which is classified into 'Category'."]},{"title":"75 Comparison to Other Methods","paragraphs":["Vi/e reported on the results of our method compar ing with other two methods, i.e. chi-square value for term weighting and Single random VaTiable with Multi ple Val1tes(SVMV) which is proposed by lwayama et.al. [Iwayama and Tokunaga1994].","The reason why We compared our method"]},{"title":"with","paragraphs":["chi square method is the following two points: • Chi-square value is one of the conventional text clas","sification [lwadera and Kikui1997]. e In our method, chi-square value is used in order to","introduce a degree of context dependency.","Jwa.yama ct. a.!. proposed a new probabilistic model for text categorization called SVMV. The probability that. the document dis classified into the category c IS shown in formula (8). P(c"]},{"title":"I","paragraphs":["d) = P(c) \"\\' P(T"]},{"title":"=","paragraphs":["t,"]},{"title":"I","paragraphs":["c)P(T"]},{"title":"=","paragraphs":["t,"]},{"title":"I","paragraphs":["d) (S)"]},{"title":"L-","paragraphs":["P(T- t,)"]},{"title":"'·","paragraphs":["P(T"]},{"title":"=","paragraphs":["i;"]},{"title":"I","paragraphs":["c)"]},{"title":"=","paragraphs":["!{v~+: NC; is the ft'equency of the term ti in the category c, and NC is the total frequency of terms in c. P(T"]},{"title":"= t, I","paragraphs":["d)"]},{"title":"= ':/J, :","paragraphs":["N"]},{"title":"n,","paragraphs":["is the ft'equency of the term ti in the document d, and N D is the -~ota! frequenc~ of t~rr~1s in d. 1'(1"]},{"title":"= ti) = 'it'","paragraphs":["N; IS the frequency of the term ti in the given training documents, and N is the total frequency of terms in the training documents."]},{"title":"P( c) ::::: lJf: De","paragraphs":["is the frequency of documents that is categorized to c in the given training documents, and D is the frequency of docu ments in the training documents. They reported that in their experiment using"]},{"title":"VVSJ","paragraphs":["1 the result of the breakeven points of TF•IDF which was proposed by Salton et. a.l. was 0.48, while the result of SVMV was 0.6:l. Furthermore, their method is similar to our technique when the following two points are considered: • Text categorization is defined as the classification of","texts with respect to a set of pre-categorized texts. • Category assignment is based on surface information","of words in texts. Therefore, we implemented Iwayama ct. al.'s method and compared it with our method. The results are shown in Figure 4. Figure 4 shows the recall/precision trade off for each rnethod with proportional assignment strategy. 'learn ing', 'SVMV' and"]},{"title":"'x","paragraphs":["2 ' shows the result of our method,","I wayama's method and"]},{"title":"x","paragraphs":["2","value, respectively. Table 2 lists the breakeven points for each method. All the breakeven points were obtained when proportionality constant \\vas about 1.0. Precision 0.9 0.8 0.7 0.6 learning 0.5 0.4 0.3 SVMV 0.2"]},{"title":"x'","paragraphs":["0.1"]},{"title":"'-+-1f-+--!-+-f-+--+-+-.,_","paragraphs":["Recall","0","0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Figure 4: The result of comparative experiment"]},{"title":"IViCChod","paragraphs":["Breakeven Points","learning 0.75","SVMV 0.61",". x 2","__ J._ _ __:o~.:::5f~i __ _"]},{"title":"Discussion Text Categorization Experiment","paragraphs":["Effectiveness of the Method According to Table ll there are 7,305 test data in all which are classified into 78 categories, and the value of the brcakcven points was 0.75. Comparing the ratios of correct judgments \\vhen the number of categories is large with when the number of it is srnall, the correctness of the former was higher in some cases. For example, when the number of categories was 10, the correct ratio was 0.76, \\vhile the nurnber of cakgories was 50) the correct ratio was 0. 77. This shows that our method can be used effec tively to characterize each text without depending on the number of categories.","Table 3 shows the first top five oft. he highest weighted value of 12 categories \\vhich were selected from 78 cat egories at random .. In Table 3, (VVord' shows the extracted words, and 'VVV shows its weighted value. 12 categories which are used in Table 3 arc shown in 'Table 1. According to Table 3, our technique for t.erm weight learning is effective, though there are sorne nouns judged highly weighted but our intuition cannot explain why. For example, (general' in 'FOD' is not a true key word in our intuition."]},{"title":"76","paragraphs":["AIR: BilK: FOD: E:NV:"]},{"title":"E:CO: DIV:","paragraphs":["Table 4: The category name Airlines Buy backs Food products Environment Economic news Dividends ARO: Aerospace BNK: Banks STK: Stock market"]},{"title":"ME:D:","paragraphs":["Media PIP:"]},{"title":"CPR:","paragraphs":["Pipeline Computers Problem of the Method The test data which was the worst result, was the data which should be classified into 'STK'. There were 499 test data which should be classified into 'STK'. Of these, !59 data (32% in all) be judged to classify into 'BBK', incorrectly. According to Table 3, the first top three \\Vords in 'BBK' and those of 'STK' are the same, and the weighted values of these words of 'BBK' are higher than those of 'STK'. 'BilK' and 'STK are semantically similar with each other and it is difficult to distinct even for a hurnan. Therefore, in this case, there are limitations to our method using term ¥.'eight. learning."]},{"title":"Comparison to Other Methods","paragraphs":["(1)"]},{"title":"x","paragraphs":["2","method and our method Table 2 shows","that the breakevcn points using our method \\vas"]},{"title":"0.75","paragraphs":["while"]},{"title":"x","paragraphs":["2","was 0.56. Table 5 shows the first. top five of","the highest weighted value of 12 categories using"]},{"title":"x","paragraphs":["2 method. According to Table 5, every noun except 'devon' and 'hadson' in 'BBK' and 'transcanada' and 'westcoast' in 'PIP' are correctly weighted as keywmds in every categories. On the other hand, t.he test data which was the worst. result, \\Vas the same data as the result using our mdhocl, i.e. the data. which should be classified into 'STK'. According t.o Table 5, three words in 'BBK' and those of 'STK' are the same, and the weighted values of these words of 'STK' are higher than those of 'STK'. As a result, it is difficult. to distinct these two categories in"]},{"title":"x","paragraphs":["2","method. One possible reason why the result of our method was","better than"]},{"title":"x","paragraphs":["2","method is that the difference between","weighting values of t.vw words in"]},{"title":"x","paragraphs":["2","was smaller than those of our method. The deviation value between an arbitrary two keywords in both met.hods is shown in Table 6. 'T'tble 6· Devhtion v·due of"]},{"title":"x","paragraphs":["2 and our rr et hods '"]},{"title":"' ' ' •","paragraphs":["Cat.. learning"]},{"title":"x'","paragraphs":["Cat. leat:ning"]},{"title":"x' AIR","paragraphs":["4.63 3.61 AIW 4.20 4.12 BllK 3.80 2.57 BNI< 2.23 2.25 FOil 2.25 2.72 STI< 1.45 2.57 ENV 2.99 2.:10"]},{"title":"MED","paragraphs":["3.89 6.10"]},{"title":"LCO","paragraphs":["4.41 2.55 PIP 3.94 :l.ll DIY 4.93 3.41"]},{"title":"CPR","paragraphs":["4.50 3.86 Table 3· The first top 5 of the highest weighted words in our method"]},{"title":"AIR","paragraphs":["ARO -BilK PIP","Wt Word \\V\"t \\Nord VVt Word Wt ] airline 522.1 aerosp<tce 118.2 share 149.0 gas 58.0 2 mile 136.5 aircrctft. 143.0 stock 71.9 pipeline 37.0 3 pa-Ssenger 120.5 au 730. company 57.2 industry 29.0 1 revenue 85.0 army 51.0 bank 51.0 foothill 24·.0","6 7. 2_-l-2j::.d:cl._.ir._-H:-_~r,~,~---'4\"':l-\". 3'-j_s:::·e::o'<.::uecr::i t.\",y=~-1._.3::·::_5_f-'oil 7. 0","BNI< FOD STK DIV No WoH'I _____ Tw·=t+'w\"Or<C'"]},{"title":"wt","paragraphs":["WOrd Vilt Word"]},{"title":"---wt·","paragraphs":["5 air 1 bank 84.0 food 110.0 company 50.'0 cent. 85.0 2 branch 32.0 fda. 27.0 share 37.7 share 70.0 3 credit 30.0 general 24.0 stock 31.7 company 60.9 4 tax 21.0 cereal 19.0 tnrdc 10.1 dividend 54.6 5 !ctter lG.O health 16.0 investment 9.4 split 46.7","ENV MED ECO CPR","-,N:co:c--l-nwiTo:crc:.dr-=---nvvcr•t:-f-\\n'Tr,-.,r_,d__::.:::_:.:::\\_ ___ I\"·V\"t-r'I\".V\"o\"r\"d-=:.=--=---cwu;--t+\"\\\\71o-r'·d'=ec.::.:__.Wt","'I--'-+-:-el::-\\\\':-,i;:'rc.o=u-::-m:cc-c:n7t-----,7\"'8:,.0;-t-'-ne'-'_,:.:,.::s ____ 281.0 gain---·----.1'2\"\"'o'.=s:-f-,'-arc:\":.;rl.::y7","t.'i-c-s--106.5 2 maquilas 19.0 d&b 108.0 tax 111.0 IBM 89.8 3 w;tter 12.0 network 69.1 c<tpit.<d 83.1 machine 69.0 4 plant 10.1 report 69.0 rate 79.5 computer 62.0","~~- L~~.~~l~-~---~---9_._1_-'--~~~!~:st.er ____i:!_:.§.~ _ CC?~.~.~~~L~-"]},{"title":"..","paragraphs":["~~·}.~:Q_ __ ?.,_Y.,st':'e:'·n.,t __ ___::4:_:8~-c 6:_ Table 5: The first top,:5f.or the highest .weighted words in"]},{"title":"x","paragraphs":["2","n .. 1e .. t.l .. w_d ..","=c=~~-"]},{"title":"---=c=-·--A","paragraphs":["flf .. -.... - ... _ ·--· \"''-","- .","----","AHO ' BBIZ P.lP"]},{"title":"N.O .. ..","paragraphs":["\\~vorcr-·-·--------w~:-"]},{"title":"·wor<F _____ \\Vt","paragraphs":["VVord-~","...... _______ \\f\\Tt· 'VVo1T--·-~~Wt","--]--"]},{"title":"ariT\\1-H'-.","paragraphs":["--~ 121"]},{"title":"o","paragraphs":["9"]},{"title":"T","paragraphs":["boeing 1886JJ-"]},{"title":"--sltal·6","paragraphs":["23 4 8 . 7 pipdine - 852i.7 - 2 ual 5268.5 force 1022.3 redemption 1902.4 foothill 59:l:l.7 3 passenger 5142.3 aircraft. 3886.7 devon 1779.4 gas 5744.4 4 pilot 4672.1 defense 2328.6 hadson 1611.1 t.ransca.nada 4948.0 5 flight 4050.8 missile 2060.7 buy-back 1616.1 wcastcoast 4191.9","BN!'{ FOD ---· -----","STK DIV","No- ·\\-\\torcr·~----~wT- Word-~----~Tt· ·---------·-·---------·-·-·-------- -----","VVord Wt \\-\\lord Wt. 1 bank 6196.4 :;pam 3148.1 stock 7265.4 dividend !0067.7 2 bnl 1517.3 food 28<18.5 sha,re ~~563.2 share 4999.4 :J bond 12]].1 cere<tl 2627.7 buy-ba.ck 23(12.0 company 3666.8 1 loan I 02-Ll cholesterol 2518.2 redemption 114.8.5 buy-back 2499.4 5 rate 890.1 cooke 2355.1 big !018.6 henley 2166.6","ENV"]},{"title":"MED ECO","paragraphs":["CPR No \\l\\1ord Wt Word Wt Word Wt \\>\\ford Wt J ozone 2650.7 magazine 4222.3 gam 2160.5 computer J,J948.8 2 cpa 2411.0 d&b :l3J3.7 democrat 1492.0 IBM 8470.1 :l <tsbestosis 2259.0 cable 2890.1 t<tx: 1410.6 softw;u-c 4709.2 4 anthrax 1183.5 network 21196.9 budget. 129·1.5 eras 3538.7 5 pollution 1165 ,;3 broadca;>ter 1_99~.:...~ ~<:_nding 1157.3 clif!;i t.a\\ 3291.7 _, ...."]},{"title":"77","paragraphs":["In Table 6, the deviation value using"]},{"title":"x","paragraphs":["2","rncthod was","smaller than our method except 'BNK', 'FOD' and",")MED). This shows that"]},{"title":"x","paragraphs":["2 method can not represent the characteristic of the text more precisely than our method. (2) SV MV method and our method According to Table 4) the breakeven points using our method was 0.75, while 8VMV was 0.64, respectively.","A possible reason why the result of our method was better than 8 V M Vis that term weight learning is efl'ec tive to classify texts. Let"]},{"title":"A and B","paragraphs":["be"]},{"title":"a","paragraphs":["category name and the total number of words which were included in each category be the same. Let a.!So w1 is included in"]},{"title":"A) B","paragraphs":["and the test data with the same frequency, and the test data consists of only w1 . In 8 V M V, the probabilities of the test. data which is classified into A and B are the same. Therefore, it could not be judged \\vhether the test data is classified into A or 1:3, correctly. However) our method introduces the degree of context dependency in order t.o judge whether a word in a text. is a true keyword or not. Therefore, our method can classify the test data into A or B, when the kcyv·wrd of the category A is judged to be the word 111 1 . As a result, our rncthod can represent the characteristic of the t.ext.s rnore precisely than"]},{"title":"SVJVIV. Conclusion","paragraphs":["VVc have reported on a.n empirical st.udy for term \\Vcight learning for a.n automatic text cat.cgoriza.t.ion. The characteristic of om a.pproach is that the degree of con·· text dependency is introduced in order to judge whether a word in a. texL is a true key\\vord or not. In the experi ment using WSJ, we could obtain 0. 75 breakeven points for 4/15~~ texts which are c.lassified into 78 categories.","In our current method, category assignment is based on a word in texts, i.e. every text. which should be clas sified and texts which are pre-categorized are character ized by a vector, each Jirnension of which is associated with a word in texts. As a result., two words arc treated quite different. even if these wmds are semantically sim ilar. In order to get more accuracy, linking words with their semantically sim.ilar words might be necessary to be introduced into our framework."]},{"title":"Acknowledgments","paragraphs":["'I\"he authors would like to thank the reviewers for their valuable comments. This work was partially supported by the Grant-in-·aid for Scientific Research of the tvlin ist.ry of Education, Science and Culture of Japan (No. 09780:)22)."]},{"title":"References","paragraphs":["[Brilll992] E. Brill. 1992. A simple rule-based parl of speech ta.gger. In Proc. of the 3rd Conference on Apphed Natuml J~anguagc Procc~sing, pages 152··--155."]},{"title":"78","paragraphs":["[Fuhrl989] N. Fuhr. 1989. Models for relrieval wilh probabilistic indexing. Infonnation Processing fd Re trieval, 25( 1) :55····72.","[Fukumoto and Suzuki 1996] F. Fukumoto and Y. Suzuki. 1996. An automatic clustering of articles using dictionary definitions."]},{"title":"In","paragraphs":["Proc. of the 16th International Conference on Com. p1llotional Linguistics, pages 406-411.","[Fukumoto et a.l.1997J F. Fukumoto) Y. Suzuki, and J. Fukumot.o. 1997. An automatic extraction of key paragraphs based on context dependency. In Proc. of the 5th Conference on Applied Nai'ural Language Processing, pages 291-298.","[Guthrie and Walker1994] L. Guthrie and E. Walker. 1994. Document classification by machine: 'fheory and practice. In Pro c. of the 15th lnterna tiona! Con~ ference on Computational Ling-uistics, pages"]},{"title":"1059","paragraphs":["1063.","[Iwadera. and Kikuil997] T. Iwadera and G. Kikui. 1997. Automatic text categorization using trend tracking technique. In Proc. of the Natural Language Processing Pacific Rim Symposium, pages 645··-6tl8.","[Iwayama and Tokunaga1991] M. lwa.yarna and T. Tokunaga. 19~J1. A probabilistic model for t.ext categorization: Based on a single ran dom variable with multiple values. In Proc. of the J,!h Conference on Applied Nat-ural Language Proassing, pages 162- Hi7.","[Jardine and SibsonlDGS] N. Jardine and H.. Sihson. 1968. 'l'he construction of hierarchic a.nd nonhierarchic classiHcations. pa.ges 177···181. [Jonesl97:l]"]},{"title":"K. S.","paragraphs":["Jones. 1973. A statislical inlerprcla .. tion ofterrn specificity and its application in retrieval Jmmwl of Documcnlation, 28(1):11 .... 2).","[Kwok1989] K. L. Kwok. 1989. Experiments with a component theory of probabi!ist.ic information re t.rieval based on single terms as docurnent compo nents. A C1H Transactions on lnformatio·fl. Systems, 8(4) 363-386.","[Lewis\\992] D. Lewis. 1992. An evaluation of phrasal and dustered representations on a text cat<~gorizat.ion task. In S'JGIR92, pages 37-.. 50.","[Lihermanl991] M. Liberman, 199L CD-ROM I. As sociation for Computational Linguistics Data. Collec t. ion Initiative University of Pennsylvania .. [Luhnl958] H. P. Luhn."]},{"title":"1958.","paragraphs":["The automatic creation of literature abstracts. IBM journal, 2(1):159 .. 1()5.","[Robertson and Jones1976] S. E. Robertson and K. Sparck Jones. 1976. Rel evance weight.ing of search terms. Number 27, pages 129 146.","[Salton and Yangl973] G. Salton aud C. S. Yang. 1973. On the specification of term values in automatic in dexing. Journal of documentation, 29(4):351-372.","[Salton1988] G. Salton. 1988. In Aatomolic Text Processing: The Transformation, Analysis, and Re trieval of Information by Computer. Addison- VVesley.","[Tokunaga and lwayaxna.1.994J T. Tokuna.gH and M. Iwayama. 1994. Text categorization based on \\Veighted inverse document. frequency. S'IG'~IPS Japan, 100(5):33-40.","[Walker and Amsler1986] D. Walker and R. Amsler. 1986. In The Use of Machine-Readable Dictionar ies in Sublanguage Analysis, pages 69-81. Lawrence Crlbaum, l!illsdalc, NJ.","[Yuasa ct al.l995] N. Yuasa, T. Ueda, and F. Togawa. 1995. Classifying articles using lexical co-occuncnce in large document databases. Trans. of Infonrwtion Processing Society Japan {In Japanese), :l6(8):1819l827."]},{"title":"-I 79","paragraphs":[]}]}
