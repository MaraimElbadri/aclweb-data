{"sections":[{"title":"[SemDis-O.2] 206","paragraphs":["21ème Traitement Automatique des Langues Naturelles, Marseille, 2014"]},{"title":"BACANAL : Balades Aléatoires Courtes pour ANAlyses Lexicales Application à la substitution lexicale Yann Desalle","paragraphs":["1"]},{"title":"Emmanuel Navarro","paragraphs":["2"]},{"title":"Yannick Chudy Pierre Magistry","paragraphs":["3, 4"]},{"title":"Bruno Gaume","paragraphs":["5"]},{"title":"(1) ATILF, CNRS, Université de Lorraine (2) IRIT, CNRS, Université de Toulouse (3) Graduate Institute of Linguistics, National Taiwan University (4) LPL, CNRS, Aix Marseille Université (5) CLLE-ERSS, CNRS, Université de Toulouse yann.desalle@gmail.com, navarro@irit.fr, ychudy@gmail.com, pmagistry@gmail.com, gaume@univ-tlse2.fr Résumé.","paragraphs":["Nous proposons ici des méthodes de désambiguisation sémantique par substition lexicale pour la tâche 1 de l’atelier SemDis2014. Les méthodes exposées dans ce papier sont toutes bâties à partir de balades aléatoires courtes dans des graphes unipartis ou bipartis construits sur diverses ressources. Certaines de ces méthodes n’utilisent que des graphes construits automatiquement à partir de corpus (méthodes non supervisées), d’autres utilisent des graphes construits à partir de ressources produites « à la main » par des lexicographes ou par les foules (méthodes supervisées)."]},{"title":"Abstract.","paragraphs":["In this paper, we propose word sense disambiguation methods based on lexical substitution and used for the task 1 of the SemDis2014 workshop. This methods are run by using short random walks on unipartite networks or bipartite networks. Some of these methods only use graphs automatically built from corpora (unsurpervised methods), others also use graphs built from handcraft resources filled by lexicographers or by the crowds (supervised methods)."]},{"title":"Mots-clés :","paragraphs":["désambiguisation sémantique, substition lexicale, réseaux lexicaux, balades aléatoires courtes."]},{"title":"Keywords:","paragraphs":["word sense disambiguation, lexical substitution, lexical networks, short random walks."]},{"title":"1 Introduction","paragraphs":["Depuis l’article de (McCarthy, 2002), la tâche de substitution lexicale s’est répandue : elle est de plus en plus utilisée dans des tâches telles que, par exemple, la désambuiguisation sémantique (McCarthy & Navigli, 2009) ou l’interprétation automatique de métaphores (voir (Desalle et al., 2009; Desalle, 2012) pour le français et (Shutova, 2010; Shutova et al., 2012) pour l’anglais).","Nous proposons ici des méthodes de désambiguisation sémantique par substitution lexicale pour la tâche 1 de l’atelier","SemDis2014 1",", adaptation pour le français de la tâche 10 de SemEval2007 (McCarthy & Navigli, 2007) à la suite de (Van","de Cruys et al., 2011). La particularité de cette tâche est de ne pas fournir à l’avance l’inventaire des substituts possibles","à ordonner en fonction des contextes d’occurrence de l’item à désambiguïser : cette inventaire est à déterminer en amont","par le système. Les méthodes de désambiguisation par substitution lexicale développées jusqu’à aujourd’hui pour cette tâche se répar-tissent en deux catégories : (a) d’une part les méthodes qui s’appuient sur des ressources lexicales construites à la main telles que WordNet (Fellbaum, 1998), le Rodget’s Thesaurus, le Macquarie Thesaurus etc. pour déterminer l’inventaire des candidats-substituts (à l’aide de filtres du type « synonymes seulement ») avant de les ordonner par des méthodes non-supervisées (Zhao et al., 2007; Hassan et al., 2007; Giuliano et al., 2007; Yuret, 2007; Dahl et al., 2007; Mohammad et al., 2007; Hawker, 2007) ou semi-supervisées (Martinez et al., 2007; Hassan et al., 2007) et, (b) d’autre part, les mé- thodes entièrement non-supervisées qui ne reposent que sur l’analyse de corpus de textes sans ressources lexicales pour 1. http://www.irit.fr/semdis2014/fr/"]},{"title":"[SemDis-O.2] 207","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME prédéfinir l’inventaire des substituts possibles (Van de Cruyset al., 2011). Le premier type d’approche est, de loin, le plus fréquent. Dans cet article nous présentons une batterie de méthodes « simples » basées sur les balades aléatoires dans les réseaux lexicaux qui, par un système d’agrégation adapté à la tâche, constituent les méthodes proposées pour SemDis2014 (une supervisée 2","et une non-supervisée 3","). Notons toutefois que dans nos méthodes supervisées l’inventaire des candidats comprend la totalité des unités lexicales constitutives de la ressources lexicales utilisée (aucun filtre n’est utilisé). La section 2 décrit le fonctionnement général de ces méthodes, la section 2.2 explique comment les balades aléatoires dans les réseaux génèrent une « vision » de proximité d’un sommet quelconque du réseau sur le reste de son réseau. Après avoir présenté en section 3 les réseaux lexicaux à partir desquels nous calculons ces « visions » de proximité, nous décrivons en section 4 l’ensemble des méthodes simples et leurs agrégations en deux méthodes supervisée et non-supervisée soumises à la tâche 1 de SemDis2014 ainsi que les résultats de leurs évaluations sur cette tâche. Enfin, en section 5, nous comparons, avec des données simples et controlées, les visions par balades aléatoires courtes aux visions par similarités construites sur une analyse en composantes principales. Nous concluons en section 6."]},{"title":"2 Méthodologie","paragraphs":["Les neuf méthodes BACANAL exposées dans ce papier sont toutes bâties à partir de balades aléatoires courtes dans des réseaux unipartis ou bipartis construits sur diverses ressources. Si au moins un des graphes utilisés pour une méthode a été construit à partir de ressources produites « à la main » par des lexicographes ou par les foules alors cette méthode sera dite supervisée, et non supervisée 4","si elle n’utilise que des graphes construits automatiquement à partir de corpus. Pour une phrase P dont ω est le mot à substituer, une méthode simple Mi sur un réseau lexical G produit un vecteur de réels Mi(G, P, ω) sur un ensemble V de mots de même partie du discours (PoS) que ω (ces méthodes sont dites simples dans la mesure où elles n’utilisent qu’un seul réseau lexical). Deux méthodes Mi et Mj peuvent être agrégées en une méthode Mk. Par exemple si Mi est une méthode simple appliquée sur un réseau lexical G1 et Mj est une méthode simple appliquée sur un réseau lexical G2 alors l’agrégation des deux méthodes Mi et Mj consiste à combiner les deux vecteurs Mi(G1, P, ω) et Mj(G2, P, ω) en un vecteur Agreg(Mi(G1, P, ω), Mj(G2, P, ω)) qui, comme les deux vecteurs Mi(G1, P, ω) et Mj(G2, P, ω), est un vecteur de réels sur le même ensemble V de mots de même PoS que ω. Différents types d’agrégations peuvent être utilisées et sont décrites en section 4.2. Par exemple, pour le mot ω =fonde à remplacer dans la phrase 5","P =« Et cette confiance fonde la responsabilité du praticien. », la méthode"]},{"title":"θ","paragraphs":["9 exposée en section 4.2, fournit un vecteur dont les 10 verbes de plus fortes coordonées rangés en ordre décroissant sont : établir, constituer, créer, former, instituer, assurer, mettre, instaurer, poser, construire. La méthode"]},{"title":"θ","paragraphs":["9 est celle qui, selon les évaluations de SemDis2014, propose les meilleures listes de substituts (les mots en gras sont les subtituts de fonde dans la phrase P qui ont été proposés par la méthode"]},{"title":"θ","paragraphs":["9 et par au moins deux des évaluateurs de SemDis2014). Nous exposons ci-dessous le cœur des méthodes BACANAL bâties à partir de balades aléatoires courtes dans des réseaux lexicaux."]},{"title":"2.1 Notations préliminaires","paragraphs":["Un graphe G = (V, E) est la donnée d’un ensemble non vide finiV de sommets, et d’un ensemble E ⊆ V ×V de couples de sommets formant des arêtes : – n = |V | est l’ordre de G (son nombre de sommets), 2. Méthode qui s’appuie sur des ressources lexicales de type dictionnairique. 3. Méthode de catégorie (b). 4. Cette dénomination peut cependant être abusive dans la mesure où le système automatique pourrait éventuellement utiliser dans sa chaîne de","traitements des ressources construites « à la main », par exemple quand la chaîne de traitements utilise un analyseur syntaxique qui lui même utilise des","ressources construites « à la main ». 5. C’est la phrase numéro 93 du jeu de test fourni par SemDis2014."]},{"title":"[SemDis-O.2] 208","paragraphs":["BACANAL : BALADES ALÉATOIRES COURTES POUR ANALYSES LEXICALES","– m = |E| est la taille de G (son nombre d’arêtes),","– le graphe est biparti lorsqu’il existe deux ensembles V⊤ ⊂ V et V⊥ ⊂ V tels que : – V⊤ ∪V⊥ = V et V⊤ ∩V⊥ = /0 : V est l’union de deux ensembles d’intersection vide ; – E ⊆ (V⊤ ×V⊥) ∪ (V⊥ ×V⊤) : il n’existe pas d’arête entre les sommets de V⊥ ni entre les sommets de V⊤. On notera alors un tel graphe biparti : G = (V⊤,V⊥, E). Par ailleurs, un graphe G = (V, E) est dit pondéré lorsque chaque arête (r, s) ∈ E est valuée par un poids w(r, s) ∈ R+",". On notera alors un tel graphe pondéré G = (V, E, w)."]},{"title":"2.2 Balades aléatoires","paragraphs":["Soit G = (V, E, w) un graphe pondéré de n sommets et m arêtes où chaque arête (i, j) ∈ E est pondérée par un poids w(i, j) ∈ R+",". On attribue à chaque sommet du graphe un vecteur de coordonnées dans Rn","qui représente la « vision » qu’a le sommet en question sur le reste du graphe. Pour modéliser la « vision » qu’a un sommet sur le reste du graphe, nous considérons un marcheur se baladant aléatoirement en suivant les arêtes du graphe. La distribution de probabilité de la position de ce marcheur est donnée par la chaîne de Markov associée au graphe. Cette chaîne de Markov est définie par la matrice de transition A (équation 1) où W (u) est la somme des poids des arêtes partant de u, soit W (u) = ∑v∈V w(u, v). A = (au,v)u,v∈V avec au,v =","{ w(u,v) W(u) si (u, v) ∈ E 0 sinon (1)","Si P0 est la distribution de probabilité initiale du marcheur (c’est-à-dire un vecteur de dimension n = |V | où [P0]u est la","probabilité de présence sur u au temps t = 0) alors la distribution de probabilité du marcheur après t pas est Pt = P0At","(le","produit du vecteur P0 de dimension n par la matrice At de dimension n × n.)","Pour modéliser la « vision » qu’a un sommet u ∈ V à un instant t donné sur le reste du graphe G, on définit le vecteur","θ (G, u,t) = δ{u}At","comme la distribution de probabilité d’un marcheur ayant effectué t pas depuis u, où δX est l’équi-","probabilité d’être sur un des sommets de X (δX est un vecteur-ligne de dimension |V | contenant la valeur 0 sur toutes ses","coordonnées, excepté celles correspondant aux sommets de X qui valent 1","|X| ). Si [θ (G, u,t)]r > [θ (G, u,t)]s c’est que le sommet u « voit mieux » le sommet r que le sommet s, et la « vision » qu’a le sommet u en question sur les sommets de V est entièrement gouvernée par la structure du graphe G = (V, E, w). Si le graphe est apériodique, ce vecteur θ (G, u,t) converge quand t → ∞. Cette limite correspond en fait à la version la plus simple du PageRank (Brin & Page, 1998; Manning et al., 2008). Notons que cette limite ne dépend plus du sommet de départ, c’est-à-dire que ∀u, r ∈ V, limt→∞ θ (G, u,t) = limt→∞ θ (G, r,t) et donne une information globale 6","sur le graphe (quels sont les sommets les plus « importants »). À l’inverse, pour t = 1, θ (G, u, 1) correspond à une version normalisée du vecteur d’adjacence du sommet u. Cette information est alors complètement locale, puisque ce vecteur ne dépend que du strict voisinage de u (u ne voit que ses voisins). Il est possible d’utiliser ce vecteur comme modèle, on a alors une modélisation vectorielle classique. Cependant cette modélisation ne prend en compte qu’une vision extrêmement locale de la topologie du graphe depuis u. En revanche, lorsqu’on effectue des balades de temps courts (3 ⩽ t ⩽ 8), θ (G, u,t) dépend d’un voisinage plus large. Dans ce cas, même si deux sommets n’ont aucun voisin immédiat en commun, la ressemblance potentielle des voisins de leurs voisins peut amener ces deux sommets à « mieux se reconnaître ». θ (G, u,t) est alors une « vision de proximité », un compromis, entre une « vision trop locale » (t = 1) et une « vision trop globale » (t → ∞). Afin de généraliser la « vision » que peut avoir un ensembleS quelconque à un instant t donné sur le reste du graphe G, on définit le vecteur : θ (G, S,t) =","{","δS∩V At","si S ∩V ̸= ∅","⃗0 sinon où⃗0 est le vecteur nul de dimension |V| (2)","6. Tout sommet a alors la même « vision ». Par exemple si G est un graphe non pondéré, réflexif et symétrique, alors le sommet qui est toujours « le mieux vu » par tous les autres sommets est le sommet de plus fort degré (voir (Gaume, 2004))."]},{"title":"[SemDis-O.2] 209","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME"]},{"title":"3 Réseaux lexicaux","paragraphs":["Deux types de réseaux lexicaux ont été utilisés pour la construction de nos méthodes BACANAL : (a) des réseaux construits à partir ressources de type dictionnairiques réalisées à la main par des lexicographes ou par les foules et (b) des ressources construites par analyse distributionnelle de corpus de textes. Réseaux lexicaux construits à partir de la ressource DicoSyn : La ressource DicoSyn a été construite lors d’un projet collaboratif entre IBM et l’Institut National de la Langue Française 7",". A partir de sept dictionnaires classiques (Bailly, Benac, Du Chazaud, Guizot, Lafaye, Larousse et Robert) ont été extraites les relations synonymiques, puis le graphe ainsi obtenu Gdsyn a été réflexivisé, symétrisé et catégorisé par PoS en trois graphes GdsynA, GdsynN, GdsynV, les caractéristiques générales de ces graphes sont décrites dans la table 2.","Réseaux lexicaux construits à partir de la ressource Jeux De Mots : La ressource Jeux De Mots 8","est construite par","les foules en utilisant un jeu décrit dans (Lafourcade, 2007). Les joueurs doivent trouver le plus de mots possible qui sont","associés à un terme présenté à l’écran, selon une règle prévue par le jeu. Le but est de trouver autant d’associations séman-","tiques que possible que les autres joueurs ont trouvées, mais que le joueur concurrent n’a pas trouvées. Plusieurs règles","peuvent être proposées, y compris la synonymie et l’association libre. Les résultats recueillis en janvier 2014 permettent","de construire un graphe de mots liés par des relations sémantiques typées (selon les règles du jeu). GjdmSA, GjdmSN,","GjdmSV sont les graphes de synonymie et GjdmA est le graphe d’association libre, tous les quatre construits à partir","de la ressource Jeux De Mots. Ces quatre graphes sont réflexivisés, symétrisés et non pondérés et leurs caractéristiques","générales sont décrites dans la table 2. Réseaux lexicaux construits à partir de la ressource LM10 : La ressource LM10 construite par Benoît Habert est un corpus de 200 millions de mots, constitué des articles du journal Le Monde des années 1991 à 2000. Une analyse syntaxique en dépendance de LM10 a été réalisée au sein du laboratoire CLLE 9","par l’analyseur syntaxique probabiliste Talismane 10","(Urieli, 2013). Pour fonctionner dans une langue L donnée, Talismane a besoin d’un lexique de L 11",", d’un ensemble d’étiquettes des parties du discours de L 12",", d’un ensemble de traits et d’un ensemble de règles spécifiques àL. La version que nous utilisons ici a été entraînée pour le français sur le French TreeBank 13","(Abeillé et al., 2003). En entrée, Talismane prend un texte brut et, en sortie, il produit une liste de tokens : identifiant du token (id), lemme, forme, PoS, caractéristiques grammaticales (CG), identifiant du recteur du token (GOV), nature de la relation de dépendance (token, recteur) (REL). Par exemple, l’analyse par Talismane de l’énoncé « Et cette confiance fonde la responsabilité du praticien. » produit la sortie décrite dans le tableau 1. Talismane fait une analyse en dépendance de ID FORME LEMME POS CG GOV REL 1 Et et CC _ 0 root 2 cette cette DET g=f|n=s 3 det 3 confiance confiance NC g=f|n=s 4 suj 4 fonde fonder V n=s|p=13|t=pst 1 dep_coord 5 la la DET g=f|n=s 6 det 6 responsabilité responsabilité NC g=f|n=s 4 obj 7 du de P+D g=m|n=s 6 dep 8 praticien praticien NC g=m|n=s 7 prep 9 . . PONCT _ 1 ponct TABLE 1 – Sorties de Talismane pour la phrase : « Et cette confiance fonde la responsabilité du praticien. » 7. Aujourd’hui ATILF :http://www.atilf.fr/ 8. http://www.lirmm.fr/jeuxdemots/jdm-accueil.php 9. http://w3.erss.univ-tlse2.fr/ 10. http://redac.univ-tlse2.fr/applications/talismane.html 11. Le Lefff (Sagot et al., 2006) pour la version utilisée ici. 12. Étiquettes en grande partie reprises de (Crabbé & Candito, 2008) pour la version utilisée ici. 13. http://www.llf.cnrs.fr/Gens/Abeille/French-Treebank-fr.php"]},{"title":"[SemDis-O.2] 210","paragraphs":["BACANAL : BALADES ALÉATOIRES COURTES POUR ANALYSES LEXICALES","surface entre tous les tokens mis en jeu, ponctuation comprise, et chaque token ne peut avoir qu’un seul recteur. Afin","d’identifier toutes les relations syntaxiques logiques entre tokens, les sorties de Talismane sont passées à un module de","déduction qui calcule :","– la relation de coordination entre tokens coordonnés :","une pomme et une poire → ⟨NC.pomme, coor_dep, NC.poire⟩","– la relation entre un token et tous ses dépendants lorsque ceux-ci sont coordonnés :","il joue et chante → ⟨V. jouer, su j, PRO.il⟩, ⟨V.chanter, su j, PRO.il⟩","– la relation entre un token et tous ces gouverneurs lorsque ceux-ci sont coordonnés :","il mange une pomme et une poire → ⟨V.manger, ob j, NC.pomme⟩, ⟨V.manger, ob j, NC.poire⟩","– la relation suj (resp. obj) entre le sujet (resp. objet) logique et le verbe lorsque le sujet (resp. objet) réel est un pronom","relatif :","le gars qui joue au foot → ⟨V. jouer, su j, NC.gars⟩","– la relation Prep 14","entre un nom ou un verbe et la tête du syntagme prépositionnel qui le complète lorsqu’un syntagme","prépositionnel complète un nom ou un verbe :","c’est un train à vapeur → ⟨NC.train, Prep/à, NC.vapeur⟩","– la relation mod entre les noms et leurs attributs du sujet :","le livre est rouge → ⟨NC.livre, mod, ADJ.rouge⟩","– la relation obj entre le complément d’objet logique d’un verbe et ce verbe lorsque le verbe est à la forme passive : la","souris est mangée par le chat → ⟨V.manger, ob j, NC.souris⟩","– la relation suj entre les participes présents et leur sujet :","l’avocat plaidant une cause → ⟨V.plaider, su j, NC.avocat⟩ Ce module de déduction pronominalise aussi les verbes qui ont un complément d’objet clitique troisième personne et réétiquette certaines parties du discours : les verbes étiquetés verbe infinitif, verbe impératif, verbe subjonctif et participe présent par Talismane sont simplement réétiquetés verbe.","Trois graphes Glm10N, Glm10A, Glm10V (c.f. tableau 3) sont ensuite construits à partir des sorties de Talismane enrichies","par le module de déduction comme suit. Définissons :","– Cl l’ensemble des contextes syntaxiques d’un lemme l dans LM10 : Cl = {(rel, lc)} tels que lc est syntaxiquement lié à","l par rel dans LM10 ;","– C l’ensemble des contextes syntaxiques de LM10 : C = ∩","l∈LCl. Soit PoS ∈ {A, N,V }, Glm10PoS = (LPoS ∪C, E) est un graphe biparti tel que {l, c} ∈ E ⇔ c ∈ Cl. Toute arête {l, c} ∈ E est pondérée par une mesure de type information mutuelle IM entre le lemme l et le contexte c : IM = f req((∗, ∗)) × f req((l, c)) f req((l, ∗)) × f req((∗, c)) (3) Réseaux lexicaux construits à partir de la ressource frWaC : La ressource frWaC 15","qui est décrite dans (Baroni et al., 2009) est un corpus de 1.6 milliard de mots construit à partir du Web en limitant l’analyse au domaine .fr. Les graphes GfrwacA GfrwacN GfrwacV (c.f. tableau 3) ont été construits de la même manière que les graphes Glm10. GdsynA GdsynN GdsynV GjdmSA GjdmSN GjdmSV GjdmA n 9 452 29 372 9 147 9 859 29 213 7 658 153 586 m 42 403 100 759 51 423 30 088 56 383 22 262 928 399 TABLE 2 – Caractéristiques des graphes unipartis : n est le nombre de sommets, m le nombre total d’arêtes. Nous indiquons ci-dessous le voisinage « immédiat » du verbe fonder dans les graphes présentés ci-dessus : Dans GdsynV, fonder a 32 voisins : affermir, appuyer, asseoir, assurer, baser, bâtir, commencer, compter, constituer, construire, créer, engendrer, enter, forger, former, instaurer, instituer, justifier, lancer, mettre, motiver, organiser, ouvrir, placer, poser, reposer, tabler, échafauder, édifier, élever, ériger, établir 14. Il y a autant de relation Prep que de prépositions. 15. http://wacky.sslmit.unibo.it/doku.php?id=corpora"]},{"title":"[SemDis-O.2] 211","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME Glm10A Glm10N Glm10V GfrwacA GfrwacN GfrwacV n 57 623 520 355 223 843 134 559 964 769 319 249 nl 21 181 48 491 8 017 55 771 133 506 18 734 nc 36 442 471 864 215 826 78 788 831 263 300 515 m 872 464 7 556 008 2 654 104 958 138 8 643 588 2 151 146 TABLE 3 – Caractéristiques des graphes bipartis : n est le nombre total de sommets, nl le nombre de lemmes, nc le nombre de contextes, m le nombre d’arêtes. Dans GjdmSV, fonder a 15 voisins : affermir, appuyer, asseoir, assoir, baser, bâtir, constituer, créer, former, instaurer, instituer, justifier, édifier, élever, ériger Dans GjdmA, fonder a 47 voisins : acte fondateur, amorcer, aménager, assurer, attaquer, commencer, composer, concevoir, construction, construire, disposer, débuter, démarrer, enfanter, engendrer, engrener, entamer, entreprendre, entreprise, esquisser, fixer, fondateur, fondation, fondement, foyer, imaginer, implanter, installer, inventer, maison, mettre, montrer, partir, placer, poser, presser, production, produire, préluder, réaliser, se fonder, ébaucher, échafauder, élaborer, équilibrer, établir, étrenner Dans Glm10V, fonder a 583 voisins 16",": NC.espoir.Dep.obj (freq=144, IM=120.347), NC.société.Dep.obj (freq=138, IM=59.6531), NC.famille.Dep.obj (freq=98, IM=77.4457), NC.revue.Dep.obj (freq=85, IM=317.996), V.venir.Gov.Prep/de (freq=82, IM=7.29996), NC.principe.Dep.suj (freq=82, IM=84.03), NC.compagnie.Dep.obj (freq=79, IM=120.454), NC.parti.Dep.obj (freq=78, IM=46.1816), NC.association.Dep.obj (freq=78, IM=100.757), NC.valeur.Dep.suj (freq=76, IM=73.5628) Dans GfrwacV, fonder a 824 voisins 17",": NC.famille.Dep.obj (freq=1144, IM=387.762), NC.monastère.Dep.obj (freq=517, IM=4889.38), NC.société.Dep.obj (freq=472, IM=137.059), NC.groupe.Dep.obj (freq=363, IM=71.3103), NC.école.Dep.obj (freq=283, IM=126.836), NC.action.Dep.obj (freq=270, IM=26.9095), V.être.Gov.Prep/de (freq=264, IM=1.91398), V.permettre.Gov.Prep/de (freq=253, IM=2.75423), NC.association.Dep.obj (freq=202, IM=77.0306), NC.compagnie.Dep.obj (freq=200, IM=383.908)"]},{"title":"4 Méthodes","paragraphs":["Dans une phrase P soit ω un mot cible de P et Cω","P l’ensemble des contextes syntaxiques de ω dans P identifié par Talismane + module de déduction. Par exemple, soit P =« Et cette confiance fonde la responsabilité du praticien. »et ω =fonde le mot-cible de P, le mot fonde a trois contextes syntaxiques dans cette phrase 18","(voir tableau 1) : Cω","P = {(NC.con f iance, Dep.su j), (NC.responsabilité, Dep.ob j), (CC.et, Gov.dep_coord)}"]},{"title":"4.1 Visions simples","paragraphs":["Nous présentons dans le tableau 4 sept méthodes qui utilisent des visions simples sur différents graphes lexicaux. Chaque méthode construit une liste ordonnée de lemmes d’un des trois types suivants : – T1, liste ordonnée sur l’axe paradigmatique de ω par rapport à ω et indépendamment du contexte Cω","P de la phrase P","(c’est à dire couvrant potentiellement l’ensemble de la polysémie du mot ω) ;","– T2, liste ordonnée sur l’axe syntagmatique de Cω","P par rapport Cω","P et indépendamment de ω ;","– T3, liste ordonnée par rapport à ω sur axe non typé (les relations entre deux lemmes peuvent être paradigmatiques ou","syntagmatiques) et indépendamment du contexte Cω P de la phrase P. Les méthodes"]},{"title":"θ","paragraphs":["1,"]},{"title":"θ","paragraphs":["2 et"]},{"title":"θ","paragraphs":["3 sont supervisées tandis que les méthodes"]},{"title":"θ","paragraphs":["4,"]},{"title":"θ","paragraphs":["5,"]},{"title":"θ","paragraphs":["6 et"]},{"title":"θ","paragraphs":["7 sont non-supervisées 16. Ces voisins sont les contextes de fonder dans LM10, nous présentons ici les 10 plus fréquents, (’freq’ est la fréquence du contexte avec fonder, et","’IM’ est le poids de l’arête entre fonder et le contexte). 17. Ces voisins sont les contextes de fonder dans f rWaC, nous présentons ici les 10 plus fréquents. 18. Le module de dépendance ne change pas les sorties de Talismane pour cette phrase."]},{"title":"[SemDis-O.2] 212","paragraphs":["BACANAL : BALADES ALÉATOIRES COURTES POUR ANALYSES LEXICALES Méthode Type de liste"]},{"title":"θ","paragraphs":["1 = θ (Gdsyn, {ω}, 3) T1"]},{"title":"θ","paragraphs":["2 = θ (G jdmS, {ω}, 3) T1"]},{"title":"θ","paragraphs":["3 = θ (G jdmA, {ω}, 3) T3"]},{"title":"θ","paragraphs":["4 = θ (Glm10, {ω}, 2) T1"]},{"title":"θ","paragraphs":["5 = θ (G f rwac, {ω}, 2) T1"]},{"title":"θ","paragraphs":["6 = θ (Glm10, Cω P , 3) T2"]},{"title":"θ","paragraphs":["7 = θ (G f rwac, Cω P , 3) T2 TABLE 4 – Sept visions simples"]},{"title":"4.2 Agrégations de visions simples","paragraphs":["Le but de la tâche 1 de SemDis2014 est la substitution lexicale : remplacer un mot ω dans une phrase P par un autre mot tout en préservant au maximum le sens de la phrase P. Aucune des sept visions simples décrites ci-dessus ne peut espérer remplir cette tâche avec succès, ce n’est d’ailleurs pas leurs buts. On peut cependant espérer s’approcher au mieux de la tâche de substitution lexicale en combinant plusieurs visions simples. Par exemple en multipliant coordonnées par coordonnées les deux vecteurs issus de deux méthodes de type T1 et T2 on peut espérer renforcer l’axe paradigmatique du mot ω sur le sens qu’il prend dans le contexte Cω","P de la phrase P. Pour aller dans ce sens nous définissons ci-dessous trois façons de combiner les méthodes19",". Soit A et B deux vecteurs de même dimension : Agreg1(A, B) : Agreg1(A, B) = [C]i =","{ [A]i . [B]i si [A]i ̸= 0 et [B]i ̸= 0 [A]i sinon (4) Agreg2(A, B) : Agreg2(A, B) = [C]i =","{ [B]i si [A]i = 0 [A]i sinon (5) Agreg3(A, B) : Agreg3(A, B) = [C]i =","{ [B]i si [A]i ̸= 0 0 sinon (6) Nous pouvons maintenant définir les deux méthodes que nous avons soumises à SemDis2014 : Méthode non supervisée :"]},{"title":"θ","paragraphs":["8 = Agreg1(Agreg1(θ4, θ5), Agreg1(θ6, θ7)) Méthode supervisée :"]},{"title":"θ","paragraphs":["9 = Agreg2(Agreg1(Agreg1(θ2, θ3), θ6 ) , Agreg3(Agreg2(θ1, θ2), Agreg1(Agreg1(θ2, θ3), θ6))) Le tableau 5 résume les résultats des méthodes exposées ici sur la phrase numéro 93."]},{"title":"4.3 Évaluation","paragraphs":["Parmis les 10 méthodes soumises par l’ensemble des participants à Semdis14, la méthode"]},{"title":"θ","paragraphs":["9 est celle qui, selon les évaluations de SemDis2014 sur un ensemble de 300 phrases avec 30 cibles à désambiguïser (10 verbes, 10 noms, 10 adjectifs avec 10 phrases par cible), propose les meilleures listes de substituts. Les résultats des méthodes ont été évalués à l’aide de deux mesures de rappel : best et oot définies par (McCarthy & Navigli, 2009) : soitH l’ensemble des annotateurs SemDis2014, T l’ensemble des phrases avec au moins deux substituts proposés par les annotateurs, hi l’ensemble des réponses produites par les annotateurs pour une phrase i ∈ T , A l’ensemble des phrases de T pour lesquels le système produit au moins une réponse, ai l’ensemble des substituts proposés par le système pour une phrase i ∈ T , Hi l’union","19. Il se peut qu’une méthode M1 donne en générale de meilleurs resultats qu’une autre methode M2, mais que la méthode M1 ai une moins bonne couverture lexicale que la méthode M2. C’est principalement pour cette raison que les méthodes d’agrégations ne sont pas symétriques."]},{"title":"[SemDis-O.2] 213","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME","Gold créer, forger, constituer, justifier, être à la base, entraîner, assurer, impliquer, baser, instaurer, induire, définir, être à l’origine, établir, installer, poser, supporter"]},{"title":"θ","paragraphs":["1 établir, bâtir, créer, construire, faire, organiser, former, constituer, élever, placer"]},{"title":"θ","paragraphs":["2 bâtir, constituer, créer, élever, établir, édifier, ériger,instaurer, instituer, appuyer"]},{"title":"θ","paragraphs":["3 responsabilité, confiance, charge, meilleur ami, sureté, affect, condamnation, devoir, poids, dette"]},{"title":"θ","paragraphs":["4 fondre, diriger, présider, animer, créer, rejoindre, perpétuer, abriter, érier, racheter"]},{"title":"θ","paragraphs":["5 se marier, ème, rejoindre, pondre, échanger, arranger, engendrer, dater, rivaliser, diriger"]},{"title":"θ","paragraphs":["6 se décréter, se mériter, se rétablir, endosser, se rejeter, se démentir, se renvoyer, saisissant, se évanouir, imputer"]},{"title":"θ","paragraphs":["7 généraliser, se mériter, se acquérir, aveugler, se rejeter, endosser, décliner, régner, se décréter, assumer"]},{"title":"θ","paragraphs":["8 reposer, se installer, se fonder, assumer, diriger, régner, rejoindre, quitter, animer, se appuyer"]},{"title":"θ","paragraphs":["9 établir, constituer, créer, former, instituer, assurer, mettre, instaurer, poser, construire TABLE 5 – Résultats sur la phrase numéro 93 : « Et cette confiance <fonde> la responsabilité du praticien. » des hi et freq(s) le nombre d’occurrences du substitut s ∈ Hi dans Hi. Une première mesure best définie par l’équation 7 indique le rappel au rang 1 de la méthode par rapport à des solutions de référence proposées par les organisateurs de SemDis2014. La seconde mesure oot (pour out of best) définie par l’équation 7 indique le rappel au rang 10 de la méthode sans prendre en compte l’orde des réponses. Les résultats obtenus par les méthodes présentées dans ce papier sur la phrase numéro 93 sont détaillés dans le tableau 5."]},{"title":"best = ∑","paragraphs":["ai:i∈T","∑s∈a","i f req(s) |ai|.|Hi|"]},{"title":"|T | oot = ∑","paragraphs":["ai:i∈T","∑s∈a i f req(s) |Hi|"]},{"title":"|T | (7)","paragraphs":["Le tableau 6 présente les résultats des méthodes simples ainsi que des méthodes"]},{"title":"θ","paragraphs":["8 (non-supervisée) et"]},{"title":"θ","paragraphs":["9 (supervisée) soumises à SemDis2014 : Méthodes Type best oot"]},{"title":"θ","paragraphs":["1 = θ (Gdsyn, {ω}, 3) supervisée .0453 .3245"]},{"title":"θ","paragraphs":["2 = θ (G jdmS, {ω}, 3) supervisée .0645 .3519"]},{"title":"θ","paragraphs":["3 = θ (G jdmA, {ω}, 3) supervisée .0022 .0736"]},{"title":"θ","paragraphs":["4 = θ (Glm10, {ω}, 2) non-supervisée .0259 .1347"]},{"title":"θ","paragraphs":["5 = θ (G f rwac, {ω}, 2) non-supervisée .0319 .0799"]},{"title":"θ","paragraphs":["6 = θ (Glm10, Cω P , 3) non-supervisée .0061 .0368"]},{"title":"θ","paragraphs":["7 = θ (G f rwac, Cω P , 3) non-supervisée .0024 .0228"]},{"title":"θ","paragraphs":["8 non-supervisée .0511 .2129"]},{"title":"θ","paragraphs":["9 supervisée .0970 .4017 TABLE 6 – Résultats des méthodes BACANAL Le tableau 6 met en évidence une amélioration significative par les méthodes agrégées des performances des méthodes simples sur lesquelles elles reposent : –"]},{"title":"θ","paragraphs":["8 /"]},{"title":"θ","paragraphs":["5 : best : +60% ; oot : +166% –"]},{"title":"θ","paragraphs":["9 /"]},{"title":"θ","paragraphs":["2 : best : +50% ; oot : +14%","Notons toutefois que les deux méthodes basées sur des ressources paradigmatiques construites à la main 20 ("]},{"title":"θ","paragraphs":["1 basée sur","20. Nous ne considérons pas l’association libre comme une relation paradigmatique puisqu’elle met en jeu des relations entre parties du discours distinctes."]},{"title":"[SemDis-O.2] 214","paragraphs":["BACANAL : BALADES ALÉATOIRES COURTES POUR ANALYSES LEXICALES Gdsyn et"]},{"title":"θ","paragraphs":["2 basée sur GjdmS), sont performantes au rang 10 (environ 32% des réponses fournies par au moins deux annotateurs sont trouvées par"]},{"title":"θ","paragraphs":["1 et 35% par"]},{"title":"θ","paragraphs":["2) et que la méthode"]},{"title":"θ","paragraphs":["9 n’améliore les performances de"]},{"title":"θ","paragraphs":["2 que de 14% au rang 10. Toutefois, au rang 1,"]},{"title":"θ","paragraphs":["9 est significativement plus performante que"]},{"title":"θ","paragraphs":["2."]},{"title":"5 Vers une comparaison avec les méthodes opérant par réduction de dimension","paragraphs":["Toutes les méthodes exposées ici sont bâties à partir de balades aléatoires courtes dans des réseaux unipartis ou bipartis construits sur diverses ressources. Cependant, un réseau lexical uniparti G = (V, E, w) peut être vu comme une matrice lexicale de dimension |V | × |V | : MG = (au,v)u,v∈V , avec au,v = w(u, v), et un réseau lexicale biparti G = (V⊤,V⊥, E, w) peut être vu comme une matrice lexicale de dimension |V⊤| × |V⊥| : MG = (au,v)u∈V⊤,v∈V⊥, avec au,v = w(u, v).","Beaucoup de méthodes (Van de Cruys et al., 2011; Erk & Padó, 2009, 2010; Dinu & Lapata, 2010; Thater et al., 2010)","commencent par réduire la matrice MG en une matrice Mk","G de dimensions k avec des méthodes d’analyse en composantes","principales (ACP) puis calculent une similarité entre les vecteurs de Mk G, par exemple : cos([Mk","G]u, Mk","G]v). C’est alors le","vecteur φ(G, u, k) = (av)v∈V , avec av = cos([Mk G]u, Mk","G]v) qui est utilisé comme « vision » de u. Nous proposons ci-dessous de comparer, sur un graphe artificiel simple et controlé, les méthodes BACANAL à celles qui utilisent une réduction d’espaces vectoriels. Une telle comparaison ne remplace en aucun cas une comparaison sur des données réelles. Cependant sur ces données controlées un résultat précis est attendu. Cela permet donc de comparer les résultats de chaque méthode par rapport aux résultats attendus. Ceci est un premier pas pour mieux comprendre les ressemblances et différences existantes entre les méthodes. Pour comparer les méthodes nous utilisons un modèle de graphe artificiel composé de deux niveaux de clusterisation : les sommets sont regroupés en trois gros clusters, eux-même décomposables en trois petits clusters. Formellement, nous utilisons un graphe G = (V, E) tel que V est l’union de k = 9 ensembles ∆1, . . . ∆9 de n = 20 sommets chacun 21",". Ces sommets sont regroupés en trois ensembles Γ1 = ∆1 ∪ ∆2 ∪ ∆3, Γ2 = ∆4 ∪ ∆5 ∪ ∆6, Γ3 = ∆7 ∪ ∆8 ∪ ∆9. Une arête e entre deux sommets u et v est créée avec la probabilité : – p1 = 0.5 si les deux sommets appartiennent à un même ensemble ∆ (∃i tel que u, v ∈ ∆i) ; – p2 = 0.01 s’ils appartiennent à des ensembles ∆ distincts mais à un même ensemble Γ (∄i tel que u, v ∈ ∆i mais","∃ j tel que u, v ∈ Γ j) ; – p3 = 0.001 s’ils appartiennent à deux ensembles Γ distincts (∄i tel que u, v ∈ Γi). Un tel graphe est représenté dans la figure 1(a). (a) G = (V,E) (b) Etiquetage des sommets FIGURE 1 – Graphe artificiel avec 3 zones densesΓ1, Γ2, Γ3 où chacune de ces zones denses est constituée de 3 zones locales encore plus denses Γ1 : ∆1, ∆2, ∆3 ; Γ2 : ∆4, ∆5, ∆6 ; Γ3 : ∆7, ∆8, ∆9. Notre idée est de comparer, pour un sommet u quelconque de G, les visions du graphe obtenues par chacune des méthodes 21. Si i ̸= j alors ∆i ∩ ∆j = ∅."]},{"title":"[SemDis-O.2] 215","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME à partir de u, à l’aide du critère suivant : l’ordre des sommets de G obtenus par ces méthodes (à partir de u) respecte-t-il l’ordre des clusters autour de u (∆u, Γu, G). En effet, on souhaite que les sommets du petit cluster ∆u arrivent avant ceux du cluster moyen Γu et eux-mêmes avant les autres sommets du graphe. Pour cela, nous allons observer les résulats de chaque métodes en notant (0) les sommets qui appartiennent à ∆u ; (1) les sommets qui appartiennent à Γu mais pas à ∆u ; (2) les sommets qui n’appartiennent pas à Γu (cet étiquetage est illustré dans la figure 1(b)). Ceci est une représentation « binaire » de ce qui peut se passer sur un graphe lexical dans une tâche de substitution.","Nous donnons ci-dessous les résultats pour une méthode utilisant des marches aléatoires courtes et différentes méthodes","par réduction de dimension. La liste L0 représente les étiquettes des sommets v ∈ V quand elles sont ordonnées selon(","θ (G, {u}, 3)) v. Les listes L3, L9, L50 et L180 représentent les mêmes étiquettes mais ordonnées après une réduction de","dimension (L3 utilise ( φ(G, u, 3))","v, L9 utilise","(","φ(G, u, 9))","v, . . . )","L0 =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,","1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,","2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] L3 =[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] L9 =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] L50 =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1] L180 =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2] Les listes L0 et L9 donnent toutes les deux, approximativement, les résultats « espérés » alors que ni la liste L3 ni la liste L50 ni même la liste L180 (changement de base simple, matrice non réduite) ne sont satisfaisantes : – La liste L3 ne distingue pas suffisamment les sommets étiquetés 0 (v ∈ ∆1) des sommets étiquetés 1 (v /∈ ∆1 mais v ∈ Γ1).","En réduisant la matrice à trois dimensions on a encore l’information de l’existence des trois gros agrégats Γ1, Γ2, Γ3","mais celles des petits agrégats ∆1, ∆2 , ∆3 est moins claire ; – La liste L50 ne distingue pas suffisamment les sommets étiquetés 1 (v /∈ ∆1 mais v ∈ Γ1) des sommets étiquetés 2","(v /∈ Γ1). En réduisant la matrice à cinquante dimensions on a encore l’information de l’existence des trois petits","agrégats ∆1, ∆2 , ∆3, mais celles des trois gros agrégats Γ1, Γ2, Γ3 est moins claire ; – La liste L180 souffre des mêmes faiblesses que la liste L50. Nous voyons donc sur ce petit exemple que les méthodes par réduction de dimension sont semblables aux méthodes BACANAL à condition que le choix de k soit bien adapté à la ressource, ce qui est parfois difficile à réaliser sur des ressources réelles. Une étude comparative plus poussée des forces et faiblesses de ces méthodes sur des données lexicales réelles mériterait d’être systématisée. Notons qu’il est aussi possible de comprendre ces différences/ressemblances d’un point de vu algébrique. En effet, les marches aléatoires peuvent se comprendre comme un renforcement des valeurs propres les plus fortes 22",", alors qu’une réduction de dimension ne conserve que les vecteurs qui ont les valeurs propres les plus fortes (Navarro, 2013)."]},{"title":"6 Conclusion","paragraphs":["Dans ce papier, nous avons présenté des méthodes bâties à partir de balades aléatoires courtes sur des réseaux lexicaux : les méthodes BACANAL. Selon les types de réseaux lexicaux qu’elles utilisent (construits à partir de corpus de textes ou à partir de ressources lexicales produites par des lexicographes ou par les foules), ces méthodes peuvent être supervisées ou entièrement non-supervisées. Un mécanisme d’agrégation de méthodes permet d’améliorer significativement les résultats","22. En effet, les marches aléatoires se basent sur la matrice A prise à la puissance t. Or A peut être décomposée sur une base de vecteurs propres :","A = UEV T","avec E la matrice diagonale des valeurs propres (on sait par ailleur que ces valeurs propres sont <= 1). On a donc que At = UEt","V T","ce qui","revient à renforcer les plus fortes valeurs propres. Une démonstration et une explication plus détailées restent cependant nécessaires."]},{"title":"[SemDis-O.2] 216","paragraphs":["BACANAL : BALADES ALÉATOIRES COURTES POUR ANALYSES LEXICALES des méthodes BACANAL simples sur lesquelles elles reposent (ex :"]},{"title":"θ","paragraphs":["8 /"]},{"title":"θ","paragraphs":["5 et"]},{"title":"θ","paragraphs":["9 /"]},{"title":"θ","paragraphs":["2).","Comme la plupart des méthodes de l’état de l’art, les évaluations oot de toutes les méthodes ayant concourues à la tâche 1","de Semdis14 sont inférieurs à 50% :"]},{"title":"θ","paragraphs":["9 la meilleurs méthode selon les évaluations de Semdis14 obtient un oot égal à 0.4017. Obtenir un rappel élevé au rang 10 lors d’une tâche de substitution lexicale face à un gold construit à « à la main » semble donc être difficile. Nous avons aussi amorcé une comparaison entre les méthodes par marche aléatoire courte et les méthodes par réduction de dimension et montré que les méthodes par réduction de dimension sont semblables aux méthodes BACANAL à condition que le choix de k soit bien adapté à la ressource. Un des avantages des méthodes BACANAL est que leur complexité est proportionnelle à la densité des graphes utilisés : une marche de temps t à partir d’un sommet quelconque d’un graphe de m arêtes se calcule avec une complexité O(mt) (Navarro, 2013). Ainsi, la complexité des méthodes BACANAL sur des réseaux peu denses en arêtes telles que les réseaux lexicaux est faible. De plus, si les graphes sont trop larges, les méthodes de Monté-Carlo 23","peuvent facilement être utilisées pour calculer une approximation des marches aléatoires en temps court. Toutefois, pour une tâche de substitution lexicale libre comme la tâche 1 de SemDis2014, la taille des graphes n’est pas le critère essentiel. En effet la qualité linguistique de ces graphes semble primer. Par exemple, les tableaux 2 et 3 montrent que les différences de résultats obtenus par les méthodes"]},{"title":"θ","paragraphs":["4 = θ (Glm10, {ω}, 2) (best = .0259 & oot = .1347) et"]},{"title":"θ","paragraphs":["5 = θ (G f rwac, {ω}, 2) (best = .0319 & oot = .0799) ne sont pas liées à des différences de taille entre graphes utilisés, mais à des différences qualitatives entre les ressources sur lesquelles elles sont construites."]},{"title":"7 Remerciements","paragraphs":["Nous remercions les organisateurs de SemDis2014 pour avoir proposé cette tâche et développé le matériel nécessaires aux évaluations. Nous remercions Franck Sajous et Assaf Urielli pour les nombreuses discussions toujours enrichissantes que nous avons eu ensemble et pour tous les pré-traitements sur les ressources que nous avons utilisées dans cet article (accessibles pour la plupart sur http://redac.univ-tlse2.fr/)."]},{"title":"Références","paragraphs":["ABEILLÉ A., CLÉMENT L. & TOUSSENEL F. (2003). Building a treebank for French. In A. ABEILLÉ, Ed., Treebanks, p. 165–188. Dordrecht : Kluwer. BARONI M., BERNARDINI S., FERRARESI A. & ZANCHETTA E. (2009). The wacky wide web : a collection of very large linguistically processed web-crawled corpora. In Proceedings of the Seventh International Language Resources and Evaluation (LREC’09), volume 43(3), p. 209–226. BRIN S. & PAGE L. (1998). The anatomy of a large-scale hypertextual web search engine. Computer Networks, 30(1-7), 107–117. CRABBÉ B. & CANDITO M. (2008). Expériences d’analyses syntaxique statistique du français. In Actes de la conférence TALN2008, Avignon, France. DAHL G., FRASSICA A. & WICENTOWSKI R. (2007). SW-AG : Local context matching for english lexical substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 304–307, Prague, Czech Republic. DESALLE Y. (2012). Réseaux lexicaux, métaphore, acquisition : une approche interdisciplinaire et inter-linguistique du lexique verbal. PhD thesis, Université de Toulouse. DESALLE Y., GAUME B. & DUVIGNAU K. (2009). SLAM : Solutions lexicales automatique pour métaphores. Traitement Automatique des Langues, 50(1), 145–175. DINU G. & LAPATA M. (2010). Measuring distributional similarity in context. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, p. 1162–1172, Cambridge, MA. ERK K. & PADÓ S. (2009). Paraphrase assessment in structured vector space : Exploring parameters and datasets. In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics, p. 57–67, Athens, Greece. 23. http://fr.wikipedia.org/wiki/Methode_de_Monte-Carlo"]},{"title":"[SemDis-O.2] 217","paragraphs":["YANN DESALLE, EMMANUEL NAVARRO, YANNICK CHUDY, PIERRE MAGISTRY, BRUNO GAUME ERK K. & PADÓ S. (2010). Exemplar-Based Models for Word Meaning in Context. In Proceedings of the ACL 2010 Conference Short Papers, p. 92–97, Uppsala, Sweden. C. FELLBAUM, Ed. (1998). WordNet : An Electronic Lexical Database. MIT Press. GAUME B. (2004). Balades Aléatoires dans les Petits Mondes Lexicaux. I3 : Information Interaction Intelligence, 4(2). GIULIANO C., GLIOZZO A. & STRAPPARAVA C. (2007). FBK-irst : Lexical substitution task exploiting domain and syntagmatic coherence. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 145–148, Prague, Czech Republic. HASSAN S., CSOMAI A., BANEA C., SINHA R. & MIHALCEA R. (2007). UNT : Subfinder : Combining knowledge sources for automatic lexical substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 410–413, Prague, Czech Republic. HAWKER T. (2007). USYD : WSD and lexical substitution using the web1t corpus. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 446–453, Prague, Czech Republic. LAFOURCADE M. (2007). Making People Play for Lexical Acquisition with the JeuxDeMots prototype. In SNLP’07 : 7th Int. Symposium on NLP, Pattaya, Thailand. LUX-POGODALLA V. & POLGUÈRE A. (2011). Construction of a french lexical network : Methodological issues. In Proceedings of the International Workshop on Lexical Resources (WoLeR 2011), p. 21–27, Ljubljana. MANNING C. D., RAGHAVAN P. & SCHÜTZE H. (2008). Introduction to Information Retrieval. Cambridge University Press. MARTINEZ D., KIM S. & BALDWIN T. (2007). MELB-MKB : Lexical substitution system based on relatives in context. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 237–240, Prague, Czech Republic. MCCARTHY D. (2002). Lexical substitution as a task for WSD evaluation. In Proceedings of the ACL-02 Workshop on Word Sense Disambiguation : Recent Successes and Future Directions - Volume 8, p. 109–115, Philadelphia, PA : WSD-02. MCCARTHY D. & NAVIGLI R. (2007). SemEval-2007 Task 10 : English Lexical Substitution Task. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 109–115, Philadelphia, PA : WSD-02. MCCARTHY D. & NAVIGLI R. (2009). The english lexical substitution task. Language Resources and Evaluation, 43, 139–159. MOHAMMAD S., HIRST G. & RESNIK P. (2007). Tor, TorMd : Distributional profiles of concepts for unsupervised word sense disambiguation. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 226–233, Prague, Czech Republic. NAVARRO E. (2013). Métrologie des graphes de terrain, application à la construction de ressources lexicales et à la recherche d’information. PhD thesis, Université de Toulouse. SAGOT B., CLÉMENT L., ÉRIC VILLEMONTE DE LA CLERGERIE & BOULLIER P. (2006). The Lefff 2 syntactic lexicon for French : architecture, acquisition. In Proceedings of LREC’06, Gênes, Italie. SHUTOVA E. (2010). Automatic metaphor interpretation as a paraphrasing task. In Proceedings of NAACL 2010, Los Angeles, USA. SHUTOVA E., VAN DE CRUYS T. & KORHONEN A. (2012). Unsepervised metaphor paraphrasing using vector space model. In Proceedings of COLING 2012, Mumbai, India. THATER S., FERSTENAU H. & PINKAL M. (2010). Contextualizing semantic representations using syntactically en-riched vector models. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, p. 948–957, Uppsala, Sweden. URIELI A. (2013). Robust French syntax analysis : reconciling statistical methods and linguistic knowledge in the Talismane toolkit. Thése soutenue à l’université de Toulouse - école doctorale CLESCO. VAN DE CRUYS T., POIBEAU T. & KORHONEN A. (2011). Latent Vector Weighting for Word Meaning in Context. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, p. 1012–1022, Edinburgh, UK. YURET D. (2007). KU : Word Sense Disambiguation by Substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 207–214, Prague, Czech Republic. ZHAO S., ZHAO L., ZHANG Y., LIU T. & LI S. (2007). HIT : Web based scoring method for English lexical substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), p. 173–176, Prague, Czech Republic."]}]}
