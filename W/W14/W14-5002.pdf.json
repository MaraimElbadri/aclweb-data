{"sections":[{"title":"","paragraphs":["Proceedings of the INLG and SIGDIAL 2014 Joint Session, pages 6ê15, Philadelphia, Pennsylvania, 19 June 2014. c⃝2014 Association for Computational Linguistics"]},{"title":"Generating effective referring expressions using charts Nikos Engonopoulos and Alexander Koller University of Potsdam, Germany {engonopo|akoller}@uni-potsdam.de Abstract","paragraphs":["We present a novel approach for generating effective referring expressions (REs). We deûne a synchronous grammar formalism that relates surface strings with the sets of objects they describe through an abstract syntactic structure. The grammars may choose to require or not that REs are distinguishing. We then show how to compute a chart that represents, in ûnite space, the complete (possibly inûnite) set of valid REs for a target object. Finally, we propose a probability model that predicts how the listener will understand the RE, and show how to compute the most effective RE according to this model from the chart."]},{"title":"1 Introduction","paragraphs":["The fundamental challenge in the generation of referring expressions (REG) is to compute an RE which is effective, i.e. understood as intended by the listener. Throughout the history of REG, we have approximated this as the problem of generating distinguishing REs, i.e. REs that are only satis- ûed by a unique individual in the domain. This has been an eminently successful approach, as documented e.g. in the overview article of Krahmer and van Deemter (2012) and a variety of recent shared tasks involving RE generation (Gatt and Belz, 2010; Belz et al., 2008; Koller et al., 2010).","Nonetheless, reducing effectiveness to uniqueness is limiting in several ways. First, in complex, real-world scenes it may not be feasible to generate fully distinguishing REs, or these may have to be exceedingly complicated. It is also not necessary to generate distinguishing REs in such situations, because listeners are very capable of taking the discourse and task context into account to resolve even ambiguous REs. Conversely, listeners can misunderstand even a distinguishing RE, so uniqueness is no guarantee for success. We propose instead to deûne and train a probabilistic RE resolution model P (a|t), which directly captures the probability that the listener will resolve a given RE t to some object a in the domain. An RE t will then be ígood enoughì if P (a∗","|t) is very high for the intended target referent a∗",".","Second, in an interactive setting like the GIVE Challenge (Koller et al., 2010), the listener may behave in a way that offers further information on how they resolved the generated RE. Engonopoulos et al. (2013) showed how an initial estimate of the distribution P (a|t) can be continuously updated based on the listenerïs behavior, and that this can improve a systemïs ability to detect misunderstandings. It seems hard to achieve this in a principled way without an explicit model of P (a|t).","In this paper, we present an algorithm that generates the RE t that maximizes P (a∗","|t), i.e. the RE that has the highest chance to be understood correctly by the listener according to the probabilistic RE resolution model. This is a challenging problem, since the algorithm must identify that RE from a potentially inûnite set of valid alternatives. We achieve this by using a chart-based algorithm, a standard approach in parsing and realization, which has (to our knowledge) never been used in REG.","We start by deûning a synchronous grammar formalism that relates surface strings to their interpretations as sets of objects in a given domain (Section 3). This formalism integrates REG with surface realization, and allows us to specify in the grammar whether REs are required to be distinguishing. We then show how to compute a chart for a given grammar and target referent in Section 4. Section 5 deûnes a log-linear model for P (a|t), and presents a Viterbi-style algorithm for computing the RE t from the chart that maximizes P (a∗","|t). Section 6 concludes by discussing how to apply our algorithm to the state-of-the-art approaches of Krahmer et al. (2003) and Golland et al. (2010), and how to address a particular challenge involving cycles that arises when dealing 6 with probabilistic listener models."]},{"title":"2 Related Work","paragraphs":["RE generation is the task of generating a natural-language expression that identiûes an object to the listener. Since the beginnings of modern REG (Appelt, 1985; Dale and Reiter, 1995), this problem has been approximated as generating a distinguishing description, i.e. one which ûts only one object in the domain and not any of the others. This perspective has made it possible to apply search-based (Kelleher and Kruijff, 2006), logic-based (Areces et al., 2008) and graph-based (Krahmer et al., 2003) methods to the problem, and overall has been one of the success stories of NLG.","However, in practice, human speakers frequently overspecify, i.e. they include information in an RE beyond what is necessary to make it distinguishing (Wardlow Lane and Ferreira, 2008; Koolen et al., 2011). An NLG system, too, might include redundant information in an RE to make it easier to understand for the user. Conversely, an RE that is produced by a human can often be easily resolved by the listener even if it is ambiguous. Here we present an NLG system that directly uses a probabilistic model of RE resolution, and is capable of generating ambiguous REs if it predicts that the listener will understand them.","Most existing REG algorithms focus on generating distinguishing REs, and then select the one that is best according to some criterion, e.g. most human-like (Krahmer et al., 2003; FitzGerald et al., 2013) or most likely to be understood (Garouû and Koller, 2013). By contrast, Mitchell et al. (2013) describe a stochastic algorithm that computes human-like, non-relational REs that may not be distinguishing. Golland et al. (2010) are close to our proposal in spirit, in that they use a log-linear probability model of RE resolution to compute a possibly non-distinguishing RE. However, they use a trivial REG algorithm which is limited to grammars that only permit a (small) ûnite set of REs for each referent. This is in contrast to general REG, where there is typically an inûnite set of valid REs, especially when relational REs (íthe button to the left of the plantì) are permitted.","Engonopoulos et al. (2013) describe how to update an estimate for P (a|t) based on a log-linear model based on observations of the listenerïs be-havior. They use a shallow model based on a string t and not an RE derived from a grammar, and they do not discuss how to generate the best t. The algorithm we develop here ûlls this gap.","Our formalism for REG can be seen as a synchronous grammar formalism; it simultaneously derives strings and their interpretations, connect-ing the two by an abstract syntactic representa-tion. This allows performing REG and surface realization with a single algorithm, along the lines of SPUD (Stone et al., 2003) and its planning-based implementation, CRISP (Koller and Stone, 2007). Probabilistic synchronous grammars are widely used in statistical machine translation (Chiang, 2007; Graehl et al., 2008; Jones et al., 2012) and semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007). Lu and Ng (2011) have applied such grammars to surface realization. Konstas and Lapata (2012) use related techniques for content selection and surface realization (with simple, non-recursive grammars).","Charts are standard tools for representing a large space of possible linguistic analyses compactly. Next to their use in parsing, they have also been applied to surface realization (Kay, 1996; Carroll et al., 1999; Kaplan and Wedekind, 2000). To our knowledge, ours is the ûrst work using charts for REG. This is challenging because the input to REG is much less structured than in parsing or realization."]},{"title":"3 Grammars for RE generation","paragraphs":["We deûne a new grammar formalism that we use for REG, which we call semantically intepreted grammar (SIG). SIG is a synchronous grammar formalism that relates natural language strings with the sets of objects in a given domain which they describe. It uses regular tree grammars (RTGs) to describe languages of derivation trees, which then project to strings and sets. 3.1 Derivation trees We describe the abstract syntax of an RE by its derivation tree, which is a tree over some ranked signature Σ of symbols representing lexicon entries and grammatical constructions. A (ranked) signature is a ûnite set of symbols r ∈ Σ, each of which is assigned an arity ar(r) ∈ N0. A tree over the signature Σ is a term r(t1,...,tn), where r ∈ Σ, n = ar(r), and t1,...,tn are trees over Σ. We write TΣ for the set of all trees over Σ.","Fig. 1b shows an example derivation tree for the RE íthe square buttonì over the signature Σ={def |1, square|1, button|0}, where r|n indicates that the symbol r has arity n. In term nota-7 (a) (b) (c) {b2}","IR ←−−−−−− def square button","IS −− −→ íthe square buttonì   ∩1 square button        ¬• the ¬• square button      Figure 1: A SIG derivation tree (b) with its interpretations (a, c). tion, it is def (square(button)). String interpretation. We interpret derivation trees simultaneously as strings and sets. First, let ∆ be a ûnite alphabet, and let ∆∗","be the string algebra over ∆. We deûne a string interpretation over ∆ as a function IS that maps each r|n ∈ Σ to a function IS(r):(∆∗",")n","→ ∆∗",". For instance, we can assign string interpretations to our example signature Σ as follows; we write w1 ¬• w2 for the concatenation of the strings w1 and w2. IS(def )(w1)=the ¬• w1","IS(square)(w1)=square ¬• w1","IS(button)=button","Since the arity of IS(r) is the same as the arity of r for any r ∈ Σ, we can use IS to recursively map derivation trees to strings. Starting at the leaves, we map the tree r(t1,...,tn) to the string IS(r)(IS(t1),...,IS(tn)), where IS(ti) is the string that results from recursively applying IS to the subtree ti. In the example, the subtree button is mapped to the string íbuttonì. We then get the string for the subtree square(button) by concatenating this with ísquareì, obtaining the string ísquare buttonì and so on, as shown in Fig. 1c. Relational interpretation. We further deûne a relational interpretation IR, which maps each r|n ∈ Σ to a function IR(r):R(U )n","→ R(U ), where R(U ) is a class of relations. We deûne IR over some ûrst-order model structure M = ⟨U, L⟩, where U is a ûnite universe U of individuals and L interprets a ûnite set of predicate symbols as relations over U . We let R(U ) be the set of all k-place relations over U for all k ≥ 0. The subsets of U are the special case of k =1. We write k(R) for the arity of a relation R ∈ R(U ).","For the purposes of this paper, we construct IR by combining the following operations:","¬• The denotations of the atomic predicate sym-","bols of M ; see Fig. 2 for an example. U = {b1,b2,b3} button = {b1,b2,b3} round = {b1,b3} square = {b2} left of = {⟨b1,b2⟩, ⟨b2,b3⟩} right of = {⟨b2,b1⟩, ⟨b3,b2⟩} Figure 2: A simple model, illustrated as a graph. ¬• proji(R)={ai |⟨a1,...,ak(R)⟩∈R} is","the projection to the i-th component; if i>","k(R), it evaluates to ∅. ¬• R1 ∩i R2 = {⟨a1,...,ak(R1)⟩∈R1 | ai ∈","R2} is the intersection on the i-th component","of R1; if i>k(R1), it evaluates to ∅. ¬• For any a ∈ U , uniqa(R) evaluates to {a} if","R = {a}, and to ∅ otherwise. ¬• For any a ∈ U , membera(R) evaluates to","{a} if a ∈ R, and to ∅ otherwise. For the example, we assume that we want to","generate REs over the scene shown in Fig. 2; it","consists of the universe U = {b1,b2,b3} and inter-","prets the atomic predicate symbols button, square,","round, left of, and right of. Given this, we can","assign a relational interpretation to the derivation","tree in Fig. 1b using the following mappings: IR(def )(R1)=R1","IR(square)(R1)=square ∩1 R1","IR(button)=button","We evaluate a derivation tree to a relation as we did for strings (cf. Fig. 1a). The subtree button maps to the denotation of the symbol button, i.e. {b1,b2,b3}. The subtree square(button) evaluates to the intersection of this set with the set of square individuals, i.e. {b2}; this is also the relational interpretation of the entire derivation tree. We thus see that íthe square buttonì is an RE that describes the individual b2 uniquely. 3.2 Semantically interpreted grammars Now we deûne grammars that describe relations between strings and relations over U . We achieve this by combining a regular tree grammar (RTG, (G¬écseg and Steinby, 1997; Comon et al., 2007)), describing a language of derivation trees, with a string interpretation and a relational interpretation. An RTG G =(N, Σ,S,P) consists of a ûnite set N of nonterminal symbols, a ranked signature Σ, a start symbol S ∈ N , and a ûnite set P of production rules A → r(B1,...,Bn), where 8 A, B1,...,Bn ∈ N and r|n ∈ Σ. We say that a tree t2 ∈ TΣ can be derived in one step from t1 ∈ TΣ, t1 ⇒ t2, if it can be obtained by replac-ing an occurrence of B in t1 with t and P contains the rule B → t. A tree tn ∈ TΣ can be derived from t1, t1 ⇒∗","t","n, if there is a sequence t1 ⇒ ... ⇒ tn of length n ≥ 0. For any nonterminal A, we write LA(G) for the set of trees t ∈ TΣ with A ⇒∗","t. We simply write L(G) for L S(G) and call it the language of G.","We deûne a semantically interpreted grammar (SIG) as a triple G =(G, IS, IR) of an RTG G over some signature Σ, together with a string interpretation IS over some alphabet ∆ and a relational interpretation IR over some universe U , both of which interpret the symbols in Σ. We assume that every terminal symbol r ∈ Σ occurs in at most one rule, and that the nonterminals of G are pairs Ab of a syntactic category A and a semantic index b = ix(Ab). A semantic index indicates the individual in U to which a given constituent is meant to refer, see e.g. (Kay, 1996; Stone et al., 2003). Note that SIGs can be seen as speciûc Interpreted Regular Tree Grammars (Koller and Kuhlmann, 2011) with a set and a string interpretation.","We ignore the start symbol of G. Instead, we say that given some individual b ∈ U and syntactic category A, the set of referring expressions for b is REG(A, b)={t ∈ LAb (G) |IR(t)={b}}, i.e. we deûne an RE as a derivation tree that G can derive from Ab and whose relational interpretation is {b}. From t, we can read off the string IS(t).1 3.3 An example grammar Consider the SIG G in Fig. 3 for example. The grammar is written in template form. Each rule is instantiated for all semantic indices speciûed in the line above; e.g. the symbol round denotes the set {b1,b3}, therefore there are rules Nb1 → roundb1(Nb1) and Nb3 → roundb3(Nb3). The values of IR and IS for each symbol are speciûed below the RTG rule for that symbol.","We can use G to generate NPs that refer to the target referent b2 given the model shown in Fig. 2 by ûnding trees in LNPb","2 (G) that refer to {b2}. One such tree is t1 = def b2(squareb2(buttonb2)), a more detailed version of the tree in Fig. 1b. It can be derived by NPb2 ⇒ def b2(Nb2) ⇒ def b2(squareb2(Nb2)) ⇒ t1. Because IR(t1)= {b2}, we see that t1 ∈ REG(NP,b2); it represents 1 Below, we will often write the RE as a string when the","derivation tree is clear. for all a ∈ U: NPa → def a(Na) IS(def a)(w1)=the ¬• w1 IR(def a)(R1)=membera(R1) for all a ∈ button: Na → buttona IS(buttona)=button IR(buttona)=button for all a ∈ round: Na → rounda(Na) IS(rounda)(w1)=round ¬• w1 IR(rounda)(R1)=round ∩1 R1 for all a ∈ square: Na → squarea(Na) IS(squarea)(w1)=square ¬• w1 IR(squarea)(R1)=square ∩1 R1 for all a, b ∈ left of: Na → leftof a,b(Na, NPb) IS(leftof a,b)(w1,w2)=w1 ¬• to ¬• the ¬• left ¬• of ¬• w2 IR(leftof a,b)(R1,R2)=proj1((left of ∩1 R1) ∩2 R2) for all a, b ∈ right of: Na → rightof a,b(Na, NPb) IS(rightof a,b)(w1,w2)=w1 ¬• to ¬• the ¬• right ¬• of ¬• w2 IR(rightof a,b)(R1,R2)=proj1((right of ∩1 R1) ∩2 R2) Figure 3: An example SIG grammar. the string IS(t1)=íthe square buttonì.","A second derivation tree for b2 is t2 = def b2(squareb2(squareb2(buttonb2))), correspond-ing to IS(t2)=íthe square square buttonì. It derives from NPb2 in four steps, and has IR(t2)= {b2}. Even the small grammar G licences an inû- nite set of REs for b2, all of which are semantically correct. Avoiding the generation of nonsensical REs like íthe square square buttonì is a technical challenge to which we will return in Section 6. G can also derive relational REs; for instance, the derivation tree in Fig. 6 for the string íthe button to the left of the square buttonì is in REG(NP,b1).","Finally, G considers the non-distinguishing t3 = def b2(buttonb2) (for íthe buttonì) a valid RE for b2. This is because memberb2 will quietly project the set {b1,b2,b3} (to which buttonb2 refers) to {b2}. As discussed in previous sections, we want to allow such non-unique REs and delegate the judgment about their quality to the probability model. It would still be straightforward, however, to impose a hard uniqueness constraint, by simply changing IR(def a)(R1) to uniqa(R1) in Fig. 3. This would yield IR(t3)=∅, i.e. t3 would no longer be in REG(NP,b2)."]},{"title":"4 Chart-based RE generation","paragraphs":["We now present a chart-based algorithm for generating REs with SIG grammars. Charts allow us to represent all REs for a target referent compactly, and can be computed efûciently. We show in Section 5 that charts also lend themselves well to computing the most effective RE. 9","Nb","1/{b1,b2,b3}→buttonb","1","Nb","2/{b1,b2,b3}→buttonb","2","Nb","3/{b1,b2,b3}→buttonb","3","Nb","1/{b1,b3}→roundb","1(Nb","1/{b1,b2,b3})","Nb","3/{b1,b3}→roundb","3(Nb","3/{b1,b2,b3})","Nb","1/{b1,b3}→roundb","1(Nb","1/{b1,b3})","Nb","3/{b1,b3}→roundb","3(Nb","3/{b1,b3})","Nb","2/{b2}→squareb 2(Nb","2/{b1,b2,b3})","Nb","2/{b2}→squareb 2(Nb","2/{b2})","NPb","2/{b2}→def b","2(Nb","2/{b1,b2,b3})","NPb","2/{b2}→def b","2(Nb","2/{b2})","Nb","1/{b1}→leftof b 1,b 2(Nb","1/{b1,b2,b3}, NPb","2/{b2})","Nb","1/{b1}→leftof b 1,b 2(Nb","1/{b1,b3}, NPb","2/{b2})","Nb","1/{b1}→leftof b 1,b 2(Nb","1/{b1}, NPb","2/{b2})","Nb","1/{b1}→roundb 1(Nb","1/{b1})","NPb","1/{b1}→def b","1(Nb","1/{b1,b2,b3})","NPb","1/{b1}→def b","1(Nb","1/{b1,b3})","NPb","1/{b1}→def b","1(Nb","1/{b1})","Nb","3/{b3}→rightof b 3,b","2(Nb","3/{b1,b2,b3}, NPb","2/{b2})","Nb","3/{b3}→rightof b 3,b","2(Nb","3/{b1,b3}, NPb","2/{b2})","Nb","3/{b3}→rightof b 3,b","2(Nb","3/{b3}, NPb","2/{b2})","Nb","3/{b3}→roundb 3(Nb","3/{b3})","NPb","3/{b3}→def b","3(Nb","3/{b1,b2,b3})","NPb","3/{b3}→def b","3(Nb","3/{b1,b3})","NPb","3/{b3}→def b","3(Nb","3/{b3})","Nb","2/{b2}→leftof b 2,b 3(Nb","2/{b1,b2,b3}, NPb","3/{b3})","Nb","2/{b2}→rightof b 2,b","1(Nb","2/{b1,b2,b3}, NPb","1/{b1})","Nb","2/{b2}→leftof b 2,b 3(Nb","2/{b2}, NPb","3/{b3})","Nb","2/{b2}→rightof b 2,b","1(Nb","2/{b2}, NPb","1/{b1}) Figure 4: The chart for the grammar in Fig. 3. 4.1 RE generation charts Generally speaking, a chart is a packed data structure which describes how larger syntactic representations can be recursively built from smaller ones. In applications such as parsing and surface realization, the creation of a chart is driven by the idea that we consume some input (words or semantic atoms) as we build up larger structures. The parallel to this intuition in REG is that ílargerì chart entries are more precise descriptions of the target, which is a weaker constraint than input consumption. Nonetheless, we can deûne REG charts whose entries are packed representations for large sets of possible REs, and compute them in terms of these entries instead of RE sets.","Technically, we represent charts as RTGs over an extended set of nonterminals. A chart for generating an RE of syntactic category A for an individual b ∈ U is an RTG C =(N ′",", Σ,S′",",P′","), where N ′","⊆ N × R(U ) and S′","= Ab/{b}. Intuitively, the nonterminal Ab/{a1,...,an} expresses that we intend to generate an RE for b from A, but each RE that we can derive from the nonterminal actually denotes the referent set {a1,...,an}.","A chart for the grammar in Fig. 3 is shown in Fig. 4. To generate an NP for b2, we let its start symbol be S′","= NP","b2/{b2}. The rule Nb2/{b1,b2,b3}→buttonb2 says that we can generate an RE t with IR(t)={b1,b2,b3} from the nonterminal symbol Nb2 by expanding this symbol with the grammar rule Nb2 → buttonb2. Similarly, A → r(B1,...,Bn) in G","B′","1 = B1/R1,...,B′","n = Bn/Rn in N′","Add A′","= A/IR(r)(R1,...,Rn) to N′","Add rule A′ → r(B′","1,...,B′","n) to P ′ Figure 5: The chart computation algorithm. the rule Nb2/{b2}→squareb2(Nb2/{b1,b2,b3}) expresses that we can generate an RE with IR(t)={b2} by expanding the nonterminal symbol Nb2 into squareb2(t′","), where t′","is any tree that the chart can generate from Nb2/{b1,b2,b3}. 4.2 Computing a chart Given a SIG G, a syntactic category A, and a target referent b, we can compute a chart C for REG(A, b) using the parsing schema in Fig. 5. The schema assumes that we have a rule A → r(B1,...,Bn) in G; in addition, for each 1 ≤ i ≤ n it assumes that we have already added the nonterminal B′","i =Bi/Ri to the chart, in-dicating that there is a tree ti with Bi ⇒∗","t","i and IR(ti)=Ri. Then we know that t = r(t1,...,tn) can be derived from A and that R′","= IR(t)=IR(r)(R1,...,Rn). We can therefore add the nonterminal A′","= A/R′","and the production rule A′","→ r(B′","1,...,B′","n) to the chart; this rule can be used as the ûrst step in a derivation of t from A′",". We can optimize the algorithm by adding A′","and the rule only if R′","̸= ∅.","The algorithm terminates when it can add no more rules to the chart. Because U is ûnite, this always happens after a ûnite number of steps, even if there is an inûnite set of REs. For instance, the chart in Fig. 4 describes an inûnite language of REs, including íthe square buttonì, íthe button to the left of the round buttonì, íthe button to the left of the button to the right of the square buttonì, etc. Thus it represents relational REs that are nested arbitrarily deeply through a ûnite number of rules.","After termination, the chart contains all rules by which a nonterminal can be decomposed into other (productive) nonterminals. As a result, L(C) contains exactly the REs for b of category A: Theorem 1 If C is a chart for the SIG G, the syntactic category A, and the target referent b, then L(C)=REG(A, b)."]},{"title":"5 Computing best referring expressions","paragraphs":["The chart algorithm allows us to compactly represent all REs for the target referent. We now show how to compute the best RE from the chart. We present a novel probability model P (b|t) for RE resolution, and take the íbestì RE to be the 10 Figure 6: The derivation tree for íthe button to the left of the square buttonì. one with the highest chance to be understood as intended. Next to the best RE itself, the algorithm also computes the entire distribution P (b|t), to support later updates in an interactive setting.","Nothing in our algorithm hinges on this particular model; it can also be used with any other scoring model that satisûes a certain monotonicity condition which we spell out in Section 5.2. 5.1 A log-linear model for effective REs We model the probability P (b|t) that the listener will resolve the RE t to the object b using a log-linear model with a set of feature functions f (a, t, M ), where a is an object, t is a derivation tree, and M is the relational interpretation model.","We focus on features that only look at information that is local to a speciûc subtree of the RE, such as the label at the root. For instance, a feature fround(a, t′",",M) might return 1 if the root label of t′","is round","a and a is round in M , and 0 otherwise.","Another feature fdef (a, t′",",M) might return 1/k if","t′ is of the form def","b(t′′ ), R = I","R(t′′",") has k elements, and a ∈ R; and 0 otherwise. This feature counterbalances the ability of the grammar in Fig. 3 to say íthe wì even when w is a non-unique description by penalizing descriptions with many possible referents through lower feature values.","When generating a relational RE, the derivation tree naturally splits into separate regions, each of which is meant to identify a speciûc object. These regions are distinguished by the semantic indices in the nonterminals that derive them; e.g., in Fig. 6, the subtree for íthe square buttonì is an attempt to refer to b2, whereas the RE as a whole is meant to refer to b1. To ûnd out how effective the RE is as a description of b1, we evaluate the features at all nodes in the region top(t) containing the root of t.","Each feature function fi is associated with a weight wi. We obtain a score tuple sc(t′",") for some subtree t′","of an RE as follows:","sc(t′ )=⟨s(a","1,t′ ,M),...,s(a","m,t′ ,M)⟩, t b1 b2 b3 íthe buttonì 0.33 0.33 0.33 íthe round buttonì 0.45 0.10 0.45 íthe button to the left of the square buttonì 0.74 0.14 0.12 Figure 7: Probability distributions for some REs t.","where U = {a1,...,am} and s(a, t′",",M)=∑n i=1 wi ° fi(a, t′",",M). We then combine these","into a score tuple score(t)=∑","u∈top(t) sc(t.u) for the whole RE t, where t.u is the subtree of t below the node u. Finally, given a score tuple s = ⟨s1,...,sm⟩ for t, we deûne the usual log-linear probability distribution as P (ai|t)=prob(ai, s)= esi","∑m j=1 esj . The best RE for the target referent b is then","bestG(A, b) = arg max t∈REG(A,b) prob(b, sc(t)).","For illustration, we consider a number of REs for b1 in our running example. We use fround and fdef and let wround = wdef =1. In this case, the RE íthe buttonì has a score tuple ⟨1/3, 1/3, 1/3⟩, which is the sum of the tuple ⟨0, 0, 0⟩ for fround (since the RE does not use the íroundì rule) and the tuple ⟨1/3, 1/3, 1/3⟩ for fdef (since íbuttonì is three-way ambiguous in M ). This yields a uni-form probability distribution over U (see Fig. 7). By contrast, íthe round buttonì gets ⟨3/2, 0, 3/2⟩, resulting in the distribution in the second line of Fig. 7. This RE is judged better than íthe buttonì because it assigns a higher probability to b1.","Relational REs involve derivation trees with multiple regions, only the top one of which is directly counted for P (b|t) (see Fig. 6). We incorporate the quality of the other regions through appropriate features. In the example, we use a feature fleftof (a, t′",",M)=∑","b:⟨a,b⟩∈left of P (b|t′′","), where","t′′ is the second subtree of t′",". This feature com-","putes the probability that the referent to which the","listener resolves t′′","is actually to the right of a,","and will thus take a high value if t′′","is a good","RE for b2. Assuming a probability distribution of","P (b2|t′",")=0.78 and P (b","1|t′ )=P (b","3|t′",")=0.11","for t′","=íthe square buttonì, we get the tuple","⟨0.78, 0.11, 0⟩ for fleftof , yielding the third line","of Fig. 7 for wleftof =1. 11 5.2 Computing the best RE We compute bestG(A, b) from the chart by adapt-ing the Viterbi algorithm. Our key data structure assigns a score tuple is(A′",") to each nonterminal A′","in the chart. Intuitively, if the semantic index of A′","is b, then is(A′",") is the score tuple sc(t) for the tree t ∈ LA′ (C) which maximizes P (b|t).We also record this best tree as bt(A′","). Thus the algorithm is correct if, after running it, we obtain bestG(A, b)=bt(Ab/{b}).","As is standard in chart algorithms, we limit our attention to features whose values can be computed bottom-up by local operations. Speciûcally, we assume that if A′","→ r(B′","1,...,B′","n) is a rule in","the chart and ti is the best RE for B′","i for all i, then","the best RE for A′","that can be built using this rule","is r(t1,...,tn). This means that features must be","monotonic, i.e. that the RE that seemed locally","best for B′","i leads to the best RE overall.","Under this assumption, we can compute is(A′",")","and bt(A′",") bottom-up as shown in Fig. 8. We it-","erate over all nonterminals A′","in the chart in a","ûxed linear order, which we call the evaluation","order. Then we compute is(A′",") and bt(A′",") by","maximizing over the rules for A′",". Assume that","the best RE for A′","can be constructed using the","rule A′","→ r(B′","1,...,B′ n). Then if, at the time we","evaluate A′",", we have fully evaluated all the B′","i in","the sense that bt(B′ i) is actually the best RE for B′","i, the algorithm will assign the best RE for A′ to bt(A′","), and its score tuple to is(A′","). Thus, if we call an evaluation order exact if the nonterminals on the right-hand side of each rule in the chart come before the nonterminal on the left-hand side, we can inductively prove the following theorem: Theorem 2 If the evaluation order is exact, then for every nonterminal A′","in the chart, we obtain bt(A′",") = arg max","t∈LA′ (C) P (ix(A′ )|t) and","is(A′ )=sc(bt(A′",")).","In other words, the algorithm is correct if the evaluation order is exact. If it is not, we might compute a sub-optimal RE as bt(A′","), which underestimates is(A′","). The choice of evaluation order is thus crucial."]},{"title":"6 Evaluating charts with cycles","paragraphs":["It remains to show how we can determine an exact evaluation order for a given chart. One way to think about the problem is to consider the ordering graph O(C) of the chart C (see Fig. 9 for an example). This is a directed graph whose nodes","1: for nonterminals A′","in evaluation order do","2: for rules r of the form A′","→ r(B′","1,...,B′","n) do","3: a = ix(A′",")","4: t′","= r(bt(B′","1),...,bt(B′","n))","5: s = sc(t′ )+ n ∑ i=1","ix(B′ i)=a","is(B′ i)","6: if prob(a, s) > prob(a, is(A′",")) then","7: is(A′ )=s","8: bt(A′ )=t′ Figure 8: Computing the best RE.","are the nonterminals of the chart; for each rule","A′ → r(B′","1,...,B′","n) in C, it has an edge from B′","i to A′","for each i. If this graph is acyclic, we can simply compute a topological sort of O(C) to bring the nodes into a linear order in which each B′","i precedes A′",". This is enough to evaluate charts using certain simpler models. For in-stance, we can apply our REG algorithm to the log-linear model of Golland et al. (2010). Because they only generate REs with a bounded number of relations, their grammars effectively only describe ûnite languages. In such a case, our charts are always acyclic, and therefore a topological sort of O(C) yields an exact evaluation order.","This simple approach will not work with grammars that allow arbitrary recursion, as they can lead to charts with cycles (indicating an inûnite set of valid REs). E.g. the chart in Fig. 4 contains a rule Nb2/{b2}→squareb2(Nb2/{b2}) (shown in Fig. 9), which can be used to construct the RE t′","= íthe square square buttonì in addition to the RE t = íthe square buttonì. Such cycles can be increasing with respect to a log-linear probability model, i.e. the model considers t′","a better RE than t. Indeed, t has a score tuple of ⟨0, 2, 0⟩, giving P (b2|t)=0.78. By contrast, t′","has a score tuple of ⟨0, 3, 0⟩, thus P (b2|t′",")=0.91. This can be continued indeûnitely, with each addition of ísquareì increasing the probability of being resolved to b2. Thus, there is no best RE for b2; every RE can be improved by adding another copy of ísquareì.","In such a situation, it is a challenge to even compute any score for every nonterminal without running into inûnite loops. We can achieve this by decomposing O(C) into its strongly connected components (SCCs), i.e. the maximal subgraphs in which each node is reachable from any other node. We then consider the component graph O′","(C); its nodes are the SCCs of O(C), and it has an edge from c1 to c2 if O(C) has an edge from some node in c1 to some node in c2. O′","(C) is acyclic by construction, so we can compute a topological 12 Figure 9: A fragment of the ordering graph for the chart in Fig. 4. Dotted boxes mark SCCs. Figure 10: A fragment of a chart ordering graph for a grammar with enriched nonterminals. sort and order all nonterminals from earlier SCCs before all nonterminals from later SCCs. Within each SCC, we order the nonterminals in the order in which they were discovered by the algorithm in Fig. 5. This yields a linear order on nonterminals, which at least ensures that by the time we evaluate a nonterminal A′",", there is at least one rule for A′ whose right-hand nonterminals have all been evaluated; so is(A′",") gets at least some value.","In our example, we obtain the order Nb2/{b1,b2,b3}, Nb2/{b2}, NPb2/{b2}. The rule Nb2/{b2}→squareb2(Nb2/{b2}) will thus not be considered in the evaluation of Nb2/{b2}, and the algorithm returns íthe square buttonì. The algorithm computes optimal REs for acyclic charts, and also for charts where all cycles are decreasing, i.e. using the rules in the cycle make the RE worse. This enables us, for instance, to encode the REG problem of Krahmer et al. (2003) into ours by using a feature that evaluates the rule for each attribute to its (negative) cost according to the Krahmer model. Krahmer et al. assume that every attribute has positive cost, and is only used if it is necessary to make the RE distinguishing. Thus all cycles in the chart are decreasing.","One limitation of the algorithm is that it does not overspecify. Suppose that we extend the example model in Fig. 2 with a color predicate green = {b2}. We might then want to prefer íthe green square buttonì over íthe square buttonì because it is easier to understand. But since all square objects (i.e. {b2}) are also green, using ígreenì does not change the denotation of the RE, i.e. it is represented by a loop from Nb2/{b2} to Nb2/{b2}, which is skipped by the algorithm. One idea could be to break such cycles by the careful use of a richer set of nonterminals in the grammar; e.g., they might record the set of all attributes that were used in the RE. Our example rule would then become Nb2/{b2}/{square, green}→ greenb2(Nb2/{b2}/{square}), which the algorithm can make use of (see Fig. 10)."]},{"title":"7 Conclusion","paragraphs":["We have shown how to generate REs using charts. Based on an algorithm for computing a chart of all valid REs, we showed how to compute the RE that maximizes the probability of being understood as the target referent. Our algorithm integrates REG with surface realization. It generates distinguishing REs if this is speciûed in the grammar; otherwise, it computes the best RE without regard to uniqueness, using features that prefer unambiguous REs as part of the probability model.","Our algorithm can be applied to earlier models of REG, and in these cases is guaranteed to compute optimal REs. The probability model we introduced here is more powerful, and may not admit íbestì REs. We have shown how the algorithm can still do something reasonable in such cases, but this point deserves attention in future research, especially with respect to overspeciûcation.","We evaluated the performance of our chart algorithm on a number of randomly sampled input scenes from the GIVE Challenge, which contained 24 objects on average. Our implementa-tion is based on the IRTG tool available at irtg. googlecode.com. While in the worst case the chart computation is exponential in the input size, in practice runtimes did not exceed 60 ms for the grammar shown in Fig. 3.","We have focused here on computing best REs given a probability model. We have left training the model and evaluating it on real-world data for future work. Because our probability model focuses on effectiveness for the listener, rather than human-likeness, our immediate next step is to train it on an interaction corpus which records the reactions of human listeners to system-generated REs. A further avenue of research is to deliberately generate succinct but ambiguous REs when the model predicts them to be easily understood. We will explore ways of achieving this by combining the effectiveness model presented here with a language model that prefers succinct REs. Acknowledgments. We thank Emiel Krahmer, Stephan Oepen, Konstantina Garouû, Mart ¬μ́n Villalba and the anonymous reviewers for their useful comments and discussions. The authors were supported by the SFB 632 íInformation Structureì. 13"]},{"title":"References","paragraphs":["Douglas E. Appelt. 1985. Planning English sentences. Cambridge University Press.","Carlos Areces, Alexander Koller, and Kristina Striegnitz. 2008. Referring expressions as formulas of description logic. In Proceedings of the 5th International Natural Language Generation Conference (INLG).","Anja Belz, Eric Kow, Jette Viethen, and Albert Gatt. 2008. The GREC challenge 2008: Overview and evaluation results. In Proceedings of the 5th International Conference on Natural Language Generation (INLG).","John Carroll, Ann Copestake, Dan Flickinger, and Victor Poznanski. 1999. An efûcient chart generator for (semi-)lexicalist grammars. In Proceedings of the 7th European Workshop on Natural Language Generation.","David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201ê228.","Hubert Comon, Max Dauchet, R¬émi Gilleron, Christof L¬öding, Florent Jacquemard, Denis Lugiez, Sophie Tison, and Marc Tommasi. 2007. Tree automata techniques and applications. Available on http: //tata.gforge.inria.fr/.","Robert Dale and Ehud Reiter. 1995. Computational interpretations of the Gricean Maxims in the generation of referring expressions. Cognitive Science, 19(2):233ê263.","Nikos Engonopoulos, Martin Villalba, Ivan Titov, and Alexander Koller. 2013. Predicting the resolution of referring expressions from user behavior. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Seattle.","Nicholas FitzGerald, Yoav Artzi, and Luke Zettlemoyer. 2013. Learning distributions over logical forms for referring expression generation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.","Konstantina Garouû and Alexander Koller. 2013. Generation of effective referring expressions in situated context. Language and Cognitive Processes.","Albert Gatt and Anja Belz. 2010. Introducing shared task evaluation to NLG: The TUNA shared task evaluation challenges. In E. Krahmer and M. The-une, editors, Empirical Methods in Natural Language Generation, number 5790 in LNCS, pages 264ê293. Springer.","Ferenc G¬écseg and Magnus Steinby. 1997. Tree languages. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3, chapter 1, pages 1ê68. Springer-Verlag.","Dave Golland, Percy Liang, and Dan Klein. 2010. A game-theoretic approach to generating spatial descriptions. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP).","Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3).","B. Jones, J. Andreas, D. Bauer, K.-M. Hermann, and K. Knight. 2012. Semantics-based machine translation with hyperedge replacement grammars. In Proceedings of COLING.","Ron Kaplan and J¬ürgen Wedekind. 2000. LFG generation produces context-free languages. In Proceedings of the 18th COLING.","Martin Kay. 1996. Chart generation. In Proceedings of the 34th ACL.","John Kelleher and Geert-Jan Kruijff. 2006. Incremental generation of spatial referring expressions in situated dialogue. In In Proceedings of Coling-ACL ï06, Sydney Australia.","Alexander Koller and Marco Kuhlmann. 2011. A generalized view on parsing and translation. In Proceedings of the 12th International Conference on Parsing Technologies, pages 2ê13. Association for Computational Linguistics.","Alexander Koller and Matthew Stone. 2007. Sentence generation as a planning problem. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL).","Alexander Koller, Kristina Striegnitz, Donna Byron, Justine Cassell, Robert Dale, Johanna Moore, and Jon Oberlander. 2010. The First Challenge on Generating Instructions in Virtual Environments. In E. Krahmer and M. Theune, editors, Empirical Methods in Natural Language Generation, number 5790 in LNAI, pages 337ê361. Springer.","Yannis Konstas and Mirella Lapata. 2012. Concept-to-text generation via discriminative reranking. In Proceedings of the 50th ACL.","Ruud Koolen, Albert Gatt, Martijn Goudbeek, and Emiel Krahmer. 2011. Factors causing overspec-iûcation in deûnite descriptions. Journal of Pragmatics, 43:3231ê3250.","Emiel Krahmer and Kees van Deemter. 2012. Computational generation of referring expressions: A survey. Computational Linguistics, 38(1):173ê218.","Emiel Krahmer, Sebastiaan van Erk, and Andr¬é Verleg. 2003. Graph-based generation of referring expressions. Computational Linguistics, 29(1):53ê72.","Wei Lu and Hwee Tou Ng. 2011. A probabilistic forest-to-string model for language generation from typed lambda calculus expressions. In Proceedings of EMNLP. 14","Margaret Mitchell, Kees van Deemter, and Ehud Re-iter. 2013. Generating expressions that refer to visible objects. In Proceedings of NAACL-HLT, pages 1174ê1184.","Matthew Stone, Christine Doran, Bonnie Webber, To-nia Bleam, and Martha Palmer. 2003. Microplanning with communicative intentions: The SPUD system. Computational Intelligence, 19(4):311ê 381.","Liane Wardlow Lane and Victor Ferreira. 2008. Speaker-external versus speaker-internal forces on utterance form: Do cognitive demands override threats to referential success? Journal of Experimental Psychology: Learning, Memory, and Cogni-tion, 34:1466ê1481.","Yuk Wah Wong and Raymond J. Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the 45th ACL.","Luke S. Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classiûcation with probabilistic categorial grammars. In Proceedings of the 21st Conference on Uncertainty in Artiûcial Intelligence (UAI) . 15"]}]}
