{"sections":[{"title":"[RLTLN-O.2] 281","paragraphs":["21Ãm̈e Traitement Automatique des Langues Naturelles, Marseille, 2014"]},{"title":"Approche basÃ©e sur les arbres sÃ©mantiques pour la dÃ©sambiguÃs̄ation lexicale de la langue arabe en utilisant une procÃ©dure de vote Laroussi Merhbene","paragraphs":["1 "]},{"title":"Anis zouaghi","paragraphs":["2 "]},{"title":"Mounir zrigui","paragraphs":["3 "]},{"title":"(1) LATICE, FacultÃ© des Sciences Juridiques, Economiques et de Gestion de Jendouba (2) LATICE, ISSAT Sousse, UniversitÃ© de Sousse, Tunis (3) LATICE, FacultÃ© des sciences de Monastir, Monastir, Tunis aroussi.merhben@hotmail.com, anis.zouaghi@gmail.com, mounir.zrigui@fsm.rnu.tn  RÃ©sumÃ©.","paragraphs":["Le problÃm̈e de dÃ©sambiguÃs̄ation lexicale du sens des mots est l'un des plus vieux problÃm̈es de traitement du langage naturel. Dans cet article, nous proposons une approche semi-supervisÃ© pour la dÃ©sambiguÃs̄ation lexicale des mots arabes. La partie supervisÃ©e de notre mÃ©thode utilise le corpus et le dictionnaire comme ressources pour classifier les contextes du mot ambigu selon le sens. Le regroupement de ces contextes est reprÃ©sentÃ© sous forme dÂ’arbre sÃ©mantique. Par la suite nous allons faire la correspondance entre lÂ’arbre sÃ©mantique (de chaque sens) et lÂ’arbre de la phrase Ã dÃ©sambiguÃs̄er pour obtenir un graphe acyclique pondÃ©rÃ©. Nous avons dÃ©fini une nouvelle mesure de score (en utilisant trois mesures de collocation) pour trouver lÂ’arbre sÃ©mantique la plus proche. La partie non supervisÃ© de ce travail est basÃ© sur une procÃ©dure de vote permettant de classifier les mesures de collocations et de choisir le sens correct du mot ambigu."]},{"title":"Abstract.","paragraphs":["The problem of word sense disambiguation is one of the oldest problems of natural language processing. In this paper, we propose a semi-supervised approach to word sense disambiguation. The Supervised part of our method uses the corpus and the dictionary as a resource to classify the contexts of the ambiguous word by sense. The combination of these contexts is represented as semantic tree. Thereafter we will make the correspondence between the semantic tree (of each sense) and the tree of the sentence to be disambiguated to obtain a weighted directed acyclic graph. We have defined a new measure score (using three measures of collocation) to find the nearest semantic tree. The unsupervised part of this work is based on a voting procedure for classifying measures collocations and chooses the correct meaning of the ambiguous word."]},{"title":"Mots-clÃ©s :","paragraphs":["Gloses, Extraction de racines, Correspondance de mots, groupement de contextes, arbre sÃ©mantique, mesure de collocation, procÃ©dure de vote."]},{"title":"Keywords:","paragraphs":["Glosses, Stemming, string-matching, Context clustering, semantic tree, collocation measures, voting procedure."]},{"title":"1 Introduction","paragraphs":["La DÃ©sambiguÃs̄ation lexicale dans sa dÃ©finition la plus large est rien de moins que de dÃ©terminer le sens de chaque mot dans son contexte, ce qui semble Ãatre un processus largement inconscient des gens. Comme un problÃm̈e de calcul, il est dÃ©crit comme Â«AI-complet\" (Ide et VÃ©ronis 1998). L'importance du WSD a Ã©tÃ© largement reconnue en informatique linguistique ; plusieurs centaines dÂ’articles publiÃ©s dans lÂ’ACL Anthology mentionnent le terme Â«Word Sense Disambiguation\". Le WSD est considÃ©rÃ© comme un catalyseur pour d'autres tÃ¢ches et les applications de traitement du langage naturel (TALN), telles que l'analyse, lÂ’interprÃ©tation sÃ©mantique, la traduction automatique, la recherche d'information, la recherche de texte et lÂ’acquisition dÂ’information lexicale. Plusieurs systÃm̈es de dÃ©sambiguÃs̄ation lexicale qui se basent soit sur des approches supervisÃ©es, non supervisÃ©es, Ã base de connaissances ou hybrides, retournent des taux de prÃ©cision au niveau de 90% ou plus (Agirre et al., 2006). Ces travaux portent gÃ©nÃ©ralement sur un nombre limitÃ© de mots et le plus souvent sur des noms dont il y a une large variance de sens entre eux."]},{"title":"[RLTLN-O.2] 282","paragraphs":["LAROUSSI MERHBENE, ANIS ZOUAGHI ET MOUNIR ZRIGUI Le non supervision signifie qu'il n'y a pas une intervention de l'humain lors du processus de dÃ©sambiguÃs̄ation, ceci est un avantage. Tandis que lÂ’intervention de lÂ’humain pour faire lÂ’apprentissage peut augmenter les performances de notre mÃ©thode. En accord avec cette idÃ©e, nous prÃ©sentons dans ce papier une mÃ©thode semi-supervisÃ©e pour la dÃ©sambiguÃs̄ation lexicale des mots arabe. La partie innovante dans ce travail est la construction d'un arbre sÃ©mantique pour chaque sens du mot ambigu. En outre, nous dÃ©finissons une procÃ©dure de vote qui donne un poids pour les mesures de collocation (utilisÃ©s pour mesurer la correspondance entre lÂ’arbre sÃ©mantique de chaque sens et lÂ’arbre de la phrase originelle). Ce papier contient quatre sections, la deuxiÃm̈e section dÃ©crit la mÃ©thode de dÃ©sambiguÃs̄ation des mots arabes. Les rÃ©sultats expÃ©rimentaux sont dÃ©crits dans la section trois. Enfin, la quatriÃm̈e section constitue la conclusion."]},{"title":"2 Description du systÃm̈e proposÃ© pour la dÃ©sambiguÃs̄ation lexicale des mots arabe","paragraphs":["Les mÃ©thodes semi-supervisÃ©es de dÃ©sambiguÃs̄ation lexicale sont une combinaison entre les mÃ©thodes supervisÃ©es et non supervisÃ©es. En sÂ’inspirant des mÃ©thodes de reprÃ©sentation des clusters telles que lÂ’arbre et le rÃ©seau lexical (Mihalcea, 2004) et (Navigili et al, 2005), nous avons dÃ©veloppÃ© une structure appelÃ©e arbre sÃ©mantique. Cette derniÃr̈e est reprÃ©sentÃ©e sous forme dÂ’arbre ou les mots clÃ©s sont classÃ©s selon leur influence sur le sens du mot ambigu. Ce traitement est basÃ© sur lÂ’extraction des racines (des mots appartenant aux phrases contenant le mot ambigu) et lÂ’utilisation de lÂ’algorithme de recherche dÂ’une sous chaine approchÃ©e dans une chaine pour trouver les occurrences de ces racines et gÃ©nÃ©rer les contextes dÂ’utilisation des mots ambigus. Ensuite, pour dÃ©terminer le sens exact, nous avons dÃ©fini une nouvelle mesure de similaritÃ© basÃ©e sur un graphe (obtenu en faisant la correspondance entre lÂ’arbre sÃ©mantique et lÂ’arbre de la phrase Ã dÃ©sambiguÃs̄er) pour trouver lÂ’arbre sÃ©mantique la plus proche de lÂ’arbre gÃ©nÃ©rÃ© pour la phrase originelle contenant le mot Ã dÃ©sambiguÃs̄er. Cette derniÃr̈e peut proposer plus quÂ’un sens, cÂ’est la raison pour laquelle, nous avons dÃ©fini une procÃ©dure de vote. Dans ce qui suit, nous dÃ©crivons avec plus de dÃ©tails chaque Ã©tape citÃ©es ci-dessus."]},{"title":"2.1 Inventaire de sens","paragraphs":["LÂ’inventaire de sens est lÂ’une des problÃ©matiques majeures des travaux de dÃ©sambiguÃs̄ation lexicale. Nous avons dÃ©fini une mÃ©thode permettant de gÃ©nÃ©rer automatiquement pour chaque sens possible du mot ambigu des clusters (Mots clÃ©s appartenant aux paragraphes des mots ambigus) permettant de le dÃ©finir. Certaines Ã©tapes de prÃ©traitement seront appliquÃ©es Ã ces groupes et sont dÃ©taillÃ©es dans la partie suivante. 2.1.1 PrÃ©traitements En utilisant le corpus, nous allons collecter les phrases contenant les racines des mots Ã dÃ©sambigÃ1⁄4iser (exp: le mot Â«نیعلا\" \"Alayn\" nous devons chercher la racine \"نیع\" \"ayn\"). La segmentation de ces phrases est basÃ©e sur la ponctuation (., ;, !; ?, etc) et sur le nombre de mots contenus dans une phrase qui doivent Ãatre plus que trois. Ensuite, on Ã©limine les mots vides qui apparaissent frÃ©quemment dans le corpus et n'ont pas une influence sur le sens du mot. La plupart des techniques proposÃ©es pour cette tÃ¢che (Zou et al., 2006) (Alajmi et al., 2012) sont fondÃ©es sur l'idÃ©e que les mots vides se produisent avec une frÃ©quence beaucoup plus grande que les mots. Dans l'Ã©tude comparative (El-Khair, 2006) trois listes de mots vides ont Ã©tÃ© utilisÃ©es. La premiÃr̈e est une liste gÃ©nÃ©rale, la seconde a Ã©tÃ© Ã©tablie en utilisant une statistique de corpus et le troisiÃm̈e est la combinaison des deux listes. Pour la tÃ¢che de recherche d'information, il a Ã©tÃ© conclu que la premiÃr̈e liste a donnÃ© les meilleurs rÃ©sultats que les deux autres listes. Pour cela, dans ce travail, nous avons utilisÃ© une liste gÃ©nÃ©rale contenant 29,985 mots vides. Cette liste a Ã©tÃ© Ã©laborÃ©e par des linguistiques arabe et considÃ©rÃ©e comme suffisante pour la tÃ¢che de dÃ©sambiguÃs̄ation du sens des mots. Plus de dÃ©tails seront donnÃ©s dans les rÃ©sultats expÃ©rimentaux. 2.1.2 Extraction des racines Chaque mot arabe, nom ou verbe, est gÃ©nÃ©ralement basÃ© sur trois lettres et quelques fois sur quatre ou deux lettres. Dans le but dÂ’extraire les racines des mots arabes, nous avons utilisÃ© lÂ’algorithme de Â«Al Shalabi Kanaan et Al serhanÂ» (Al-Shalabi et al., 2003) qui n'utilise pas de ressources."]},{"title":"[RLTLN-O.2] 283","paragraphs":["MODELE DE DOCUMENT POUR TALN 2014 Cet algorithme, permet lÂ’extraction de la racine en assignant des poids et des rangs aux lettres constituant un mot. Les poids sont des nombres rÃ©els entre 0 et 5. Il divise lÂ’alphabet arabe en 6 groupes. Ces poids affiliÃ©s aux lettres ont Ã©tÃ© dÃ©terminÃ©s Ã travers des expÃ©riences sur des textes arabes. Le rang de lÂ’ordre des lettres dans un mot dÃ©pend de la longueur de ce mot, et si le mot contient un nombre pair ou impair de lettres. Suite Ã la dÃ©termination du poids et du rang de chaque lettre dans un mot, les poids des lettres sont multipliÃ©s par le rang de la lettre. Les trois lettres ayant la plus petite valeur du produit constituent la racine (lire de droite Ã gauche). Cet algorithme obtient un taux de 90% (Al-shalabi et al., 2003).","La sortie de cet Ã©tape est une liste de racines des mots qui constituent les mots appartenant aux gloses R(gi) = { R1, R2,","Â..., Rn}, ou gi est la iÃ©me glose et Rn est la niÃ©me","racine obtenu. 2.1.3 Groupement des sens L'idÃ©e de regroupement des sens est que les phrases extraites du corpus seront classÃ©es en groupes en utilisant les racines des mots appartenant aux gloses. Nous utilisons la liste des racines obtenues par la derniÃr̈e Ã©tape et l'algorithme de recherche dÂ’une sous-chaine approchÃ©e dans une chaine (Elloumi, 1998) pour trouver les occurrences possibles des racines.Cet algorithme est composÃ© de deux parties essentielles. Ã€ lÂ’aide de lÂ’algorithme de remplissage (voir figure 2), nous arrivons Ã remplir la matrice contenant les deux mots Ã comparer.","FIGURE 1 : PremiÃr̈e partie Â« Remplissage de la matrice Â» de lÂ’algorithme recherche dÂ’une sous-chaine approchÃ©e dans une chaine. Soient t et x deux chaÃ®nes telles que |x|<|t| et cout de substitution. Par la suite on utilise lÂ’algorithme de traÃ§age arriÃr̈e (voir figure 3) pour trouver la plus courte sous sÃ©quence commune. Soient le coÃ»t dÂ’insertion et i,j le coÃ»t de surpression. Les mots contenant cette sous sÃ©quence commune seront considÃ©rÃ©s comme des occurrences de la racine. Une liste L(Ri) dÂ’occurrences sera gÃ©nÃ©rÃ©e des racines obtenues Ã partir de la derniÃr̈e Ã©tape.","FIGURE 2: DeuxiÃm̈e partie Â« TraÃ§age arriÃr̈e Â» de lÂ’algorithme recherche dÂ’une sous-chaine approchÃ©e dans une chaine. Vu que cet algorithme prend beaucoup de temps lors de son exÃ©cution, nous avons pensÃ© pour faciliter cette tÃ¢che de gÃ©nÃ©rer une base de connaissances dans laquelle on enregistre les occurrences de chaque racine. Ainsi avant dÂ’exÃ©cuter","DÃ©but","(i) (i.a) Construire une matrice M de taille (|x|+1)*(|t|+1); //","Remplissage","(i.b) pour i:=1 Ã |x| faire M[i,0]:=i*ffaire;","pour j:=0 Ã |t| faire M[0,j]:= 0 ffaire;","(ii) pour i:=1 Ã |x| faire","pour j:=1 Ã |t| faire","M[i,j]:= min{ M[i-1,j-1]+1, M[i,j-1]+1, M[i-1,j]+ }","ffaire ffaire  (iii) (iii.a) Choisir q, 1≤q≤|t|, telle que","M[|x|,q]=min1≤j≤|t|{M[|x|,j]}; // TraÃ§age-ArriÃr̈e","i:=|x|; j:=q; (iii.b) tant que i≠0 et j≠0 faire si M[i,j]=M[i,j-1]+ alors j:=j-1 sinon si M[i,j]=M[i-1,j-1]+","i,j alors j:=j-1; i:=i-1 sinon i:=i-1 fsi fsi ffaire; (iv) p:=j+1;","x':=t","p,q","Fin "]},{"title":"[RLTLN-O.2] 284","paragraphs":["LAROUSSI MERHBENE, ANIS ZOUAGHI ET MOUNIR ZRIGUI cet algorithme on commence par parcourir la base de connaissances, si on ne trouve pas la racine on exÃ©cute cet algorithme de correspondance des mots."]},{"title":"2.2 ModÃ©lisation des groupes de sens","paragraphs":["Plusieurs types de reprÃ©sentations textuelles structurÃ©s ont Ã©tÃ© Ã©laborÃ©s, Ã savoir les graphes de cooccurrences (VÃ©ronis, 2004) et les graphes sÃ©mantiques pour lÂ’analyse des chemins et des liens (Mihalcea, 2004) et (Navigili et al, 2005). Dans ce travail nous avons choisi de reprÃ©senter le texte (les groupes de sens) avec des arbres binaires. Ce choix est dÃ1 aux besoins de notre approche, Ã la rapiditÃ© de recherche pour les arbres, la compacitÃ© de la reprÃ©sentation et simplicitÃ© des algorithmes de calcul. Le mot ambigu est reprÃ©sentÃ© comme racine de lÂ’arbre binaire et les mots qui lÂ’entourent sont reprÃ©sentÃ©s comme des descendants. Les niveaux des descendants dans lÂ’arbre binaire dÃ©pendent de la position de ces descendants par rapport au mot ambigu, c'est-Ã-dire, en premier niveau de lÂ’arbre on trouve les mots qui sont situÃ©s juste Ã droite et Ã gauche du mot ambigu dans le corpus. Les diffÃ©rents phrases contenus dans les groupes de sens ou clusters obtenus seront transformÃ©s en arbre binaire dont la structure est la suivante T = (N, E, R, RC, LC, L), ou :  N est un ensemble de nÂœuds, N = {n1Â... nn}. Chaque nÂœud correspond Ã un concept dans l'arbre binaire.  E est un ensemble d'arÃates qui reprÃ©sente la relation entre le nÂœud Ni et le nÂœud Nj.  R est la racine de l'arbre qui est le mot ambigu.  RC est l'ensemble des fils droits qui sont les mots apparaissant Ã droite du mot ambigu.  LC est l'ensemble des fils gauche, qui sont les mots apparaissant Ã gauche du mot ambigu.  L est une fonction qui dÃ©termine le niveau des nÂœuds, il correspond Ã leur position par rapport au mot ambigu.  Si on excepte la racine R, chaque nÂœud de lÂ’arbre possÃd̈e exactement un seul fils. On appelle <R, RC, LC> un arbre binaire schÃ©matisÃ© dans la figure 3 (b) suivante. Un arbre sÃ©mantique permet dÂ’arranger les mots contenus dans les diffÃ©rents clusters de sens. Cette tÃ¢che dÃ©pend du nombre d'occurrences des mots (contenue dans le mÃame contexte du mot ambigu), aussi de la position par rapport au mot ambigu dans son contexte. Les mots les plus proches du mot ambigu ont gÃ©nÃ©ralement une influence sur sa signification. Le choix de ces facteurs a Ã©tÃ© fait Ã partir des travaux de Yarowsky (Yarowsky, 1993) montrant que la performance d'un systÃm̈e de dÃ©sambiguÃs̄ation lexicale diminue lorsque la distance par rapport au mot ambigu augmente. La crÃ©ation dÂ’arbre sÃ©mantique se fait Ã partir de la fusion de plusieurs arbres binaires obtenus. Nous obtenons un graphe acyclique dirigÃ© ou arbre n-aire que nous appelons arbre sÃ©mantique, ST = (N, E, R, C, L, Nb, H), oÃ1 :  CÂ’est l'ensemble des nÂœuds fusionnÃ©s, C = {c1, ... cn}. Les fils gauche et droite de chaque arbre binaire seront liÃ©s Ã la racine de l'arbre sÃ©mantique.  Nb est une fonction qui retourne le nombre de nÂœuds dans l'arbre sÃ©mantique.  H est une fonction qui retourne la hauteur de l'arbre sÃ©mantique. ","Pour chaque nÂœud de l'arbre sÃ©mantique, nous dÃ©finissons une structure qui contient les donnÃ©es suivantes :  W est un ensemble de mots qui reprÃ©sente les Ã©tiquettes des nÂœuds. Ces mots sont les mots clÃ©s qui caractÃ©risent un sens spÃ©cifique (obtenue Ã partir de l'Ã©tape de crÃ©ation de contexte dÂ’utilisation).  Enfant (N) est une fonction qui renvoie le nombre de fils d'un nÂœud N.  Freq (N) est une fonction qui retourne le nombre de frÃ©quences d'un nÂœud N. ","Nous avons utilisÃ© comme notation lÂ’arbre sÃ©mantique, arbre en raison de sa structure basÃ©e sur la position des mots par","rapport au mot ambigu et sÃ©mantique car les nÂœuds sont les mots des groupes de sens. Dans le cas oÃ1 l'on trouve un nÂœud qui existe dÃ©jÃ dans l'arbre sÃ©mantique, nous devons le fusionner. Lors de lÂ’Ã©tape de fusion des arbres, nous utilisons un algorithme de parcours en largeur pour trouver le nÂœud rÃ©pÃ©tÃ© soit dans un niveau plus Ã©levÃ©, mÃame niveau ou un niveau infÃ©rieur."]},{"title":"2.3 ProcÃ©dure de dÃ©sambiguÃs̄ation","paragraphs":["La procÃ©dure de dÃ©sambiguÃs̄ation dÃ©taillÃ©e dans cette section est basÃ©e sur 3 Ã©tapes. Nous commenÃ§ons par la crÃ©ation de liens pondÃ©rÃ©s par des mesures de collocation entre lÂ’arbre binaire de la phrase Ã dÃ©sambiguÃs̄er et lÂ’arbre"]},{"title":"[RLTLN-O.2] 285","paragraphs":["MODELE DE DOCUMENT POUR TALN 2014 sÃ©mantique, cette Ã©tape est appelÃ©e correspondance. Par la suite nous mesurons la similaritÃ© sÃ©mantique entre l'arbre de la phrase originale et l'arbre sÃ©mantique de chaque sens appelÃ© ST, ou Sk correspond au kiÃm̈e","sens). Cette mesure peut proposer plus qu'un seul sens, dans ce cas, nous utilisons la procÃ©dure de vote. 2.3.1 Correspondance des arbres : graphe acyclique pondÃ©rÃ© Les nÂœuds de l'arbre correspondant Ã la phrase originelle (contenant le mot Ã dÃ©sambiguÃs̄er) sont liÃ©s aux nÂœuds de mÃame niveau dans l'arbre sÃ©mantique de chaque sens. Les liens sont pondÃ©rÃ©s Ã l'aide de trois mesures diffÃ©rentes de collocation (dÃ©taillÃ©es dans ce qui suit). Cette Ã©tape est appelÃ©e correspondance des arbres, on obtient un graphe orientÃ© pondÃ©rÃ©e avec l'une des trois mesures de collocation (dÃ©taillÃ©s dans ce qui suit) comme un poids d'une arÃate (notÃ© wcij). Nous ajoutons des liens pondÃ©rÃ©s par les mesures de collocation entre les nÂœuds Ni de l'arbre de la phrase Ã dÃ©sambiguÃs̄er Tos et les nÂœuds Nj de l'arbre sÃ©mantique de chaque sens. La figure 3 montre un exemple de correspondance entre l'arbre de la phrase d'origine et l'arbre sÃ©mantique obtenue prÃ©cÃ©demment. La phrase originale contenant le mot ambigu est la suivante: \". لامعلأا هذھ لثم دھاشت و رصبت نیعلا و كلذك رملأا نوكی لا فیك و\" \"Et comment ne pas Ãatre le cas et la perspicacitÃ© des yeux et de voir de tels actes.\"   Pour cette phrase, nous devons Ã©liminer les mots vides Ã l'aide de la liste prÃ©dÃ©finie de mots vides. Les mots vides qui seront Ã©liminÃ©s sont (هذھ ,لثم ,كلذك ,نوكی ,لا ,فیك ,و) (et, comment, pas, Ãatre, bien, comme, Ã§a). Par la suite nous allons extraire les racines des mots contenus dans la phrase originelle, ces racines sont les nÂœuds de l'arbre et selon leur position par rapport au mot ambigu nous allons affilier le niveau dans l'arbre. Les liens entre les nÂœuds sont pondÃ©rÃ©s par wp (= 1 / niveau des nÂœuds). Par exemple le mot \"رمأ\" \"AMR\" est dans la deuxiÃm̈e position, le nÂœud qui lui correspond est situÃ© dans le deuxiÃm̈e niveau de l'arbre. Le poids affiliÃ©e Ã la liaison entre les mots \"نیع\" \"ayn\" et \"رمأ\" \"amr\" est 1/2 = 0,5. Chaque nÂœud de l'arbre extrait de la phrase originale, est liÃ© avec les nÂœuds du mÃame niveau dans l'arbre sÃ©mantique d'un sens particulier. Les liens utilisÃ©s pour l'Ã©tape de correspondance apparaissent en bleu en pointillÃ©s. Ils sont pondÃ©rÃ©s en utilisant des mesures de collocations (dÃ©finit dans ce qui suit) normalisÃ©s entre 0 et 1 et appelÃ© wcij qui correspond aux arcs qui lient les nÂœuds wi et wj. Par exemple, le mot \"رم\" \"marra\" occurre 7 fois dans le corpus avec le mot \"رصب\" \"bsr\", en normalisant le poids de lÂ’information mutuelle, on obtient wcij = 0,38. Pour la correspondance entre lÂ’arbre de la phrase originelle et lÂ’arbre sÃ©mantique dÂ’un sens particulier du mot ambigu, nous utilisons trois mesures de collocation citÃ©s dans ce qui suit. 2.3.1.1 Le T-test LÂ’un des tests les plus connues dans le domaine de recherche de collocations (Manning et al., 1999), le t-test (voir Ã©quation 1) est calculÃ© de la faÃ§on suivante :","FIGURE 3 : Exemple de correspondance entre lÂ’arbre binaire de la phrase originelle (b) et un fragment de lÂ’arbre sÃ©mantique de la premiÃr̈e glose du mot Â“نیعÂ” Â“aynÂ” (a). (a) Fragment de lÂ’arbre sÃ©mantique de la premiÃr̈e glose du mot Â“نیعÂ” Â“aynÂ”. (b) Arbre binaire de la phrase originelle"]},{"title":"[RLTLN-O.2] 286","paragraphs":["LAROUSSI MERHBENE, ANIS ZOUAGHI ET MOUNIR ZRIGUI wcij = T = (̅ - ) / (   ) (Equation 1) OÃ1 ̅ (la moyenne d'Ã©chantillon) est Ã©gale Ã s2","(variance dÂ’Ã©chantillon) est Ã©gale au nombre dÂ’occurrence des deux mots divisÃ© par le nombre total de mots dans le corpus ; N la taille dÂ’Ã©chantillon; LÂ’hypothÃs̈e nulle est mesurÃ© en multipliant P(wi) par P(wj), ou P(wi) = Nombre dÂ’occurrence de wi dans le corpus divisÃ© par le nombre total de mots dans le corpus. 2.3.1.2 Le Khi CarrÃ© Pour le calcul du khi carrÃ© χ 2",", nous mesurons C1,1 qui est le nombre de fois ou w1 et w2 occurrent ensemble, C1,2 correspond au nombre dÂ’occurrence de w1 sans prendre en considÃ©ration w2, C2,1 correspond au nombre dÂ’occurrence de w2 sans prendre en considÃ©ration w1 et enfin C2,2 le nombre de couples dans le corpus sans considÃ©rer le couple w1,w2. Dans ce qui, nous allons donner lÂ’Ã©quation 2 utilisÃ© pour le calcul du Khi CarrÃ© en utilisant le tableau 2 par 2. χ2 =","Ã— (,Ã— , ,Ã— ,) , ,Ã— , ,Ã— , ,Ã— , , (Equation 2) DÂ’aprÃs̈ (Maning et al., 1999), le χ2 est appropriÃ© pour les probabilitÃ©s larges, pour lesquelles le t test ne donne pas des rÃ©sultats satisfaisantes. Pour cela le χ2 est utilisÃ© dans la plupart des problÃm̈es de dÃ©couverte de collocation. 2.3.1.3 Information Mutuelle Cette mesure dÃ©termine combien un mot peut nous indiquer un autre mot (Manning et al., 1999), Elle est dÃ©finit de la maniÃr̈e suivante (voir Ã©quation 3). IM(wi,wj) = log2","(,) () () (Equation 3) Les bi-grammes ayant un nombre de frÃ©quence qui nÂ’est pas important, auront un score Ã©levÃ© que ceux qui ont un nombre de frÃ©quence Ã©levÃ©. 2.3.2 Mesure de similaritÃ© sÃ©mantique Pour la dÃ©finition de la mesure de similaritÃ©, nous partons de la logique que pour mesurer la similaritÃ© entre deux phrases (la phrase Ã dÃ©sambiguÃs̄er et le contexte dÂ’utilisation gÃ©nÃ©rÃ©e pour le sens i du mot ambigu), nous devons mesurer la similaritÃ© entre les mots de chaque phrase. DÂ’autre part dans cette mesure, nous intÃ©grons la position des diffÃ©rents mots de la phrase Ã dÃ©sambiguÃs̄er par rapport au mot ambigu. Pour cela, nous utilisons le niveau des mots dans lÂ’arbre sÃ©mantique, celui-ci dÃ©pond la position du terme correspondant Ã gauche ou Ã droite du mot ambigu. La mesure de score dÃ©finit dans ce qui suit (voir Ã©quation 4) nous permet de trouver lÂ’arbre sÃ©mantique Tst la plus proche Ã lÂ’arbre de la phrase originelle Tos.","Score = ∑ (∑ (wc/ ST(L(N))/Nb(ST))/Nb(T)) ∈ ∈ (Equation 4) Cette mesure est la moyenne du produit de wp et wcij entre les nÂœuds de Tos et STsk. OÃ1 Nb(T) Est le nombre total de nÂœuds dans lÂ’arbre Tos et Nb(ST) le nombre total des nÂœuds liÃ©s aux nÂœuds de lÂ’arbre ST. ST(L(N)) Correspond au niveau des nÂœuds Nj contenu dans lÂ’arbre sÃ©mantique ST. 2.3.3 Classification des mesures de collocation La procÃ©dure de vote est utilisÃ©e pour un ensemble dÂ’algorithmes. Chaque algorithme va donner un sens au mot ambigu et le sens qui a la majoritÃ© des votes sera choisi comme le sens correct (Navigili, 2009). Nous distinguons la majoritÃ© de vote, la combinaison de probabilitÃ©s et la combinaison basÃ©e sur le rang, ces mÃ©thodes de vote ont Ã©tÃ© diffÃ©renciÃ©es en variant le poids utilisÃ© pour le vote."]},{"title":"[RLTLN-O.2] 287","paragraphs":["MODELE DE DOCUMENT POUR TALN 2014 Notre contribution par rapport Ã ce qui est existant est que nous donnons un poids pour les mesures de collocation utilisÃ©es par la mesure de score, non pas pour les sens proposÃ©s par les diffÃ©rents mÃ©thodes. La procÃ©dure de vote est une nouvelle approche supervisÃ©e, l'idÃ©e est que lors de l'Ã©tude expÃ©rimentale, nous avons classÃ© les mesures de collocation selon l'attribution du sens. Un rang sera donnÃ© pour chaque mesure permettant de les classer selon lÂ’attribution correcte des sens. Nous distinguons trois cas. Dans le cas oÃ1 les mesures de collocations donnent des rÃ©sultats diffÃ©rents, alors la procÃ©dure de vote sera appliquÃ©e. Outre, lorsque les trois mesures de collocation donnent le mÃame rÃ©sultat, alors le sens donnÃ© sera attribuÃ© au mot ambigu et les rangs ne seront pas modifiÃ©s. Les mesures de collocation peuvent donner des rÃ©sultats diffÃ©rents, dans le cas oÃ1 plus d'une mesure est en accord sur l'attribution d'un sens au mot ambigu, nous devons choisir le sens ayant la majoritÃ© des votes. Les rangs des mesures qui ont votÃ©s pour le sens attribuÃ© seront incrÃ©mentÃ©s et les rangs des mesures qui nÂ’ont pas votÃ©s pour le sens attribuÃ© seront dÃ©crÃ©mentÃ©s. Lorsque chacune des mesures de collocation donne un sens diffÃ©rent. Dans ce cas, le rÃ©sultat donnÃ© par la mesure ayant le rang le plus Ã©levÃ© (attribuÃ© lors du dernier test de classification N) sera utilisÃ© pour attribuer le sens du mot ambigu. Dans ce qui suit, nous dÃ©taillons les rÃ©sultats donnÃ©s par la mÃ©thode dÃ©crite."]},{"title":"3 RÃ©sultats ExpÃ©rimentaux","paragraphs":["Avant dÂ’entamer la partie ou nous donnons les rÃ©sultats de notre mÃ©thode, nous allons dÃ©crire les donnÃ©es testÃ©s et les ressources utilisÃ©es."]},{"title":"3.1 Ressources utilisÃ©s 3.1.1 Dictionnaire","paragraphs":["Pour la dÃ©sambiguÃs̄ation de la langue arabe nous avons besoin dÂ’un dictionnaire arabe-arabe qui contient les diffÃ©rents sens du mot ambigu, le problÃm̈e dans les dictionnaires classiques est quÂ’ils contiennent des sens qui ne sont plus utilisÃ©s de nos jours. Nous utilisons le dictionnaire Â« Alwassit Â» (Muṣṭafá et al., 2008) qui est trÃs̈ connu pour la langue arabe et contient les anciens et nouveaux sens. La plupart des travaux de dÃ©sambiguÃs̄ation lexicale de la langue arabe et les autres langues, utilisent des sens ayant une granularitÃ© grosse, cela signifie que les sens des mots ne sont pas nombreux dÂ’une part et ne sont pas trÃs̈ dÃ©taillÃ©s dÂ’autre part. Vu le nombre important de sens donnÃ© par le dictionnaire, nous devons travailler avec les sens de granularitÃ© fine. Ce choix rend notre travail plus ardu et complexe puisquÂ’il augmente le nombre de sens Ã considÃ©rer. 3.1.2 Corpus Le corpus utilisÃ© dans ce travail est lÂ’ensemble de plusieurs corpus collectÃ©s. Les textes contenus dans ces corpus sont des articles de presse, des articles, des livres, des magazines et des articles de blogs tÃ©lÃ©chargÃ©s du net qui ont Ã©tÃ© enregistrÃ©s sans restriction. Le nombre total de mots dans le corpus est 123,8554,642 mots. Ce nombre important de mots dans le corpus, nous a aidÃ©s Ã trouver les occurrences pour la plupart des sens des mots ambigus testÃ©s."]},{"title":"3.2 DonnÃ©es expÃ©rimentÃ©es et problÃm̈es rencontrÃ©s","paragraphs":["Nous avons testÃ©s 127 mots ambigus qui ont Ã©tÃ© choisis par leur sens hors contexte. Pour chacun de ces mots ambigus, nous avons Ã©valuÃ© 60 exemples par sens et 20 exemples lors de la partie de classification des mesures de collocations. De nombreux problÃm̈es ont Ã©tÃ© rencontrÃ©s lors du processus de dÃ©sambiguÃs̄ation citÃ© dans ce qui suit:"," Nous avons trouvÃ© des exemples pour les tests qui peuvent Ãatre jugÃ©s comme satisfaisants pour le processus de dÃ©sambiguÃs̄ation. Nous avons eu recours Ã quatre annotateurs qui nous ont aidÃ©s Ã choisir des phrases qui permettent de donner plusieurs possibilitÃ©s pour le choix du sens du mot ambigu. Le taux dÂ’accord entre les annotateurs est de 73%."]},{"title":"[RLTLN-O.2] 288","paragraphs":["LAROUSSI MERHBENE, ANIS ZOUAGHI ET MOUNIR ZRIGUI  Pour certains mots considÃ©rÃ©s, nous avons trouvÃ© des sens qui apparaissent dans le corpus et n'existent pas dans","le dictionnaire. Pour le mot \"ayn\" on extrait une dizaine de phrases du corpus oÃ1 il signifie un nom d'une ville au","Liban. Un Ã©chantillon est donnÃ© dans ce qui suit: \"يبظوبأ يف هانفلأ امع امامت فلتخی ءاھبب نیعلا ةنیدم انلبقتست\"  \"La ville d'Ayn nous reÃ§oit brillamment complÃẗement diffÃ©rente","avec ce quÂ’on sÂ’est habituÃ© Ã Abu-Dhabi\"."," Nous avons utilisÃ© la granularitÃ© fine des sens et certaines sens sont presque inexistantes dans les textes du corpus, pour cela le nombre dÂ’exemples testÃ©s varie dÂ’un sens Ã un autre pour un seul mot. Comme solution nous avons essayÃ© de gÃ©nÃ©rer du net le maximum de phrases qui correspond au sens ayant un nombre dÂ’occurrence faible dans notre corpus."]},{"title":"3.3 RÃ©sultats obtenus","paragraphs":["Nous dÃ©taillons dans le tableau 1 suivant, les rÃ©sultats obtenus par notre mÃ©thode. En divisant le nombre de mots dÃ©sambiguÃs̄Ã©s correctement par le nombre de mots testÃ© nous mesurons la prÃ©cision. En plus de ces donnÃ©es, nous utilisons le nombre de mots ambigus pour mesurer le rappel et la couverture. On trouve aussi le F-score qui dÃ©termine la moyenne harmonique pondÃ©rÃ©e de la prÃ©cision et du rappel (Navigili, 2009). Ces taux sont dÃ©taillÃ©s pour chaque mesure de collocation ainsi que pour la procÃ©dure de vote. wcij Rappel PrÃ©cision F-Score Couverture T 0,739 0,754 0,747 0,9798 MI 0,70382 0,7182 0,7109 0,9798 χ 2 0,7590 0,7746 0,7668 0,9798","ProcÃ©dure de vote 0,8305 0,8305 0,8305 1 TABLEAU 1: Les performances de notre mÃ©thode. On remarque que le F-score obtenu en appliquant la procÃ©dure de vote est supÃ©rieur Ã celui obtenu par quelconque mesure de collocations. Il n'y a pas une grande diffÃ©rence entre la prÃ©cision et le rappel obtenu par les mesures de collocations. Ceci peut s'expliquer par le fait que la majoritÃ© des mots testÃ©s ont Ã©tÃ© dÃ©sambiguÃs̄Ã©s, ce qui est mesurÃ© par la couverture (proche de 100%). Cependant, la meilleure mesure de collocation est le χ 2, sinon la procÃ©dure de vote augmente le F-score de 6%. L'avantage de l'arbre sÃ©mantique peut Ãatre dÃ©montrÃ© si on mesure la performance de notre mÃ©thode en variant le nombre de nÂœuds utilisÃ©s lors de l'Ã©tude expÃ©rimentale (voir la figure 4 ci-dessus). Nous trouvons que plus l'arbre sÃ©mantique est enrichi par les nÂœuds, plus le F-score augmente. La diminution du F-score est principalement due Ã l'insuffisance du nombre de nÂœuds, ce qui conduit Ã l'Ã©chec de rÃ©pondre Ã tous les Ã©vÃ©nements possibles.  0102030405060708090 O 500 1000 1500 2000 2500 3000 F - S c o r e  (% ) Nombre de noeuds dans l'arbre sÃ©mantique FIGURE 4. Performance de notre mÃ©thode et le nombre de nÂœuds correspondant dans lÂ’arbre sÃ©mantique."]},{"title":"[RLTLN-O.2] 289","paragraphs":["MODELE DE DOCUMENT POUR TALN 2014 Nos rÃ©sultats indiquent que pour les arbres sÃ©mantiques ayant au moins 500 nÂœuds, les performances de notre mÃ©thode augmente constamment. Outre, le F-score atteint le maximum et devient stable pour les tailles d'arbres sÃ©mantiques entre 2.000 et 3.000 nÂœuds. Nous allons maintenant discuter les performances de notre mÃ©thode pour quelques mots ambigus. Nous mentionnons dans le tableau 2 ci-dessous, certains mots ambigus et le nombre de sens. Aussi pour le sens le plus frÃ©quent nous dÃ©taillons le F-score obtenu et le rang des mesures de collocation obtenu aprÃs̈ la phase de classification de la procÃ©dure de vote. Mots Vocalisation Nombre de sens F-Score Rang Ttest Rang MI Rang χ2 نیع Ain 16 0,7421 +14 +4 +12 بسح Hsb 14 0,7532 +12 -3 +10 رعش Chaar 8 0,8926 +14 +0 +19 رجف Fjr 6 0,8420 +10 +18 +17 رون nr 4 0,9605 +9 +3 +19 TABLEAU 2 : RÃ©sultats dÂ’Ã©valuation individuelle pour quelques mots ambigus. D'aprÃs̈ le tableau 2, nous pouvons noter que le plus faible F-score est obtenu par les mots ambigus ayant le plus grand nombre de sens. Dans les trois derniÃr̈es colonnes du tableau 2, nous dÃ©taillons le rang des mesures de collocations pour le sens le plus frÃ©quent. Pour les mots ambigus ayant plus de 10 sens, les rangs des mesures de collocation est infÃ©rieur Ã 15. En revanche, les mots ayant moins de 10 sens donnent le meilleur F-Score. Les mesures de collocations correspondantes Ã ces mots sont les plus classÃ©es (plus de 16). En rÃ©sumÃ©, nos rÃ©sultats indiquent que le χ2 est la mesure de collocation ayant le rang le plus Ã©levÃ© pour la majoritÃ© des donnÃ©es testÃ©es. Les mots ambigus ayant le nombre de sens le moins Ã©levÃ© donnent les meilleures performances. Ceci s'explique par le fait qu'elles facilitent le choix du sens correct. La plupart des travaux qui ont Ã©tÃ© rÃ©alisÃ©s dans le domaine de dÃ©sambiguÃs̄ation lexicale des autres langues, ont l'avantage d'Ãatre Ã©valuÃ©s tout au cours des confÃ©rences Senseval et SemEval. Ces travaux ont Ã©tÃ© testÃ©s en utilisant les mÃames ressources, les mÃames Ã©chantillons et la mÃame granularitÃ© des sens. Pour les travaux de la langue arabe, les ressources et les Ã©chantillons testÃ©s sont inexistantes et non disponibles pour pouvoir comparer les travaux."]},{"title":"4 Conclusion","paragraphs":["Cet article dÃ©crit une approche basÃ©e sur les arbres sÃ©mantiques pour la dÃ©sambiguÃs̄ation semi-supervisÃ©e de la langue arabe. Le principal inconvÃ©nient de la langue arabe semble Ãatre le grand nombre de sens hors contexte pour les mots ambigus. L'Ã©tape de regroupement de sens Ã©tait trÃs̈ bÃ©nÃ©fique pour atteindre les performances obtenues par notre mÃ©thode. D'autre part, la reprÃ©sentation de l'arbre sÃ©mantique pour chaque sens Ã©tait trÃs̈ pratique. La mesure de score proposÃ©e (pour mesurer la correspondance entre lÂ’arbre sÃ©mantique et lÂ’arbre de la phrase originelle) utilise trois mesures de collocations qui seront classÃ©s en utilisant une procÃ©dure de vote supervisÃ©. Lors lÂ’Ã©tude expÃ©rimentale nous avons testÃ© des mots arabes ambigus choisis par leur nombre de sens hors de contexte. Les rÃ©sultats montrent que notre mÃ©thode permet d'obtenir un taux de rappel et de prÃ©cision Ã©levÃ© (83%). Nous proposons dans les futurs travaux dÂ’utiliser dÂ’autres ressources utiles pour la langue arabe afin dÂ’augmenter les performances de notre mÃ©thode."]},{"title":"Remerciements","paragraphs":["Nous adressons nos plus vifs remerciements aux linguistes de notre universitÃ© pour leur aide quÂ’ils nous ont apportÃ©s. Nous tenons aussi Ã exprimer notre gratitude envers les membres de notre unitÃ© de recherche LATICE pour leur soutien."]},{"title":"[RLTLN-O.2] 290","paragraphs":["LAROUSSI MERHBENE, ANIS ZOUAGHI ET MOUNIR ZRIGUI "]},{"title":"RÃ©fÃ©rences","paragraphs":["AGIRRE E. AND EDMOND P. (2006). Word Sense Disambiguation: Algorithms and Applications. Springer. AL-SHALABI R., KANAAN G., AL-SERHAN H. (2003). New approach for extracting Arabic roots. Papier prÃ©sentÃ© Ã ACIT, the International Arab Conference on Information Technology. Egypt, p. 42-59. ALAJMI A., SAAD E.M., DARWISH R.R.(2012). Toward an Arabic Stop-words List Generation. International Journal of Computer Applications (0975-8887), vol.46, nÂ°8, p. 9-13. EL-KHAIR I. A. (2006). Effect of Stop Words Elimination for Arabic Information Retrieval: A comparative Study. International journal of Computing & Information Sciences, vol.4, nÂ°3, p.119-133. ELLOUMI M. (1998). Comparison of Strings Belonging to the Same Family. Information Sciences, An International Journal, Elsevier Publishing Co., Amsterdam, North-Holland (Publisher), vol. 111, nÂ°(1-4), p. 49-63. IDE I. AND VERONIS J. (1998). Word Sense Disambiguation : The State of the Art. Computational Linguistics, vol. 24 (1), p. 1-41. MANNING C., SCHUTZE H. (1999). Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA. MERHBENE L., ZOUAGHI A. AND ZRIGUI M. (2012). Lexical Disambiguation of Arabic Language: An Experimental Study Â». In proceeding of 11th","Mexican International Conference on Artificial Intelligence, San Luis PotosÃ, SLP, MÃ©xico. MUṢṬAFA M., SAYED AHMED N., DARWICH M., ABDALLAH A. (2008). MuÂ‘jam al-Wasīṭ. Published in Bayrūt : Dār Iḥyā’ al-Turāth al-‘Arabī lil-Ṭibā‘ah wa-al-Nashr wa-al-Tawzī‘. MIHALCEA, R., TARAU, P., AND FIGA E. (2004). Pagerank on semantic networks, with application to word sense disambiguation. In Proceedings of the 20th","International Conference on Computational Linguistics (COLING, Geneva, Switzerland), p. 1126Â–1132. NAVIGLI, R. (2005). Semi-automatic extension of large-scale linguistic knowledge bases. In Proceedings of the 18th Florida Artificial Intelligence Research Society Conference (FLAIRS, Clearwater Beach, FL), p.p: 548Â–553. NAVIGILI R. (2009). Word Sense Disambiguation: A Survey. ACM Computing Surveys, Vol. 41, No. 2, Article 10, Publication date: February, p. 1-69. VERONIS, J. (2004). Hyperlex: Lexical cartography for information retrieval. Comput. Speech Lang. 18, 3, p.p: 223Â– 252. YAROWSKY, D. (1993). ONE SENSE PER COLLOCATION. In Proceedings, ARPA Human Language Technology Workshop. Princeton, pp. 266-271. ZOU F., WANG L., DENG X., HAN S. AND WANG L. S. (2006). Automatic Construction of Chinese Stop Word List Â», in proceeding of the 5th","WSEAS International Conference on Applied Computer Science, Hangzhou, China, p. 1010-1015. "]}]}
