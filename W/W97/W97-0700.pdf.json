{"sections":[{"title":"Intelligent Scalable Text Summarization Proceedings of a Workshop Sponsored by the Association for Computational Linguistics Edited by Inderjeet Mani and Mark Maybury Supported by The MITRE Corporation 11 July 1997 Universidad Nacional de EducaciSn a Distancia Madrid, Spain Â© 1997, AsSoclatmn for ComputaUonal Lmgmsttcs Order addmonal cop~es from ACL P O Box 6090 Somerset, NJ, 08875 USA +1-908-873-3898 acl@bellcore corn ! I ,I .| I I I i ! ! I I i i 1 i i","paragraphs":[","]},{"title":"I PREFACE","paragraphs":["This volume contam~ the papers presented at the (first) workshop on Intelhgent Scalable Text Summarization, held on 11 July 1997 m conjunction . with the joint conference of the 35th Annual Meeting of the Association for Computational Linguistics (ACL) and the 8th European Chapter of the ACL (ACL-EACL'97 Joint Conference)","With the explosion in the quantity of on-hne information in recent years, demand for text summarization technology appears to be growing Commercial compames are increasingly starting to oiTer text summarization capabilities, of. ten bundled with information retrieval tools and database systems These recent developments offer opportunities as well as substantial challenges for research in text summarization In general, such developments create a practical need for summarization systems which scale up when apphed to largevolumes of unrestricted text While there have been focused workshops in the past on text summarization, they have pre-dated the tremendous expansion of on-hne reformation access fueled by the recent growth of the World Wide Web This workshop is aimed at researchers interested m advancing the scientific frontiers of text summarization to meet these new practical challenges and opportunities","The papers presented here include statistical paradigms for mtelhgent text summarization, methods for identifying summary topics in text, exploitation of recent advances m reformation extraction m summarization, evaluation methods and metrics, and theoretical foundations, including cogmtlve models\" Of particular interest to the issue of scalahlhty is the increased emphasis on hybrid approaches winch combine statistical techniques with robustly extracted lmgumtic representations The papers m this one-day workshop offer only a sample of the emer~ng approaches, other relevant topics, which may be touched on m the discussion sessions, include the exploitation of corpus-based resources, multidocumentÂ•.summarizatlon, multihngual summarization, and the use of multimodal information presentation strategies in summarization","We would hke to first of all thank the authors, whose research contributions have made this workshop possible We also appreclate the.efforts of other members of the Program Committee m revmwing papers and assisting in the design and running of the workshop Udo Hahn, Juhan Kupmc, Kathy McKeown, Boyan Onyshksvych, Dragomir Radev, Lisa Rau, and Kazuo Tanaka Dragomlr Radev also provided valuable services as our Webmaster Thanks are due also to the following Harald Tros t (the ACL workshop chair) and Fehsa Verdejo (local arrangements), for their logistics support at various points In addition, we thank Anne Roemez at MITRE, for her help m assembhng the master ,copy of these Proceedings Finally, we are grateful to the ACL for sponsoring the workshop, and to the MITRE Corporation for supporting the pubhcatton of these Proceedings Inderjeet Mani Mark Maybury Program Chmrs"]},{"title":"PROGRAM COMMITTEE","paragraphs":["Udo Hahn Juhan Kuplec Inderjeet Mare Mark Maybury","Kathy McKeown","Boyan Onyshkevych Dragomlr Rade","Lma Rau Kazuo Tanaka Un:vers:ty of Fre,burg","Xeroz Palo Alto Research Center","The MITRE Corporat:on","The MITRE Corporat:on Columbfa Un,vers:ty","US Department of Defense Columb:a Umvers:ty","SRA Internat:onal","IVTT Human Interface Laboratories ii"]},{"title":"i I I I ! I I i I I I. ! i I i I i ! I i I I i J I ! I | ! I ! i I WORKSHOP PROGRAM 11 July I997 Unwerszdad Nacwnal de Educac~6n a D~tancza Madrid, Spare","paragraphs":["OPENING SESSION 9 00-9 10 Opening Remarks","Inder3eet Main 9 10-9 40 Keynote Address Where are we now ? Where should we go?","Karen Sparck Jones 9 40-9 50 Dmcusmon SESSION 1: TOPIC-LEVEL ABSTRACTION (chair Udo Hahn) 9 50-10 10 10 10-10 30 10 30-10 50 10 50-11 05 Sahence-based Content Characterization of Text Documents Brammtr Boguraev and Chrmtopher Kennedy Using LeJacal Chains for Text Summarization Re~na Barzllay and Michael Elhadad Automated Text Summarization m SUMMARIST Eduard Hovy and Chin Yew Lm Dmcusslon ii 05--11 20 BREAK SESSION 2: 1i 20-11 40 11 40-12 00 12 00-12 15 EVALUATION METHODS (chmr Boyan Onyshkevlch) How to Appreciate the Quality of Automatic Text Summarization Jean-Luc Mmel, Sylvame Nugmr, and G&ald Plat A Proposal for Task-Based Evaluation of Text Surnmanzatlon Systems Thdr~se F Hand Dmcusmon 12 15--2 00 LUNCH iii SESSION 3: STATISTICAL APPROACHES (chair Eduard Hovy) 2 00-2 20 2 20-2 40 2 40-3 00 3 00-3 20 3 20-3 35 Automatic Text Summarization by Paragraph Extraction Mandar Mltra, Amit Smghal, and Chris Buckley Goal Directed Approach for Text Summamzation Ryo Odntanl, Yoshlo Nakao, and Fum,h,to Nmhmo Statistical Methods for Retrieving Most Significant Paragraphs in Newspaper Articles Jose Abracos and Gabriel Perelra Lopes Sentence extraction as a clasmficatlon task Slmone H Teufel and Marc Moens D~cu~lon 3 35-4 00 BREAK SESSION 4: COMBINING DISCOURSE-LEVEL FEATURES (chau Inderjeet Man!) 4 00-4 20 A Scalable Summarization System using Robust NLP","Ctnnatsu Aone, Mary Ellen Okurowsh, James Gorhnsky, Bjornar Larsen 4 20-4 40 COSY-MATS An Intelhgent and Scalable Summanzahon Shell","Maria Aretoulah 4 40-5 00 From Discourse Structures to Text Summaries","Daniel Marcu 5 00-5 15 Discussion 5 15-5 30 BREAK SESSION 5: SUMMARIZATION MODELS (chair Mark Maybury) 5 30-5 50 5 50-6 10 6 10-6 25 6 25-6 35 SunSum Smaulahon of summarizing Bngltte Endres-Nlggemeyer A Formal Model of Text Summarization Based on Condensahon Operators","of a Terminological L0g~c Ulrich Relmer and Udo tI~h-Discussion Wrap-Up Mark Maybury iv"]},{"title":"i I I i I ! I | I I i i I i I i I i TABLE OF CONTENTS","paragraphs":["Summarssrag Where are we nowO Where Should we go ~, Kaxen Sparck Jones","Sahenee-based Content Character:zat:on of Text Documents, Brammlr Boguraev and Chrmtopher Kennedy","Using Lez:cal Cha:ns for Tezt Summar:zatwn,Regma Barzday and Michael Elhadad","Automated Tezt Summar:zatwn m SUMMARIST, Eduard Hovy and Clnn Yew Lm","How to Appreczate the Quahty of Automatw Ted Summar:zatson, Jean-Luc Mmel, Sylvmne Nugter, and Gdrald Plat","A Proposal for Task-Based Eraluat:on of Tezt Summartzatwn Systems, Th&~e F Hand","Automat:e Ted Summanzatwn by Paragraph Extractzon, Mandar Mttra, Amlt Smghal, and Chrm Buckley","Goal Dsrected Approach for TeE Summarszatwn, Ryo Ochltam, Yosho Nakao, and Fumlhto Nmhmo","-","Statzst:cal Methods for Retrter:ng Most Ssgn:ficant Paragraphs m Newspaper Art:cles, Josd Abracos and Gabriel Perexra Lopes",".Sentence Eztract:on as a Class:fieat:on Task, Sxmone H Teufel and Marc Moens","A Scalable Summar:zatlon System Uszng Robust NLP, Chmatsu Aone, Mary Ellen Okurowskt, James Gorhnsky, and Bjomar Laxsen","COSY-MATS An Intelhgent and Scalable Summar:zat:on Shell, Mama Aretoulah From D:scourse Structures to Tezt Summar:es, Darnel Marcu S:mSum S, mulatzon of summarzzmg, Bngttte Endres-Nlggemeyer","A Formal Model of Tezt Summar:zat:on Based on Condensat:on Operators of a Term:nolog:cal Log:e, Ulrich Relmer and Udo Hahn V 10 18 25 31 39 47 51 58 66 74 82 89 97"]},{"title":"AUTHOR INDEX","paragraphs":["Joss Abracos Chmatsu Aone Maua Aretoulah Regina Barzflay Bramralr Boguraev Chins Buckley Michael Elhadad Bngltte Endres-Nlggemeyer James Gorhnsky Udo H~hn Th&~se F Hand Eduard Hovy Chrmtopher Kennedy Bjomar Larsen Chin Yew Lm Gabrml Perelra Lopes Darnel Marcu Jean-Luc Mmel Mandar Mrtra Marc Moens Yoslno Nakao Fulmhlto Nmhmo Sylvame Nugmr gyo Ochtam Mary Ellen 0kurowsh G&ald Plat Ulrich Relmer Amlt Smghal Karen Sparck-Jones Sunone H Teufel vl 51 66 74 10 .:. 2 39 10 89 66 2 97 18 2 66 18 51 82 25 39 58 47 47 25 47 66 25 97 39 .1 58"]},{"title":"I I I I I I ! I i I. I ! i i I I i I I","paragraphs":[]}]}
