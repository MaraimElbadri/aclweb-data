{"sections":[{"title":"","paragraphs":["Proceedings of the 12th European Workshop on Natural Language Generation, pages 185–186, Athens, Greece, 30 – 31 March 2009. c⃝2009 Association for Computational Linguistics"]},{"title":"Generation of Referring Expression with an Individual Imprint Bernd Bohnet International Computer Science Institute 1947 Center Street, CA 94704 Berkeley bohnet@icsi.berkeley.edu Abstract","paragraphs":["A major outcome of the last Shared Tasks for Referring Expressions Generation was that each human prefers distinct properties, syntax and lexical units for building referring expressions. One of the reasons for this seems to be that entities might be identified faster since the conversation partner has already some knowledge about how his conversation partner builds referring expressions. Therefore, artificial referring expressions should provide such individual preferences as well so that they become human like. With this contribution to the shared task, we follow this idea again. For the development set, we got a very good DICE score of 0.88 for the furniture domain and of 0.79 for the people domain."]},{"title":"1 Introduction","paragraphs":["We expect that the test set does not provide the information to which human a referring expression belongs. Therefore, we implemented a fall back strategy in order to get still acceptable DICE scores. In such cases, we select among all sets the set of referring expressions which is most similar to all others. We compute the similarity between two sets as the average DICE score between all referring expression of two sets. The basis for our algorithm is an extended full brevity implementation, cf. (Bohnet and Dale, 2005). IS-FP uses also the nearest neighbor technique like the IS-FBN algorithm that was introduced by Bohnet (2007).","With the nearest neighbor technique, IS-FP selects the expressions which are most similar to the referring expressions of the same human and a human that builds referring expressions similar or in the case that the human is unknown it uses the most similar one to all others referring expressions. The similarity is computed as the average of all DICE scores between all combinations of the available trails for two humans. From the result of the nearest neighbor evaluation, FP selects the shortest and if still more than one expressions remain then it computes the similarity among them and chooses the most typical and finally, if still alternatives remain, it selects one with the attributes having the highest frequency. Table 1 shows the results for IS-FP trained on the training set and applied to the development set. Set Dice MASI Accuracy . Furniture 0.880 0.691 51.25% People 0.794 0.558 36.8% Total 0.837 0.625 44% Table 1: Results for the IS-FP algorithm"]},{"title":"2 IS-GT: Realization with Graph Transducers","paragraphs":["We build the input dependency tree for the text generator due to the statistical information that we collect from the training data for each person. This procedure is consistent with our referring expression generator IS-FP that reproduces the individual imprint in a referring expression for the target person. We start with the realization of the referring expressions from a surface syntactic dependency tree, cf. (Mel’čuk, 1988). For the realization of the text, we use the Text Generator and Linguistic Environment MATE. 185"]},{"title":"3 The Referring Expression Models","paragraphs":["An algorithm learns a Referring Expression Model for each person that contributed referring expression to the corpus. The model contains the following information:","(1) The lexicalization for the values of a attribute such as couch for the value sofa, man for value person, etc.","(2) The preferred usage of determiners for the type that can be definite (the), indefinite (a), no article.","(3) The syntactic preferences such as the top left chair, the chair at the bottom to the left, etc.","The information about the determiner and the lexicalization is collected from the annotated word string and the word string itself. We collect the most frequent usage for each person in the corpus. In order to collect the preferred syntax, we annotated the word strings with syntactic dependency trees. Each of the dependency tress contains additional attributes, which describe the information content of a branch outgoing from the root as well as the possible value of the attribute at the nodes which carry the information. The learning program cuts the syntactic tree at edges starting at the root node and stores the branches in the referring expression model for the person."]},{"title":"4 Realization","paragraphs":["For the realization, we use a handcrafted grammar that generates out of the dependency trees topologic graphs. The main task of the grammar is to determine the word order. The system was developed only by using the training data without any consideration of the development data. We used as guide for the optimization cross validation of training data."]},{"title":"5 IS-FP-GT: The Combination of Attribute Selection and Realization","paragraphs":["For the combination of the both methods, we combine the two procedure in a pipeline architecture. Table 2 shows the results."]},{"title":"6 Conclusion","paragraphs":["The IS-FP algorithm reproduces the imprint of human referring expressions. When the test set contains the reference to the human then the scores are exceptional high. Set Accuracy String ED Mean SED Blue 3 Furniture 15 % 3,8625 0.3826 0.3684 People 4,41 % 4,764 0.4817 0.2263 Total 9,71 4,313 0.4321 0.297 Table 2: Results for the TUNA-REG Task"]},{"title":"References","paragraphs":["B. Bohnet and R. Dale. 2005. Viewing referring expression generation as search. In IJCAI, pages 1004–1009.","B. Bohnet. 2007. IS-FBN, IS-FBS, IS-IAC: The Adaptation of Two Classic Algorithms for the Generation of Referring Expressions in order to Produce Expressions like Humans Do. In MT Summit XI, UC-NLG+MT, pages 84–86.","I.A. Mel’čuk. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, Albany. 186"]}]}
