{"sections":[{"title":"","paragraphs":["Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 33–40, Athens, Greece, 30 March 2009. c⃝2009 Association for Computational Linguistics"]},{"title":"A note on contextual binary feature grammars Alexander Clark Department of Computer Science Royal Holloway, University of London alexc@cs.rhul.ac.uk Rémi Eyraud and Amaury Habrard Laboratoire d’Informatique Fondamentale de Marseille, CNRS, Aix-Marseille Université, France remi.eyraud,amaury.habrard@lif.univ-mrs.fr Abstract","paragraphs":["Contextual Binary Feature Grammars were recently proposed by (Clark et al., 2008) as a learnable representation for richly structured context-free and context sensitive languages. In this paper we examine the representational power of the formalism, its relationship to other standard formalisms and language classes, and its appropriateness for modelling natural language."]},{"title":"1 Introduction","paragraphs":["An important issue that concerns both natural language processing and machine learning is the ability to learn suitable structures of a language from a finite sample. There are two major points that have to be taken into account in order to define a learning method use-ful for the two fields: first the method should rely on intrinsic properties of the language it-self, rather than syntactic properties of the representation. Secondly, it must be possible to associate some semantics to the structural elements in a natural way.","Grammatical inference is clearly an important technology for NLP as it will provide a foundation for theoretically well-founded unsupervised learning of syntax, and thus avoid the annotation bottleneck and the limitations of working with small hand-labelled treebanks.","Recent advances in context-free grammatical inference have established that there are large learnable classes of context-free languages. In this paper, we focus on the basic representation used by the recent approach proposed in (Clark et al., 2008). The authors consider a formalism called Contextual Binary Feature Grammars (CBFG) which defines a class of grammars using contexts as features instead of classical non terminals. The use of features is interesting from an NLP point of view because we can associate some semantics to them, and because we can represent complex, structured syntactic categories. The notion of contexts is relevant from a grammatical inference standpoint since they are easily observable from a finite sample. In this paper we establish some basic language theoretic results about the class of exact Contextual Binary Feature Grammars (defined in Section 3), in particular their relationship to the Chomsky hierarchy: exact CBFGs are those where the contextual features are associated to all the possible strings that can appear in the corresponding contexts of the language defined by the grammar.","The main results of this paper are proofs that the class of exact CBFGs:","• properly includes the regular languages (Section 5),","• does not include some context-free languages (Section 6),","• and does include some non context-free languages (Section 7).","Thus, this class of exact CBFGs is orthogonal to the classic Chomsky hierarchy but can represent a very large class of languages. Moreover, it has been shown that this class is efficiently learnable. This class is therefore an interesting candidate for modeling natural language and deserves further investigation."]},{"title":"2 Basic Notation","paragraphs":["We consider a finite alphabet Σ, and Σ∗","the free monoid generated by Σ. λ is the empty string, and a language is a subset of Σ∗",". We will write the concatenation of u and v as uv, and similarly for sets of strings. u ∈ Σ∗","is a substring of v ∈ Σ∗","if there are strings l, r ∈ Σ∗ such that v = lur. 33","A context is an element of Σ∗","× Σ∗",". For a string u and a context f = (l, r) we write f ⊙ u = lur; the insertion or wrapping operation. We extend this to sets of strings and contexts in the natural way. A context is also known in structuralist linguistics as an environment.","The set of contexts, or distribution, of a string u of a language L is, CL(u) = {(l, r) ∈ Σ∗","× Σ∗","|lur ∈ L}. We will often drop the subscript where there is no ambiguity. We define the syntactic congruence as u ≡L v iff CL(u) = CL(v). The equivalence classes under this relation are the congruence classes of the language. In general we will assume that λ is not a member of any language."]},{"title":"3 Contextual Binary Feature Grammars","paragraphs":["Most definitions and lemmas of this section were first introduced in (Clark et al., 2008). 3.1 Definition Before the presentation of the formalism, we give some results about contexts to help to give an intuition of the representation. The basic insight behind CBFGs is that there is a relation between the contexts of a string w and the contexts of its substrings. This is given by the following trivial lemma:","Lemma 1. For any language L and for any","strings u, u′ , v, v′","if C(u) = C(u′",") and C(v) =","C(v′","), then C(uv) = C(u′","v′","). We can also consider a slightly stronger result: Lemma 2. For any language L and for any strings u, u′",", v, v′","if C(u) ⊆ C(u′",") and C(v) ⊆ C(v′","), then C(uv) ⊆ C(u′","v′",").","C(u) ⊆ C(u′",") means that we can replace any occurrence of u in a sentence, with a u′",", without affecting the grammaticality, but not necessarily vice versa. Note that none of these strings need to correspond to non-terminals: this is valid for any fragment of a sentence.","We will give a simplified example from English syntax: the pronoun it can occur every-where that the pronoun him can, but not vice versa1",". Thus given a sentence “I gave him away”, we can substitute it for him, to get the","1","This example does not account for a number of syn-","tactic and semantic phenomena, particularly the distri-","bution of reflexive anaphors. grammatical sentence I gave it away, but we cannot reverse the process. For example, given the sentence it is raining, we cannot substitute him for it, as we will get the ungrammatical sentence him is raining. Thus we observe C(him) ⊊ C(it).","Looking at Lemma 2 we can also say that, if we have some finite set of strings K, where we know the contexts, then: Corollary 1. C(w) ⊇ ⋃","u′ ,v′",":","u′ v′","=w ⋃ u∈K:","C(u)⊆C(u′",") ⋃ v∈K:","C(v)⊆C(v′",") C(uv)","This is the basis of the representation: a word w is characterised by its set of contexts. We can compute the representation of w, from the representation of its parts u′",", v′",", by looking at all of the other matching strings u and v where we understand how they combine (with subset inclusion). In order to illustrate this concept, we give here a simple example.","Consider the language {an","bn","|n > 0} and the set K = {aabb, ab, abb, aab, a, b}. Suppose we want to compute the set of contexts of aaabbb, Since C(abb) ⊆ C(aabbb), and vacuously C(a) ⊆ C(a), we know that C(aabb) ⊆ C(aaabbb). More generally, the contexts of ab can represent an","bn",", those of aab the strings an+1","bn","and the ones of abb the strings an","bn+1",".","The key relationships are given by context set inclusion. Contextual binary feature grammars allow a proper definition of the combina-tion of context inclusion: Definition 1. A Contextual Binary Feature Grammar (CBFG) G is a tuple ⟨F, P, PL, Σ⟩. F is a finite set of contexts, called features, where we write C = 2F","for the power set of F defining the categories of the grammar, P ⊆ C × C × C is a finite set of productions that we write x → yz where x, y, z ∈ C and PL ⊆ C × Σ is a set of lexical rules, written x → a. Normally PL contains exactly one production for each letter in the alphabet (the lexicon). A CBFG G defines recursively a map fG 34","from Σ∗ → C as follows: fG(λ) = ∅ (1) fG(w) = ⋃ (c→w)∈PL c iff |w| = 1 (2) fG(w) = ⋃ u,v:uv=w ⋃ x→yz∈P : y⊆fG(u)∧ z⊆fG(v) x iff |w| > 1. (3)","We give here more explanation about the map fG. It defines in fact the analysis of a string by a CBFG. A rule z → xy is applied to analyse a string w if there is a cut uv = w s.t. x ⊆ fG(u) and y ⊆ fG(v), recall that x and y are sets of contexts. Intuitively, the relation given by the production rule is linked with Lemma 2: z is included in the set of features of w = uv. From this relationship, for any (l, r) ∈ z we have lwr ∈ L(G).","The complete computation of fG is then justified by Corollary 1: fG(w) defines all the possible features associated by G to w with all the possible cuts uv = w (i.e. all the possible derivations).","Finally, the natural way to define the membership of a string w in L(G) is to have the context (λ, λ) ∈ fG(w) which implies that λuλ = u ∈ L(G). Definition 2. The language defined by a CBFG G is the set of all strings that are as-signed the empty context: L(G) = {u|(λ, λ) ∈ fG(u)}.","As we saw before, we are interested in cases where there is a correspondence between the language theoretic interpretation of a context, and the occurrence of that context as a feature in the grammar. From the basic definition of a CBFG, we do not require any specific condition on the features of the grammar, except that a feature is associated to a string if the string appears in the context defined by the feature. However, we can also require that fG defines exactly all the possible features that can be associated to a given string according to the underlying language. Definition 3. Given a finite set of contexts F = {(l1, r1), . . . , (ln, rn)} and a language L we can define the context feature map FL :","Σ∗","→ 2F","which is just the map u ↦→ {(l, r) ∈","F |lur ∈ L} = CL(u) ∩ F .","Using this definition, we now need a correspondence between the language theoretic context feature map FL and the representation in the CBFG fG. Definition 4. A CBFG G is exact if for all u ∈ Σ∗",", fG(u) = FL(G)(u).","Exact CBFGs are a more limited formalism than CBFGs themselves; without any limits on the interpretation of the features, we can define a class of formalisms that is equal to the class of Conjunctive Grammars (see Section 4). However, exactness is an important notion because it allows to associate intrinsic components of a language to strings. Contexts are easily observable from a sample and more-over it is only when the features correspond to the contexts that distributional learning algorithms can infer the structure of the language. A basic example of such a learning algorithm is given in (Clark et al., 2008). 3.2 A Parsing Example To clarify the relationship with CFG parsing, we will give a simple worked example. Consider the CBFG G = ⟨{(λ, λ), (aab, λ), (λ, b), (λ, abb), (a, λ)(aab, λ)}, P, PL, {a, b}⟩ with PL = {{(λ, b), (λ, abb)} → a, {(a, λ), (aab, λ)} → b} and P = {{(λ, λ)} → {(λ, b)}{(aab, λ)}, {(λ, λ)} → {(λ, abb)}{(a, λ)}, {(λ, b)} → {(λ, abb)}{(λ, λ)}, {(a, λ)} → {(λ, λ)}{(aab, λ)}}.","If we want to parse the string w = aabb the usual way is to have a bottom-up approach. This means that we recursively compute the fG map on the substrings of w in order to check whether (λ, λ) belongs to fG(w).","The Figure 1 graphically gives the main steps of the computation of fG(aabb). Basically there are two ways to split aabb that allow the derivation of the empty context: aab|b and a|abb. The first one correspond to the top part of the figure while the second one is drawn at the bottom. We can see for instance that the empty context belongs to fG(ab) thanks to the rule {(λ, λ)} → {(λ, abb)}{(a, λ)}: {(λ, abb)} ⊆ fG(a) and {(a, λ)} ⊆ fG(b). But for symmetrical reasons 35 the result can also be obtained using the rule {(λ, λ)} → {(λ, b)}{(aab, λ)}.","As we trivially have fG(aa) = fG(bb) = ∅, since no right-hand side contains the concatenation of the same two features, an induction proof can be written to show that (λ, λ) ∈ fG(w) ⇔ w ∈ {an","bn",": n > 0}."]},{"title":"a a b b","paragraphs":["f G {(λ,b),(λ,abb)} {(λ,b),(λ,abb)} {(a,λ),(aab,λ)} {(a,λ),(aab,λ)}","f","G f G","f","G Rule: (λ,λ) → (λ,b) (aab,λ) f G(ab) »{(λ,λ)} Rule: (a,λ) → (λ,λ) (aab,λ) f G(abb) »{(a,λ)} Rule: (λ,λ) → (λ,abb) (a,λ) f G(aabb) »{(λ,λ)} f G {(λ,b),(λ,abb)} {(λ,b),(λ,abb)} {(a,λ),(aab,λ)} {(a,λ),(aab,λ)}","f","G f G","f","G Rule: (λ,λ) → (λ,abb) (a,λ) f G(ab) »{(λ,λ)} Rule: (λ,b) → (λ,abb) (λ,λ) f G(aab) »{(λ,b)} Rule: (λ,λ) → (λ,b) (aab,λ) f G(aabb) »{(λ,λ)} Figure 1: The two derivations to obtain (λ, λ) in fG(aabb) in the grammar G.","This is a simple example that illustrates the parsing of a string given a CBFG. This example does not characterize the power of CBFG since no right handside part is composed of more than one context. A more interesting, example with a context-sensitive language, will be presented in Section 7."]},{"title":"4 Non exact CBFGs","paragraphs":["The aim here is to study the expressive power of CBFG compare to other formalism recently introduced. Though the inference can be done only for exact CBFG, where features are directly linked with observable contexts, it is still worth having a look at the more general characteristics of CBFG. For instance, it is interesting to note that several formalisms introduced with the aim of representing natural languages share strong links with CBFG. Range Concatenation Grammars Range Concatenation Grammars are a very powerful formalism (Boullier, 2000), that is a current area of research in NLP. Lemma 3. For every CBFG G, there is a non-erasing positive range concatenation grammar of arity one, in 2-var form that defines the same language. Proof. Suppose G = ⟨F, P, PL, Σ⟩. Define a RCG with a set of predicates equal to F and the following clauses, and the two variables U, V . For each production x → yz in P , for each f ∈ x, where y = {g1, . . . gi}, z = {h1, . . . hj} add clauses f (U V ) → g1(U ), . . . gi(U ), h1(V ), . . . hj(V ). For each lexical production {f1 . . . fk} → a add clauses fi(a) → ε. It is straightforward to verify that f (w) ⊢ ε iff f ∈ fG(w). Conjunctive Grammar A more exact correspondence is to the class of Conjunctive Grammars (Okhotin, 2001), in-vented independently of RCGs. For every every language L generated by a conjunctive grammar there is a CBFG representing L# (where the special character # is not included in the original alphabet).","Suppose we have a conjunctive grammar G = ⟨Σ, N, P, S⟩ in binary normal form (as defined in (Okhotin, 2003)). We construct the equivalent CBFG G′","= ⟨F, P ′",", P L, Σ⟩ as followed:","• For every letter a we add a context (la, ra) to F such that laara ∈ L;","• For every rules X → a in P , we create a rule {(la, ra)} → a in PL.","• For every non terminal X ∈ N , for every rule X → P1Q1& . . . &PnQn we add distinct contexts {(lPiQi, rPiQi)} to F, such that for all i it exists ui, lPiQiuirPiQi ∈ L and PiQi ∗ ⇒G ui;","• Let FX,j = {(lPiQi, rPiQi) : ∀i} the set of contexts corresponding to the jth","rule applicable to X. For all 36 (lPiQi, rPiQi) ∈ FX,j, we add to P ′","the rules (lPiQi, rPiQi) → FPi,kFQi,l (∀k, l).","• We add a new context (w, λ) to F such that S ∗ ⇒G w and (w, λ) → # to PL;","• For all j, we add to P ′","the rule (λ, λ) → FS,j{(w, λ)}.","It can be shown that this construction gives an equivalent CBFG."]},{"title":"5 Regular Languages","paragraphs":["Any regular language can be defined by an exact CBFG. In order to show this we will propose an approach defining a canonical form for representing any regular language.","Suppose we have a regular language L, we consider the left and right residual languages:","u−1 L = {w|uw ∈ L} (4)","Lu−1","= {w|wu ∈ L} (5)","They define two congruencies: if l, l′","∈ u−1","L","(resp. r, r′","∈ Lu−1",") then for all w ∈ Σ∗",", lw ∈","L iff l′","w ∈ L (resp. wr ∈ L iff wr′","∈ L).","For any u ∈ Σ∗",", let l min(u) be the lexico-","graphically shortest element such that l−1","minL =","u−1 L. The number of such l","min is finite by","the Myhil-Nerode theorem, we denote by Lmin","this set, i.e. {lmin(u)|u ∈ Σ∗","}. We de-","fine symmetrically Rmin for the right residuals","(Lr−1","min = Lu−1","). We define the set of contexts as: F (L) = Lmin × Rmin. (6) F (L) is clearly finite by construction.","If we consider the regular language defined by the deterministic finite automata of Figure 2, we obtain Lmin = {λ, a, b} and Rmin = {λ, b, ab} and thus F (L) = {(λ, λ), (a, λ), (b, λ), (λ, b), (a, b), (b, b), (λ, ab), (a, ab), (b, ab)}.","By considering this set of features, we can prove (using arguments about congruence classes) that for any strings u, v such that FL(u) ⊃ FL(v), then CL(u) ⊃ CL(v). This means the set of feature F is sufficient to represent context inclusion, we call this property the fiduciality.","Note that the number of congruence classes of a regular language is finite. Each congruence class is represented by a set of contexts","Figure 2: Example of a DFA. The left residuals","are defined by λ−1","L, a−1","L, b−1","L and the right","ones by Lλ−1 , Lb−1",", Lab−1","(note here that","La−1","= Lλ−1 ). FL(u). Let KL be finite set of strings formed by taking the lexicographically shortest string from each congruence class. The final grammar can be obtained by combining elements of KL. For every pair of strings u, v ∈ KL, we define a rule FL(uv) → FL(u), FL(v) (7) and we add lexical productions of the form FL(a) → a, a ∈ Σ.","Lemma 4. For all w ∈ Σ∗ , fG(w) = FL(w). Proof. (Sketch) Proof in two steps: ∀w ∈ Σ∗",", F","L(w) ⊆ fG(w) and fG(w) ⊆ FL(w). Each step is made by induction on the length of w and uses the rules created to build the grammar, the derivation process of a CBFG and the fiduciality for the second step. The key point rely on the fact that when a string w is parsed by a CBFG G, there exists a cut of w in uv = w (u, v ∈ Σ∗",") and a rule z → xy in G such that x ⊆ fG(u) and y ⊆ fG(v). The rule z → xy is also obtained from a substring from the set used to build the grammar using the FL map. By inductive hypothesis you obtain inclusion between fG and FL on u and v.","For the language of Figure 2, the following set is sufficient to build an exact CBGF: {a, b, aa, ab, ba, aab, bb, bba} (this corresponds to all the substrings of aab and bba). We have: FL(a) = F (L)\\{(λ, λ), (a, λ)} → a FL(b) = F (L) → b FL(aa) = FL(a) → FL(a), FL(a) FL(ab) = F (L) → FL(a), FL(b) = FL(a), F (L) FL(ba) = F (L) → FL(b), FL(a) = F (L), FL(a) FL(bb) = F (L) → FL(b), FL(b) = F (L), F (L) 37 FL(aab) = FL(bba) = FL(ab) = FL(ba)","The approach presented here gives a canonical form for representing a regular language by an exact CBFG. Moreover, this is is complete in the sense that every context of every substring will be represented by some element of F (L): this CBFG will completely model the relation between contexts and substrings."]},{"title":"6 Context-Free Languages","paragraphs":["We now consider the relationship between CFGs and CBFGs. Definition 5. A context-free grammar (CFG) is a quadruple G = (Σ, V, P, S). Σ is a finite alphabet, V is a set of non terminals (Σ ∩ V = ∅), P ⊆ V × (V ∪ Σ)+","is a finite set of productions, S ∈ V is the start symbol.","In the following, we will suppose that a CFG is represented in Chomsky Normal Form, i.e. every production is in the form N → U W with N, U, W ∈ V or N → a with a ∈ Σ. We will write uN v ⇒G uαv if there is a production N → α ∈ P . ∗ ⇒G is the reflexive tran-","sitive closure of ⇒G. The language defined by","a CFG G is L(G) = {w ∈ Σ∗","|S ∗","⇒G w}. 6.1 A Simple Characterization A simple approach to try to represent a CFG by a CBFG is to define a bijection between the set of non terminals and the set of context features. Informally we define each non terminal by a single context and rewrite the productions of the grammar in the CBFG form.","To build the set of contexts F , it is sufficient to choose |V | contexts such that a bijection bC can be defined between V and F with bC (N ) = (l, r) implies that S ∗ ⇒ lN r. Note that we fix","bT (S) = (λ, λ).","Then, we can define a CBFG","⟨F, P ′",", P ′","L, Σ⟩, where P ′","= {b","T (N ) → bT (U )bT (W )|N → U W ∈ P } and P ′","L = {bT (N ) → a|N → a ∈ P, a ∈ Σ}. A similar proof showing that this construction produces an equivalent CBFG can be found in (Clark et al., 2008).","If this approach allows a simple syntactical convertion of a CFG into a CBFG, it is not relevant from an NLP point of view. Though we associate a non-terminal to a context, this may not correspond to the intrinsic property of the underlying language. A context could be associated with many non-terminals and we choose only one. For example, the context (He is, λ) allows both noun phrases and adjective phrases. In formal terms, the resulting CBFG is not exact. Then, with the bijection we introduced before, we are not able to characterize the non-terminals by the contexts in which they could appear. This is clearly what we don’t want here and we are more interested in the relationship with exact CBFG. 6.2 Not all CFLs have an exact CBFG We will show here that the class of context-free grammars is not strictly included in the class of exact CBFGs. First, the grammar defined in Section 3.2 is an exact CBFG for the context-free and non regular language {an","bn","|n > 0}, showing the class of exact CBFG has some elements in the class of CFGs.","We give now a context-free language L that can not be defined by an exact CBFG:","L = {an","b|n > 0} ∪ {am","cn","|n > m > 0}. Suppose that there exists an exact CBFG that recognizes it and let N be the length of the biggest feature (i.e. the longuest left part of the feature). For any sufficiently large k > N , the sequences ck","and ck+1","share the same features: FL(ck",") = F","L(ck+1","). Since the CBFG is exact we have FL(b) ⊆ FL(ck). Thus any derivation of ak+1","b could be a derivation of ak+1","ck","which does not belong to the language.","However, this restriction does not mean that the class of exact CBFG is too restrictive for modelling natural languages. Indeed, the example we have given is highly unnatural and such phenomena appear not to occur in at-tested natural languages."]},{"title":"7 Context-Sensitive Languages","paragraphs":["We now show that there are some exact CBFGs that are not context-free. In particular, we define a language closely related to the MIX language (consisting of strings with an equal number of a’s, b’s and c’s in any order) which is known to be non context-free, and indeed is conjectured to be outside the class of indexed grammars (Boullier, 2003). 38 Let M = {(a, b, c)∗","}, we consider the language L = Labc∪Lab∪Lac∪{a′","a, b′","b, c′","c, dd′",", ee′",", f f ′","}: Lab = {wd|w ∈ M, |w|a = |w|b}, Lac = {we|w ∈ M, |w|a = |w|c}, Labc = {wf |w ∈ M, |w|a = |w|b = |w|c}. In order to define a CBFG recognizing L, we have to select features (contexts) that can represent exactly the intrinsic components of the languages composing L. We propose to use the following set of features for each sublanguages: • For Lab: (λ, d) and (λ, ad), (λ, bd). • For Lac: (λ, e) and (λ, ae), (λ, ce). • For Labc: (λ, f ).","• For the letters a′",", b′ , c′",", a, b, c we add:","(λ, a), (λ, b), (λ, c), (a′ , λ), (b′",", λ), (c′",", λ).","• For the letters d, e, f, d′",", e′",", f ′","we add;","(λ, d′","), (λ, e′","), (λ, f ′","), (d, λ), (e, λ), (f, λ). Here, Lab will be represented by (λ, d), but we will use (λ, ad), (λ, bd) to define the internal derivations of elements of Lab. The same idea holds for Lac with (λ, e) and (λ, ae), (λ, ce).","For the lexical rules and in order to have an exact CBFG, note the special case for a, b, c: {(λ, bd), (λ, ce), (a′",", λ)} → a {(λ, ad), (b′",", λ)} → b {(λ, ad), (λ, ae), (c′",", λ)} → c For the nine other letters, each one is defined with only one context like {(λ, d′",")} → d.","For the production rules, the most important one is: (λ, λ) → {(λ, d), (λ, e)}, {(λ, f ′",")}.","Indeed, this rule, with the presence of two contexts in one of categories, means that an element of the language has to be derived so that it has a prefix u such that fG(u) ⊇ {(λ, d), (λ, e)}. This means u is both an element of Lab and Lac. This rule represents the language Labc since {(λ, f ′",")} can only represent the letter f .","The other parts of the language will be defined by the following rules: (λ, λ) → {(λ, d)}, {(λ, d′",")}, (λ, λ) → {(λ, e)}, {(λ, e′",")}, (λ, λ) → {(λ, a)}, {(λ, bd), (λ, ce), (a′",", λ)}, (λ, λ) → {(λ, b)}, {(λ, ad), (b′",", λ)}, (λ, λ) → {(λ, c)}, {(λ, ad), (λ, ae), (c′",", λ)}, (λ, λ) → {(λ, d′",")}, {(d, λ)}, (λ, λ) → {(λ, e′",")}, {(e, λ)},","(λ, λ) → {(λ, f ′ )}, {(f, λ)}.","This set of rules is incomplete, since for representing Lab, the grammar must contain the rules ensuring to have the same number of a’s and b’s, and similarly for Lac. To lighten the presentation here, the complete grammar is presented in Annex.","We claim this is an exact CBFG for a context-sensitive language. L is not context-free since if we intersect L with the regular language {Σ∗","d}, we get an instance of the non context-free MIX language (with d appended). The exactness comes from the fact that we chose the contexts in order to ensure that strings belonging to a sublanguage can not belong to another one and that the derivation of a substring will provide all the possible correct features with the help of the union of all the possible derivations.","Note that the Mix language on its own is probably not definable by an exact CBFG: it is only when other parts of the language can distributionally define the appropriate partial structures that we can get context sensitive languages. Far from being a limitation of this formalism (a bug), we argue this is a feature: it is only in rather exceptional circumstances that we will get properly context sensitive languages. This formalism thus potentially accounts not just for the existence of non context free natural language but also for their rarity."]},{"title":"8 Conclusion","paragraphs":["The chart in Figure 3 summarises the different relationship shown in this paper. The substitutable languages (Clark and Eyraud, 2007) and the very simple ones (Yokomori, 2003) form two different learnable class of languages. There is an interesting relationship with Marcus External Contextual Grammars (Mitrana, 2005): if we defined the language of a CBFG to be the set {fG(u) ⊙ u : u ∈ Σ∗","} we would be taking some steps towards contextual grammars.","In this paper we have discussed the weak generative power of Exact Contextual Binary Feature Grammars; we conjecture that the class of natural language stringsets lie in this class. ECBFGs are efficiently learnable (see (Clark et al., 2008) for details) which is a com-39 Context-free Regular Context sensitive very simple substitutable Range Concatenation"," Conjunctive = CBFG Exact CBFG Figure 3: The relationship between CBFG and other classes of languages. pelling technical advantage of this formalism over other more traditional formalisms such as CFGs or TAGs."]},{"title":"References","paragraphs":["Pierre Boullier. 2000. A Cubic Time Extension of Context-Free Grammars. Grammars, 3:111– 131.","Pierre Boullier. 2003. Counting with range concatenation grammars. Theoretical Computer Science, 293(2):391–416.","Alexander Clark and Rémi Eyraud. 2007. Polynomial identification in the limit of substitutable context-free languages. Journal of Machine Learning Research, 8:1725–1745, Aug.","Alexander Clark, Rémi Eyraud, and Amaury Habrard. 2008. A polynomial algorithm for the inference of context free languages. In Proceedings of International Colloquium on Grammatical Inference, pages 29–42. Springer, September.","V. Mitrana. 2005. Marcus external contextual grammars: From one to many dimensions. Fundamenta Informaticae, 54:307–316.","Alexander Okhotin. 2001. Conjunctive grammars. J. Autom. Lang. Comb., 6(4):519–535.","Alexander Okhotin. 2003. An overview of conjunctive grammars. Formal Language Theory Column, bulletin of the EATCS, 79:145–163.","Takashi Yokomori. 2003. Polynomial-time identification of very simple grammars from positive data. Theoretical Computer Science, 298(1):179–206."]},{"title":"Annex","paragraphs":["(λ, λ) → {(λ, d), (λ, e)}, {(λ, f ′",")}","(λ, λ) → {(λ, d)}, {(λ, d′",")}","(λ, λ) → {(λ, e)}, {(λ, e′",")}","(λ, λ) → {(λ, a)}, {(λ, bd), (λ, ce), (a′",", λ)}","(λ, λ) → {(λ, b)}, {(λ, ad), (b′",", λ)}","(λ, λ) → {(λ, c)}, {(λ, ad), (λ, ae), (c′",", λ)}","(λ, λ) → {(λ, d′",")}, {(d, λ)}","(λ, λ) → {(λ, e′",")}, {(e, λ)}","(λ, λ) → {(λ, f ′",")}, {(f, λ)} (λ, d) → {(λ, d)}, {(λ, d)} (λ, d) → {(λ, ad)}, {(λ, bd)} (λ, d) → {(λ, bd)}, {(λ, ad)} (λ, d) → {(λ, d)}, {(λ, ad), (λ, ae), (c′",", λ)} (λ, d) → {(λ, ad), (λ, ae), (c′",", λ)}, {(λ, d)}","(λ, ad) → {(λ, ad), (λ, ae), (c′",", λ)}, {(λ, ad)}","(λ, ad) → {(λ, ad)}, {(λ, ad), (λ, ae), (c′",", λ)}","(λ, ad) → {(λ, ad), (b′",", λ)}, {(λ, d)}","(λ, ad) → {(λ, d)}, {(λ, ad), (b′",", λ)} (λ, bd) → {(λ, ad), (λ, ae), (c′",", λ)}, {(λ, bd)} (λ, bd) → {(λ, bd)}, {(λ, ad), (λ, ae), (c′",", λ)} (λ, bd) → {(λ, bd), (λ, ce), (a′",", λ)}, {(λ, d)} (λ, bd) → {(λ, d)}, {(λ, bd), (λ, ce), (a′",", λ)} (λ, e) → {(λ, e)}, {(λ, e)} (λ, e) → {(λ, ae)}, {(λ, ce)} (λ, e) → {(λ, ce)}, {(λ, ae)} (λ, e) → {(λ, e)}, {(λ, ad), (b′",", λ)} (λ, e) → {(λ, ad), (b′",", λ)}, {(λ, e)} (λ, ae) → {(λ, ad), (b′",", λ)}, {(λ, ae)} (λ, ae) → {(λ, ae)}, {(λ, ad), (b′",", λ)} (λ, ae) → {(λ, ad), (λ, ae), (c′",", λ)}, {(λ, e)} (λ, ae) → {(λ, e)}, {(λ, ad), (λ, ae), (c′",", λ)} (λ, ce) → {(λ, ad), (b′",", λ)}, {(λ, ce)} (λ, ce) → {(λ, ce)}, {(λ, ad), (b′",", λ)} (λ, ce) → {(λ, bd), (λ, ce), (a′",", λ)}, {(λ, e)} (λ, ce) → {(λ, e)}, {(λ, bd), (λ, ce), (a′",", λ)} {(λ, bd), (λ, ce), (a′",", λ)} → a {(λ, ad), (b′",", λ)} → b {(λ, ad), (λ, ae), (c′",", λ)} → c {(λ, d′",")} → d {(λ, e′",")} → e {(λ, f ′",")} → f {(λ, a)} → a′ {(λ, b)} → b′ {(λ, c)} → c′ {(d, λ)} → d′ {(e, λ)} → e′ {(f, λ)} → f ′ 40"]}]}
