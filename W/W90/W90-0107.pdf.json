{"sections":[{"title":"Using Bidirectional Semantic Rules for Generation","paragraphs":["Jim Barnett and Inderjeet Mani","Microelectronics and Computer Technology Corporation (MCC)","3500 West Balcones Center Drive","Austin, Texas 78759 U.S.A.","Abstract This paper describes the use of a system of semantic rules to generate noun compounds, vague or polysemous words, and cases of metonymy. The rules are bidirectional and are used by the understanding system to interpret the same constructions.","Introduction In generation systems that are paired with understanding systems, bidirectionality is desirable for reasons that are both theoretical (a single model of linguistic behaviour) and practical (shorter development time, greater consistency, etc.) 1. Recently, [Shieber et al. 89] and [Calder at al. 89] have presented generation algorithms that share both semantics and syntax with the understanding system. This paper presents an extension of these algorithms to deal with phenomena that have often been lumped together under 'pragmatics', namely noun compounding, metonymy (the use of a word to refer to a related concept), and vague or polysemous words like \"have.\"","The difficulty with these constructions is that they are productive, and cannot be handled easily by simply listing meanings in a lexicon. Taking noun compounding as an example, we have \"corn oil\" and \"olive oil\" referring to oil made from corn or olives. We could add a lexical sense for \"corn\" meaning \"made from corn,\" but then we face an explosion in the size of the lexicon, and an inability to understand or generate novel compounds: if we acquire \"safflower\" as the name of a plant, we would like the system to be able to handle \"safflower oil\" immediately, but this won't be possible if we need a separate lexical sense to handle compounding. The system will be more robust (and the lexicon more compact) if we can derive the desired sense of \"safflower\" from the basic noun sense when we need it. We have therefore developed a system of bidirectional semantic rules to handle these phenomena at the appropriate level of generality.","IF or more detailed arguments along these lines, see [Appelt 87], [Shieber 88], [Jacobs 88a].","We have implemented these rules in Common Lisp as part of the KBNL system [Barnett et M. 90] at MCC, but nothing depends on the idiosyncracies of our for-malisms or implementation, so the technique is compatible with a wide variety of theories of the kinds of relations that are likely to occur in these constructions, as in, e.g., [Finin 80] for noun compounds and [Nunberg 78] for oblique reference.","The Framework The algorithms for recognition and generation use an agenda-based blackboard for communication and control [Cohen et al. 89]. Our syntax component uses an extension of Categorial Unification Grammar [Wittenburg 86] as the phrase-structure component of an LFG-style functional representation (f-struCture), and the semantic component maps from this representation to sets of assertions in the interface language of the CYC knowledge base [Lenat et al. 90].","Semantic rules map partial semantic interpretations onto other partial interpretations. They consist of a left-hand side and a right-hand side, each consisting of one or more templates, plus a mechanism for mapping an instantiation of either set of templates onto an instantiation of the other set. The intuitive semantics of these rules is that any interpretation that matches the left-hand side licenses a second interpretation matching the right-hand side. For example, we can use the name of an author to refer to his works (\"I read Shakespeare\"), and the corresponding semantic rule states that the existence of an NP denoting an artist licences the use of the same NP to refer to his works. The generation system applies the rules in a backward-chaining direction, while the understanding system runs them forward. A later section contains a fuller discussion of the implementation of the rules, while the next sections discuss their use at runtime. Generation The generator is divided into strategic and tactical components. The former takes a frame as input and creates a description of it based on a set of discriminative 47 properties which are recorded in the KB and indicate which aspects of a frame are likely to be salient. If a comparison class is available, the resulting description uniquely identifies the frame with respect to that class, otherwise it contains default 'interesting' properties. Once it has generated this set of assertions, the strategic component calls the tactical component with a goal"]},{"title":"Semantics : Syntax,","paragraphs":["where"]},{"title":"Semantics","paragraphs":["consists of the assertions plus the distinguished variable that the utterance is 'about', and"]},{"title":"Syntax","paragraphs":["is an f-structure (which may specify no more than the category.)","Given this input, the tactical component uses a variant of the semantic-head driven algorithms described by [Calder at al. 89] and [Shieber et al. 89] to generate a phrase whose syntax and semantics match the goal. Before examining this algorithm, we note that in categorial grammars, most of the syntactic information is contained in the lexical definitions of words. For example, the lexical entry for a transitive verb like \"read\" specifies that it takes an object NP to its right and then a subject NP to its left. Any such constituent that takes at least one argument is called a"]},{"title":"funclor,","paragraphs":["while a constituent with no arguments is called"]},{"title":"atomic.","paragraphs":["Functors and their arguments are combined by a small number of"]},{"title":"binary rules,","paragraphs":["and there is also a set of"]},{"title":"unary rules,","paragraphs":["which can change the category of a constituent (forming passive verbs out of actives, for example.) Next we define two relationships between con-","stituents and goals: first, a constituent"]},{"title":"matches","paragraphs":["a goal if its semantics subsumes the goal's semantics and its syntactic category is the same as the goal's, with possible extra arguments. Thus the transitive verb \"eat\", with category"]},{"title":"S\\NP/NP,","paragraphs":["is a syntactic match for the goal category S because it will he an S once it gets its arguments. Second, a constituent"]},{"title":"satisfies","paragraphs":["a goal if it has identical semantics and its f-structure is a supergraph of the goal's f-structure.","Given this syntactic framework, the algorithm works by peeling off lexical functors and recursing on their arguments until it bottoms out in an atomic constituent. Given a goal, the first step consists of lexical look-up to find an item that matches the goal. Once this item, called the semantic head, is found, the algorithm proceeds both top-down and bottom up. If the semantic head is a functor, it proceeds top-down trying to solve the sub-goal for its argument. Once this sub-goal is satisfied, the algorithm works bottom-up by applying unary grammar rules to to the argument constituent alone, or binary rules to combine it with the functor. When a complete constituent is found which satisfies the goal, we are done. Extension: Goal Revision The algorithm described above assumes a fixed set of choices in the lexicon. It can generate metonymic expressions and noun compounds, but only at the cost of massive lexical ambiguity. We therefore extend it by considering the possibility of goal revision as an alternative to the lexical look-up step s. By running a semantic rule backward, we can map the current goal onto one or more new goals to which the algorithm recursively applies. Satisfying the new goals will generate an expression with the desired meaning and thus indirectly satisfy the original goal.","Revision using noun compounding rules leads to a binary decomposition of the original goal, as shown in Figure 2, while metonymy rules result in a unary decomposition, as shown in Figure 3. From this perspective, we note that the lexical look-up of a functor can be viewed as a kind of guided binary decomposition (Figure 1), splitting the original goal into two sub-goals with the knowledge that one of them will be satisfied immediately."]},{"title":"[ :o.L I","paragraphs":["(X HRSCOLOR Y) [ (x Isg BOOK) I (Y EOURLS RED) | (X HRSCRER/OR Z) I (Z EOURLS MRO) ] .t. I (U HRSCOLOR V)l |(X ISR BOOK) |","[(X HRSCRERTOR Z)["]},{"title":"l(V E%URLS","paragraphs":["RED)] [(Z EOURLS .BO) I Figure 1: Lexical Lookup as Decomposition","Our extension to the algorithms of [Calder at al. 89] and [Shieber et al. 89] thus amounts to the decision to allow top-down decomposition to be guided by rules as well as lexical items. As we would expect, this is the mirror image of the situation during understanding, where semantic rules are used as an extension to the lexicon in the process of merging translations bottom-up. The extended algorithm is shown in the Appendix. Controlling Rule Application The strategic component can control the choice among alternatives through its specification of the goal's syntax. For example, the strategic component can force the use of a compound by providing an appropriately detailed f-structure (i.e., one that specifies the presence of a modifier of category N.) If it does so, no matter whether we are in best-first or all-paths mode, only the compounding alternative will succeed and satisfy the syntactic goal. On the other hand, if the syntactic goal is underspecified, the output (in best-first mode) will","aThe notion of goal revision in generation dates back to [Appelt 83] where various conditions could lead to replanning of the input; for recent work incorporating goal revision see [Vaughan et al. 86]. 48 depend on the tactical component's heuristic ordering. In this case, given the default ordering which prefers lexical look-up to noun compounding to metonymy, the tactical component will use a noun compound when lexical look-up fails (i.e., there is no corresponding adjective or preposition). Another result of this default ordering is that metonymy will never fire in the absence of a syntactic specification since there is always another way (unless the lexicon is incomplete) of say-ing the same thing using words that are in the lexicon. However, the literal alternative is usually more verbose than the metonymous expression, ,so the strategic component can force the use of metonymy by specifying a limit on the number of words the tactical component is allowed to use. Given a limit of 3 words, descriptive phrases like \"a book by Joyce\" will fail, and only the metonymous expression \"Joyce\" will succeed.","In best-first mode, substantial improvements in efficiency are possible by re-ordering the alternatives based on the syntactic properties of the goal. For example, it makes sense to try metonymy first if the desired length is significantly less than the number of assertions in the goal's semantics, since each lexical item normally covers only a few assertions. Generating Noun Compounds Suppose we have a Software-Machine rule, stating that if \"y\" denotes any kind of"]},{"title":"Software","paragraphs":["and \"x\" a computer, \"a y x\" means a"]},{"title":"Computer","paragraphs":["x that"]},{"title":"CanRun-Language","paragraphs":["y. Now consider a goal with semantics"]},{"title":"(W ISA Computer)(Z Equals Lisp)(W CanRunLanguage Z),","paragraphs":["distinguished variable W, and syntax NP. There is no lexical item covering all these assertions, or any lexical functor covering part of them (i.e., \"Lisp\" is not in the lexicon as an adjective.) Thus, even in best-first mode, we will end up applying the Software-Machine rule to this goal, resulting in the decomposition shown in Figure 2. GOAL rtP (Q CRMRUMLPJIGURGE Z) (W ISR COMPUTER) (Z EOURLS LIGP)"]},{"title":"I","paragraphs":["(Z EOURLS LISP) I I(W ISR CO.PUIER) I isfy the other. Combining the sub-goal solutions yields \"Lisp machine\" as a solution to the original goal.","Multiple compounds are handled by repeated invocations of the rules. Suppose we have a Mechanism-Maintenance rule, stating that if \"x\" denotes a"]},{"title":"Machine","paragraphs":["and \"y\" denotes any kind of"]},{"title":"MaintenanceOperalion,","paragraphs":["\"x y\" denotes a"]},{"title":"MaintenanceOperation","paragraphs":["y with y"]},{"title":"Maintains","paragraphs":["x. Given input semantics"]},{"title":"(Y ISA Repair-Operation)(Y Maintains X)(X ISA Computer)(X Can-RunLanguage Z)(Z Equals Lisp),","paragraphs":["with distinguished referent Y, the maintenance rule will eventually fire, generating patterns for a head"]},{"title":"(Y ISA RepairOperation)","paragraphs":["and a modifier"]},{"title":"(X ISA Computer)(X CanRunLanguage Z)(Z Equals Lisp).","paragraphs":["The head's goal will be satisfied by the entry for \"repair\", but processing of the modifier will invoke the Software-Machine rule, just as in the example above. The output will be \"Lisp machine repair\", with the left-branching structure [[Lisp machine] repair].","For an example of a right-branching compound, suppose we have a Product-Manufacturer rule stating that if \"x\" is the name of a"]},{"title":"Product","paragraphs":["and \"y\" is the name of a"]},{"title":"Company,","paragraphs":["then \"a y x\" is a"]},{"title":"Product","paragraphs":["x that is"]},{"title":"ManuffacluredBy","paragraphs":["company y. Given the input"]},{"title":"(X ISA Computer)(X UanufacturedBy Y)(X CanRunianguage Z)(Y Equals Symbolics)(Z Equals Lisp),","paragraphs":["the product rule will fire, producing a modifier sub-goal for"]},{"title":"(Y Equals Symbolics)","paragraphs":["and a head sub-goal for"]},{"title":"(X ISA Computer)(X CanRunLanguage Z)(Z Equals Lisp).","paragraphs":["This time the Software-Machlne rule will be invoked on the head sub-goal, while lexical item \"Symbolics\" will satisfy the modifier sub-goal, and the output will be [Symbolics [Lisp machine]]. Generating Metonymic References"]},{"title":"I","paragraphs":["GORL ~ ISR BOOK) (X HRSCRERTO~ Â¥) (Y EOURLS JRMESJOYCE)"]},{"title":"I","paragraphs":["Figure 3: Decomposition for Metonymy Figure 2: Decomposition for a Noun Compound","Recursing on the sub-goals, the lexical item \"Lisp\" will satisfy the left sub-goal, and \"machine\" will sat-Suppose we have an Artist rule licensing the use of an artist's name to refer to his works, and are trying to generate an NP with semantics"]},{"title":"(X ISA Book)(X HasCrealor JamesJoyce).","paragraphs":["If we are in all-paths mode, or if the strategic component has requested a succinct 49 rule, we need to compute the inverse of the relation. 4 To do this we reverse the order of the statements and replace each Bind statement (which computes a relation between variable bindings) with its inverse. Here we rely on the fact that the CYC KB automatically maintains inverses for all relations defined in it (for KBs without this feature, we would have to define inverses for all relations used in rules). If"]},{"title":"CreatorOffis","paragraphs":["the inverse of"]},{"title":"HasGreator,","paragraphs":["then the inverse of"]},{"title":"(Bind Z (X CreatorOf))","paragraphs":["is simply"]},{"title":"(Bind X (Z HasCreator)).","paragraphs":["A few more details are necessary to complete the implementation. First, we define tlie relation"]},{"title":"Instances,","paragraphs":["which maps from classes to their elements, as the inverse of"]},{"title":"ISA.","paragraphs":["Next we define a concatenation operator + on relations, so that"]},{"title":"(Z (Instances + ttasGreator))","paragraphs":["returns all the creators of instances of the class Z. 5 Next, we stipulate that if the variable X is already bound,"]},{"title":"(Bind X (Z ttasCreator))","paragraphs":["acts as a Filter, returning T iff X is among the values for"]},{"title":"(Z gasCreator.)","paragraphs":["Finally, for reasons of efficiency, we cache separate patterns for backward and forward application, instead of reversing the expressions at run time. The generation and understanding patterns for the Artist rule are given below: Input Pattern"]},{"title":"(W ISA Z)(new-var HasCreator X)","paragraphs":["Bind"]},{"title":"Y (Z Instances 4- HasCreator)","paragraphs":["Filter"]},{"title":"(Y ISA Person)","paragraphs":["OutputPattera"]},{"title":"(X Equals Y)","paragraphs":["Input Pattern"]},{"title":"(X Equals Y)","paragraphs":["Filter"]},{"title":"(Y ISA Person)","paragraphs":["Bind"]},{"title":"Z (Y CreatorOf + ISA)","paragraphs":["Output"]},{"title":"Pattern(W ISA Z)(new-var HasCreator Y)","paragraphs":["Running the rule backward on"]},{"title":"(Q ISA Book)(Q HasCreator JamesJoyce),","paragraphs":["initial unification binds Q to W, Z to"]},{"title":"Book","paragraphs":["and Y to"]},{"title":"JamesJoyce.","paragraphs":["The Bind expression serves as a filter in this case, checking that Y is in fact the"]},{"title":"CrealorOfsome","paragraphs":["instance of Z, the Filter expression checks that Y is a"]},{"title":"Person,","paragraphs":["and the output is"]},{"title":"(X Equals JamesJoyce),","paragraphs":["which will match the lexical semantics for \"Joyce\" permitting us to use that NP to refer to the book. Running the rule forward on"]},{"title":"(X Equals JamesJoyce),","paragraphs":["Yis bound to"]},{"title":"JamesJoyce,","paragraphs":["the Filter expression again checks that Yis a"]},{"title":"Person,","paragraphs":["and the Bind expression binds Z to all the classes of objects Yis the"]},{"title":"CreatorOf(in","paragraphs":["this case, the class"]},{"title":"Book).","paragraphs":["The output is an expression denoting any"]},{"title":"Book","paragraphs":["which"]},{"title":"HasCreator JamesJoyce,","paragraphs":["thus letting us understand \"Joyce\" as referring to a"]},{"title":"Book.","paragraphs":["The rule format is similar for noun compounds, except that there are two input patterns (in the forward direction) and a single output pattern. During understanding, the two patterns are unified with the inter-","4Mathematically, a relation is a set of ordered pairs, and","its inverse is the set of inverted pairs. Any relation is there-","fore guaranteed to have a unique inverse.","5The inverse of (rl + r2) is ((inverse r2) + (inverse rl)). pretations of the head and modifier nouns, the Filters and Binds work as before, and the output pattern is the interpretation of the compound. Backward application is as before, except that the output is a pair of instantiated patterns which the generation routine then uses as new goals. Related Work A variety of systems have used rules of the kind we are considering, either explicitly or implicitly, for use in"]},{"title":"understanding","paragraphs":["compounds, vague expressions, and metonymy, for example, [DaM et at. 87], [Hobbs et al. 88], [Grosz et at. 85], [Stallard 87], but no mention is made of reversing these rules for generation.","A number of systems generate compounds, but most apparently do so using either phrasal lexicons (e.g., [Hovy 88], [Jacobs 88b], [Wilensky 88]), or multiple lexical senses (e.g., [Pustejovsky et at. 87], [Nirenburg et al. 88]), rather than rules of the sort we propose. Other generation systems apparently construct noun compounds via specialized (uni-directional) strategies specified in the interface to the tactical component [McDonald et at. 88], or a combination of these techniques [McKeown 82]. We have been unable to find discussions of generation of metonymy, though at least some cases of it could obviously be handled via lexical ambiguity."]},{"title":"Discussion","paragraphs":["The use of semantic rules seems to us to handle most of the technical problems in providing an economical, bidirectional treatment of a variety of non-literal and/or vague constructions. At the heart of any reversible system is the notion of being able to run mappings for-wards or backwards, so that, for example, the understanding and generation lexicons are inverses of each other. These rules are a natural extension of this mechanism to more complex constructions. Furthermore, these rules can handle a wide variety of phenomena. In addition to the examples discussed above, we have used semantic rules for the lexical semantics of vague words like \"have\" and \"of\", which are like noun compounding and metonymy in that the only alternative to massive lexical ambiguity is to compute the nature of the relation based on the interpretation of the arguments. This use of semantic rules for lexical semantics amounts to permitting a lexical item to further decompose its sub-goal, instead of satisfying it immediately in the manner of Figure 1. Finally, these rules do not commit us to any particular analysis of the constructions in ques-tion (except insofar as they assume separate levels of syntactic and semantic representation.) To take noun compounding as an example, we can implement a wide variety of theories of the kinds of relations compounds express and of the hierarchies among them. 51","The main open issue is the development of strategies for the use of these expressions. The problem is most acute in the case of metonymy. At present, the strategic component can force the use of metonymous expressions by requiring brevity. However, use of metonymy is not just a matter of succinctness since it also tends to indicate informality and familiarity. In more extreme uses, it may have a poetic or humorous force. To use metonymy, compounds, or other vague expressions successfully, we need a theory of how they effect the discourse, as well as a strategic component which is sophisticated enough to exploit the theory. As a first step in this direction, we are implementing a discourse module which will allow us to address some of these issues. For example, metonymous expressions are safer when used to refer to classes of objects that have already been described than when used to introduce new ones. If \"an Orris fishing rod\" has already been mentioned, then \"an Orris\" is likely to make sense, even to people who wouldn't have understood it the first time around. However, such individual heuristics will be of limited usefulness until they are integrated into a comprehensive model of communication. Acknowledgments We are grateful to Elaine Rich for comments on an earlier draft of this paper. Appendix: Generation Algorithm The psuedocode for the generation algorithm is shown below, identifying the point of departure from the [Calder at al. 89] algorithm. The lexical lookup-step of line 1 is replaced with the more general top-down step of line la, by calling the new function"]},{"title":"ge,erafe-tp-dn.","paragraphs":["The rest of the (pseudo)code remains unchanged.","Here are the language constructs used in the pseudocode. We denote local variable assignment as X := Y, with scope extending to the immediate containing construct. Destructuring by pattern matching is allowed, e.g. < X1 X2 X3 >:= Y simultaneously binds"]},{"title":"X1, X2","paragraphs":["and"]},{"title":"X3","paragraphs":["to the corresponding components in Y."]},{"title":"AND","paragraphs":["and"]},{"title":"OR","paragraphs":["have exactly the behavior of Common","Lisp AND and OR. For the sake of conciseness,the function"]},{"title":"choose","paragraphs":["is used as a shorthand for control strategies: in all-paths mode, it finds all solutions; in best-first mode it imposes a heuristic ordering on the choices and finds a single solution, finding any subsequent solutions on backtrack-ing. The function"]},{"title":"choose-tp-dn-operatio,","paragraphs":["heuristically picks the best operation based on the goal. The functions"]},{"title":"match","paragraphs":["and"]},{"title":"satisfy","paragraphs":["are as defined earlier. The functions"]},{"title":"apply-unavy-bup-rule","paragraphs":["and"]},{"title":"apply-bi.avy-bup-rule","paragraphs":["constitute the rule application interface to grammar rules; similarly, the functions"]},{"title":"apply-uuary-tp-dn-rule","paragraphs":["and"]},{"title":"apply-binary-tp-d.-rule","paragraphs":["constitute the rule application interface for the semantic rules. FUNCTION generate(Goal); 1AND(;;OLD: Subgoal :ffi lex-decomp(Goal)",";; NEW: la Subgoal := choose(generate-tp-dn(Goal))",";; AS BEFORE: 2 choose(generate-bup(Subgoal, Goal))).","FUNCTION generate-tp-dn(Goal);","operation :=","choose(choose-tp-dn-operation(Goal))","CASE operation",":lex","lex-decomp(Goal)",":unary-decomp",";; e.g. METONYMY RULES:","choose(apply-unary-tp-dn-rule(Goal))",":binary-decomp",";; e.g. COMPOL~DING/VAGUEWORD RULES:","AND(<lef$-subgoal, right-subgoal> :=","choose(apply-binary-tp-dn-rule","(Goal)),","choose(generate(left-subgoal)),","choose(generate(right-subgoal)),","choose(apply-binary-bup-rule","(left-subgoal, right-subgoal))).","FUNCTION generate-bup(Subgoal, Goal);","OR(satisfies(Subgoal, Goal),","AND(Arg :=","choose(extract-arg(Subgoal)), Goall := choose(apply-binary-bup-rule (Subgoal, ARE)), choose(generate(Arg)), choose(generate-bup (Goall, Goal))),","AND(Goall := choose(apply-unary-bup-rule (Subgoal)), choose(generate-bup (Goall, Goal)))).","FUNCTION lex-decomp(Goal);","AND(Subgoal := choose(lexical-lookup(Goal)), matches(Subgoal, Goal), Subgoal)."]},{"title":"References [Appelt 83] D. E. Appelt, \"Telegram: A Grammar For-malism For Language Planning\", Proceedings of the ACt, M.I.T., 15-17 June, 1983. [Appelt 87] D. E. Appelt, \"Bidirectional Grammars and the Design of Natural Language Generation Systems\", TINLAP-3 Posilion Papers, New Mexico State University, 7-9 January, 1987. [Barnett et al. 90] J. Barnett, K. Knight, I. Mani, and E. Rich, \"Knowledge and Natural Language Pro-","paragraphs":["52"]},{"title":"eessing', to appear in Communications of the ACM, August, 1990. [Calder at al. 89] J. Calder, M. Reape, and H. Zeevat, \"An Algorithm for Generation in Unification Categorial Grammar\", Proceedings of the 4th Conference of the European Chapter of the ACL, pp. 233-- 240, Manchester, 10-12 April, 1989. [Cohen et al. 89] R. M. Cohen, T. P. McCandless, and E. Rich, \"A Problem Solving Approach to Human-Computer Interface Management\", MCC Tech Report ACT-HI-g06-89, Fall 1989. [Dahl et al. 87] D. Dahl, M. Palmer, and R. Passonneau, \"Nominalizations in Pundit\", Proceedings of the ACL, Stanford, 6-9 July, 1987. [Finin 80] T. Finin, \"The Semantic Interpretation of Compound Nominals\", University of Illinois, Ph.D. Dissertation, 1980. [Grosz et al. 85] B. Grosz, D. Appelt, P. Martin, and F. C. N. Pereira, \"Team: An Experiment in the Design of Transportable Natural-Language Interfaces\", Artificial Intelligence. [Hobbs et al. 88] J. K. Hobbs, M. Stickel, P. Martin, and D. Edwards, \"Interpretation as Abduction\", Proceedings of the ACL, Buffalo, 7-10 June, 1988. [IIovy 88] E. H. Hovy, \"Generating Language with a Phrasal Lexicon\", in D. D. McDonald and L. Bole, eds., Natural Language Generation Systems, Springer-Verlag, 1988. [Jacobs 88a] P. S. Jacobs, \"Achieving Bidirectionality\", Proceedings of the lth International Conference on Computational Linguistics, Budapest, 22-27 August, 1988, pp. 267-269. [Jacobs 88b] P. S. Jacobs, \"PHRED: A Generator for Natural Language Interfaces\", in D. D. McDonald and L. Bole, eds., Natural Language Generation Systems, Springer-Verlag, 1988. [Lenat et al. 90] D. Lenat and R. Guha, f'Building Large Knowledge Based Systems, Representations and Inference in the CYC Project\", Addison Wesley, 1990. [McDonald et al. 88] D. D. McDonald and M. W. Meteer, \"From Water to Wine: Generating Natural Language Text from Today's Application Programs\", Second Conference on Applied Natural Language Processing, Austin, 9-12 February, 1988. [McKeown 82] K. R. McKeown, \"Generating Natural Language Text in Response to Questions About Database Structure\", University of Pennsylvania, Ph.D. Dissertation, 1982. [Nirenburg et al. 88] S. Nirenburg, R. MeCardell, E. Nyberg, P. Werner, S. Huffman, E. Kenschaft and I. Nirenburg, \"DIOGENES-88\", CMU Tech Report CMU-CMT-88-107, June 1988. [Nunberg 78] G. Nunberg, \"The Pragmatics of Refer-ence\", City College of New York, Ph.D. Disserta-tion, 1978. [Pustejovsky et al. 87] J. Pustejovsky and S. Nirenburg, \"Lexical Selection in the Process of Language Generation\", Proceedings of the A CL, Stanford, 6-9 July, 1987. [Shieber 88] S. M. Shieber, \"A Uniform Architecture for Parsing and Generation\", Proceedings of the 121h International Conference on Computational Linguistics, Budapest, 22-27 August, 1988, pp. 614-619. [Shieber et al. 89] S. M. Shieber, G. van Noord, R. C. Moore, and F. C. N. Pereira, \"A Semantic-fiend-Driven Generation Algorithm for Unification-Based Formalisms\", Proceedings of the AGL, Vancouver, 26-29 June, 1989. [Stallard 87] D. Stallard, \"The Logical Analysis of Lexteal Ambiguity\", Proceedings of the ACL, Stanford, 6-9 July, 1987. [Vaughan et al. 86] M. M. Vaughan and D. D. McDonald, \"A Model of Revision in Natural Language Generation\", Proceedings of the ACL, New York, 10-13 June, 1986. [Wilensky 88] R. Wilensky, D. N. Chin, M. Luria, J. Martin, J. Mayfield, and D. Wu, \"The Berkeley UNIX Consultant Project\", Computational Linguistics, Vol. 14, No. 4, December 1988. [Wittenburg 86] K. Wittenburg, \"A Parser for Portable NL Interfaces Using Graph-Unification-Based Grammars\", Proceedings of AAAI 86, 1986. 53","paragraphs":[]}]}
